{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('2.1. fraudTrain.xlsx')\n",
    "test = pd.read_excel('2.2. fraudTest.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # display all columns\n",
    "pd.set_option('display.max_rows', 150) # display all rows\n",
    "sns.set_style('whitegrid') # set the grid style\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "matplotlib.rcParams['figure.facecolor'] = '#00000000' # remove the background color\n",
    "plt.rcParams['xtick.color'] = 'white'  \n",
    "plt.rcParams['ytick.color'] = 'white'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_sample = train.sample(frac=0.1, random_state=42) # 10% sample of the data\n",
    "train_sample, train_val = train_test_split(train_sample, test_size=0.25, random_state=42) # 75% train, 25% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78643, 23), (26215, 23))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.shape, train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382661</th>\n",
       "      <td>382661</td>\n",
       "      <td>2019-06-24 15:38:17</td>\n",
       "      <td>30273037698427</td>\n",
       "      <td>fraud_Stiedemann Ltd</td>\n",
       "      <td>food_dining</td>\n",
       "      <td>1.92</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>06959 Stephen Branch Suite 246</td>\n",
       "      <td>Thida</td>\n",
       "      <td>AR</td>\n",
       "      <td>72165</td>\n",
       "      <td>35.5762</td>\n",
       "      <td>-91.4539</td>\n",
       "      <td>111</td>\n",
       "      <td>Careers information officer</td>\n",
       "      <td>2000-06-13</td>\n",
       "      <td>08a3a0e5bf710d0e866731514cda5c9f</td>\n",
       "      <td>1340552297</td>\n",
       "      <td>36.072938</td>\n",
       "      <td>-91.947932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505568</th>\n",
       "      <td>505568</td>\n",
       "      <td>2019-08-07 15:12:23</td>\n",
       "      <td>3513618443244540</td>\n",
       "      <td>fraud_Nienow PLC</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>73.25</td>\n",
       "      <td>Amber</td>\n",
       "      <td>Perez</td>\n",
       "      <td>F</td>\n",
       "      <td>954 Reyes Ways</td>\n",
       "      <td>Fulton</td>\n",
       "      <td>SD</td>\n",
       "      <td>57340</td>\n",
       "      <td>43.7588</td>\n",
       "      <td>-97.8712</td>\n",
       "      <td>355</td>\n",
       "      <td>Financial adviser</td>\n",
       "      <td>1955-06-26</td>\n",
       "      <td>26605441c6cc358a7759ea2ce03b7471</td>\n",
       "      <td>1344352343</td>\n",
       "      <td>43.583311</td>\n",
       "      <td>-98.733287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160698</th>\n",
       "      <td>160698</td>\n",
       "      <td>2019-03-26 02:34:14</td>\n",
       "      <td>4378993458389620</td>\n",
       "      <td>fraud_Koepp-Witting</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>118.45</td>\n",
       "      <td>Travis</td>\n",
       "      <td>Hayes</td>\n",
       "      <td>M</td>\n",
       "      <td>1561 Chase Grove</td>\n",
       "      <td>Conway</td>\n",
       "      <td>NH</td>\n",
       "      <td>3818</td>\n",
       "      <td>43.9742</td>\n",
       "      <td>-71.1503</td>\n",
       "      <td>3807</td>\n",
       "      <td>Surgeon</td>\n",
       "      <td>1999-10-25</td>\n",
       "      <td>111c0733e3b0f0166f0541a164c3f549</td>\n",
       "      <td>1332729254</td>\n",
       "      <td>44.132304</td>\n",
       "      <td>-70.585401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252453</th>\n",
       "      <td>252453</td>\n",
       "      <td>2019-05-05 23:54:36</td>\n",
       "      <td>5456776410929280</td>\n",
       "      <td>fraud_Kub-Heaney</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>36.48</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>Khan</td>\n",
       "      <td>F</td>\n",
       "      <td>658 Diane Glen Apt. 677</td>\n",
       "      <td>North Washington</td>\n",
       "      <td>PA</td>\n",
       "      <td>16048</td>\n",
       "      <td>41.0472</td>\n",
       "      <td>-79.8089</td>\n",
       "      <td>139</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1954-05-25</td>\n",
       "      <td>3640cc9f2c44e15055e04f51f6c01a2e</td>\n",
       "      <td>1336262076</td>\n",
       "      <td>40.765927</td>\n",
       "      <td>-80.265882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845278</th>\n",
       "      <td>845278</td>\n",
       "      <td>2019-12-14 18:17:27</td>\n",
       "      <td>3585740823295290</td>\n",
       "      <td>fraud_Bins-Howell</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>85.13</td>\n",
       "      <td>James</td>\n",
       "      <td>Greene</td>\n",
       "      <td>M</td>\n",
       "      <td>082 Hernandez Bypass Apt. 886</td>\n",
       "      <td>Quanah</td>\n",
       "      <td>TX</td>\n",
       "      <td>79252</td>\n",
       "      <td>34.2956</td>\n",
       "      <td>-99.7494</td>\n",
       "      <td>3202</td>\n",
       "      <td>Librarian, public</td>\n",
       "      <td>1998-03-18</td>\n",
       "      <td>15adf89741bfb2387e78053df2962a8f</td>\n",
       "      <td>1355509047</td>\n",
       "      <td>34.650810</td>\n",
       "      <td>-99.895160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "382661      382661   2019-06-24 15:38:17    30273037698427   \n",
       "505568      505568   2019-08-07 15:12:23  3513618443244540   \n",
       "160698      160698   2019-03-26 02:34:14  4378993458389620   \n",
       "252453      252453   2019-05-05 23:54:36  5456776410929280   \n",
       "845278      845278   2019-12-14 18:17:27  3585740823295290   \n",
       "\n",
       "                    merchant        category     amt   first       last  \\\n",
       "382661  fraud_Stiedemann Ltd     food_dining    1.92  Andrew  Patterson   \n",
       "505568      fraud_Nienow PLC   entertainment   73.25   Amber      Perez   \n",
       "160698   fraud_Koepp-Witting     grocery_pos  118.45  Travis      Hayes   \n",
       "252453      fraud_Kub-Heaney  health_fitness   36.48  Taylor       Khan   \n",
       "845278     fraud_Bins-Howell   personal_care   85.13   James     Greene   \n",
       "\n",
       "       gender                          street              city state    zip  \\\n",
       "382661      M  06959 Stephen Branch Suite 246             Thida    AR  72165   \n",
       "505568      F                  954 Reyes Ways            Fulton    SD  57340   \n",
       "160698      M                1561 Chase Grove            Conway    NH   3818   \n",
       "252453      F         658 Diane Glen Apt. 677  North Washington    PA  16048   \n",
       "845278      M   082 Hernandez Bypass Apt. 886            Quanah    TX  79252   \n",
       "\n",
       "            lat     long  city_pop                          job        dob  \\\n",
       "382661  35.5762 -91.4539       111  Careers information officer 2000-06-13   \n",
       "505568  43.7588 -97.8712       355            Financial adviser 1955-06-26   \n",
       "160698  43.9742 -71.1503      3807                      Surgeon 1999-10-25   \n",
       "252453  41.0472 -79.8089       139              Patent attorney 1954-05-25   \n",
       "845278  34.2956 -99.7494      3202            Librarian, public 1998-03-18   \n",
       "\n",
       "                               trans_num   unix_time  merch_lat  merch_long  \\\n",
       "382661  08a3a0e5bf710d0e866731514cda5c9f  1340552297  36.072938  -91.947932   \n",
       "505568  26605441c6cc358a7759ea2ce03b7471  1344352343  43.583311  -98.733287   \n",
       "160698  111c0733e3b0f0166f0541a164c3f549  1332729254  44.132304  -70.585401   \n",
       "252453  3640cc9f2c44e15055e04f51f6c01a2e  1336262076  40.765927  -80.265882   \n",
       "845278  15adf89741bfb2387e78053df2962a8f  1355509047  34.650810  -99.895160   \n",
       "\n",
       "        is_fraud  \n",
       "382661         0  \n",
       "505568         0  \n",
       "160698         0  \n",
       "252453         0  \n",
       "845278         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0               78643\n",
       "trans_date_trans_time    78533\n",
       "cc_num                     936\n",
       "merchant                   693\n",
       "category                    14\n",
       "amt                      19224\n",
       "first                      343\n",
       "last                       473\n",
       "gender                       2\n",
       "street                     936\n",
       "city                       856\n",
       "state                       51\n",
       "zip                        923\n",
       "lat                        921\n",
       "long                       922\n",
       "city_pop                   842\n",
       "job                        485\n",
       "dob                        922\n",
       "trans_num                78643\n",
       "unix_time                78533\n",
       "merch_lat                78485\n",
       "merch_long               78565\n",
       "is_fraud                     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "train_sample.drop(columns=['Unnamed: 0', 'trans_num', 'unix_time', 'merch_lat','merch_long','trans_date_trans_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['Unnamed: 0', 'trans_num', 'unix_time', 'merch_lat','merch_long','trans_date_trans_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.drop(columns=['Unnamed: 0', 'trans_num', 'unix_time', 'merch_lat','merch_long','trans_date_trans_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.drop(columns=['first','last'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['first','last'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.drop(columns=['first','last'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "train_sample['age'] = datetime.now().year - train_sample['dob'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['age'] = datetime.now().year - test['dob'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val['age'] = datetime.now().year - train_val['dob'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.drop(columns=['dob'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['dob'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.drop(columns=['dob'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cc_num        936\n",
       "merchant      693\n",
       "category       14\n",
       "amt         19224\n",
       "gender          2\n",
       "street        936\n",
       "city          856\n",
       "state          51\n",
       "zip           923\n",
       "lat           921\n",
       "long          922\n",
       "city_pop      842\n",
       "job           485\n",
       "is_fraud        2\n",
       "age            80\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "is_fraud=0<br>city_pop=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "0",
         "offsetgroup": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          111,
          355,
          3807,
          139,
          3202,
          2054,
          3279,
          1195,
          475,
          1196,
          470,
          5666,
          765,
          3224,
          16183,
          493806,
          2121,
          3395,
          1684,
          4056,
          471,
          33917,
          2470,
          17867,
          3862,
          1506,
          277,
          1847,
          137,
          1075,
          5657,
          301,
          1725,
          413574,
          194500,
          2471,
          1063,
          19685,
          4680,
          1656,
          817312,
          828,
          11256,
          1563,
          4653,
          1140,
          2376,
          1228,
          1274,
          223,
          2470,
          1443,
          1132,
          1080,
          757530,
          2368,
          215,
          346,
          504,
          91,
          969,
          1970,
          1577385,
          79008,
          71485,
          1563,
          94014,
          37,
          149,
          9784,
          1595797,
          532,
          5161,
          214518,
          21134,
          26120,
          139,
          104,
          3766,
          5648,
          5927,
          52126,
          99,
          4542,
          5621,
          4074,
          1019,
          1213,
          640470,
          1201,
          67082,
          798,
          895,
          3224,
          737,
          1791,
          639,
          123373,
          24645,
          76,
          84106,
          172817,
          530,
          836,
          928,
          467,
          477,
          11256,
          79008,
          123373,
          493,
          1126,
          1126,
          241,
          4138,
          2691,
          3495,
          276002,
          207,
          1577385,
          1274,
          2518,
          158701,
          237282,
          76,
          5760,
          77,
          540,
          2456,
          25459,
          5341,
          606,
          186140,
          31970,
          722,
          753116,
          1675,
          350,
          106,
          276896,
          5196,
          31394,
          35371,
          533,
          2523,
          964,
          1526206,
          970,
          191096,
          93193,
          12486,
          459921,
          18128,
          1420,
          270712,
          1684,
          1019,
          530,
          9496,
          23045,
          93193,
          1645,
          2456,
          606,
          6006,
          2906700,
          378909,
          633,
          31515,
          804,
          47249,
          1847,
          1063,
          1190,
          30770,
          1850,
          1925,
          1228,
          1606,
          3343,
          3684,
          832,
          4471,
          2518,
          1841,
          466,
          14742,
          4575,
          140,
          217,
          1512,
          18128,
          3684,
          139,
          104396,
          3833,
          3996,
          2408,
          1645,
          2916,
          4056,
          222785,
          7692,
          166081,
          2036,
          275,
          31394,
          645,
          922,
          5895,
          4542,
          136,
          381459,
          965,
          888,
          71485,
          1051,
          602,
          1228,
          190178,
          10076,
          6841,
          3833,
          79008,
          190,
          14075,
          19090,
          1228,
          128,
          5778,
          2395,
          823,
          641349,
          1201,
          93193,
          460,
          140,
          2906700,
          1679,
          2504700,
          695,
          4913,
          27020,
          136,
          2304,
          1461,
          1132,
          595,
          47249,
          11250,
          1131,
          3224,
          2471,
          1645,
          34882,
          4895,
          328,
          3343,
          1571,
          1288,
          163415,
          1186,
          1791,
          1970,
          35439,
          247,
          1312,
          3495,
          973849,
          1038,
          1263321,
          502,
          630,
          581,
          1979,
          1446,
          1196,
          6460,
          35371,
          241,
          217,
          1700,
          307,
          1970,
          158701,
          128354,
          475,
          4474,
          6713,
          639,
          1312,
          54185,
          149,
          137067,
          1140,
          695,
          6951,
          2395,
          365,
          4354,
          18128,
          5719,
          1312922,
          519,
          10717,
          1423,
          277,
          372,
          139,
          6841,
          22191,
          14228,
          972,
          922,
          1423,
          1762,
          123373,
          74,
          1213,
          1446,
          653,
          828,
          878,
          271,
          863,
          271,
          1102,
          302,
          17867,
          1478,
          224256,
          94014,
          372,
          11432,
          737,
          782,
          7565,
          911,
          673342,
          581,
          895,
          92985,
          341,
          2135,
          1201,
          1946,
          11256,
          269,
          18182,
          46,
          295,
          4081,
          122111,
          378909,
          5457,
          307,
          397,
          239,
          2971,
          6508,
          545147,
          215,
          255,
          49,
          2206,
          7565,
          4603,
          123,
          1804,
          269,
          87124,
          1725,
          9587,
          116001,
          9506,
          7646,
          4993,
          1966,
          413574,
          2290,
          1196,
          333497,
          30770,
          5989,
          1643,
          5895,
          899,
          626,
          1126,
          1766,
          5161,
          2504700,
          163415,
          11250,
          2368,
          1789,
          910148,
          1770,
          241,
          686,
          1745,
          9034,
          5621,
          2566,
          24536,
          328,
          137067,
          914,
          1988,
          31515,
          230,
          24536,
          271,
          4573,
          167,
          1166,
          7646,
          1970,
          888,
          224256,
          34882,
          1804,
          3228,
          25459,
          564,
          176,
          69,
          888,
          502,
          409656,
          75830,
          207410,
          4533,
          128,
          105549,
          95,
          258,
          3805,
          581,
          540,
          1523,
          1078,
          5621,
          571,
          28425,
          5875,
          269,
          135332,
          2856,
          1383,
          409656,
          276002,
          267,
          158701,
          87124,
          761,
          1725,
          2870,
          653,
          5927,
          1190,
          1847,
          8830,
          2644,
          25459,
          6713,
          1684,
          1850,
          55581,
          139,
          568,
          372,
          1943,
          76383,
          4729,
          5875,
          5989,
          6951,
          888,
          126,
          35371,
          3833,
          817312,
          71485,
          911,
          88735,
          4049,
          1892,
          14871,
          969,
          258,
          782,
          3224,
          8874,
          5791,
          198,
          1412,
          31515,
          2148,
          626,
          710,
          1645,
          3224,
          722,
          467,
          51,
          885,
          124967,
          1472,
          1302,
          87124,
          3032,
          9496,
          2691,
          137,
          190178,
          2518,
          601723,
          564,
          1970,
          224256,
          23,
          1700,
          5927,
          18408,
          186140,
          1306,
          409656,
          295,
          4542,
          5848,
          718,
          5908,
          1241364,
          1186,
          6508,
          186140,
          478,
          836,
          647,
          3224,
          190178,
          5512,
          43,
          2435,
          267,
          12349,
          5341,
          153,
          324,
          167,
          5211,
          18408,
          5895,
          291,
          267,
          21902,
          4090,
          1526206,
          5666,
          1241364,
          798,
          427,
          1523,
          626,
          5726,
          2566,
          42384,
          5927,
          2121,
          1766,
          589,
          1446,
          1789,
          504,
          19685,
          34496,
          1190,
          7163,
          1749,
          71485,
          1190,
          321490,
          77,
          26120,
          1565,
          94325,
          4056,
          198,
          969,
          640470,
          7565,
          606,
          1263321,
          5950,
          1766,
          6006,
          817312,
          8333,
          68211,
          759,
          14871,
          571,
          34496,
          2457,
          5621,
          639,
          71463,
          11250,
          137067,
          1196,
          128354,
          3730,
          470,
          3104,
          3395,
          1126,
          914,
          1858,
          54185,
          910148,
          3289,
          237282,
          17867,
          163415,
          218,
          2872,
          233717,
          6508,
          270712,
          2443,
          11253,
          3996,
          149,
          1312922,
          328,
          645,
          695,
          1178,
          178,
          140,
          2836,
          653,
          104,
          17047,
          878,
          1749,
          5848,
          811,
          165,
          7268,
          647,
          239,
          27020,
          6581,
          34153,
          1847,
          19408,
          19090,
          832,
          94325,
          471,
          10076,
          1595797,
          341043,
          782,
          970,
          1352,
          5354,
          75830,
          13422,
          2443,
          1271,
          1923,
          450,
          3833,
          1472,
          5507,
          302,
          1858,
          5875,
          606,
          2376,
          1089,
          248,
          9594,
          782,
          237282,
          498,
          3096,
          1201,
          376,
          5619,
          137067,
          760,
          4056,
          800,
          168,
          69,
          217,
          16183,
          391389,
          450,
          217,
          9784,
          1526206,
          99,
          7155,
          1261,
          4533,
          344,
          5989,
          3289,
          84106,
          6713,
          5621,
          17867,
          35439,
          2691,
          84861,
          673342,
          116001,
          31515,
          192805,
          34496,
          192,
          3766,
          2607,
          5211,
          21134,
          77,
          732,
          717255,
          14228,
          3699,
          648,
          470,
          743,
          970,
          24536,
          927396,
          5577,
          198,
          32891,
          4159,
          1923,
          191096,
          1892,
          14871,
          271,
          828,
          733,
          1766,
          37,
          828,
          9587,
          3451,
          233717,
          2401,
          2644,
          1700,
          647,
          1051,
          1186,
          4508,
          96942,
          237282,
          9772,
          765,
          1533,
          1617,
          84861,
          1261,
          513,
          2223,
          190178,
          343,
          757530,
          59744,
          1453,
          5848,
          718,
          75903,
          248,
          828,
          24645,
          5211,
          4533,
          1426,
          238602,
          5621,
          172817,
          2870,
          381459,
          320420,
          206,
          804,
          733,
          165556,
          50489,
          864,
          3487,
          76,
          112,
          13422,
          1770,
          5666,
          673342,
          1120,
          165,
          645,
          343,
          493806,
          7268,
          42817,
          254,
          2872,
          914,
          1507,
          172817,
          149,
          642,
          128715,
          95035,
          1595797,
          2872,
          509,
          23727,
          7268,
          1758,
          68211,
          192,
          1526206,
          4533,
          1770,
          16163,
          10256,
          74,
          34882,
          35439,
          51,
          15426,
          46,
          79008,
          18408,
          725,
          21902,
          158701,
          2395,
          3805,
          1563,
          8874,
          1306,
          263,
          320420,
          7268,
          34496,
          350,
          2906700,
          198,
          163415,
          1507,
          139650,
          242,
          5161,
          1666,
          1201,
          42817,
          163415,
          5760,
          372,
          13973,
          470,
          7268,
          11256,
          16183,
          1791,
          215,
          663,
          397,
          1312922,
          1847,
          475,
          1228,
          647,
          1089,
          606,
          269,
          4049,
          540,
          165556,
          2523,
          9815,
          5908,
          4081,
          1850,
          4913,
          1532,
          1143,
          1617,
          804,
          2383912,
          1789,
          1909,
          3263,
          376,
          1051,
          2856,
          224256,
          9496,
          307,
          237282,
          389246,
          2471,
          478,
          172817,
          3996,
          88735,
          2471,
          2379,
          1446,
          4878,
          478,
          71485,
          104396,
          725,
          156391,
          13973,
          2135,
          54185,
          217,
          92337,
          1512,
          10295,
          6460,
          308,
          71335,
          21134,
          1745,
          71463,
          123373,
          5901,
          34153,
          1075,
          267,
          937,
          18128,
          1493,
          5512,
          1075,
          5438,
          1140,
          3223,
          1480,
          2304,
          167,
          74,
          4575,
          4680,
          123,
          71463,
          11432,
          1789,
          3343,
          116001,
          178,
          23045,
          27829,
          137,
          139,
          1684,
          1504,
          1063,
          158701,
          128715,
          4726,
          530,
          105549,
          8830,
          1689,
          192805,
          1892,
          190178,
          6469,
          341,
          184,
          128715,
          1363,
          533,
          5908,
          277,
          34496,
          71463,
          1841,
          1190,
          18182,
          1274,
          7155,
          18408,
          631,
          493806,
          324,
          1312922,
          34882,
          513,
          2471,
          21134,
          7987,
          5619,
          6284,
          1443,
          4573,
          346,
          1507,
          1263321,
          2408,
          2856,
          1577385,
          55581,
          46,
          2148,
          21134,
          686,
          341,
          99,
          3104,
          2906700,
          1302,
          1493,
          1526206,
          2376,
          207,
          1595797,
          2376,
          733,
          165556,
          4367,
          105549,
          2368,
          1302,
          969,
          765,
          1689,
          346,
          2317,
          970,
          798,
          732,
          493806,
          123373,
          467,
          169,
          15647,
          14871,
          11432,
          346,
          178,
          1382480,
          49,
          8874,
          579,
          172817,
          191096,
          14783,
          3508,
          642,
          520,
          895,
          1565,
          1841,
          2644,
          8269,
          581,
          9594,
          4090,
          1022298,
          2060,
          2443,
          2206,
          1923,
          239,
          413574,
          1565,
          471,
          5507,
          1383,
          1847,
          104,
          595,
          118,
          5457,
          198,
          3805,
          237282,
          413574,
          6508,
          2092,
          1140,
          1526206,
          841711,
          184,
          1312,
          630,
          28739,
          606,
          32891,
          1643,
          3776,
          9034,
          333497,
          34496,
          1423,
          213,
          10256,
          718,
          378909,
          217,
          3096,
          372,
          2054,
          341043,
          4056,
          11250,
          1577385,
          95035,
          3833,
          2368,
          74,
          969,
          710,
          4005,
          4074,
          237282,
          1643,
          7268,
          190178,
          2258,
          4138,
          7268,
          757530,
          1126,
          2121,
          206,
          46563,
          1241364,
          1512,
          38912,
          136,
          10256,
          5950,
          1858,
          55581,
          466,
          27971,
          13422,
          1563,
          2518,
          4993,
          5457,
          1684,
          2526,
          18408,
          34882,
          2906700,
          313,
          276002,
          864,
          530,
          757530,
          2036,
          10256,
          479994,
          1654,
          165,
          602,
          4424,
          2807,
          1725,
          922,
          110,
          632,
          864,
          478,
          50835,
          1363,
          589,
          321,
          1810,
          21125,
          14871,
          84861,
          51427,
          5438,
          1022298,
          590,
          1423,
          272134,
          1892,
          20478,
          350,
          5196,
          50489,
          237282,
          302,
          302,
          647,
          1102,
          8097,
          606,
          427,
          606,
          118,
          320,
          248858,
          59744,
          519,
          391389,
          1791,
          1810,
          27971,
          2916,
          12335,
          771,
          206,
          254,
          828,
          3684,
          5662,
          1526206,
          1228,
          149,
          3805,
          1577385,
          26120,
          4512,
          3289,
          27971,
          757530,
          190249,
          14742,
          3096,
          4138,
          61,
          50835,
          69,
          75830,
          1507,
          238602,
          302,
          3833,
          1654,
          1523,
          9679,
          1089,
          391389,
          5989,
          1201,
          270712,
          530,
          2435,
          6006,
          286,
          18408,
          376,
          911,
          23,
          276,
          841711,
          19685,
          1019,
          614,
          1807,
          895,
          1190,
          1228,
          9679,
          4533,
          331,
          46,
          106,
          4074,
          137067,
          470,
          2142,
          4306,
          1453,
          1442,
          589,
          805,
          5512,
          601723,
          302,
          370,
          4573,
          378909,
          176,
          922,
          13602,
          46944,
          798,
          6581,
          3343,
          337,
          321,
          1930,
          647,
          105549,
          1583,
          4074,
          1631,
          5903,
          6469,
          804,
          471,
          135332,
          647,
          937,
          346,
          263,
          1970,
          4677,
          26120,
          663,
          564,
          302,
          1892,
          1078,
          21125,
          165,
          20328,
          128354,
          4198,
          3202,
          6713,
          1654,
          17867,
          16163,
          186140,
          230,
          640470,
          5875,
          641,
          349,
          186140,
          45303,
          222785,
          633,
          927396,
          1306,
          7155,
          478,
          1606,
          310,
          632,
          1523,
          757530,
          163415,
          5666,
          8269,
          530,
          828,
          1850,
          85,
          190,
          4542,
          630,
          509,
          190178,
          540,
          370,
          804,
          217,
          23727,
          247,
          238602,
          355,
          3343,
          2401,
          526,
          95015,
          530,
          1943,
          276,
          841711,
          1334,
          1195,
          136,
          732,
          78968,
          633,
          1675,
          177,
          139,
          343,
          1102,
          502,
          222785,
          1988,
          1165,
          116001,
          2607,
          1241364,
          4575,
          9587,
          1102,
          4081,
          5989,
          46,
          645,
          1420,
          3766,
          46563,
          165,
          4575,
          270712,
          308,
          172247,
          186140,
          129,
          545147,
          302,
          911,
          2097,
          2408,
          3996,
          34153,
          136,
          3451,
          69793,
          13835,
          5989,
          973849,
          14742,
          1970,
          878,
          2470,
          105549,
          1645,
          1423,
          1165,
          601723,
          242,
          169,
          320420,
          932,
          1930,
          32891,
          2523,
          9772,
          260,
          75830,
          626,
          19685,
          2691,
          1988,
          2807,
          736284,
          1241364,
          3202,
          31394,
          680,
          1302,
          2661,
          95,
          1453,
          20328,
          1533,
          477,
          48194,
          118,
          1179,
          18408,
          1745,
          640470,
          116001,
          1532,
          46563,
          1412,
          1979,
          337,
          2526,
          4090,
          381459,
          13422,
          6025,
          1807,
          255,
          21134,
          765,
          817312,
          2870,
          471,
          272,
          15269,
          1382480,
          647,
          1490,
          1686,
          545147,
          743,
          184,
          176,
          413574,
          602,
          238602,
          1196,
          1858,
          269,
          1324,
          136,
          3224,
          2906700,
          2456,
          238602,
          1126,
          104,
          276,
          267,
          32891,
          198,
          1426,
          2258,
          498,
          3684,
          12335,
          276002,
          8007,
          105638,
          3395,
          32891,
          84861,
          381459,
          19408,
          75830,
          136,
          26551,
          640470,
          765,
          5950,
          798,
          863,
          743,
          8097,
          5908,
          18408,
          222,
          9034,
          13973,
          128,
          9034,
          673342,
          3451,
          1514,
          230,
          3224,
          3807,
          1504,
          370,
          32891,
          10076,
          743,
          78968,
          86954,
          647,
          2870,
          6469,
          2078,
          71335,
          564,
          4090,
          308,
          4074,
          1675,
          186140,
          61,
          1766,
          75903,
          749635,
          1334,
          31515,
          71485,
          260,
          3684,
          186140,
          333497,
          7646,
          214703,
          595,
          166081,
          3495,
          653,
          18459,
          85,
          1526206,
          2307,
          1126,
          6460,
          749635,
          3224,
          198,
          3996,
          922,
          878,
          341043,
          6581,
          3066,
          267,
          324,
          27829,
          2148,
          355,
          163415,
          190,
          43102,
          477,
          3223,
          910148,
          4471,
          1745,
          2661,
          1970,
          798,
          158701,
          53,
          1360,
          466,
          927396,
          1146,
          1892,
          743,
          3119,
          21125,
          647,
          13983,
          1412,
          1606,
          3032,
          34882,
          972,
          467,
          680,
          237282,
          91,
          1847,
          545147,
          7565,
          1506,
          19408,
          743,
          2317,
          255,
          4172,
          163415,
          192,
          4512,
          3688,
          1446,
          1363,
          489,
          1506,
          5211,
          328,
          1858,
          753116,
          2401,
          47,
          328,
          35299,
          7155,
          686,
          823,
          178,
          6006,
          248858,
          1228,
          20328,
          1089,
          466,
          3684,
          545147,
          111,
          1241364,
          76383,
          640470,
          23,
          23045,
          1595797,
          163415,
          5895,
          50835,
          520,
          804,
          75830,
          277,
          663,
          489,
          5438,
          467,
          17867,
          1102,
          104,
          346,
          24840,
          27971,
          2304,
          123,
          1213,
          207410,
          1725,
          18128,
          2376,
          237282,
          92106,
          9815,
          9512,
          7646,
          1925,
          1565,
          498,
          51,
          427,
          2208,
          571,
          1523,
          2135,
          348,
          1201,
          863,
          46,
          888,
          2566,
          15647,
          1745,
          7155,
          722,
          2401,
          139,
          69793,
          198,
          2456,
          1925,
          1241364,
          917,
          795,
          61,
          1022298,
          46944,
          2206,
          2263,
          4424,
          198,
          3876,
          910148,
          630,
          267,
          34496,
          1288,
          540,
          21125,
          509,
          736284,
          3807,
          73,
          4533,
          910148,
          606,
          3487,
          105549,
          2799,
          1526206,
          15647,
          1583,
          46563,
          46563,
          2258,
          31515,
          533,
          4664,
          3395,
          1271,
          270712,
          1165,
          2408,
          59744,
          2872,
          595,
          140,
          1577385,
          10076,
          566,
          3202,
          11751,
          3263,
          741,
          310,
          427,
          17047,
          4367,
          190,
          878,
          564,
          1577385,
          3458,
          341043,
          3224,
          3066,
          16183,
          269,
          5648,
          381459,
          178,
          241,
          184,
          5791,
          5666,
          566,
          5161,
          1565,
          31394,
          1897,
          4575,
          176,
          427,
          71335,
          59705,
          331,
          3833,
          3285,
          27971,
          6006,
          33917,
          1791,
          258,
          2121,
          165,
          1595797,
          1490,
          277,
          1423,
          525713,
          1126,
          1526206,
          18128,
          33917,
          346,
          341043,
          1334,
          8333,
          4172,
          2158,
          1847,
          308,
          241,
          5438,
          165556,
          602,
          3996,
          2290,
          302,
          172817,
          50835,
          1051,
          21902,
          743,
          14742,
          2906700,
          46,
          5548,
          15426,
          76383,
          6120,
          9594,
          1617,
          1563,
          92337,
          51,
          45303,
          186140,
          741,
          1022298,
          776,
          1190,
          1166,
          4367,
          1766,
          409656,
          2383912,
          21902,
          10295,
          23727,
          1565,
          5875,
          144160,
          258,
          1939,
          1139,
          530,
          355,
          6469,
          4090,
          5903,
          631,
          1334,
          2317,
          5161,
          4090,
          4542,
          477,
          1745,
          270712,
          1132,
          1312,
          8097,
          47249,
          450,
          805,
          824,
          1132,
          1078,
          1368,
          6508,
          864,
          1684,
          128,
          27971,
          824,
          741,
          5666,
          134056,
          1970,
          33917,
          1810,
          93193,
          46,
          31394,
          35705,
          632,
          12486,
          2258,
          10295,
          5875,
          21437,
          6469,
          1577385,
          6713,
          888,
          2456,
          1645,
          34496,
          828,
          134056,
          1420,
          378909,
          4056,
          47772,
          137,
          190178,
          46563,
          2456,
          86954,
          2408,
          255,
          1804,
          55581,
          3255,
          3289,
          276002,
          50489,
          878,
          2872,
          824,
          124967,
          1063,
          136,
          470,
          34153,
          1453,
          165556,
          13422,
          1075,
          4074,
          19054,
          6951,
          1201,
          27971,
          133,
          9594,
          489,
          973849,
          277,
          260,
          6841,
          128,
          471,
          3684,
          8830,
          2368,
          725,
          743,
          5662,
          1506,
          828,
          1480,
          1606,
          759,
          6713,
          1810,
          17867,
          276896,
          21134,
          92985,
          4573,
          1923,
          626,
          308,
          1078,
          153,
          217,
          254282,
          1679,
          23805,
          3402,
          391389,
          23,
          172817,
          760,
          1892,
          4720,
          1666,
          3451,
          606,
          276896,
          11432,
          47772,
          477,
          128354,
          626,
          1656,
          151785,
          241,
          1789,
          118,
          976,
          782,
          1504,
          581,
          3224,
          165,
          836,
          673342,
          4664,
          7420,
          165,
          836,
          530,
          14228,
          973849,
          1131,
          6469,
          206,
          191096,
          328,
          5666,
          1228,
          1850,
          6469,
          753116,
          313,
          50835,
          6120,
          92043,
          6460,
          1075,
          321,
          4367,
          3876,
          1166,
          478,
          28425,
          888,
          85,
          2872,
          1656,
          4603,
          12335,
          298,
          198,
          765,
          832,
          1735,
          2691,
          2566,
          276896,
          2435,
          295,
          21125,
          237282,
          733,
          828,
          165,
          1201,
          50489,
          1988,
          32891,
          5927,
          267,
          233717,
          128,
          1565,
          478,
          4074,
          9512,
          158701,
          184,
          172817,
          630,
          136,
          5621,
          4726,
          1363,
          316665,
          71463,
          5908,
          30770,
          137,
          190178,
          4895,
          2223,
          471,
          7163,
          1312922,
          10295,
          346,
          2379,
          1423,
          5901,
          190178,
          7268,
          217,
          2307,
          1087,
          1574,
          471,
          184,
          631,
          4664,
          922,
          3202,
          53,
          23727,
          20328,
          1595797,
          878,
          2401,
          5989,
          1577385,
          1925,
          4424,
          641349,
          67082,
          2135,
          836,
          378909,
          267,
          1563,
          1293,
          20328,
          95035,
          5621,
          3862,
          92337,
          4474,
          759,
          19685,
          271,
          532,
          475,
          4090,
          1146,
          5648,
          4471,
          518429,
          1324,
          2368,
          680,
          324,
          1643,
          2906700,
          4542,
          1909,
          836,
          2872,
          139650,
          1241364,
          8830,
          1126,
          35439,
          2395,
          4677,
          17867,
          2097,
          149,
          5354,
          4542,
          1523,
          1946,
          571,
          725,
          5354,
          69,
          7297,
          27020,
          105638,
          1595797,
          540,
          1293,
          34153,
          489,
          3202,
          6951,
          824,
          76,
          1274,
          1512,
          43,
          1186,
          18408,
          272,
          95,
          372,
          1512,
          192805,
          7646,
          11256,
          99,
          1512,
          372,
          46,
          42384,
          186140,
          95015,
          1186,
          725,
          6120,
          1925,
          530,
          888,
          27971,
          46,
          302,
          7268,
          3688,
          34882,
          222,
          302,
          124967,
          25459,
          513,
          54287,
          391389,
          520,
          47772,
          1363,
          198,
          1789,
          247,
          1523,
          118,
          30770,
          2504700,
          3343,
          1645,
          4680,
          5657,
          348,
          11256,
          192805,
          1274,
          13717,
          158701,
          895,
          1504,
          1143,
          647,
          1523,
          489,
          12335,
          3202,
          1453,
          1847,
          471,
          526,
          1075,
          1263321,
          4913,
          8874,
          184,
          4508,
          276002,
          6951,
          4015,
          69793,
          1745,
          828,
          123,
          11253,
          479994,
          67082,
          1241364,
          135332,
          1643,
          1312,
          276002,
          828,
          1595797,
          1766,
          77,
          271,
          1643,
          134056,
          1789,
          454,
          158701,
          1643,
          378909,
          1302,
          50835,
          238602,
          15647,
          759,
          1970,
          140,
          20478,
          6469,
          47211,
          328,
          124967,
          3688,
          3289,
          190178,
          489,
          156391,
          48194,
          92985,
          2206,
          15269,
          2121,
          1472,
          642,
          47772,
          1019,
          1360,
          85,
          350,
          635,
          1019,
          69793,
          118,
          12335,
          165,
          6120,
          272134,
          2121,
          12486,
          631,
          302,
          5211,
          19408,
          2607,
          470,
          1312922,
          217,
          1312,
          2408,
          1261,
          198,
          1512,
          76,
          9587,
          30770,
          1178,
          1645,
          817312,
          12335,
          23,
          532,
          23045,
          520,
          17867,
          136,
          741,
          128354,
          1312922,
          217,
          4074,
          1791,
          1312922,
          1252,
          888,
          2135,
          1923,
          355,
          8830,
          464,
          4913,
          7155,
          48194,
          695,
          6018,
          68211,
          18128,
          158701,
          1383,
          3807,
          14742,
          4573,
          46563,
          54767,
          241,
          922,
          45100,
          128354,
          10076,
          722,
          475,
          8097,
          467,
          565,
          2501,
          276,
          13422,
          50835,
          136,
          1831,
          717255,
          832,
          722,
          186140,
          24536,
          6951,
          54185,
          54185,
          85,
          16183,
          409656,
          2566,
          630,
          6629,
          381459,
          107941,
          192805,
          71485,
          237282,
          6460,
          2395,
          92985,
          910148,
          1178,
          376,
          76,
          413574,
          2471,
          308,
          77,
          3402,
          52126,
          4056,
          1810,
          1196,
          811,
          1943,
          186140,
          85,
          1909,
          2135,
          673342,
          5196,
          1645,
          69,
          633,
          1523,
          1102,
          43102,
          1490,
          13973,
          7268,
          647,
          3996,
          732,
          19054,
          286,
          43,
          504,
          32891,
          1810,
          5778,
          964,
          4090,
          12486,
          2135,
          4508,
          213,
          828,
          213,
          46563,
          3730,
          1324,
          348,
          302,
          817312,
          1324,
          186140,
          222,
          24536,
          24536,
          153,
          5196,
          47,
          1131,
          518429,
          5577,
          885,
          5760,
          736284,
          717255,
          258,
          1725,
          2135,
          79008,
          1352,
          276,
          27971,
          7565,
          1643,
          443,
          3805,
          3805,
          3805,
          3430,
          1654,
          885,
          254,
          5662,
          1617,
          18408,
          122111,
          6006,
          1271,
          84106,
          3224,
          269,
          972,
          8097,
          823,
          5161,
          565,
          214703,
          3104,
          13422,
          6469,
          321490,
          198,
          328,
          34882,
          128,
          710,
          276002,
          1241364,
          1970,
          1493,
          11250,
          50835,
          2263,
          836,
          34882,
          95035,
          163415,
          214703,
          1201,
          409656,
          3805,
          276002,
          277,
          478,
          2916,
          737,
          71463,
          4090,
          123,
          248858,
          545147,
          976,
          2691,
          5548,
          54287,
          18128,
          242,
          470,
          1645,
          7155,
          397,
          190249,
          2471,
          673342,
          96942,
          28739,
          376,
          27971,
          10717,
          13602,
          3766,
          1412,
          1847,
          21125,
          18182,
          194500,
          260,
          964,
          76383,
          5507,
          741,
          1684,
          237282,
          2906700,
          355,
          349,
          79613,
          83,
          2607,
          137067,
          823,
          20328,
          5848,
          84861,
          35439,
          224256,
          1382480,
          1689,
          247,
          151785,
          2054,
          214518,
          2971,
          1700,
          4090,
          272,
          136,
          6469,
          46,
          1078,
          36784,
          1654,
          581,
          31515,
          92985,
          1571,
          1645,
          24840,
          4049,
          13973,
          267,
          653,
          6581,
          341,
          3279,
          241,
          6469,
          84861,
          104,
          23727,
          2471,
          1102,
          2836,
          477,
          1577385,
          23805,
          106,
          1075,
          241,
          5577,
          1725,
          69,
          663,
          224256,
          1656,
          1263321,
          136895,
          3279,
          9772,
          21902,
          19090,
          759,
          1749,
          267,
          1132,
          1804,
          1383,
          647,
          308,
          105638,
          213,
          9772,
          86954,
          35371,
          2501,
          10717,
          1196,
          653,
          498,
          47,
          355,
          1526206,
          6469,
          861,
          198,
          270712,
          106,
          50835,
          3996,
          16305,
          3766,
          743,
          104396,
          23,
          16305,
          99,
          1970,
          626,
          1089,
          337,
          1100,
          502,
          489,
          5791,
          60,
          136,
          1725,
          3862,
          4653,
          478,
          213,
          1970,
          6469,
          4573,
          143,
          6120,
          7155,
          31515,
          1810,
          5875,
          140,
          20478,
          328,
          63,
          23,
          61,
          519,
          4172,
          1139,
          765,
          1202,
          804,
          817312,
          93193,
          4474,
          9496,
          717255,
          3495,
          3805,
          2408,
          2906700,
          241,
          1288,
          1810,
          1196,
          836,
          46563,
          328,
          2443,
          276002,
          76383,
          21134,
          163415,
          93193,
          123373,
          1690,
          3699,
          92608,
          14871,
          2078,
          2501,
          31515,
          1979,
          922,
          276,
          518429,
          207410,
          144160,
          878,
          190178,
          1195,
          5341,
          91,
          27971,
          14783,
          76,
          192805,
          372,
          1909,
          46563,
          2263,
          19090,
          2223,
          502,
          71463,
          2060,
          47249,
          186140,
          9815,
          782,
          1312922,
          207410,
          5548,
          2471,
          3096,
          641,
          6469,
          6025,
          2383912,
          635,
          1645,
          937,
          34496,
          532,
          3279,
          3807,
          1661,
          717255,
          1360,
          2395,
          53,
          192,
          3202,
          1196,
          77,
          4074,
          760,
          885,
          4508,
          54767,
          1523,
          642,
          54287,
          328,
          895,
          79008,
          1186,
          475,
          223,
          272134,
          832,
          4575,
          1810,
          965,
          302,
          1383,
          1140,
          1383,
          1382480,
          2148,
          271,
          832,
          2523,
          632,
          686,
          1195,
          87124,
          1228,
          5341,
          5989,
          6508,
          192,
          42384,
          333497,
          606,
          6434,
          151022,
          10717,
          3996,
          1847,
          4354,
          4575,
          7268,
          32891,
          321,
          1725,
          168,
          116001,
          1126,
          1414,
          186140,
          1126,
          1089,
          7565,
          8333,
          7268,
          11751,
          3684,
          5341,
          1075,
          151022,
          381459,
          14783,
          6120,
          2135,
          190178,
          4005,
          149,
          1988,
          1442,
          3395,
          69,
          1504,
          4508,
          2290,
          369,
          1760,
          2518,
          9521,
          55581,
          2401,
          6120,
          26120,
          4878,
          2135,
          5666,
          1643,
          2092,
          571,
          11256,
          59744,
          545147,
          10076,
          470,
          21902,
          2661,
          571,
          3202,
          320,
          632,
          642,
          247,
          16183,
          1368,
          6841,
          1577385,
          4090,
          1383,
          922,
          2872,
          5161,
          5512,
          741,
          1841,
          349,
          771,
          2691,
          2501,
          1745,
          28278,
          2906700,
          9521,
          15426,
          206,
          1749,
          1263321,
          1423,
          1166,
          71335,
          863,
          551,
          24536,
          165556,
          1453,
          128715,
          34882,
          140,
          6006,
          13422,
          1766,
          530,
          229,
          4138,
          3688,
          270712,
          4653,
          301,
          85,
          2661,
          1274,
          2691,
          23045,
          581,
          749635,
          313,
          4424,
          3805,
          695,
          313,
          1274,
          2092,
          27020,
          1075,
          759,
          337,
          176,
          413574,
          391389,
          67082,
          48194,
          419,
          111,
          836,
          348,
          502,
          2872,
          2206,
          2317,
          680,
          248,
          16183,
          299480,
          1383,
          233717,
          344,
          3119,
          1897,
          35371,
          198,
          6018,
          633,
          3255,
          4895,
          271,
          10256,
          43,
          5927,
          21902,
          2078,
          2307,
          1666,
          2518,
          158701,
          804,
          59744,
          910148,
          641,
          795,
          932,
          43102,
          878,
          743,
          25459,
          4015,
          478,
          1504,
          165556,
          129,
          1571,
          673342,
          4474,
          346,
          20478,
          1656,
          1577385,
          836,
          48194,
          718,
          743,
          2304,
          5875,
          165556,
          1684,
          139,
          49,
          601723,
          2208,
          7268,
          1943,
          922,
          1645,
          4575,
          8512,
          1274,
          6581,
          695,
          754,
          139650,
          37,
          145,
          242,
          7268,
          4993,
          376,
          139650,
          795,
          14871,
          118,
          27971,
          673342,
          1352,
          310,
          642,
          1725,
          5161,
          795,
          489,
          60,
          11256,
          1078,
          761,
          1190,
          1146,
          2303,
          601723,
          3876,
          1690,
          1841,
          260,
          163415,
          2526,
          75830,
          722,
          17867,
          17047,
          1146,
          5875,
          69793,
          34882,
          718,
          46563,
          6951,
          973849,
          606,
          9496,
          128354,
          1443,
          737,
          153,
          1565,
          4049,
          641349,
          53,
          222785,
          1126,
          21134,
          47772,
          5211,
          6581,
          3833,
          4056,
          355,
          9815,
          419,
          100,
          19408,
          149,
          269,
          409656,
          105638,
          1766,
          207,
          85,
          276002,
          111,
          144160,
          3032,
          71335,
          493,
          4090,
          1725,
          932,
          111,
          1190,
          1089,
          6951,
          13973,
          1684,
          213,
          1804,
          3104,
          1414,
          1841,
          1507,
          151022,
          632,
          269,
          513,
          299480,
          3688,
          695,
          370,
          341,
          2379,
          584,
          6469,
          466,
          798,
          30770,
          551,
          1850,
          50489,
          2089,
          1063,
          914,
          1302,
          349,
          118,
          24840,
          885,
          1507,
          970,
          105638,
          71485,
          94014,
          105638,
          34496,
          217,
          20478,
          2263,
          369,
          566,
          247,
          1383,
          55581,
          4653,
          463,
          222785,
          338,
          2856,
          302,
          186140,
          4198,
          151815,
          2644,
          5354,
          1897,
          823,
          372,
          1831,
          1810,
          112,
          2092,
          1577385,
          1841,
          61,
          471,
          4878,
          92043,
          4512,
          1312,
          128715,
          87124,
          626,
          8512,
          2376,
          687276,
          13835,
          218,
          733,
          237282,
          4726,
          269,
          55345,
          6469,
          177,
          20478,
          22305,
          9815,
          888,
          2036,
          805,
          217,
          5438,
          5216,
          4653,
          1504,
          12335,
          370,
          2443,
          11751,
          1666,
          2872,
          744,
          10076,
          1925,
          23045,
          800,
          276,
          885,
          258,
          741,
          5341,
          258,
          2206,
          2526,
          186140,
          911,
          3032,
          308,
          757530,
          15647,
          136,
          370,
          743,
          823,
          134056,
          166081,
          142,
          9815,
          828,
          1063,
          5895,
          1909,
          6469,
          134056,
          532,
          88735,
          878,
          18459,
          277,
          67858,
          653,
          589,
          1666,
          13973,
          1970,
          355,
          77,
          169,
          2457,
          54767,
          606,
          760,
          3876,
          1493,
          53,
          1178,
          1847,
          1631,
          732,
          87124,
          276896,
          1228,
          15269,
          519,
          765,
          502,
          504,
          4680,
          504,
          6508,
          2317,
          92608,
          1478,
          3805,
          9587,
          60,
          91,
          75830,
          1970,
          1970,
          71485,
          2607,
          2644,
          4913,
          178,
          10295,
          28425,
          341,
          863,
          92608,
          1766,
          149,
          413574,
          3495,
          4575,
          10256,
          5161,
          885,
          6284,
          467,
          19054,
          15426,
          59744,
          2870,
          105549,
          1412,
          471,
          1472,
          1789,
          14742,
          1617,
          489,
          601723,
          413574,
          8830,
          471,
          186140,
          207410,
          3699,
          5621,
          43,
          928,
          1051,
          579,
          2258,
          1645,
          13835,
          2501,
          471,
          321,
          1970,
          1523,
          899,
          718,
          1228,
          337,
          1022298,
          680,
          760,
          1679,
          1363,
          466,
          272134,
          2036,
          653,
          645,
          4049,
          1120,
          1909,
          3104,
          532,
          178,
          31970,
          4474,
          17867,
          1595797,
          19090,
          338,
          9034,
          372,
          568,
          6120,
          22930,
          16163,
          885,
          757530,
          145,
          270712,
          50835,
          13422,
          37,
          19054,
          1478,
          3684,
          2304,
          391389,
          151022,
          1078,
          1810,
          1506,
          757530,
          4677,
          84106,
          2786,
          2368,
          3688,
          116155,
          12335,
          1442,
          116001,
          4542,
          75830,
          3224,
          337,
          123373,
          606,
          48194,
          568,
          107941,
          254282,
          2607,
          7646,
          54185,
          105549,
          6508,
          910148,
          9506,
          33804,
          1078,
          5666,
          1075,
          2607,
          79613,
          237282,
          1414,
          1089,
          6120,
          346,
          1606,
          28739,
          24645,
          116001,
          1228,
          602,
          9506,
          1563,
          1645,
          475,
          124967,
          18760,
          13422,
          817312,
          99,
          1261,
          5903,
          229,
          337,
          10256,
          233717,
          206,
          718,
          14228,
          2607,
          630,
          4653,
          13717,
          1423,
          471,
          7155,
          5903,
          1051,
          230,
          973849,
          8830,
          21125,
          2304,
          111,
          1132,
          1526206,
          632,
          2290,
          3119,
          11751,
          5619,
          59744,
          4729,
          1022298,
          16305,
          1577385,
          105549,
          92043,
          3776,
          85,
          118,
          1563,
          1923,
          4533,
          1089,
          6469,
          516,
          5875,
          217,
          765,
          166081,
          2054,
          3766,
          77,
          140,
          54287,
          192,
          61,
          1131,
          2258,
          5216,
          3255,
          28739,
          230,
          12335,
          776,
          92985,
          798,
          516,
          1102,
          4512,
          717255,
          61,
          1493,
          93193,
          800,
          23,
          601723,
          3766,
          4508,
          1139,
          134056,
          2121,
          54185,
          19408,
          3343,
          4090,
          123373,
          6006,
          36438,
          1858,
          31394,
          532,
          631,
          71463,
          1595797,
          969,
          1690,
          964,
          4680,
          736284,
          1675,
          467,
          77,
          320420,
          34153,
          5662,
          24840,
          4508,
          695,
          2836,
          18182,
          1306,
          2443,
          49,
          841711,
          1201,
          10295,
          11250,
          27971,
          640470,
          4575,
          331,
          4575,
          686,
          2148,
          104396,
          75830,
          2274,
          2263,
          21134,
          43,
          765,
          6025,
          1382480,
          1261,
          3766,
          564,
          84106,
          608,
          1302,
          1654,
          464,
          1078,
          673342,
          6841,
          4159,
          1628,
          77,
          5791,
          321,
          1745,
          222785,
          349,
          888,
          749635,
          760,
          67082,
          1078,
          286,
          21134,
          2644,
          46,
          498,
          4575,
          46944,
          190178,
          718,
          1666,
          7268,
          158701,
          798,
          9594,
          972,
          276002,
          1970,
          222,
          1166,
          6434,
          6508,
          571,
          1766,
          1979,
          970,
          7646,
          686,
          51427,
          258,
          269,
          4074,
          77,
          972,
          324,
          1686,
          2470,
          1019,
          1858,
          1571,
          1087,
          9772,
          2148,
          1725,
          1089,
          55581,
          1334,
          18760,
          19054,
          50835,
          973849,
          4677,
          526,
          397,
          532,
          381459,
          1038,
          760,
          43102,
          24840,
          6460,
          1841,
          277,
          1970,
          95035,
          3202,
          372,
          11250,
          23727,
          489,
          502,
          5354,
          4542,
          8269,
          372,
          126,
          571,
          186140,
          1925,
          1526206,
          6841,
          2379,
          321490,
          5950,
          222,
          213,
          564,
          530,
          1565,
          276002,
          1897,
          1195,
          144160,
          2303,
          478,
          341,
          4508,
          1324,
          302,
          79008,
          4056,
          237282,
          3688,
          43,
          151815,
          15647,
          96942,
          331,
          1019,
          16183,
          1178,
          1312922,
          519,
          841711,
          276896,
          271,
          276002,
          276002,
          631,
          687276,
          214703,
          489,
          1666,
          3430,
          632,
          595,
          32891,
          85,
          348,
          5438,
          63,
          633,
          158701,
          341,
          1166,
          1143,
          7268,
          5895,
          21635,
          47211,
          1383,
          1679,
          4729,
          18408,
          167,
          7155,
          13422,
          1666,
          910148,
          129,
          663,
          186140,
          3684,
          1930,
          7155,
          522,
          5507,
          519,
          1507,
          2906700,
          128,
          237282,
          276002,
          17867,
          5211,
          545147,
          166081,
          16305,
          459921,
          15269,
          270712,
          3766,
          647,
          19054,
          922,
          4508,
          343,
          836,
          1442,
          1383,
          564,
          741,
          165556,
          207,
          316665,
          635,
          5666,
          4154,
          9521,
          1563,
          645,
          43,
          54767,
          1383,
          1595797,
          1841,
          13602,
          776,
          3395,
          75830,
          258,
          450,
          1412,
          2523,
          68211,
          470,
          1075,
          4726,
          1595797,
          190,
          2607,
          237282,
          3508,
          1666,
          42817,
          823,
          3508,
          21635,
          1760,
          1523,
          533,
          1946,
          7297,
          6581,
          2303,
          1970,
          343,
          19054,
          7155,
          4161,
          5927,
          1970,
          3395,
          372,
          7987,
          4542,
          733,
          3776,
          190178,
          172247,
          299480,
          1324,
          5726,
          932,
          7155,
          1263321,
          46,
          18128,
          1577385,
          277,
          722,
          4573,
          409656,
          198,
          1293,
          217,
          606,
          2395,
          1201,
          76383,
          42619,
          914,
          2036,
          765,
          1686,
          1988,
          167,
          1645,
          6469,
          107941,
          12335,
          1228,
          899,
          450,
          302,
          1139,
          61,
          107941,
          782,
          1312922,
          139,
          47249,
          84861,
          475,
          331,
          1523,
          5621,
          34496,
          151785,
          459921,
          1075,
          6841,
          9772,
          21902,
          1312922,
          198,
          71485,
          4993,
          198,
          687276,
          725,
          687276,
          888,
          1080,
          5648,
          630,
          4895,
          178,
          10295,
          92106,
          1789,
          116155,
          2836,
          725,
          23805,
          100,
          475,
          116001,
          1970,
          54185,
          1126,
          836,
          606,
          7692,
          463,
          5512,
          73,
          2328,
          5895,
          1312,
          269,
          34153,
          2526,
          1312922,
          341043,
          5895,
          1166,
          4074,
          2526,
          8874,
          2368,
          823,
          1360,
          206,
          34496,
          1288,
          3688,
          35371,
          9815,
          378909,
          328,
          1383,
          912,
          42384,
          824,
          647,
          823,
          2121,
          2290,
          761,
          601723,
          2644,
          128,
          1766,
          241,
          800,
          34496,
          3807,
          341,
          2906700,
          91,
          134056,
          1324,
          308,
          46563,
          804,
          391389,
          1196,
          2870,
          648,
          1241364,
          753116,
          466,
          1324,
          3395,
          863,
          545147,
          224256,
          2368,
          32891,
          186140,
          910148,
          1563,
          1195,
          344,
          10717,
          48194,
          1089,
          31515,
          46,
          21902,
          602,
          3279,
          28425,
          104,
          5950,
          307,
          1312,
          2443,
          597,
          8007,
          190,
          181438,
          1745,
          218,
          4729,
          2258,
          3684,
          2317,
          19054,
          71335,
          5875,
          52126,
          54185,
          1850,
          1526206,
          2054,
          163415,
          27971,
          759,
          258,
          328,
          7420,
          450,
          395,
          184,
          346,
          42384,
          2456,
          52126,
          2471,
          302,
          718,
          1725,
          2518,
          3730,
          3395,
          776,
          895,
          198,
          241,
          1946,
          1075,
          3684,
          1383,
          4015,
          5901,
          24536,
          99,
          106,
          5619,
          479994,
          1360,
          51,
          673342,
          3066,
          470,
          190,
          349,
          158701,
          3451,
          2158,
          9051,
          2290,
          36784,
          4090,
          493806,
          272,
          95,
          9772,
          71485,
          4172,
          3279,
          42619,
          1735,
          4533,
          595,
          167,
          7155,
          642,
          2504700,
          107941,
          61,
          450,
          1725,
          91,
          1563,
          1532,
          106,
          2368,
          4159,
          1442,
          222,
          248858,
          1988,
          1831,
          525713,
          565,
          1146,
          46,
          53,
          59744,
          139,
          46,
          1725,
          28278,
          5791,
          156391,
          372,
          1789,
          381459,
          217,
          2691,
          1312922,
          530,
          85,
          1263321,
          493806,
          7163,
          3395,
          722,
          3285,
          133,
          4575,
          972,
          43,
          6006,
          459921,
          1201,
          276,
          2807,
          5875,
          3833,
          12486,
          601723,
          1563,
          4729,
          4090,
          4653,
          7155,
          79008,
          5901,
          10295,
          2906700,
          1288,
          365,
          276002,
          20478,
          1725,
          8019,
          1306,
          1690,
          165556,
          31394,
          878,
          606,
          192,
          238602,
          1383,
          525713,
          69,
          2872,
          3119,
          52126,
          18408,
          1892,
          1617,
          47249,
          111,
          1512,
          589,
          1789,
          165556,
          725,
          4593,
          137067,
          1453,
          1312,
          1789,
          1443,
          6841,
          530,
          13717,
          1019,
          343,
          2836,
          20478,
          6120,
          6120,
          606,
          25459,
          213,
          92608,
          4090,
          9512,
          832,
          1766,
          7692,
          1087,
          8874,
          3684,
          741,
          18408,
          1595797,
          823,
          71463,
          7163,
          95015,
          1850,
          4778,
          313,
          471,
          1523,
          73,
          34153,
          1201,
          2504700,
          1930,
          1725,
          331,
          158701,
          811,
          525713,
          144160,
          124967,
          5619,
          520,
          1312922,
          71463,
          695,
          471,
          15647,
          5577,
          30770,
          1178,
          3487,
          169,
          272,
          4603,
          736284,
          509,
          5875,
          532,
          94014,
          313,
          2368,
          3776,
          104396,
          100,
          2092,
          969,
          566,
          885,
          413574,
          2786,
          2526,
          2971,
          760,
          718,
          186140,
          1304,
          2906700,
          760,
          5666,
          673342,
          1654,
          6629,
          1019,
          1595797,
          836,
          2395,
          471,
          28739,
          136,
          1368,
          1241364,
          2870,
          836,
          1312,
          516,
          4729,
          1423,
          337,
          9496,
          761,
          1725,
          94014,
          4159,
          2523,
          601723,
          1166,
          1841,
          1087,
          626,
          238602,
          291,
          207,
          606,
          2471,
          71335,
          5161,
          2504700,
          24536,
          38912,
          1312922,
          2290,
          42817,
          1143,
          14871,
          19685,
          493806,
          31394,
          14783,
          2644,
          1089,
          824,
          7155,
          2328,
          3495,
          12349,
          45303,
          532,
          2443,
          99,
          328,
          369,
          782,
          595,
          965,
          136,
          13717,
          7155,
          3996,
          191096,
          847,
          1504,
          5196,
          2906700,
          14783,
          128715,
          139650,
          320420,
          230,
          471,
          5726,
          248858,
          4677,
          1760,
          1847,
          1749,
          695,
          18760,
          1383,
          186140,
          973849,
          186140,
          5657,
          241,
          1165,
          1789,
          5548,
          177,
          601723,
          276002,
          338,
          564,
          5619,
          84106,
          1453,
          640470,
          477,
          18408,
          1725,
          10717,
          1089,
          86954,
          4726,
          4677,
          757530,
          381459,
          1563,
          2148,
          18408,
          34496,
          2872,
          2870,
          8269,
          67082,
          509,
          5895,
          722,
          759,
          140,
          811,
          1420,
          397,
          1675,
          106,
          176,
          2036,
          509,
          4729,
          50835,
          391389,
          519,
          741,
          1490,
          513,
          176,
          239,
          4878,
          48194,
          927396,
          85,
          1131,
          79613,
          811,
          545147,
          5161,
          1126,
          19685,
          171170,
          2856,
          341043,
          247,
          242,
          151815,
          2471,
          145,
          1195,
          3451,
          2060,
          3451,
          6581,
          149,
          1523,
          3730,
          653,
          1504,
          85,
          107941,
          45303,
          33917,
          1195,
          5895,
          1684,
          513,
          111,
          11751,
          3699,
          355,
          509,
          128715,
          744,
          158701,
          67082,
          973849,
          50835,
          76,
          910148,
          21134,
          530,
          8512,
          238602,
          1770,
          36784,
          1909,
          836,
          1892,
          6629,
          5950,
          1858,
          1850,
          540,
          37,
          608,
          6006,
          743,
          233717,
          207,
          493,
          2206,
          140,
          571,
          695,
          1563,
          3228,
          725,
          372,
          13835,
          1228,
          42817,
          308,
          6508,
          6469,
          743,
          4593,
          1512,
          100,
          215,
          6581,
          2092,
          18182,
          969,
          4913,
          1841,
          95015,
          116155,
          6006,
          116001,
          5950,
          158701,
          922,
          12335,
          2223,
          302,
          3224,
          15269,
          116001,
          13061,
          6120,
          24536,
          640470,
          105549,
          3688,
          1684,
          2328,
          55581,
          2457,
          27020,
          1939,
          1595797,
          7297,
          2471,
          885,
          19408,
          16183,
          67082,
          1139,
          9506,
          4993,
          4778,
          9679,
          5621,
          3487,
          13422,
          6508,
          6120,
          722,
          276002,
          13983,
          144160,
          478,
          765,
          493,
          2786,
          27020,
          7268,
          35439,
          4913,
          71485,
          1804,
          134056,
          156391,
          5507,
          6284,
          10076,
          1666,
          28425,
          171170,
          1490,
          1831,
          885,
          118,
          344,
          673342,
          54767,
          937,
          602,
          2501,
          7692,
          6469,
          1766,
          218,
          19408,
          4074,
          14783,
          190249,
          1143,
          888,
          640470,
          606,
          973849,
          163415,
          2807,
          1654,
          124967,
          116001,
          291,
          276896,
          6951,
          75830,
          686,
          194500,
          1143,
          31515,
          224256,
          3688,
          1686,
          718,
          140,
          14742,
          6460,
          46,
          2870,
          2471,
          601723,
          1930,
          647,
          14783,
          123,
          5901,
          192805,
          2799,
          2401,
          16305,
          129,
          99,
          104396,
          917,
          68211,
          3508,
          75830,
          4542,
          34882,
          5354,
          1201,
          464,
          4729,
          7987,
          372,
          7155,
          192805,
          297,
          1595797,
          5211,
          337,
          4726,
          863,
          217,
          1334,
          595,
          2971,
          6581,
          163415,
          1595797,
          1078,
          133,
          8512,
          1758,
          95035,
          798,
          341,
          207410,
          1745,
          1241364,
          965,
          45303,
          1334,
          20478,
          92043,
          74,
          1412,
          532,
          34882,
          4090,
          614,
          9051,
          663,
          71463,
          463,
          1190,
          6629,
          765,
          3343,
          5901,
          571,
          10717,
          59744,
          1312922,
          7155,
          389246,
          3684,
          5507,
          2691,
          509,
          8830,
          8830,
          190178,
          6951,
          8007,
          628,
          581,
          233717,
          25459,
          1190,
          1841,
          2408,
          22305,
          2304,
          922,
          270712,
          3096,
          30770,
          9815,
          105549,
          1504,
          123373,
          16305,
          1758,
          376,
          79613,
          1507,
          635,
          1507,
          1472,
          477,
          817312,
          407,
          321490,
          5895,
          6581,
          1312922,
          1858,
          1791,
          595,
          4895,
          744,
          67858,
          71485,
          744,
          1252,
          1925,
          1725,
          972,
          4090,
          2526,
          76383,
          765,
          13061,
          27829,
          47249,
          1504,
          489,
          3402,
          1051,
          79613,
          355,
          847,
          895,
          1178,
          20328,
          136,
          16183,
          177,
          8269,
          116001,
          46563,
          5950,
          27829,
          471,
          24840,
          606,
          899,
          1970,
          344,
          4090,
          99,
          100,
          4913,
          372,
          1252,
          1420,
          970,
          77,
          564,
          502,
          198,
          528,
          525713,
          63,
          2872,
          1139,
          320420,
          4533,
          2644,
          71335,
          248,
          2526,
          26551,
          4090,
          737,
          1841,
          365,
          2691,
          92106,
          910148,
          2906700,
          2368,
          1504,
          222,
          2456,
          878,
          3279,
          1126,
          237282,
          1988,
          1472,
          1847,
          564,
          145,
          47,
          145,
          341,
          69793,
          1810,
          53,
          6284,
          50489,
          1789,
          1595797,
          21902,
          639,
          18182,
          722,
          71335,
          370,
          46,
          1766,
          13422,
          1533,
          1858,
          1760,
          964,
          1228,
          2078,
          1595797,
          310,
          1139,
          493,
          192,
          640470,
          341,
          1970,
          6951,
          5901,
          2691,
          841711,
          2661,
          3228,
          139650,
          1271,
          105549,
          192,
          2089,
          590,
          36784,
          35439,
          1089,
          5621,
          25459,
          2456,
          116155,
          166081,
          4664,
          94325,
          722,
          34153,
          223,
          5657,
          519,
          1186,
          69,
          1530,
          1583,
          12486,
          5895,
          601723,
          258,
          181438,
          7297,
          165,
          1446,
          3996,
          320,
          145,
          1166,
          519,
          1595797,
          753116,
          230,
          1186,
          888,
          35371,
          530,
          136,
          134056,
          320,
          192,
          1423,
          2135,
          4354,
          2471,
          1725,
          12335,
          229,
          350,
          4090,
          5760,
          2526,
          471,
          1897,
          2036,
          532,
          4542,
          151815,
          6629,
          190178,
          489,
          910148,
          136,
          737,
          5341,
          76,
          1078,
          79613,
          269,
          2401,
          1368,
          409656,
          1190,
          5760,
          9993,
          3289,
          35371,
          2471,
          4913,
          17047,
          139,
          5901,
          1131,
          520,
          633,
          69793,
          895,
          2368,
          3430,
          69793,
          565,
          302,
          743,
          73,
          2408,
          2368,
          5648,
          145,
          1075,
          571,
          181438,
          372,
          533,
          258,
          5512,
          475,
          673342,
          1690,
          1577385,
          932,
          13983,
          5507,
          1595797,
          1412,
          5507,
          168,
          254282,
          6581,
          1595797,
          3776,
          194500,
          348,
          1383,
          2836,
          1261,
          5457,
          10717,
          343,
          1789,
          1022298,
          42817,
          94014,
          1078,
          13835,
          861,
          28739,
          771,
          2092,
          10295,
          320420,
          2290,
          680,
          4575,
          1075,
          910148,
          1831,
          1645,
          530,
          112,
          1446,
          8019,
          5760,
          25459,
          832,
          1595797,
          1583,
          206,
          50489,
          1577385,
          1102,
          4367,
          105638,
          2054,
          24645,
          516,
          765,
          1420,
          540,
          3224,
          5950,
          67082,
          272,
          595,
          95035,
          4913,
          1762,
          608,
          69,
          6006,
          2807,
          6434,
          1426,
          217,
          413574,
          1334,
          165,
          5901,
          509,
          77,
          42817,
          489,
          1530,
          207410,
          5666,
          722,
          628,
          51,
          276002,
          2304,
          76383,
          341043,
          37,
          2211,
          589,
          4575,
          5648,
          1577385,
          1970,
          3684,
          466,
          5989,
          518429,
          5507,
          313,
          1126,
          5451,
          95035,
          513,
          606,
          237282,
          1925,
          1166,
          6951,
          258,
          328,
          13835,
          1791,
          579,
          1078,
          1382480,
          63,
          1577385,
          4878,
          43102,
          21134,
          33917,
          1850,
          16183,
          1804,
          1725,
          1312922,
          1810,
          1923,
          5507,
          2304,
          333497,
          77,
          229,
          601723,
          20328,
          4533,
          6018,
          242,
          3684,
          595,
          76,
          551,
          545147,
          1493,
          13835,
          1725,
          4508,
          498,
          194500,
          13422,
          129,
          42384,
          46944,
          5577,
          1643,
          316665,
          2456,
          3402,
          753116,
          459921,
          722,
          4575,
          1595797,
          84106,
          687276,
          149,
          7155,
          241,
          3224,
          743,
          3451,
          341043,
          13835,
          1334,
          31394,
          4726,
          258,
          647,
          475,
          321,
          5512,
          33804,
          1679,
          493,
          149,
          8512,
          1228,
          242,
          413574,
          20328,
          757530,
          30770,
          10295,
          1228,
          1201,
          2644,
          9993,
          2906700,
          34882,
          168,
          1930,
          37,
          695,
          68211,
          1089,
          19090,
          1680,
          140,
          123,
          733,
          1312922,
          10076,
          1892,
          23,
          1643,
          1970,
          2135,
          571,
          1606,
          213,
          2307,
          3451,
          1574,
          76383,
          463,
          5950,
          513,
          3495,
          2304,
          59744,
          7646,
          140,
          1186,
          378909,
          518429,
          1186,
          27971,
          5778,
          928,
          5662,
          5903,
          85,
          18182,
          4172,
          34496,
          34153,
          1442,
          3032,
          1643,
          77,
          69,
          24536,
          71335,
          5619,
          25459,
          1426,
          134056,
          2036,
          88735,
          163415,
          46944,
          836,
          302,
          8007,
          47211,
          798,
          85,
          241,
          178,
          13422,
          2303,
          601723,
          2401,
          1412,
          91,
          6006,
          92043,
          1517,
          2054,
          271,
          2872,
          1139,
          5662,
          229,
          4512,
          1892,
          614,
          1766,
          18408,
          1102,
          9815,
          509,
          24840,
          144160,
          5577,
          530,
          5726,
          528,
          341,
          2304,
          1139,
          1643,
          116001,
          3508,
          47249,
          151815,
          47249,
          1517,
          27829,
          530,
          271,
          299480,
          2016,
          32891,
          50489,
          7646,
          341043,
          928,
          2401,
          343,
          5908,
          92294,
          238602,
          680,
          118,
          128354,
          733,
          760,
          5196,
          27020,
          1126,
          525713,
          1324,
          313,
          969,
          2691,
          530,
          4074,
          1089,
          581,
          19408,
          1139,
          2906700,
          467,
          2054,
          2401,
          911,
          55345,
          145,
          224256,
          2644,
          13061,
          95035,
          47249,
          4512,
          1288,
          71463,
          165556,
          248,
          1478,
          67082,
          471,
          2607,
          5848,
          59744,
          601723,
          94014,
          27971,
          965,
          316665,
          2870,
          14871,
          276002,
          24536,
          817312,
          1523,
          741,
          1536,
          3066,
          139,
          30770,
          2607,
          43102,
          207,
          215,
          1063,
          218,
          136,
          2872,
          5354,
          277,
          22930,
          149,
          5621,
          2078,
          1078,
          18408,
          695,
          663,
          158701,
          6120,
          75830,
          2092,
          1595797,
          475,
          3688,
          1532,
          71335,
          2206,
          376,
          2092,
          1480,
          190,
          409656,
          48194,
          3805,
          313,
          76,
          1749,
          4542,
          571,
          34496,
          489,
          5848,
          6713,
          1810,
          3395,
          2971,
          602,
          753116,
          722,
          224256,
          103927,
          1504,
          271,
          450,
          1804,
          123,
          30770,
          1507,
          123373,
          16163,
          99,
          795,
          516,
          139,
          1526206,
          51,
          190,
          647,
          99,
          4508,
          241,
          972,
          71485,
          1271,
          413574,
          4074,
          118,
          94325,
          7163,
          823,
          824,
          1810,
          16305,
          1453,
          5666,
          85,
          6006,
          1858,
          224256,
          1565,
          76383,
          2142,
          2148,
          267,
          238602,
          687276,
          5666,
          355,
          10076,
          177,
          5216,
          9521,
          8874,
          21125,
          2304,
          1241364,
          1791,
          863,
          207,
          614,
          74,
          54287,
          192,
          1762,
          836,
          828,
          4720,
          911,
          2870,
          3402,
          248858,
          888,
          92608,
          1847,
          99,
          128354,
          895,
          4913,
          910148,
          4056,
          1523,
          349,
          2607,
          139650,
          17047,
          464,
          647,
          2856,
          140,
          21902,
          76383,
          324,
          1075,
          2206,
          24536,
          260,
          9051,
          1241364,
          686,
          92337,
          2457,
          2148,
          717255,
          34153,
          376,
          343,
          34153,
          9815,
          6120,
          1078,
          464,
          5507,
          1139,
          31515,
          914,
          7297,
          477,
          254,
          759,
          3395,
          2135,
          5621,
          391389,
          1423,
          24645,
          1139,
          77,
          123,
          632,
          8874,
          105638,
          176,
          165556,
          1368,
          5211,
          1666,
          71463,
          47772,
          7692,
          6006,
          71335,
          2443,
          48194,
          239,
          2906700,
          2971,
          1414,
          1179,
          1789,
          5908,
          9784,
          1643,
          1334,
          7646,
          1686,
          3684,
          391389,
          2307,
          32891,
          475,
          2274,
          2148,
          1617,
          1595797,
          2471,
          192,
          191096,
          10076,
          973849,
          233060,
          5895,
          1196,
          5512,
          241,
          95,
          2290,
          376,
          1617,
          1383,
          4845,
          2644,
          215,
          545147,
          3343,
          1490,
          30770,
          106,
          493806,
          530,
          3495,
          973849,
          1075,
          31515,
          230,
          7163,
          1841,
          606,
          630,
          21902,
          186140,
          409656,
          5950,
          85,
          2401,
          172817,
          17867,
          18408,
          964,
          1847,
          3688,
          5507,
          4056,
          192,
          26551,
          475,
          828,
          443,
          27971,
          647,
          1446,
          6006,
          4367,
          1970,
          91,
          863,
          602,
          3805,
          1383,
          198,
          673342,
          4056,
          5457,
          328,
          9594,
          158701,
          31515,
          71485,
          964,
          124967,
          2435,
          6284,
          302,
          4512,
          272134,
          1645,
          1261,
          1178,
          18128,
          2078,
          1263321,
          34153,
          1288,
          92106,
          14783,
          242,
          71463,
          47,
          2872,
          725,
          4367,
          7268,
          7565,
          647,
          911,
          248858,
          248,
          34882,
          229,
          5760,
          277,
          1583,
          84106,
          1443,
          277,
          230,
          34153,
          27829,
          4573,
          4542,
          186140,
          2456,
          687276,
          77,
          1443,
          1789,
          2661,
          5848,
          19408,
          2644,
          743,
          230,
          475,
          18182,
          391389,
          3688,
          70,
          3451,
          581,
          2258,
          13835,
          1063,
          4603,
          1201,
          238602,
          1179,
          12747,
          254,
          13973,
          295,
          922,
          55581,
          6951,
          33917,
          7155,
          602,
          94325,
          1120,
          190178,
          3395,
          1925,
          861,
          34496,
          471,
          21125,
          254282,
          509,
          9512,
          35299,
          1517,
          5548,
          63,
          6469,
          346,
          9496,
          493806,
          467,
          551,
          970,
          99,
          5760,
          1143,
          4575,
          3495,
          7297,
          1302,
          5211,
          308,
          198,
          139,
          722,
          69793,
          38912,
          4542,
          571,
          1446,
          632,
          21902,
          493806,
          1988,
          7268,
          602,
          12335,
          140,
          207,
          70,
          530,
          1523,
          144160,
          16305,
          153,
          5719,
          247,
          28425,
          489,
          2258,
          178,
          156391,
          313,
          4573,
          470,
          1360,
          2317,
          564,
          5507,
          2395,
          2691,
          241,
          753116,
          395,
          51,
          78968,
          79613,
          1288,
          4664,
          969,
          1530,
          291,
          832,
          9815,
          92043,
          27971,
          158701,
          8097,
          136,
          1766,
          551,
          4778,
          313,
          320,
          4090,
          602,
          10256,
          606,
          51427,
          836,
          4845,
          895,
          23,
          105549,
          2906700,
          4074,
          172247,
          381459,
          47249,
          1288,
          630,
          1847,
          6018,
          31515,
          397,
          69,
          9165,
          1196,
          2836,
          9594,
          1190,
          18408,
          7420,
          1126,
          2368,
          928,
          1766,
          25459,
          532,
          1988,
          1263321,
          2211,
          5438,
          6951,
          525713,
          165,
          540,
          107941,
          106,
          19054,
          7163,
          737,
          743,
          2401,
          348,
          937,
          165556,
          346,
          1675,
          460,
          737,
          6006,
          136,
          6469,
          899,
          137067,
          21125,
          328,
          1312,
          1791,
          647,
          13835,
          71335,
          341,
          5341,
          139,
          73,
          190,
          30770,
          1745,
          504,
          13835,
          35371,
          923,
          92043,
          5848,
          6006,
          118,
          3805,
          914,
          1228,
          46,
          1051,
          1080,
          118,
          911,
          270712,
          3766,
          100,
          564,
          1382480,
          836,
          811,
          343,
          104396,
          663,
          6469,
          1595797,
          1312922,
          4575,
          1684,
          372,
          6951,
          2872,
          878,
          391389,
          3104,
          26551,
          645,
          4603,
          67082,
          4056,
          736284,
          190178,
          3066,
          13061,
          140,
          34882,
          964,
          12335,
          25459,
          2135,
          238602,
          10295,
          413574,
          122111,
          269,
          6713,
          123,
          571,
          52,
          2518,
          263,
          3451,
          7268,
          3224,
          3684,
          864,
          1324,
          761,
          18182,
          695,
          9594,
          1080,
          5950,
          129,
          9496,
          4056,
          18182,
          1504,
          1312922,
          13422,
          87124,
          409656,
          1446,
          1841,
          391389,
          3224,
          54287,
          42817,
          1196,
          158701,
          1643,
          198,
          6284,
          1850,
          3994,
          333497,
          686,
          10717,
          194500,
          320420,
          470,
          459921,
          69,
          307,
          2856,
          2971,
          4664,
          67082,
          489,
          123373,
          7987,
          1178,
          24645,
          370,
          759,
          7155,
          631,
          5341,
          3104,
          298,
          895,
          1847,
          129,
          1745,
          737,
          1414,
          4726,
          46,
          85,
          47249,
          2304,
          191096,
          36784,
          5662,
          36438,
          59744,
          910148,
          5457,
          217,
          19090,
          10256,
          530,
          551,
          237282,
          95035,
          112,
          970,
          6951,
          5657,
          163415,
          2906700,
          725,
          10076,
          241,
          3285,
          18182,
          1675,
          467,
          2368,
          3730,
          1925,
          172817,
          118,
          85,
          1517,
          3451,
          3395,
          99,
          687276,
          71335,
          914,
          2121,
          5161,
          4573,
          413574,
          571,
          1654,
          277,
          3202,
          381459,
          5196,
          3688,
          1645,
          1178,
          927396,
          1274,
          1126,
          313,
          13602,
          4074,
          214703,
          1577385,
          116001,
          308,
          61,
          92985,
          450,
          1201,
          3508,
          642,
          832,
          84861,
          1165,
          10256,
          111,
          86954,
          973849,
          489,
          2906700,
          4573,
          2211,
          910148,
          743,
          54287,
          910148,
          5760,
          478,
          520,
          2661,
          18760,
          1312,
          4090,
          2916,
          2290,
          198,
          71485,
          26120,
          95035,
          1493,
          140,
          718,
          4015,
          18128,
          663,
          258,
          324,
          1925,
          1363,
          771,
          277,
          140,
          99,
          725,
          8874,
          23727,
          828,
          4895,
          1263321,
          795,
          1140,
          1943,
          1261,
          136,
          626,
          343,
          1472,
          111,
          2089,
          733,
          8874,
          276002,
          3224,
          5950,
          7646,
          19054,
          163415,
          59744,
          722,
          215,
          224256,
          333497,
          92608,
          1970,
          291,
          172817,
          135332,
          823,
          269,
          1577385,
          754,
          140,
          885,
          1770,
          217,
          1979,
          9034,
          530,
          237282,
          2258,
          2856,
          2644,
          1063,
          632,
          2135,
          59744,
          16183,
          194500,
          172817,
          2408,
          1423,
          932,
          1831,
          35371,
          19090,
          467,
          823,
          509,
          470,
          911,
          20478,
          914,
          3876,
          836,
          86954,
          5621,
          192,
          24840,
          355,
          276002,
          28278,
          6018,
          725,
          1979,
          184,
          828,
          895,
          2644,
          922,
          640470,
          21125,
          1850,
          30770,
          3776,
          5548,
          207,
          137067,
          32891,
          68211,
          695,
          310,
          5657,
          33917,
          1847,
          76383,
          299480,
          3862,
          78968,
          630,
          1810,
          19685,
          516,
          13602,
          5451,
          6120,
          5895,
          1679,
          258,
          10717,
          270712,
          1196,
          271,
          237282,
          571,
          1923,
          46563,
          344,
          817312,
          1847,
          1526206,
          1312,
          969,
          1261,
          302,
          1617,
          1970,
          69,
          105549,
          914,
          324,
          4172,
          761,
          60,
          5196,
          61,
          8097,
          47249,
          9521,
          5901,
          1850,
          2208,
          229,
          673342,
          1126,
          2206,
          737,
          6713,
          2504700,
          28425,
          759,
          341,
          3066,
          11250,
          1645,
          241,
          1368,
          341,
          1979,
          372,
          1780,
          2148,
          1745,
          18408,
          71485,
          350,
          680,
          2566,
          1022298,
          5760,
          2408,
          104,
          20478,
          1078,
          1443,
          1490,
          149,
          1241364,
          3224,
          124967,
          2054,
          1472,
          328,
          46944,
          1909,
          5950,
          1504,
          4074,
          1038,
          43102,
          26551,
          1645,
          1526206,
          92608,
          9594,
          16305,
          71335,
          589,
          337,
          530,
          564,
          9034,
          254282,
          6841,
          653,
          6841,
          749635,
          1312,
          743,
          1078,
          5512,
          34153,
          4720,
          1645,
          467,
          178,
          11250,
          2148,
          107941,
          20328,
          167,
          823,
          2661,
          509,
          1382480,
          348,
          1760,
          320,
          94014,
          123,
          4090,
          516,
          1383,
          1190,
          270712,
          4074,
          165,
          470,
          608,
          69,
          13717,
          254282,
          1178,
          1595797,
          1288,
          1925,
          832,
          71463,
          4005,
          5341,
          1656,
          1126,
          1523,
          35371,
          564,
          320420,
          134056,
          218,
          1577385,
          477,
          16183,
          540,
          337,
          824,
          47249,
          35371,
          31515,
          2135,
          4056,
          1725,
          43102,
          1810,
          105549,
          1847,
          18408,
          502,
          1412,
          34153,
          10256,
          184,
          4664,
          75830,
          349,
          1312922,
          1312922,
          736284,
          9587,
          269,
          3202,
          23,
          718,
          923,
          2121,
          313,
          4575,
          19685,
          43,
          1420,
          2395,
          471,
          686,
          92608,
          46944,
          965,
          4664,
          48194,
          184,
          67082,
          589,
          71463,
          2206,
          254282,
          970,
          2870,
          1766,
          3255,
          595,
          2379,
          3289,
          1577385,
          595,
          320420,
          50489,
          1274,
          18128,
          5760,
          413574,
          3228,
          6951,
          19685,
          2456,
          3223,
          71463,
          3807,
          15426,
          5901,
          2307,
          321490,
          186140,
          4726,
          1126,
          571,
          31394,
          218,
          1645,
          771,
          248,
          1791,
          153,
          1312922,
          3224,
          2036,
          45303,
          923,
          3104,
          571,
          3495,
          2523,
          5875,
          76,
          84861,
          2290,
          6006,
          782,
          2856,
          2258,
          214703,
          139,
          532,
          69,
          1312922,
          186140,
          43,
          601723,
          331,
          21125,
          355,
          194500,
          34882,
          2870,
          84106,
          2456,
          5848,
          3066,
          2135,
          2408,
          76,
          9815,
          5621,
          17867,
          9772,
          19685,
          4729,
          626,
          106,
          2368,
          1412,
          5901,
          269,
          75830,
          9521,
          35371,
          4533,
          3289,
          3430,
          3202,
          2135,
          653,
          10076,
          1766,
          1666,
          970,
          2307,
          46,
          302,
          42817,
          878,
          1656,
          350,
          92985,
          564,
          2307,
          320420,
          2121,
          1645,
          111,
          4015,
          272,
          4512,
          760,
          372,
          23,
          1453,
          6006,
          516,
          2443,
          18760,
          528,
          606,
          4895,
          198,
          965,
          520,
          77,
          8830,
          186140,
          1831,
          346,
          1261,
          863,
          1228,
          61,
          673342,
          337,
          965,
          320,
          632,
          233717,
          5791,
          1988,
          1523,
          346,
          184,
          129,
          467,
          823,
          123,
          1352,
          128715,
          2395,
          378909,
          477,
          1504,
          4542,
          4074,
          509,
          43102,
          2872,
          1446,
          5507,
          1078,
          8512,
          1789,
          28425,
          1512,
          3699,
          52126,
          1909,
          836,
          87124,
          3224,
          3451,
          308,
          1858,
          14871,
          331,
          1939,
          1526206,
          771,
          5927,
          1892,
          4512,
          23,
          27020,
          207,
          601723,
          1700,
          895,
          333497,
          1078,
          972,
          17867,
          5438,
          222785,
          1745,
          103927,
          31394,
          14228,
          1228,
          229,
          21902,
          32891,
          471,
          1190,
          32891,
          3066,
          7565,
          5719,
          73,
          761,
          964,
          184,
          545147,
          1925,
          626,
          2456,
          85,
          2401,
          276896,
          478,
          47772,
          5548,
          73,
          1382480,
          31970,
          207,
          5161,
          355,
          9496,
          128,
          5548,
          16163,
          1213,
          6841,
          5211,
          4056,
          782,
          1383,
          2206,
          771,
          1383,
          695,
          1241364,
          3224,
          16305,
          1595797,
          1909,
          602,
          25459,
          895,
          466,
          2870,
          10295,
          450,
          372,
          92106,
          59744,
          3228,
          47211,
          238602,
          765,
          69,
          836,
          1312922,
          595,
          645,
          167,
          1766,
          165,
          565,
          2263,
          1446,
          1892,
          34153,
          1446,
          3451,
          3085,
          759,
          1766,
          910148,
          6841,
          725,
          2566,
          1675,
          85,
          207,
          8269,
          349,
          186140,
          270712,
          1443,
          35439,
          2916,
          191096,
          673342,
          602,
          8269,
          333497,
          17047,
          133,
          190178,
          106,
          765,
          78968,
          30770,
          6469,
          4677,
          922,
          21635,
          186140,
          116001,
          4172,
          5196,
          337,
          313,
          1563,
          186140,
          673342,
          5621,
          139,
          760,
          269,
          1382480,
          372,
          545147,
          177,
          192,
          233060,
          111,
          54287,
          1858,
          1051,
          832,
          71463,
          5211,
          733,
          136,
          2376,
          7565,
          2290,
          1190,
          191096,
          163415,
          207410,
          4542,
          9034,
          3343,
          3032,
          2368,
          94014,
          7430,
          24840,
          9772,
          198,
          47,
          1766,
          725,
          606,
          21134,
          1078,
          4729,
          1334,
          493806,
          6713,
          51,
          1930,
          71485,
          2290,
          4729,
          1577385,
          3224,
          217,
          42817,
          6841,
          91,
          206,
          43,
          3688,
          19054,
          1363,
          471,
          5196,
          75903,
          1762,
          59744,
          2644,
          397,
          341043,
          16163,
          3279,
          765,
          626,
          5875,
          1352,
          3066,
          836,
          151785,
          478,
          2303,
          307,
          917,
          1925,
          1631,
          1970,
          149,
          33804,
          965,
          42384,
          34882,
          32891,
          242,
          124967,
          836,
          463,
          832,
          276002,
          166081,
          19054,
          1304,
          2401,
          167,
          687276,
          5666,
          4575,
          2526,
          5875,
          10295,
          46563,
          67082,
          167,
          2135,
          2328,
          31394,
          47,
          4090,
          50835,
          584,
          464,
          93193,
          520,
          2518,
          7297,
          817312,
          95015,
          2328,
          320420,
          136,
          92985,
          79008,
          5895,
          20328,
          4049,
          413574,
          178,
          9815,
          1132,
          168,
          2328,
          2872,
          18408,
          5196,
          2328,
          1196,
          73,
          88735,
          21125,
          111,
          11256,
          3032,
          972,
          42619,
          1063,
          5211,
          286,
          21134,
          4729,
          4542,
          741,
          78968,
          4081,
          757530,
          5950,
          397,
          2148,
          6434,
          301,
          1517,
          47211,
          2504700,
          1966,
          15623,
          337,
          9772,
          1766,
          1426,
          207,
          61,
          1897,
          190178,
          60,
          1089,
          8874,
          247,
          308,
          84106,
          7268,
          139,
          8830,
          7297,
          23,
          1126,
          134056,
          899,
          1512,
          680,
          663,
          645,
          922,
          5354,
          19054,
          5927,
          198,
          1126,
          489,
          565,
          186140,
          6469,
          771,
          17867,
          1089,
          2376,
          1140,
          1302,
          1897,
          2401,
          2906700,
          927396,
          13835,
          1923,
          34153,
          12335,
          31394,
          9521,
          910148,
          11256,
          8874,
          33917,
          5657,
          258,
          1493,
          2304,
          1725,
          5354,
          922,
          1022298,
          1925,
          3495,
          140,
          338,
          140,
          3263,
          95,
          516,
          42817,
          2566,
          16183,
          105638,
          633,
          632,
          1791,
          760,
          725,
          2016,
          1022298,
          4005,
          76,
          969,
          1143,
          12747,
          6841,
          1850,
          302,
          172817,
          687276,
          346,
          1684,
          551,
          5875,
          1131,
          687276,
          239,
          34882,
          1166,
          17867,
          1312922,
          4664,
          545147,
          230,
          207,
          2456,
          2206,
          46563,
          744,
          67082,
          614,
          344,
          1583,
          172817,
          338,
          69,
          1504,
          2383912,
          1532,
          5341,
          9772,
          2036,
          346,
          3430,
          4198,
          498,
          2135,
          759,
          74,
          8830,
          59744,
          459921,
          467,
          2258,
          100,
          1684,
          59744,
          5512,
          3395,
          1306,
          139,
          2303,
          532,
          378909,
          2870,
          1263321,
          782,
          1523,
          43,
          1725,
          95015,
          2457,
          1530,
          1679,
          1140,
          1178,
          1360,
          43,
          198,
          137,
          276,
          1735,
          413574,
          5512,
          722,
          568,
          1643,
          1925,
          601723,
          93193,
          5161,
          1841,
          79613,
          151785,
          13983,
          5196,
          8830,
          581,
          1966,
          532,
          911,
          76,
          52,
          5989,
          2661,
          663,
          1019,
          601723,
          76,
          4729,
          2202,
          35439,
          673342,
          2607,
          71463,
          6469,
          324,
          601723,
          1202,
          1288,
          1810,
          24840,
          2607,
          1925,
          139,
          2518,
          95035,
          1679,
          1526206,
          2274,
          242,
          475,
          475,
          104,
          467,
          579,
          10076,
          111,
          69,
          46,
          45100,
          765,
          932,
          1453,
          124967,
          4512,
          7163,
          3224,
          194500,
          54287,
          3255,
          71335,
          7155,
          214703,
          1507,
          741,
          1166,
          237282,
          1526206,
          213,
          3096,
          1925,
          247,
          99,
          123,
          158701,
          6469,
          1574,
          1930,
          28739,
          34153,
          5760,
          647,
          71335,
          2307,
          753116,
          2523,
          9496,
          1770,
          136,
          218,
          4056,
          12335,
          581,
          69,
          118,
          1684,
          811,
          59744,
          1478,
          20328,
          566,
          158701,
          2408,
          69,
          50835,
          36438,
          1571,
          626,
          3833,
          3776,
          969,
          1131,
          86954,
          270712,
          178,
          2872,
          3279,
          68211,
          77,
          5196,
          467,
          927396,
          165556,
          2092,
          2376,
          9496,
          27020,
          9815,
          817312,
          59705,
          3228,
          105549,
          2368,
          4138,
          3096,
          78968,
          1680,
          171170,
          736284,
          2211,
          528,
          479994,
          94014,
          276002,
          140,
          568,
          248,
          42384,
          233717,
          247,
          1312922,
          795,
          267,
          3833,
          14871,
          717255,
          16183,
          2206,
          172817,
          26120,
          139,
          17047,
          124967,
          673342,
          1241364,
          964,
          798,
          5719,
          2526,
          1606,
          378909,
          7268,
          2092,
          31515,
          23045,
          1643,
          9815,
          255,
          31970,
          1923,
          626,
          9993,
          5895,
          1909,
          3833,
          95,
          46,
          15426,
          22930,
          12349,
          1241364,
          1810,
          19090,
          276,
          1312,
          17867,
          76,
          2644,
          165,
          47772,
          927396,
          269,
          1930,
          19685,
          2092,
          5901,
          1979,
          2607,
          307,
          46944,
          3699,
          3996,
          2501,
          3699,
          732,
          320,
          139650,
          399,
          2376,
          1195,
          632,
          6018,
          167,
          633,
          34496,
          165,
          1126,
          3430,
          765,
          241,
          54767,
          1075,
          828,
          224256,
          153,
          258,
          2471,
          1139,
          3766,
          13602,
          53,
          223,
          1178,
          811,
          606,
          520,
          378909,
          1453,
          1089,
          828,
          124967,
          1530,
          795,
          761,
          270712,
          1563,
          242,
          733,
          2906700,
          686,
          43102,
          14228,
          3862,
          302,
          722,
          459921,
          67858,
          2501,
          7268,
          308,
          1565,
          5760,
          7163,
          224256,
          1850,
          3096,
          213,
          270712,
          106,
          168,
          372,
          5908,
          520,
          34882,
          10295,
          6703,
          910148,
          2523,
          5507,
          76383,
          12747,
          1063,
          18182,
          186140,
          970,
          46,
          1766,
          165556,
          409656,
          163415,
          344,
          1645,
          5196,
          184,
          5657,
          1563,
          1228,
          307,
          2501,
          3104,
          5354,
          389246,
          1514,
          1089,
          1126,
          1442,
          1089,
          471,
          313,
          493806,
          50835,
          5901,
          1892,
          11250,
          516,
          36784,
          4161,
          1762,
          241,
          47211,
          6713,
          1789,
          260,
          337,
          73,
          123373,
          7268,
          341,
          828,
          6120,
          804,
          2304,
          7987,
          2607,
          1523,
          1847,
          372,
          5950,
          178,
          1680,
          1847,
          5619,
          68211,
          3395,
          255,
          21902,
          111,
          136,
          4653,
          2158,
          782,
          19090,
          530,
          6629,
          2054,
          5211,
          1979,
          630,
          1288,
          3699,
          2304,
          18408,
          1595797,
          725,
          2408,
          6284,
          53,
          771,
          4367,
          321490,
          602,
          28739,
          55345,
          1288,
          493806,
          1504,
          1195,
          233060,
          5791,
          1858,
          4367,
          5621,
          28739,
          409656,
          2408,
          470,
          86954,
          1946,
          2523,
          1306,
          1179,
          1196,
          31515,
          533,
          1831,
          626,
          695,
          1563,
          54185,
          1063,
          4653,
          54767,
          2691,
          3032,
          1075,
          242,
          1530,
          1661,
          928,
          172247,
          1523,
          878,
          1288,
          2303,
          1480,
          190,
          391389,
          2328,
          970,
          324,
          5895,
          3279,
          2807,
          2036,
          1443,
          1442,
          5619,
          61,
          1810,
          118,
          32891,
          1654,
          3279,
          2906700,
          631,
          2401,
          11432,
          1228,
          5666,
          648,
          372,
          27971,
          823,
          156391,
          1423,
          79613,
          94014,
          1595797,
          381459,
          4306,
          3862,
          343,
          528,
          45303,
          16183,
          4993,
          910148,
          328,
          4664,
          1063,
          100,
          1423,
          1087,
          229,
          341,
          878,
          4512,
          757530,
          736284,
          105549,
          20478,
          1892,
          2644,
          832,
          153,
          2971,
          378909,
          118,
          1252,
          545147,
          6025,
          237282,
          1897,
          25459,
          50489,
          372,
          2456,
          1442,
          9506,
          140,
          341,
          3224,
          10295,
          151022,
          2258,
          2135,
          17867,
          863,
          370,
          1749,
          213,
          4729,
          46,
          100,
          5657,
          7155,
          9506,
          1749,
          1453,
          24840,
          888,
          8097,
          60,
          725,
          4726,
          1700,
          4090,
          320420,
          1946,
          184,
          2807,
          320420,
          642,
          595,
          248858,
          973849,
          1595797,
          302,
          530,
          910148,
          239,
          4573,
          21902,
          489,
          5989,
          122111,
          4056,
          11256,
          92106,
          238602,
          2054,
          48194,
          341,
          1261,
          1770,
          1686,
          222,
          14228,
          5621,
          413574,
          630,
          111,
          207410,
          733,
          776,
          471,
          3224,
          673342,
          6713,
          397,
          277,
          1532,
          42619,
          338,
          525713,
          1923,
          828,
          564,
          1383,
          1583,
          76,
          27020,
          6120,
          9521,
          493806,
          3996,
          365,
          106,
          832,
          5875,
          1507,
          1126,
          4424,
          5354,
          217,
          3805,
          20478,
          7155,
          648,
          37,
          77,
          6460,
          509,
          2435,
          1526206,
          331,
          509,
          128715,
          2471,
          151785,
          46,
          4049,
          602,
          1858,
          606,
          128715,
          1966,
          601723,
          2661,
          8333,
          1312,
          4653,
          1360,
          743,
          238602,
          263,
          372,
          49,
          753116,
          1725,
          972,
          34153,
          18408,
          134056,
          5354,
          5512,
          21437,
          413574,
          640470,
          744,
          21134,
          1684,
          1760,
          1472,
          3032,
          1523,
          1140,
          2303,
          35439,
          832,
          564,
          241,
          645,
          673342,
          3495,
          5875,
          355,
          35371,
          42619,
          13602,
          6284,
          3402,
          2135,
          20328,
          198,
          84106,
          976,
          2317,
          6703,
          2206,
          460,
          99,
          1617,
          14742,
          1139,
          6841,
          79008,
          338,
          1131,
          2383912,
          217,
          217,
          2121,
          973849,
          135332,
          1228,
          1490,
          6025,
          192805,
          3996,
          38912,
          378909,
          673342,
          54287,
          1420,
          2870,
          95015,
          1166,
          798,
          2408,
          795,
          4056,
          28739,
          271,
          1506,
          407,
          1195,
          568,
          5950,
          28425,
          276002,
          1532,
          1140,
          47249,
          10717,
          2408,
          1363,
          1970,
          2523,
          9815,
          198,
          61,
          863,
          129,
          13717,
          3730,
          260,
          1631,
          128354,
          165556,
          1643,
          2836,
          53,
          6284,
          30770,
          4729,
          647,
          1201,
          320,
          3395,
          3032,
          19408,
          198,
          1504,
          94325,
          3066,
          17867,
          320420,
          2092,
          5662,
          106,
          52126,
          564,
          71335,
          466,
          1312922,
          5908,
          324,
          20478,
          4056,
          9784,
          1228,
          5507,
          1970,
          1368,
          1760,
          67082,
          922,
          32891,
          28739,
          1533,
          217,
          35371,
          6460,
          224256,
          12349,
          10076,
          84106,
          1087,
          1131,
          2376,
          1478,
          1789,
          736284,
          1383,
          1810,
          2401,
          4306,
          5657,
          391389,
          1804,
          27971,
          1165,
          214518,
          271,
          832,
          248858,
          320,
          1909,
          760,
          3688,
          34496,
          3096,
          5507,
          84106,
          5196,
          885,
          3807,
          328,
          42384,
          1725,
          6460,
          2142,
          302,
          4542,
          320420,
          376,
          686,
          606,
          2395,
          3684,
          267,
          1132,
          1506,
          4015,
          540,
          10256,
          2016,
          14783,
          139650,
          22930,
          5507,
          151785,
          63,
          4198,
          823,
          601723,
          242,
          1051,
          836,
          519,
          2870,
          1178,
          912,
          606,
          140,
          6629,
          242,
          895,
          680,
          71463,
          525713,
          5732,
          1943,
          1656,
          67858,
          1478,
          1689,
          10256,
          725,
          105549,
          6951,
          136895,
          2135,
          5621,
          165,
          2054,
          14742,
          5760,
          376,
          149,
          6006,
          470,
          1080,
          104396,
          1126,
          1490,
          10256,
          2457,
          4471,
          124967,
          190,
          2097,
          133,
          308,
          191096,
          1288,
          478,
          302,
          302,
          2376,
          1686,
          1526206,
          116001,
          1577385,
          2870,
          85,
          237282,
          42817,
          4603,
          633,
          248,
          1725,
          817312,
          1263321,
          2089,
          19054,
          663,
          23,
          3688,
          5211,
          1654,
          3996,
          14228,
          914,
          60,
          145,
          338,
          55581,
          16163,
          163415,
          184,
          3395,
          1791,
          1725,
          1970,
          1420,
          836,
          8333,
          192805,
          1423,
          1324,
          1261,
          1758,
          5666,
          4664,
          3996,
          74,
          1770,
          3032,
          4593,
          118,
          5791,
          1504,
          3289,
          54767,
          86954,
          144160,
          4913,
          1363,
          94014,
          258,
          276002,
          9496,
          2870,
          530,
          2906700,
          743,
          1725,
          2304,
          302,
          19685,
          6006,
          191096,
          1334,
          17867,
          2836,
          71335,
          1360,
          632,
          4154,
          899,
          471,
          1186,
          2408,
          54767,
          6508,
          427,
          606,
          7430,
          4542,
          49,
          2906700,
          5438,
          22305,
          5507,
          2060,
          22930,
          1363,
          1051,
          255,
          641349,
          741,
          21125,
          14075,
          248,
          46,
          4354,
          5760,
          1493,
          21134,
          248858,
          136,
          2092,
          5895,
          2435,
          824,
          520,
          128715,
          7155,
          198,
          299480,
          95,
          1420,
          151785,
          828,
          242,
          320420,
          11751,
          267,
          601723,
          1368,
          77,
          346,
          2328,
          1517,
          8333,
          17867,
          143,
          466,
          413574,
          267,
          5548,
          48194,
          92043,
          194500,
          885,
          276,
          2036,
          77,
          5760,
          6951,
          7268,
          823,
          5657,
          100,
          606,
          2135,
          2036,
          207410,
          502,
          241,
          153,
          1532,
          5211,
          2566,
          1563,
          413574,
          459921,
          153,
          233717,
          178,
          725,
          1617,
          970,
          3289,
          732,
          1577385,
          84106,
          53,
          31515,
          2807,
          4653,
          687276,
          1563,
          828,
          1100,
          1334,
          12335,
          1804,
          1532,
          910148,
          75830,
          207410,
          24536,
          27020,
          144160,
          276002,
          647,
          3688,
          2290,
          10717,
          151815,
          8874,
          272,
          1675,
          346,
          54287,
          128354,
          922,
          795,
          1684,
          1892,
          2408,
          9051,
          331,
          4005,
          145,
          321,
          910148,
          5621,
          95,
          241,
          54185,
          1102,
          5507,
          4074,
          1666,
          581,
          1461,
          878,
          178,
          509,
          1810,
          804,
          308,
          4677,
          128715,
          824,
          35439,
          242,
          645,
          24536,
          190178,
          128,
          49,
          116155,
          110,
          2504700,
          895,
          1102,
          149,
          1063,
          399,
          4306,
          116001,
          239,
          601723,
          4575,
          1577385,
          76,
          1831,
          1979,
          248,
          633,
          23727,
          2368,
          19685,
          28425,
          749635,
          3430,
          1680,
          20328,
          1051,
          1577385,
          267,
          2523,
          9051,
          1631,
          4729,
          237282,
          1382480,
          413574,
          19054,
          2290,
          2121,
          5438,
          2304,
          847,
          1453,
          23,
          753116,
          10717,
          230,
          630,
          2523,
          2607,
          1312922,
          149,
          16305,
          1368,
          308,
          1063,
          6120,
          3996,
          6703,
          71463,
          804,
          5161,
          313,
          3263,
          973849,
          3487,
          165,
          3684,
          2036,
          5666,
          85,
          1631,
          1595797,
          61,
          104,
          11250,
          87124,
          31394,
          4993,
          8830,
          1679,
          14871,
          680,
          5196,
          757530,
          1979,
          28425,
          47249,
          7297,
          1684,
          37,
          85,
          1288,
          743,
          504,
          214703,
          222785,
          46,
          5848,
          1274,
          91,
          2060,
          2870,
          128715,
          13717,
          128,
          5507,
          736284,
          743,
          1490,
          743,
          198,
          475,
          111,
          673342,
          1725,
          190,
          84106,
          12486,
          16183,
          1190,
          7646,
          177,
          190178,
          759,
          6006,
          1595797,
          628,
          589,
          258,
          186140,
          467,
          229,
          372,
          271,
          3495,
          614,
          2607,
          134056,
          832,
          895,
          2376,
          722,
          1512,
          493806,
          2036,
          1766,
          922,
          349,
          140,
          4542,
          3776,
          2158,
          372,
          139650,
          3104,
          217,
          2607,
          172817,
          12486,
          213,
          795,
          1126,
          54185,
          67082,
          27971,
          3085,
          46,
          71335,
          372,
          2504700,
          241,
          824,
          5901,
          1686,
          6120,
          606,
          1179,
          307,
          3876,
          28425,
          3458,
          9587,
          190,
          606,
          1312922,
          2807,
          151022,
          276002,
          1228,
          54287,
          2870,
          341,
          733,
          1506,
          1166,
          30770,
          4677,
          163415,
          4913,
          33917,
          1532,
          2470,
          230,
          736284,
          71335,
          308,
          4138,
          5875,
          69,
          754,
          105549,
          346,
          69,
          168,
          1453,
          2368,
          1228,
          3776,
          48194,
          647,
          8007,
          5895,
          1791,
          116001,
          3279,
          1725,
          54767,
          18408,
          163415,
          885,
          601723,
          761,
          238602,
          4664,
          3684,
          1324,
          532,
          271,
          1725,
          509,
          206,
          3996,
          99,
          28739,
          9034,
          50835,
          1139,
          206,
          3994,
          647,
          27971,
          27829,
          307,
          23,
          270712,
          565,
          1760,
          129,
          910148,
          4542,
          5950,
          111,
          1850,
          93193,
          118,
          765,
          124967,
          732,
          77,
          11256,
          564,
          1970,
          7297,
          35439,
          9815,
          248,
          337,
          863,
          230,
          13422,
          470,
          16305,
          198,
          1201,
          1645,
          136,
          276,
          976,
          760,
          350,
          15426,
          1804,
          5989,
          1675,
          1847,
          969,
          248,
          128715,
          206,
          1530,
          836,
          198,
          741,
          1324,
          328,
          45303,
          642,
          2263,
          324,
          467,
          73,
          18408,
          153,
          223,
          94014,
          502,
          899,
          2408,
          530,
          1532,
          139650,
          1302,
          725,
          1274,
          172817,
          493806,
          680,
          1606,
          863,
          1139,
          47249,
          34496,
          824,
          2258,
          17047,
          520,
          163415,
          467,
          1897,
          530,
          7692,
          1760,
          1140,
          2807,
          47,
          1324,
          765,
          3451,
          1760,
          324,
          725,
          1382480,
          308,
          15647,
          4664,
          532,
          4677,
          35705,
          3285,
          78968,
          914,
          7268,
          564,
          76383,
          67082,
          2395,
          320420,
          3699,
          53,
          94014,
          1675,
          1892,
          13602,
          19685,
          2368,
          2089,
          477,
          50835,
          11250,
          24645,
          4895,
          272134,
          3263,
          1565,
          824,
          2504700,
          76,
          106,
          606,
          47249,
          1850,
          639,
          3032,
          267,
          18182,
          760,
          2807,
          42817,
          1631,
          4533,
          1087,
          3699,
          4878,
          15426,
          1263321,
          2376,
          4533,
          10295,
          1923,
          213,
          2526,
          718,
          140,
          4542,
          969,
          4172,
          4575,
          1126,
          551,
          337,
          76,
          13717,
          471,
          1970,
          144160,
          134056,
          238602,
          4090,
          9993,
          22930,
          28278,
          1423,
          331,
          28425,
          1271,
          276002,
          737,
          653,
          1923,
          1850,
          3224,
          459921,
          372,
          3395,
          1195,
          732,
          910148,
          1666,
          59744,
          1360,
          687276,
          2395,
          1656,
          27971,
          1526206,
          149,
          1143,
          176,
          1631,
          4726,
          13973,
          5161,
          1577385,
          3289,
          5657,
          2856,
          4056,
          725,
          4005,
          247,
          914,
          2457,
          291,
          566,
          2471,
          5211,
          18182,
          6703,
          269,
          1766,
          16163,
          22305,
          55581,
          308,
          1810,
          6581,
          2856,
          2471,
          4074,
          248,
          736284,
          1196,
          724,
          450,
          861,
          18408,
          365,
          478,
          269,
          2971,
          1382480,
          602,
          4575,
          60,
          532,
          35439,
          928,
          3224,
          5196,
          4845,
          163415,
          136,
          74,
          229,
          376,
          1178,
          116001,
          3279,
          1196,
          551,
          4198,
          2376,
          31515,
          248,
          1526206,
          2206,
          3776,
          1178,
          3104,
          1490,
          186140,
          328,
          92294,
          4913,
          545147,
          413574,
          149,
          1758,
          153,
          9993,
          6018,
          1063,
          50489,
          136,
          116001,
          255,
          19090,
          54287,
          1606,
          1178,
          13835,
          328,
          9772,
          1271,
          6018,
          641,
          17047,
          4542,
          263,
          206,
          18182,
          258,
          741,
          2135,
          6018,
          6434,
          2971,
          6006,
          269,
          1461,
          53,
          46563,
          1745,
          1645,
          1506,
          741,
          241,
          2142,
          6841,
          2807,
          217,
          344,
          2395,
          1368,
          1414,
          192,
          18128,
          1360,
          641349,
          937,
          3776,
          27020,
          2135,
          823,
          2870,
          2317,
          2523,
          136,
          3032,
          190,
          47249,
          5895,
          116001,
          71485,
          1304,
          7646,
          276002,
          158701,
          965,
          343,
          1831,
          737,
          54185,
          77,
          3833,
          313,
          1850,
          217,
          106,
          2290,
          166081,
          95035,
          106,
          337,
          1228,
          19685,
          229,
          151022,
          207,
          381459,
          76,
          190178,
          222785,
          5341,
          144160,
          2471,
          343,
          4729,
          504,
          31394,
          928,
          18408,
          10256,
          1178,
          3289,
          2870,
          571,
          2526,
          630,
          493806,
          67082,
          2097,
          5161,
          765,
          21635,
          427,
          765,
          4664,
          302,
          1504,
          254282,
          832,
          85,
          95,
          214703,
          67858,
          2092,
          1334,
          15426,
          798,
          2870,
          158701,
          4677,
          6469,
          489,
          79008,
          46,
          922,
          2526,
          1334,
          798,
          269,
          1645,
          4074,
          9815,
          19054,
          2836,
          5848,
          105638,
          3996,
          4367,
          1051,
          5621,
          568,
          454,
          184,
          741,
          3096,
          532,
          725,
          606,
          737,
          99,
          1512,
          2290,
          4172,
          13422,
          94325,
          3096,
          298,
          1897,
          5875,
          140,
          3224,
          321490,
          16305,
          6006,
          528,
          2274,
          2470,
          1749,
          1758,
          5211,
          2644,
          3451,
          2060,
          31515,
          741,
          233717,
          502,
          207410,
          6434,
          324,
          320420,
          976,
          35299,
          54287,
          14871,
          111,
          54287,
          973849,
          21134,
          391389,
          217,
          722,
          123,
          687276,
          18182,
          55581,
          136,
          133,
          760,
          13973,
          765,
          3223,
          7565,
          59744,
          2408,
          2870,
          1089,
          320420,
          27020,
          1213,
          732,
          1078,
          13717,
          230,
          28278,
          1745,
          258,
          19408,
          60,
          20478,
          4198,
          3224,
          1201,
          203571,
          34882,
          313,
          757530,
          149,
          355,
          725,
          832,
          633,
          168,
          378909,
          21134,
          1766,
          1195,
          165,
          241,
          136,
          263,
          2036,
          104396,
          137,
          19408,
          1512,
          128354,
          2807,
          34496,
          753116,
          601723,
          589,
          1190,
          230,
          14783,
          47249,
          1563,
          2376,
          190178,
          116001,
          760,
          372,
          1643,
          4512,
          247,
          2457,
          103927,
          3833,
          206,
          83,
          1274,
          1807,
          67082,
          270712,
          912,
          4913,
          313,
          23727,
          1271,
          163415,
          2526,
          2870,
          4993,
          1909,
          2376,
          1446,
          7692,
          7155,
          16163,
          151785,
          477,
          595,
          1334,
          176,
          18128,
          2078,
          1897,
          5791,
          2368,
          19054,
          218,
          811,
          736284,
          1725,
          1190,
          1382480,
          824,
          800,
          498,
          22930,
          139,
          8269,
          248,
          5621,
          55581,
          1595797,
          1526206,
          3684,
          376,
          6120,
          2135,
          1478,
          4677,
          2317,
          5161,
          1645,
          1804,
          1563,
          153,
          551,
          1051,
          391389,
          31394,
          365,
          427,
          568,
          673342,
          95035,
          3202,
          1312922,
          33917,
          242,
          565,
          1382480,
          331,
          224256,
          847,
          369,
          568,
          7646,
          1565,
          177,
          95035,
          61,
          1383,
          67082,
          399,
          4726,
          9496,
          4138,
          333497,
          736284,
          545147,
          18408,
          639,
          263,
          104,
          31394,
          7155,
          932,
          798,
          2457,
          606,
          2836,
          46,
          100,
          27829,
          88735,
          4172,
          1565,
          504,
          8019,
          2644,
          67858,
          10076,
          136,
          4542,
          60,
          105549,
          4677,
          1446,
          23,
          17047,
          365,
          50835,
          1126,
          139,
          3402,
          313,
          504,
          391389,
          28739,
          163415,
          1966,
          3096,
          213,
          378909,
          54287,
          1288,
          7692,
          206,
          653,
          71335,
          1595797,
          722,
          2807,
          973849,
          3395,
          35299,
          4533,
          1423,
          1684,
          970,
          5621,
          798,
          2523,
          6508,
          313,
          2376,
          111,
          13602,
          1970,
          1563,
          4159,
          140,
          27971,
          782,
          184,
          2408,
          6006,
          836,
          836,
          7268,
          184,
          2089,
          4729,
          20328,
          32891,
          1684,
          31515,
          2135,
          632,
          321,
          46563,
          687276,
          50489,
          823,
          67082,
          163415,
          277,
          5354,
          1368,
          1595797,
          276,
          100,
          2368,
          498,
          641349,
          9496,
          4090,
          1196,
          3430,
          28425,
          45303,
          286,
          5161,
          302,
          5791,
          1789,
          291,
          3776,
          571,
          1368,
          17867,
          3066,
          92043,
          59705,
          4049,
          798,
          276,
          1213,
          4074,
          540,
          276002,
          804,
          1139,
          602,
          520,
          969,
          255,
          18182,
          111,
          320,
          1302,
          192805,
          4542,
          606,
          3688,
          241,
          1526206,
          498,
          14871,
          526,
          134056,
          1892,
          3996,
          2691,
          2376,
          493,
          67082,
          1186,
          1789,
          9594,
          5451,
          50489,
          186140,
          1517,
          105549,
          5791,
          4306,
          192805,
          191096,
          78968,
          17867,
          653,
          4074,
          3430,
          5901,
          817312,
          5196,
          3996,
          530,
          11250,
          214518,
          1038,
          1850,
          7268,
          2158,
          1850,
          5621,
          2435,
          1201,
          1850,
          77,
          105549,
          158701,
          35705,
          67082,
          94325,
          969,
          737,
          1228,
          10076,
          1196,
          139650,
          1909,
          509,
          4878,
          8512,
          73,
          1312922,
          1762,
          795,
          324,
          75830,
          34882,
          104396,
          1925,
          1804,
          68211,
          149,
          49,
          973849,
          258,
          965,
          2504700,
          28278,
          1749,
          324,
          254,
          626,
          1490,
          1179,
          271,
          1760,
          888,
          11250,
          248,
          47772,
          1196,
          23,
          1645,
          1643,
          7646,
          2836,
          27020,
          1789,
          3202,
          1645,
          1423,
          73,
          2443,
          1426,
          2526,
          99,
          4049,
          5950,
          238602,
          276896,
          49,
          26120,
          19090,
          545147,
          4993,
          736284,
          171170,
          673342,
          5791,
          7987,
          43102,
          4677,
          136895,
          139,
          4367,
          2518,
          1504,
          526,
          55581,
          55581,
          4074,
          602,
          4878,
          343,
          1523,
          35439,
          3508,
          4367,
          502,
          1178,
          922,
          3487,
          105549,
          2328,
          4290,
          1089,
          2054,
          1523,
          4677,
          3402,
          6841,
          863,
          606,
          9512,
          493806,
          459921,
          36784,
          12486,
          5726,
          71485,
          601723,
          595,
          2870,
          1087,
          765,
          4575,
          176,
          471,
          1595797,
          112,
          320,
          320420,
          9815,
          32891,
          186140,
          4878,
          632,
          805,
          4729,
          1810,
          70,
          341,
          73,
          1725,
          1762,
          16305,
          2016,
          2211,
          1571,
          566,
          2691,
          17047,
          1022298,
          207410,
          14075,
          467,
          1493,
          2408,
          878,
          46,
          581,
          331,
          4005,
          269,
          888,
          581,
          17867,
          344,
          298,
          7297,
          95,
          722,
          140,
          1533,
          2786,
          35439,
          3766,
          2054,
          516,
          5927,
          269,
          695,
          10256,
          6469,
          4895,
          8333,
          191096,
          6951,
          4508,
          1892,
          885,
          11751,
          91,
          128,
          5760,
          19408,
          1810,
          6469,
          7155,
          123,
          207,
          4512,
          2526,
          1725,
          722,
          241,
          6841,
          718,
          1186,
          3805,
          2906700,
          218,
          5760,
          4471,
          2121,
          248,
          3508,
          128,
          14783,
          9165,
          222,
          116001,
          2518,
          571,
          478,
          5875,
          1979,
          1132,
          53,
          28739,
          165556,
          741,
          372,
          1563,
          87124,
          222,
          2135,
          111,
          42619,
          42384,
          976,
          12486,
          93193,
          324,
          205,
          1563,
          1472,
          1022298,
          1051,
          76,
          601723,
          24840,
          7163,
          166081,
          76,
          15426,
          6120,
          254282,
          116155,
          470,
          2435,
          9565,
          1334,
          914,
          1461,
          413574,
          11250,
          343,
          1051,
          1165,
          2016,
          205,
          69793,
          3776,
          1426,
          922,
          33804,
          15269,
          2376,
          338,
          4290,
          50835,
          2906700,
          459921,
          2644,
          824,
          12335,
          4090,
          5778,
          241,
          198,
          7155,
          1383,
          43102,
          3996,
          1382480,
          471,
          378909,
          269,
          1749,
          545147,
          33804,
          798,
          687276,
          509,
          1304,
          36438,
          230,
          1139,
          9521,
          545147,
          811,
          105638,
          1858,
          1645,
          67082,
          5875,
          2906700,
          4354,
          970,
          1126,
          4913,
          504,
          509,
          28739,
          2906700,
          6025,
          1478,
          1051,
          19090,
          9679,
          595,
          11250,
          1196,
          4575,
          1512,
          1595797,
          2644,
          295,
          186140,
          1302,
          5778,
          258,
          99,
          2303,
          1426,
          4015,
          6469,
          75903,
          28739,
          1631,
          2644,
          2504700,
          1190,
          31394,
          18408,
          1442,
          1089,
          899,
          914,
          718,
          5621,
          1252,
          23,
          1312922,
          260,
          14742,
          45303,
          653,
          313,
          526,
          899,
          1120,
          140,
          145,
          2304,
          16183,
          3688,
          15426,
          1019,
          1143,
          233717,
          540,
          172247,
          104396,
          74,
          215,
          606,
          4677,
          116001,
          302,
          1595797,
          7987,
          1165,
          2906700,
          6951,
          1423,
          3096,
          518429,
          45303,
          23,
          540,
          5619,
          761,
          94014,
          2142,
          313,
          355,
          1970,
          9679,
          355,
          3228,
          53,
          258,
          743,
          4081,
          69,
          5211,
          647,
          2870,
          928,
          395,
          466,
          21902,
          1383,
          46563,
          1241364,
          2368,
          475,
          6951,
          4542,
          42384,
          298,
          4778,
          136895,
          964,
          1143,
          1766,
          602,
          413574,
          519,
          647,
          24536,
          144160,
          1228,
          571,
          295,
          71485,
          276,
          964,
          4913,
          198,
          140,
          26551,
          1645,
          2471,
          1201,
          5726,
          19685,
          76383,
          5648,
          341,
          7155,
          836,
          663,
          68211,
          526,
          3451,
          1512,
          2328,
          1312922,
          76,
          337,
          139,
          2304,
          192,
          184,
          4533,
          863,
          765,
          2872,
          630,
          2368,
          4172,
          1577385,
          217,
          1645,
          277,
          743,
          7297,
          2504700,
          899,
          493806,
          4049,
          467,
          478,
          18182,
          5211,
          965,
          207,
          1360,
          910148,
          530,
          86954,
          3395,
          230,
          47772,
          7155,
          5760,
          3994,
          9521,
          2872,
          4729,
          171170,
          254282,
          32891,
          77,
          407,
          532,
          1645,
          213,
          1100,
          91,
          328,
          5161,
          5791,
          207,
          46,
          1228,
          4354,
          71335,
          184,
          27020,
          4895,
          1228,
          3096,
          498,
          372,
          6951,
          824,
          176,
          1847,
          11250,
          680,
          2457,
          111,
          1631,
          525713,
          1334,
          1507,
          1506,
          910148,
          124967,
          184,
          653,
          7163,
          2526,
          1789,
          459921,
          24840,
          272,
          255,
          27020,
          1120,
          3833,
          732,
          1831,
          9784,
          3684,
          104396,
          313,
          6841,
          123,
          124967,
          277,
          530,
          4573,
          1202,
          237282,
          397,
          409656,
          28278,
          2303,
          1643,
          2566,
          95015,
          1745,
          1770,
          186140,
          190178,
          459921,
          743,
          13422,
          177,
          565,
          532,
          471,
          68211,
          1850,
          1645,
          247,
          23,
          2036,
          71463,
          6025,
          33917,
          123373,
          5438,
          1563,
          295,
          717255,
          320420,
          736284,
          470,
          467,
          4913,
          230,
          34153,
          71463,
          229,
          1038,
          71485,
          307,
          765,
          31394,
          4508,
          566,
          6841,
          51427,
          163415,
          18182,
          19685,
          1078,
          5196,
          341043,
          466,
          128715,
          1766,
          350,
          888,
          478,
          43102,
          258,
          3994,
          639,
          331,
          163415,
          21902,
          3996,
          466,
          2644,
          34496,
          3066,
          2661,
          2456,
          2786,
          2395,
          1490,
          687276,
          46563,
          23,
          153,
          1770,
          324,
          1988,
          1766,
          4056,
          2054,
          46563,
          94014,
          32891,
          87124,
          1577385,
          133,
          2644,
          79613,
          4138,
          6841,
          59744,
          4542,
          144160,
          158701,
          504,
          4074,
          34496,
          5760,
          6284,
          35299,
          84106,
          70,
          5908,
          9772,
          92106,
          1426,
          69,
          372,
          6284,
          9594,
          3994,
          47,
          4154,
          589,
          427,
          1789,
          111,
          5621,
          344,
          2691,
          1179,
          23,
          2290,
          653,
          722,
          1523,
          1506,
          798,
          1453,
          522,
          5901,
          969,
          1446,
          1453,
          2148,
          92294,
          4993,
          1478,
          626,
          28739,
          695,
          1749,
          55345,
          1523,
          5778,
          6951,
          92043,
          194500,
          3508,
          1426,
          5341,
          391389,
          566,
          513,
          1051,
          328,
          59744,
          5621,
          6841,
          2872,
          6120,
          7646,
          471,
          372,
          295,
          16183,
          192805,
          42619,
          76383,
          128,
          3495,
          307,
          5196,
          7692,
          3289,
          1306,
          376,
          110,
          6120,
          50835,
          2691,
          1617,
          4056,
          470,
          1563,
          4172,
          6951,
          3066,
          12349,
          37,
          111,
          4471,
          828,
          10256,
          6006,
          333497,
          3085,
          477,
          1504,
          28739,
          1274,
          3833,
          641,
          741,
          321,
          1363,
          23,
          2383912,
          630,
          33804,
          129,
          564,
          2368,
          269,
          242,
          4056,
          4993,
          376,
          92294,
          4677,
          1533,
          3684,
          5791,
          1334,
          16305,
          1512,
          215,
          2661,
          26551,
          647,
          4913,
          140,
          601723,
          67858,
          3202,
          3395,
          2518,
          2526,
          4074,
          864,
          631,
          460,
          1526206,
          165556,
          2290,
          346,
          9034,
          5875,
          1791,
          3104,
          1758,
          276002,
          270712,
          471,
          291,
          1506,
          710,
          395,
          137,
          18408,
          899,
          95,
          17047,
          471,
          69,
          1019,
          4533,
          413574,
          45303,
          140,
          116001,
          269,
          31394,
          151022,
          61,
          9594,
          165556,
          1684,
          759,
          1312922,
          286,
          804,
          376,
          3688,
          1595797,
          381459,
          144160,
          1196,
          910148,
          413574,
          937,
          3119,
          142,
          565,
          695,
          489,
          95,
          17867,
          3730,
          1892,
          6120,
          1190,
          1442,
          85,
          1131,
          970,
          757530,
          759,
          1909,
          1288,
          4677,
          1131,
          129,
          5161,
          71463,
          140,
          1312922,
          123,
          52,
          20328,
          2906700,
          3228,
          1312,
          71335,
          516,
          1490,
          1453,
          628,
          23727,
          35439,
          217,
          2661,
          1577385,
          139,
          6508,
          75903,
          77,
          467,
          7155,
          3451,
          4895,
          1517,
          35371,
          4354,
          99,
          1850,
          3996,
          224256,
          192805,
          10076,
          2786,
          606,
          1595797,
          341,
          2906700,
          50835,
          1725,
          77,
          17047,
          736284,
          878,
          4533,
          79613,
          4575,
          223,
          759,
          1252,
          92985,
          5950,
          140,
          899,
          912,
          4729,
          1263321,
          648,
          3066,
          832,
          4367,
          1909,
          6951,
          1383,
          1414,
          2470,
          823,
          107941,
          741,
          128715,
          1312,
          254282,
          46,
          344,
          19685,
          1810,
          3776,
          5760,
          172817,
          3688,
          972,
          7268,
          970,
          1645,
          673342,
          126,
          504,
          3487,
          753116,
          67082,
          17047,
          6581,
          310,
          878,
          9034,
          964,
          2443,
          2092,
          3395,
          302,
          1196,
          378909,
          1412,
          409656,
          2092,
          145,
          1453,
          237282,
          156391,
          3495,
          2870,
          94014,
          9521,
          1063,
          1506,
          302,
          270712,
          5901,
          540,
          13973,
          526,
          3807,
          15269,
          378909,
          2870,
          2376,
          224256,
          242,
          642,
          104,
          302,
          2054,
          19090,
          759,
          3343,
          308,
          276002,
          2223,
          11256,
          13602,
          2526,
          310,
          6703,
          22305,
          509,
          3104,
          1850,
          18760,
          99,
          1766,
          276002,
          190178,
          1504,
          1689,
          450,
          737,
          5548,
          5760,
          1970,
          1858,
          1628,
          1165,
          525713,
          1241364,
          565,
          378909,
          1078,
          258,
          128715,
          4056,
          99,
          186140,
          15426,
          6469,
          3862,
          14871,
          1302,
          198,
          54185,
          320420,
          571,
          1078,
          1760,
          247,
          84106,
          151785,
          804,
          1089,
          4074,
          2443,
          3224,
          635,
          3684,
          165,
          2092,
          7155,
          22930,
          59744,
          1126,
          922,
          540,
          1745,
          2566,
          18182,
          1196,
          626,
          733,
          1423,
          241,
          1446,
          632,
          1645,
          263,
          757530,
          1766,
          5989,
          27971,
          4542,
          1490,
          1263321,
          1563,
          2303,
          409656,
          1766,
          3285,
          316665,
          4993,
          3996,
          673342,
          1565,
          1766,
          1143,
          2211,
          2971,
          4993,
          76,
          4542,
          2092,
          2799,
          1666,
          2135,
          1631,
          18459,
          6951,
          145,
          3263,
          338,
          270712,
          795,
          21134,
          6841,
          2691,
          489,
          19685,
          31515,
          1831,
          30770,
          1631,
          568,
          346,
          2135,
          5875,
          1725,
          1288,
          3223,
          771,
          76383,
          722,
          1312922,
          45303,
          34496,
          545147,
          2092,
          14871,
          24645,
          6508,
          16163,
          498,
          94325,
          1271,
          1302,
          2135,
          14228,
          5161,
          973849,
          3430,
          23805,
          16183,
          59744,
          1512,
          5341,
          25459,
          310,
          885,
          381459,
          2135,
          4005,
          632,
          504,
          84106,
          3487,
          213,
          11751,
          885,
          1943,
          409656,
          95035,
          1324,
          6703,
          163415,
          1360,
          3096,
          47772,
          165556,
          3224,
          1414,
          718,
          333497,
          11256,
          67082,
          1201,
          2317,
          10295,
          836,
          2501,
          3395,
          1892,
          895,
          832,
          3766,
          804,
          50489,
          1178,
          841711,
          214703,
          824,
          4508,
          1780,
          365,
          263,
          1925,
          1442,
          32891,
          5438,
          186140,
          177,
          99,
          248,
          504,
          972,
          31515,
          1656,
          1675,
          14871,
          276002,
          53,
          91,
          36784,
          28739,
          5211,
          55581,
          824,
          3224,
          331,
          1051,
          1420,
          1274,
          606,
          378909,
          761,
          158701,
          9565,
          478,
          1577385,
          3833,
          341,
          71463,
          10295,
          1420,
          4778,
          7155,
          9679,
          372,
          255,
          717255,
          19685,
          48194,
          2036,
          7268,
          722,
          540,
          466,
          76,
          1472,
          43102,
          5548,
          198,
          50489,
          24840,
          1241364,
          95,
          1725,
          5507,
          165,
          1847,
          5657,
          76383,
          782,
          1946,
          76,
          255,
          2457,
          717255,
          5548,
          2368,
          1201,
          2836,
          2054,
          736284,
          1166,
          922,
          71335,
          5875,
          1791,
          1988,
          151785,
          590,
          16183,
          5507,
          4154,
          137,
          1643,
          18760,
          5161,
          564,
          836,
          2644,
          717255,
          13061,
          3289,
          1420,
          186140,
          1195,
          2691,
          5161,
          5341,
          128715,
          92043,
          1680,
          3224,
          95,
          350,
          2526,
          18408,
          145,
          1196,
          9815,
          16163,
          1228,
          18128,
          663,
          217,
          333497,
          324,
          1766,
          75903,
          502,
          680,
          271,
          2471,
          346,
          255,
          320420,
          753116,
          217,
          564,
          110,
          493806,
          224256,
          149,
          19054,
          910148,
          841711,
          653,
          759,
          77,
          350,
          754,
          163415,
          10076,
          134056,
          5666,
          2206,
          4306,
          1312,
          551,
          350,
          269,
          2870,
          1595797,
          3343,
          263,
          3224,
          2054,
          2607,
          493,
          68211,
          33804,
          4367,
          8512,
          111,
          321,
          1241364,
          680,
          71485,
          1120,
          7155,
          601723,
          970,
          1453,
          686,
          341043,
          3402,
          258,
          277,
          8830,
          25459,
          190178,
          70,
          45100,
          165556,
          1810,
          4090,
          2206,
          2307,
          229,
          51427,
          343,
          4726,
          565,
          23727,
          2092,
          123,
          129,
          1946,
          1532,
          4172,
          540,
          26551,
          673342,
          1261,
          6006,
          836,
          269,
          33804,
          126,
          104,
          222785,
          6460,
          817312,
          6460,
          2304,
          286,
          2368,
          836,
          3994,
          4198,
          338,
          92294,
          6460,
          3224,
          1858,
          372,
          489,
          9815,
          237282,
          177,
          3766,
          885,
          104396,
          1102,
          1680,
          647,
          927396,
          6018,
          92985,
          7646,
          276,
          1577385,
          15426,
          100,
          7692,
          191096,
          69,
          163415,
          478,
          172817,
          695,
          52126,
          1080,
          2906700,
          1312922,
          1252,
          1063,
          1512,
          123373,
          55345,
          4575,
          178,
          1312922,
          381459,
          194500,
          509,
          237282,
          526,
          122111,
          84106,
          1988,
          50489,
          3263,
          795,
          1925,
          4508,
          34882,
          4895,
          149,
          1766,
          1970,
          493,
          1897,
          753116,
          477,
          653,
          263,
          413574,
          964,
          191096,
          1126,
          310,
          139,
          328,
          718,
          15647,
          122111,
          972,
          4542,
          1453,
          59705,
          21134,
          2607,
          2872,
          71335,
          35439,
          391389,
          509,
          5927,
          233717,
          74,
          2518,
          126,
          8269,
          798,
          129,
          922,
          4306,
          1847,
          2263,
          1583,
          532,
          118,
          2807,
          237282,
          520,
          21134,
          328,
          2092,
          1850,
          804,
          1263321,
          6284,
          263,
          71463,
          10256,
          6951,
          3395,
          207,
          104,
          1512,
          84106,
          3223,
          54185,
          191096,
          95,
          3451,
          30770,
          878,
          493,
          673342,
          397,
          190178,
          2368,
          177,
          817312,
          139,
          20478,
          2607,
          2379,
          6841,
          823,
          3224,
          5196,
          370,
          2501,
          190,
          217,
          1426,
          84861,
          804,
          1490,
          459921,
          271,
          87124,
          365,
          3395,
          3032,
          493,
          1078,
          2870,
          1461,
          760,
          21134,
          31515,
          1453,
          1178,
          2202,
          1446,
          144160,
          1606,
          43,
          15647,
          238602,
          910148,
          5895,
          105549,
          2078,
          1847,
          302,
          631,
          94325,
          1490,
          24645,
          59744,
          21902,
          964,
          186140,
          123,
          302,
          519,
          5577,
          128354,
          99,
          3263,
          176,
          673342,
          973849,
          1656,
          1595797,
          341,
          9815,
          71463,
          632,
          1675,
          1595797,
          6508,
          1126,
          217,
          2054,
          192805,
          17047,
          3766,
          722,
          3766,
          23727,
          310,
          214703,
          6120,
          545147,
          316665,
          122111,
          1507,
          276896,
          4198,
          42619,
          771,
          9815,
          5621,
          166081,
          1523,
          23727,
          1563,
          601723,
          1563,
          647,
          34153,
          165556,
          3343,
          36438,
          123373,
          2471,
          9034,
          14871,
          248,
          1131,
          75830,
          6508,
          20478,
          1312,
          5791,
          34153,
          1690,
          932,
          75903,
          7297,
          112,
          31394,
          222,
          192,
          213,
          1595797,
          111,
          134056,
          11256,
          759,
          5621,
          190178,
          1126,
          328,
          647,
          35439,
          337,
          100,
          233717,
          67082,
          52126,
          391389,
          1847,
          2504700,
          5666,
          2258,
          1925,
          568,
          93193,
          163415,
          6713,
          795,
          165556,
          504,
          937,
          263,
          459921,
          2691,
          804,
          641349,
          13717,
          277,
          7646,
          4729,
          85,
          718,
          381459,
          17047,
          50835,
          1363,
          144160,
          23,
          1078,
          653,
          601723,
          213,
          12335,
          741,
          743,
          1423,
          35299,
          4726,
          241,
          2607,
          413574,
          255,
          181438,
          6120,
          128354,
          771,
          9772,
          6713,
          50835,
          241,
          12486,
          260,
          34882,
          895,
          337,
          2223,
          1583,
          1532,
          1766,
          3805,
          2376,
          47249,
          6469,
          632,
          299480,
          19054,
          639,
          94014,
          79008,
          1063,
          31394,
          1493,
          338,
          1507,
          355,
          1517,
          111,
          267,
          4895,
          241,
          589,
          28739,
          184,
          1453,
          14742,
          13717,
          759,
          1923,
          96942,
          241,
          302,
          744,
          68211,
          92043,
          217,
          571,
          718,
          1478,
          92608,
          27020,
          1360,
          2836,
          2691,
          19408,
          2379,
          1360,
          19685,
          471,
          1324,
          1075,
          1019,
          454,
          2376,
          365,
          725,
          1533,
          1789,
          260,
          1507,
          1252,
          1606,
          139650,
          722,
          841711,
          782,
          2644,
          1228,
          1228,
          545147,
          798,
          413574,
          725,
          568,
          463,
          1472,
          1261,
          92294,
          15426,
          6951,
          1526206,
          1263321,
          145,
          722,
          399,
          71485,
          3807,
          76,
          2258,
          1304,
          3458,
          1925,
          3395,
          1126,
          895,
          530,
          50489,
          4138,
          502,
          4512,
          192,
          3862,
          3996,
          673342,
          3085,
          25459,
          28278,
          9051,
          9496,
          1970,
          836,
          2328,
          30770,
          647,
          372,
          34153,
          1143,
          391389,
          151022,
          4049,
          6629,
          242,
          118,
          4074,
          6284,
          95,
          1645,
          5512,
          6025,
          1478,
          804,
          798,
          2501,
          760,
          5732,
          1274,
          811,
          75830,
          24645,
          7297,
          53,
          937,
          7297,
          1766,
          258,
          633,
          579,
          2208,
          1102,
          1617,
          798,
          2786,
          18408,
          124967,
          136,
          9815,
          76,
          13422,
          2401,
          149,
          6713,
          1019,
          1565,
          167,
          2054,
          13973,
          645,
          207,
          2135,
          1758,
          343,
          4090,
          19408,
          2607,
          6713,
          695,
          260,
          87124,
          17047,
          516,
          922,
          153,
          969,
          137,
          1804,
          71485,
          21635,
          27971,
          545147,
          471,
          1423,
          5989,
          1263321,
          95,
          2872,
          269,
          10295,
          71485,
          471,
          5621,
          1679,
          186140,
          166081,
          525713,
          743,
          1423,
          1412,
          1201,
          229,
          1565,
          1478,
          1263321,
          2206,
          77,
          95015,
          9772,
          263,
          242,
          104,
          5895,
          328,
          6284,
          5760,
          470,
          640470,
          320420,
          79613,
          2303,
          166081,
          272134,
          640470,
          1631,
          466,
          1970,
          4508,
          165,
          88735,
          140,
          14871,
          3224,
          642,
          378909,
          42384,
          73,
          1165,
          2290,
          765,
          2142,
          571,
          836,
          128715,
          158701,
          836,
          965,
          9051,
          53,
          836,
          5507,
          532,
          308,
          2408,
          1228,
          828,
          6951,
          12486,
          55581,
          151022,
          47249,
          528,
          9051,
          1312922,
          16163,
          47211,
          7646,
          1019,
          1228,
          1453,
          12335,
          134056,
          832,
          275,
          11253,
          10256,
          579,
          86954,
          878,
          2661,
          151815,
          1897,
          27020,
          248858,
          1758,
          59705,
          50489,
          269,
          69793,
          9587,
          19054,
          14871,
          6006,
          258,
          75903,
          30770,
          2121,
          198,
          4680,
          1523,
          241,
          14075,
          5161,
          71463,
          391389,
          1126,
          11256,
          346,
          2290,
          31515,
          606,
          341,
          128354,
          350,
          2135,
          686,
          630,
          50835,
          564,
          156391,
          1252,
          190,
          525713,
          28739,
          73,
          1684,
          198,
          20328,
          23045,
          1631,
          1766,
          5875,
          5577,
          341,
          15426,
          198,
          2121,
          49,
          922,
          6006,
          47772,
          4081,
          9594,
          1178,
          260,
          1577385,
          1461,
          493,
          45303,
          91,
          37,
          378909,
          94014,
          5211,
          346,
          2526,
          217,
          71335,
          1970,
          427,
          128715,
          7155,
          320420,
          2408,
          1414,
          18182,
          18128,
          18760,
          5791,
          166081,
          718,
          104396,
          269,
          3202,
          3805,
          242,
          823,
          1426,
          3776,
          84106,
          450,
          2376,
          217,
          1583,
          92043,
          1360,
          8333,
          1831,
          579,
          54287,
          489,
          54287,
          391389,
          1532,
          969,
          26551,
          5196,
          20328,
          409656,
          5621,
          5875,
          3343,
          134056,
          450,
          165556,
          3688,
          584,
          248858,
          5341,
          238602,
          35439,
          5648,
          242,
          18760,
          653,
          1925,
          1804,
          2523,
          1019,
          2786,
          198,
          171170,
          2078,
          60,
          687276,
          673342,
          27971,
          3776,
          213,
          21134,
          525713,
          509,
          48194,
          99,
          3805,
          23727,
          19685,
          1595797,
          378909,
          78968,
          478,
          7646,
          737,
          3766,
          23,
          136,
          828,
          215,
          1563,
          1100,
          722,
          71463,
          545147,
          4542,
          1490,
          1789,
          4138,
          30770,
          5512,
          776,
          2092,
          1334,
          399,
          2206,
          45303,
          4575,
          1063,
          222785,
          270712,
          79613,
          76,
          33804,
          1526206,
          76383,
          24645,
          477,
          18128,
          276,
          3688,
          350,
          153,
          1383,
          24536,
          2317,
          277,
          409656,
          743,
          832,
          1532,
          348,
          1504,
          270712,
          1925,
          471,
          1241364,
          105638,
          1512,
          863,
          9565,
          1126,
          85,
          673342,
          4424,
          2290,
          5548,
          95015,
          23805,
          3263,
          22305,
          1423,
          217,
          1577385,
          21134,
          765,
          5512,
          1725,
          9034,
          88735,
          1571,
          137,
          450,
          1263321,
          2526,
          1909,
          633,
          35299,
          269,
          4424,
          218,
          21134,
          21902,
          2836,
          190249,
          151022,
          76383,
          757530,
          914,
          52,
          606,
          77,
          6469,
          1735,
          2401,
          1595797,
          2054,
          77,
          67082,
          158701,
          9506,
          3807,
          13717,
          4354,
          269,
          1507,
          888,
          186140,
          1442,
          5196,
          964,
          864,
          471,
          248858,
          1263321,
          35439,
          343,
          2607,
          230,
          2504700,
          2054,
          4542,
          217,
          69,
          1019,
          5927,
          648,
          254,
          324,
          177,
          217,
          95,
          2526,
          932,
          69,
          30770,
          129,
          1178,
          1517,
          49,
          1506,
          564,
          128,
          139,
          493,
          5908,
          5196,
          7268,
          140,
          4074,
          35371,
          5666,
          34496,
          1760,
          2036,
          59744,
          34153,
          6469,
          286,
          2471,
          105549,
          178,
          47249,
          20478,
          242,
          725,
          5161,
          4354,
          129,
          2870,
          36784,
          673342,
          5211,
          597,
          63,
          3876,
          7297,
          2856,
          847,
          260,
          1196,
          5791,
          15426,
          163415,
          34153,
          9594,
          46,
          737,
          6460,
          341043,
          92043,
          1195,
          741,
          525713,
          878,
          823,
          276,
          832,
          3224,
          911,
          217,
          95035,
          5726,
          320,
          6120,
          3395,
          407,
          70,
          10076,
          493806,
          828,
          722,
          632,
          16305,
          144160,
          190178,
          1490,
          48194,
          3395,
          2457,
          608,
          343,
          105638,
          13835,
          1923,
          1363,
          5341,
          419,
          3495,
          6841,
          732,
          376,
          4508,
          3766,
          1766,
          1190,
          601723,
          1426,
          5657,
          19685,
          46563,
          4993,
          5196,
          12335,
          800,
          1577385,
          19408,
          530,
          1760,
          530,
          48194,
          1383,
          2518,
          5760,
          145,
          343,
          493,
          19685,
          1690,
          2328,
          5901,
          20478,
          286,
          74,
          133,
          589,
          10076,
          970,
          99,
          77,
          4677,
          641349,
          1533,
          136,
          9587,
          54287,
          817312,
          526,
          6006,
          899,
          1595797,
          5901,
          504,
          184,
          163415,
          34153,
          973849,
          32891,
          348,
          184,
          35439,
          910148,
          927396,
          23,
          23045,
          3032,
          105549,
          765,
          1666,
          63,
          241,
          1196,
          2906700,
          1412,
          722,
          1780,
          765,
          258,
          2526,
          4512,
          1925,
          471,
          5341,
          1190,
          381459,
          647,
          2501,
          186140,
          525713,
          2607,
          270712,
          96942,
          71485,
          1810,
          2870,
          178,
          601723,
          1656,
          1312922,
          20328,
          471,
          10076,
          606,
          365,
          1382480,
          34882,
          1363,
          24645,
          31515,
          166081,
          828,
          1063,
          2290,
          43102,
          93193,
          320,
          1766,
          545147,
          4508,
          498,
          3224,
          513,
          1966,
          241,
          3096,
          1645,
          46,
          10076,
          910148,
          5161,
          2317,
          1523,
          341043,
          136,
          1725,
          4895,
          7268,
          139,
          139,
          99,
          134056,
          910148,
          10256,
          3119,
          76,
          5438,
          128,
          3862,
          1363,
          551,
          3343,
          320420,
          349,
          8333,
          571,
          912,
          1766,
          1063,
          928,
          2092,
          3395,
          1810,
          184,
          970,
          765,
          6581,
          1126,
          2836,
          299480,
          21125,
          7565,
          20478,
          140,
          2504700,
          136,
          215,
          3343,
          1442,
          11432,
          54767,
          34153,
          47249,
          128715,
          1970,
          237282,
          413574,
          4993,
          761,
          565,
          338,
          3224,
          1478,
          736284,
          165,
          35371,
          1089,
          532,
          1139,
          626,
          14871,
          52,
          3833,
          761,
          165,
          680,
          324,
          7155,
          5211,
          23045,
          5760,
          1577385,
          276896,
          36784,
          1858,
          365,
          60,
          7268,
          3766,
          1988,
          10717,
          502,
          653,
          973849,
          1892,
          5619,
          970,
          595,
          641,
          1453,
          18408,
          68211,
          725,
          8269,
          1946,
          2016,
          3289,
          21437,
          6841,
          1201,
          134056,
          1493,
          1970,
          1810,
          79613,
          20328,
          601723,
          21125,
          14742,
          11250,
          3224,
          13602,
          9521,
          459921,
          914,
          2089,
          107941,
          2644,
          2303,
          1507,
          270712,
          233060,
          2258,
          2206,
          4198,
          6629,
          59744,
          2258,
          970,
          34882,
          13973,
          45100,
          910148,
          2456,
          30770,
          4056,
          30770,
          76383,
          178,
          4512,
          520,
          6629,
          11250,
          489,
          104396,
          1512,
          370,
          11256,
          247,
          198,
          16163,
          1526206,
          1804,
          2523,
          241,
          43,
          1360,
          4367,
          1507,
          320420,
          1241364,
          7297,
          8874,
          328,
          832,
          1143,
          3066,
          606,
          1120,
          166081,
          545147,
          1132,
          932,
          35705,
          241,
          18459,
          33917,
          7420,
          466,
          5512,
          1423,
          24536,
          276002,
          13973,
          761,
          52126,
          1565,
          42817,
          6713,
          1383,
          502,
          149,
          1196,
          124967,
          2856,
          27971,
          460,
          824,
          46563,
          217,
          765,
          459921,
          2078,
          320420,
          5666,
          38912,
          19090,
          532,
          1595797,
          4290,
          238602,
          3395,
          1443,
          1302,
          1241364,
          1126,
          48194,
          828,
          3833,
          566,
          565,
          391389,
          20328,
          828,
          2807,
          9772,
          71485,
          1274,
          111,
          5875,
          2456,
          106,
          3862,
          407,
          206,
          263,
          1120,
          316665,
          106,
          725,
          2368,
          272134,
          9993,
          24840,
          276,
          12486,
          1841,
          824,
          348,
          2836,
          76,
          1446,
          1263321,
          888,
          477,
          5875,
          828,
          5760,
          899,
          348,
          176,
          753116,
          99,
          6508,
          737,
          2836,
          207,
          23,
          165,
          1766,
          47,
          516,
          7268,
          9521,
          24536,
          1493,
          1645,
          177,
          269,
          895,
          2971,
          2870,
          46944,
          3451,
          571,
          1146,
          25459,
          11751,
          1412,
          2408,
          54287,
          3996,
          63,
          144160,
          471,
          23727,
          2691,
          24840,
          1577385,
          7268,
          55581,
          6713,
          1970,
          5950,
          2054,
          224256,
          3279,
          771,
          5760,
          298,
          1645,
          1725,
          2317,
          4653,
          493806,
          397,
          6018,
          1523,
          459921,
          3096,
          341043,
          471,
          1252,
          459921,
          1196,
          6284,
          122111,
          2206,
          5648,
          6951,
          1368,
          118,
          19054,
          718,
          1789,
          128354,
          910148,
          1274,
          42384,
          5848,
          4720,
          145,
          3996,
          99,
          86954,
          190,
          1100,
          198,
          22191,
          9772,
          1789,
          1063,
          18182,
          1132,
          96942,
          3395,
          321,
          1666,
          26551,
          139,
          798,
          571,
          2644,
          238602,
          78968,
          1810,
          1791,
          525713,
          4542,
          673342,
          3862,
          3202,
          37,
          35439,
          69793,
          23727,
          369,
          242,
          10076,
          1577385,
          1909,
          5621,
          7155,
          973849,
          269,
          6469,
          14075,
          61,
          276002,
          93193,
          1261,
          1565,
          79008,
          502,
          92608,
          530,
          648,
          313,
          258,
          84106,
          1334,
          276002,
          1810,
          308,
          1804,
          520,
          149,
          2395,
          7268,
          1666,
          1892,
          1909,
          272,
          269,
          899,
          2328,
          1019,
          5666,
          139,
          1423,
          2443,
          680,
          1178,
          1063,
          475,
          135332,
          18408,
          3263,
          5848,
          18408,
          35299,
          320420,
          1970,
          71463,
          1606,
          24840,
          1179,
          7155,
          5161,
          1241364,
          3263,
          1679,
          450,
          1274,
          525713,
          2872,
          13602,
          5621,
          626,
          7430,
          6006,
          3119,
          7163,
          19685,
          149,
          2208,
          2148,
          9165,
          686,
          895,
          532,
          59744,
          254282,
          970,
          307,
          761,
          19685,
          6434,
          5507,
          1656,
          1770,
          344,
          153,
          530,
          7163,
          828,
          1324,
          2408,
          1526206,
          205,
          190178,
          4056,
          5196,
          19054,
          9815,
          3833,
          84106,
          51427,
          1312922,
          922,
          632,
          1480,
          50835,
          3263,
          1686,
          9815,
          2135,
          1100,
          2376,
          443,
          1645,
          1102,
          6713,
          73,
          478,
          376,
          194500,
          2307,
          1089,
          36784,
          4159,
          1306,
          493,
          34153,
          741,
          258,
          1631,
          1139,
          1565,
          1063,
          743,
          969,
          1804,
          344,
          686,
          3996,
          1684,
          35439,
          241,
          741,
          4575,
          92106,
          1051,
          6713,
          1745,
          372,
          93193,
          71335,
          642,
          4913,
          346,
          276002,
          158701,
          23,
          95,
          222785,
          1288,
          1979,
          741,
          17867,
          192,
          1679,
          370,
          106,
          3104,
          198,
          85,
          85,
          104396,
          13717,
          286,
          964,
          1563,
          217,
          333497,
          493806,
          2383912,
          1166,
          765,
          1631,
          614,
          1595797,
          2872,
          192805,
          23,
          2368,
          795,
          35371,
          3430,
          346,
          450,
          241,
          965,
          2501,
          391389,
          224256,
          1186,
          70,
          106,
          470,
          1087,
          18408,
          1126,
          2504700,
          267,
          718,
          1423,
          1252,
          2054,
          718,
          795,
          626,
          1523,
          270712,
          1789,
          2906700,
          5901,
          372,
          15647,
          348,
          7163,
          2443,
          31394,
          477,
          1089,
          4508,
          27971,
          320,
          736284,
          276,
          18760,
          1760,
          5901,
          69793,
          15426,
          9496,
          46563,
          378909,
          4074,
          760,
          308,
          76383,
          520,
          3458,
          190,
          3776,
          95,
          910148,
          1186,
          3805,
          2078,
          4056,
          53,
          1532,
          1631,
          1312922,
          3684,
          35371,
          1943,
          4306,
          733,
          1909,
          1382480,
          910148,
          663,
          6951,
          760,
          13973,
          341043,
          498,
          54185,
          1019,
          795,
          5760,
          686,
          464,
          110,
          381459,
          21902,
          4172,
          122111,
          1526206,
          1565,
          77,
          258,
          1019,
          320,
          2607,
          370,
          5512,
          1745,
          427,
          69,
          4090,
          1274,
          2443,
          3833,
          53,
          7430,
          43,
          861,
          9993,
          2691,
          832,
          5901,
          241,
          914,
          178,
          242,
          836,
          19090,
          4306,
          1302,
          2211,
          1526206,
          8333,
          804,
          910148,
          275,
          972,
          137,
          3395,
          34496,
          836,
          258,
          31515,
          630,
          5908,
          144160,
          6629,
          1075,
          3862,
          1446,
          32891,
          639,
          217,
          247,
          43,
          626,
          5726,
          24840,
          2607,
          1423,
          1382480,
          295,
          1166,
          1526206,
          828,
          11250,
          2456,
          1645,
          463,
          861,
          3289,
          540,
          1423,
          46944,
          4090,
          34153,
          355,
          276002,
          106,
          687276,
          1078,
          136,
          642,
          1847,
          5161,
          409656,
          346,
          75903,
          3766,
          2644,
          13422,
          308,
          10256,
          9587,
          370,
          59744,
          718,
          233717,
          47249,
          92043,
          11432,
          338,
          1490,
          1654,
          1831,
          1686,
          100,
          11751,
          471,
          134056,
          3104,
          3699,
          86954,
          19685,
          24536,
          308,
          589,
          1766,
          79008,
          321,
          718,
          32891,
          136895,
          6951,
          640470,
          1446,
          116155,
          12335,
          17047,
          2135,
          9594,
          46944,
          9496,
          6284,
          177,
          1383,
          1312922,
          2036,
          4474,
          46563,
          13422,
          18128,
          24536,
          2799,
          124967,
          99,
          8830,
          5196,
          45100,
          1051,
          832,
          1146,
          6841,
          276896,
          1139,
          54287,
          540,
          1383,
          333497,
          4653,
          606,
          1970,
          722,
          263,
          2566,
          214703,
          331,
          725,
          105549,
          530,
          21902,
          177,
          673342,
          61,
          34153,
          467,
          606,
          53,
          5666,
          104396,
          2906700,
          7155,
          12349,
          21125,
          1383,
          1725,
          1946,
          233060,
          5901,
          69,
          1690,
          5548,
          123,
          217,
          645,
          4993,
          3224,
          525713,
          338,
          6951,
          248,
          93193,
          242,
          223,
          1526206,
          92294,
          391389,
          1725,
          1532,
          145,
          1684,
          725,
          46,
          46563,
          1966,
          571,
          2395,
          3996,
          163415,
          140,
          84106,
          6951,
          263,
          7297,
          2661,
          74,
          760,
          686,
          1190,
          695,
          20478,
          673342,
          1075,
          5341,
          895,
          1563,
          140,
          1762,
          4589,
          3032,
          5791,
          1725,
          5196,
          3202,
          13717,
          1577385,
          87124,
          3684,
          3487,
          450,
          1988,
          123373,
          899,
          1131,
          2501,
          1745,
          1858,
          107941,
          3224,
          470,
          4913,
          2211,
          18760,
          1631,
          20478,
          1019,
          743,
          343,
          2443,
          397,
          937,
          6469,
          276002,
          126,
          2092,
          970,
          1583,
          922,
          1909,
          765,
          1139,
          3202,
          328,
          6703,
          526,
          7268,
          1038,
          653,
          1131,
          270712,
          207410,
          1446,
          1228,
          35371,
          718,
          3766,
          828,
          1490,
          139650,
          516,
          3730,
          3684,
          1897,
          795,
          1080,
          239,
          9512,
          4056,
          6120,
          263,
          267,
          601723,
          76,
          3688,
          6006,
          172817,
          5666,
          6469,
          238602,
          4081,
          673342,
          128,
          123373,
          10717,
          2916,
          722,
          885,
          276002,
          1228,
          116001,
          970,
          341,
          11256,
          1461,
          55345,
          519,
          144160,
          105549,
          74,
          686,
          17867,
          540,
          2836,
          136895,
          782,
          92985,
          467,
          45100,
          1595797,
          2408,
          134056,
          42384,
          27971,
          123,
          2856,
          124967,
          233717,
          5927,
          602,
          269,
          2135,
          493,
          564,
          2872,
          1766,
          520,
          520,
          365,
          16183,
          1804,
          4056,
          291,
          1263321,
          3862,
          94014,
          1758,
          1526206,
          217,
          76,
          2644,
          1263321,
          50489,
          545147,
          26551,
          1970,
          77,
          1804,
          1645,
          1382480,
          5621,
          1507,
          589,
          92106,
          54767,
          1426,
          2644,
          568,
          18408,
          639,
          1126,
          47249,
          242,
          3699,
          11751,
          33917,
          2328,
          1383,
          1019,
          673342,
          5548,
          4090,
          286,
          2661,
          2526,
          606,
          545147,
          203571,
          2328,
          258,
          8830,
          4895,
          3684,
          92106,
          571,
          24645,
          1078,
          5908,
          163415,
          88735,
          601723,
          3776,
          27020,
          2501,
          71485,
          271,
          923,
          1263321,
          2223,
          178,
          63,
          79613,
          1293,
          899,
          5438,
          276002,
          1897,
          1363,
          5760,
          24840,
          419,
          70,
          54767,
          4354,
          2395,
          3487,
          203571,
          1858,
          23727,
          1725,
          1810,
          3096,
          3805,
          35299,
          1412,
          237282,
          1195,
          1453,
          601723,
          888,
          16183,
          1925,
          365,
          32891,
          15269,
          86954,
          2526,
          1770,
          3684,
          498,
          3430,
          1166,
          31515,
          2263,
          736284,
          910148,
          378909,
          20328,
          365,
          2135,
          1019,
          20478,
          2501,
          3451,
          2135,
          2202,
          129,
          1132,
          516,
          1847,
          2317,
          493806,
          782,
          5848,
          1201,
          222785,
          17867,
          5895,
          27971,
          4198,
          1679,
          320420,
          878,
          5341,
          237282,
          47,
          85,
          320420,
          391389,
          911,
          50835,
          1420,
          832,
          5341,
          67858,
          230,
          4090,
          6018,
          737,
          2206,
          2518,
          238602,
          79613,
          3285,
          565,
          972,
          3289,
          96942,
          18760,
          464,
          5211,
          19054,
          302,
          198,
          8874,
          145,
          2368,
          1766,
          254282,
          247,
          76,
          1412,
          207410,
          9679,
          459921,
          145,
          5161,
          1420,
          1190,
          475,
          4056,
          94325,
          1263321,
          2395,
          124967,
          899,
          213,
          320420,
          128715,
          4074,
          34882,
          2328,
          12486,
          540,
          105549,
          123,
          238602,
          241,
          43,
          1789,
          1140,
          2208,
          355,
          1426,
          95015,
          910148,
          899,
          4603,
          78968,
          67082,
          2258,
          18182,
          5666,
          186140,
          1312922,
          145,
          139,
          530,
          5196,
          641349,
          1684,
          18182,
          46,
          1892,
          757530,
          565,
          302,
          50489,
          513,
          717255,
          7692,
          9512,
          7155,
          14871,
          376,
          2054,
          376,
          1979,
          1178,
          5621,
          10256,
          863,
          1190,
          413574,
          165556,
          8512,
          8019,
          520,
          172817,
          1126,
          75830,
          106,
          467,
          471,
          4354,
          5438,
          1100,
          1504,
          69793,
          493806,
          2786,
          3279,
          5512,
          30770,
          1504,
          1766,
          76383,
          95,
          298,
          178,
          242,
          1443,
          74,
          3263,
          1089,
          17867,
          1126,
          4653,
          725,
          5457,
          54767,
          3279,
          124967,
          12335,
          3279,
          4367,
          5732,
          3255,
          153,
          601723,
          50489,
          470,
          168,
          348,
          1684,
          77,
          2523,
          69,
          247,
          1382480,
          48194,
          320420,
          1038,
          2971,
          1202,
          291,
          88735,
          1858,
          96942,
          370,
          35439,
          51,
          320420,
          13061,
          11253,
          79613,
          168,
          9772,
          16163,
          9512,
          520,
          1804,
          1102,
          798,
          381459,
          5875,
          276,
          92043,
          2906700,
          1760,
          964,
          718,
          502,
          2443,
          54767,
          15426,
          639,
          841711,
          238602,
          20328,
          1526206,
          4653,
          238602,
          3776,
          218,
          163415,
          55345,
          1930,
          110,
          13973,
          885,
          1517,
          5908,
          151815,
          1443,
          207410,
          2872,
          269,
          1274,
          628,
          647,
          149,
          149,
          42817,
          1228,
          2661,
          46563,
          4508,
          564,
          6284,
          1383,
          530,
          800,
          5196,
          3289,
          18182,
          1892,
          1019,
          4512,
          35439,
          55345,
          1420,
          1970,
          337,
          230,
          970,
          18182,
          45303,
          4056,
          99,
          795,
          413574,
          718,
          520,
          647,
          217,
          4726,
          95015,
          116155,
          5791,
          6120,
          899,
          3343,
          1241364,
          21134,
          2317,
          94014,
          139,
          478,
          7646,
          606,
          1078,
          1563,
          2856,
          341,
          4198,
          1523,
          4895,
          23,
          765,
          5719,
          217,
          1075,
          4726,
          136,
          69793,
          136,
          836,
          8874,
          1595797,
          2395,
          19054,
          4895,
          1565,
          9815,
          46563,
          1461,
          277,
          207410,
          25459,
          2504700,
          888,
          885,
          741,
          18760,
          69,
          606,
          1988,
          899,
          761,
          7646,
          493806,
          1507,
          5438,
          190249,
          5211,
          7565,
          1988,
          1760,
          970,
          365,
          15647,
          34882,
          105638,
          145,
          640470,
          1302,
          530,
          5895,
          737,
          344,
          333497,
          27971,
          1595797,
          4542,
          1089,
          140,
          258,
          743,
          722,
          466,
          391389,
          1749,
          19408,
          5875,
          85,
          4138,
          4542,
          233717,
          107941,
          4895,
          198,
          525713,
          1051,
          18128,
          1051,
          94325,
          1490,
          1804,
          190,
          1512,
          443,
          59744,
          24645,
          186140,
          1126,
          1988,
          1970,
          156391,
          641,
          5927,
          54287,
          4913,
          21134,
          139,
          5875,
          910148,
          732,
          1925,
          1766,
          8007,
          67082,
          3032,
          4074,
          1453,
          365,
          16305,
          277,
          6284,
          2089,
          910148,
          69,
          27020,
          27020,
          1241364,
          2211,
          134056,
          324,
          35371,
          1132,
          673342,
          36784,
          166081,
          493806,
          33804,
          1789,
          21902,
          277,
          248,
          1201,
          61,
          1760,
          1526206,
          2206,
          1766,
          2457,
          1078,
          1690,
          811,
          2135,
          71485,
          1263321,
          59744,
          167,
          725,
          18408,
          5895,
          1383,
          522,
          84106,
          149,
          4049,
          753116,
          355,
          687276,
          77,
          156391,
          6841,
          8512,
          1078,
          1022298,
          17867,
          343,
          1263321,
          24536,
          348,
          1523,
          230,
          10256,
          343,
          1909,
          53,
          516,
          1252,
          30770,
          331,
          107941,
          516,
          498,
          864,
          269,
          3395,
          1132,
          60,
          194500,
          823,
          35439,
          47772,
          11432,
          1523,
          1804,
          71335,
          116001,
          302,
          642,
          566,
          647,
          84106,
          409656,
          502,
          10076,
          2691,
          5657,
          1574,
          1063,
          2501,
          17867,
          33917,
          5791,
          2456,
          207,
          254282,
          100,
          31970,
          475,
          302,
          2395,
          885,
          477,
          52126,
          28739,
          158701,
          502,
          18760,
          176,
          4593,
          71463,
          6629,
          111,
          3289,
          333497,
          504,
          328,
          1131,
          2290,
          3495,
          3766,
          581,
          5908,
          2395,
          641349,
          22305,
          2290,
          1507,
          471,
          1789,
          21902,
          2526,
          642,
          4575,
          207,
          1078,
          832,
          743,
          1595797,
          213,
          1078,
          2644,
          302,
          15426,
          158701,
          2443,
          1523,
          3684,
          4542,
          545147,
          21125,
          718,
          2206,
          1271,
          1480,
          2121,
          2691,
          75830,
          597,
          5791,
          143,
          27971,
          1858,
          2060,
          6951,
          222785,
          9772,
          7646,
          308,
          1228,
          307,
          5548,
          106,
          372,
          2799,
          7430,
          3996,
          710,
          145,
          1631,
          4138,
          36784,
          276896,
          519,
          207410,
          95,
          106,
          2054,
          6469,
          3807,
          626,
          215,
          276002,
          135332,
          76,
          467,
          1654,
          1228,
          276896,
          695,
          928,
          43102,
          4542,
          1063,
          1166,
          6951,
          51427,
          92337,
          912,
          466,
          178,
          276002,
          27971,
          722,
          1019,
          741,
          2376,
          927396,
          76,
          4993,
          1791,
          207410,
          218,
          1925,
          1423,
          1446,
          568,
          836,
          761,
          391389,
          1645,
          348,
          937,
          47249,
          83,
          46,
          149,
          1745,
          409656,
          190178,
          4575,
          46944,
          1631,
          63,
          10295,
          111,
          198,
          60,
          9587,
          2036,
          190,
          584,
          307,
          6469,
          128354,
          759,
          1165,
          92608,
          77,
          2304,
          2607,
          7420,
          24536,
          798,
          286,
          302,
          2383912,
          1583,
          817312,
          6006,
          365,
          116001,
          5903,
          35439,
          60,
          516,
          129,
          2016,
          5512,
          12335,
          804,
          350,
          276896,
          192805,
          94325,
          630,
          341043,
          8512,
          3032,
          601723,
          526,
          22930,
          46,
          1453,
          1760,
          24840,
          5901,
          24536,
          136895,
          20478,
          878,
          6284,
          25459,
          1923,
          795,
          5161,
          1684,
          76,
          178,
          50835,
          54767,
          158701,
          1970,
          1472,
          92985,
          3096,
          589,
          258,
          10717,
          1368,
          743,
          3224,
          5341,
          27020,
          1195,
          1382480,
          8830,
          5760,
          2135,
          2135,
          3395,
          136,
          3495,
          1363,
          973849,
          270712,
          16163,
          2054,
          1195,
          516,
          1847,
          2807,
          1595797,
          741,
          24840,
          1063,
          5950,
          237282,
          910148,
          19090,
          237282,
          1617,
          1506,
          2206,
          817312,
          2263,
          1241364,
          272134,
          241,
          2408,
          4993,
          3833,
          863,
          1577385,
          9815,
          343,
          4056,
          1766,
          118,
          5791,
          606,
          540,
          5161,
          6006,
          217,
          912,
          1063,
          2872,
          606,
          5666,
          258,
          3684,
          409656,
          67082,
          106,
          11250,
          922,
          239,
          686,
          2470,
          276896,
          471,
          5161,
          33917,
          328,
          5196,
          1841,
          885,
          272,
          19685,
          241,
          198,
          1909,
          626,
          409656,
          2121,
          765,
          589,
          1019,
          233717,
          5895,
          94014,
          687276,
          1263321,
          86954,
          718,
          973849,
          427,
          841711,
          4074,
          5507,
          36784,
          6951,
          1807,
          76383,
          11751,
          6841,
          74,
          106,
          42384,
          5778,
          55345,
          54767,
          116001,
          595,
          163415,
          545147,
          55581,
          1078,
          1143,
          20328,
          964,
          269,
          2661,
          145,
          365,
          4049,
          753116,
          1087,
          198,
          391389,
          87124,
          69,
          2691,
          2504700,
          12335,
          7297,
          237282,
          3688,
          564,
          372,
          1804,
          969,
          10076,
          798,
          1078,
          663,
          466,
          1201,
          190178,
          1312922,
          46563,
          1493,
          841711,
          3289,
          1382480,
          2054,
          5161,
          471,
          7692,
          565,
          1725,
          1143,
          16183,
          20478,
          165,
          1533,
          1412,
          45100,
          23,
          136,
          520,
          35439,
          75830,
          571,
          1847,
          276896,
          1595797,
          2148,
          937,
          1078,
          635,
          413574,
          973849,
          526,
          277,
          2523,
          378909,
          3451,
          277,
          8830,
          9815,
          1019,
          34882,
          743,
          308,
          1526206,
          630,
          965,
          68211,
          471,
          964,
          1139,
          106,
          142,
          1131,
          878,
          128715,
          140,
          51427,
          493806,
          47249,
          2526,
          2401,
          22305,
          2089,
          540,
          151022,
          1241364,
          71463,
          129,
          1574,
          399,
          69,
          4508,
          932,
          722,
          2121,
          2383912,
          687276,
          16183,
          51427,
          606,
          1196,
          75830,
          74,
          1022298,
          321,
          832,
          348,
          526,
          1089,
          2121,
          509,
          5548,
          177,
          20478,
          75830,
          736284,
          1675,
          60,
          59744,
          601723,
          224256,
          3807,
          409656,
          105638,
          817312,
          2523,
          53,
          276002,
          836,
          1517,
          737,
          1304,
          4367,
          910148,
          7692,
          31515,
          30770,
          3684,
          2054,
          471,
          973849,
          545147,
          1201,
          84106,
          571,
          641,
          566,
          27020,
          1909,
          376,
          165556,
          885,
          1595797,
          5895,
          525713,
          184,
          5901,
          276,
          13061,
          105549,
          47772,
          321,
          19408,
          1126,
          2092,
          5989,
          21125,
          928,
          736284,
          864,
          2317,
          3224,
          914,
          3996,
          725,
          105549,
          21902,
          50489,
          18760,
          270712,
          91,
          1140,
          23805,
          1841,
          4367,
          3699,
          5927,
          3684,
          828,
          551,
          53,
          1645,
          350,
          42817,
          5903,
          1360,
          14871,
          2036,
          5901,
          12335,
          1019,
          3224,
          5908,
          3487,
          528,
          295,
          31515,
          4367,
          6951,
          639,
          8333,
          581,
          291,
          242,
          73,
          1019,
          8830,
          2208,
          142,
          3430,
          2872,
          7268,
          198,
          85,
          2870,
          1810,
          26551,
          722,
          205,
          4573,
          31515,
          895,
          2870,
          823,
          136,
          2661,
          43102,
          470,
          198,
          341,
          320420,
          129,
          1420,
          28739,
          927396,
          471,
          372,
          581,
          1595797,
          686,
          9772,
          49,
          16183,
          3807,
          2304,
          973849,
          92985,
          93193,
          25459,
          9496,
          21902,
          151022,
          105549,
          1446,
          687276,
          24840,
          1643,
          1087,
          4090,
          571,
          1847,
          606,
          137067,
          841711,
          99,
          1241364,
          1749,
          2916,
          1643,
          206,
          74,
          579,
          76383,
          516,
          99,
          4056,
          320,
          478,
          8007,
          158701,
          133,
          6006,
          2607,
          17047,
          922,
          564,
          35299,
          376,
          2368,
          1166,
          207410,
          1595797,
          1943,
          9772,
          595,
          5895,
          48194,
          2078,
          2054,
          1850,
          641349,
          308,
          4653,
          328,
          798,
          1595797,
          73,
          3279,
          53,
          1892,
          111,
          9815,
          3224,
          899,
          31394,
          258,
          1493,
          42384,
          571,
          73,
          2443,
          2054,
          489,
          695,
          13835,
          467,
          471,
          218,
          6951,
          128,
          18128,
          55345,
          307,
          19685,
          43,
          151815,
          5341,
          59744,
          18760,
          277,
          2036,
          743,
          2786,
          4290,
          344,
          722,
          21902,
          23,
          5895,
          43,
          153,
          214703,
          15647,
          4677,
          4895,
          1583,
          1271,
          135332,
          725,
          21134,
          320420,
          3430,
          85,
          26551,
          3807,
          836,
          413574,
          2607,
          206,
          782,
          3289,
          7297,
          5216,
          247,
          310,
          1970,
          1412,
          52,
          276,
          10717,
          106,
          45100,
          88735,
          1178,
          74,
          4056,
          71485,
          836,
          520,
          1504,
          3202,
          3032,
          10295,
          224256,
          19054,
          7987,
          1213,
          4878,
          4005,
          10256,
          1228,
          4542,
          23045,
          276002,
          14228,
          635,
          475,
          717255,
          6469,
          276002,
          489,
          1654,
          18128,
          12486,
          52,
          1533,
          128,
          158701,
          19685,
          19090,
          84106,
          2307,
          540,
          52126,
          5211,
          37,
          14742,
          4056,
          771,
          1979,
          2906700,
          6006,
          6629,
          2906700,
          269,
          798,
          149,
          836,
          695,
          427,
          215,
          118,
          3224,
          1063,
          1063,
          2518,
          895,
          100,
          21125,
          1925,
          1925,
          139,
          276,
          328,
          9594,
          1363,
          67858,
          1892,
          104,
          1241364,
          214518,
          6581,
          757530,
          8512,
          2092,
          1841,
          45303,
          2328,
          37,
          94014,
          34882,
          276896,
          4573,
          5950,
          2317,
          96942,
          899,
          1252,
          100,
          34496,
          54287,
          269,
          1526206,
          2607,
          626,
          237282,
          275,
          471,
          2148,
          172817,
          338,
          34496,
          2303,
          4729,
          608,
          1563,
          73,
          260,
          832,
          3766,
          2290,
          95035,
          3876,
          1675,
          1274,
          19054,
          92985,
          73,
          28739,
          717255,
          94014,
          12335,
          158701,
          19685,
          910148,
          4159,
          632,
          213,
          5666,
          633,
          1461,
          753116,
          233060,
          1383,
          5161,
          4198,
          4198,
          7646,
          540,
          1745,
          5908,
          128715,
          1909,
          1140,
          1126,
          878,
          2121,
          61,
          976,
          2135,
          6120,
          5760,
          602,
          54767,
          1263321,
          1909,
          4198,
          1126,
          186140,
          184,
          343,
          597,
          69,
          5875,
          460,
          3458,
          5903,
          5621,
          95035,
          765,
          597,
          76,
          136,
          2401,
          1939,
          4512,
          5196,
          71485,
          722,
          15269,
          153,
          20478,
          9993,
          372,
          4512,
          166081,
          258,
          128354,
          1334,
          642,
          1684,
          5848,
          128715,
          1526206,
          137,
          79613,
          2317,
          13983,
          1271,
          308,
          1789,
          3684,
          589,
          732,
          186140,
          105638,
          602,
          42817,
          932,
          1312,
          14783,
          516,
          35439,
          1749,
          1186,
          2607,
          602,
          2471,
          828,
          2148,
          737,
          37,
          36438,
          369,
          1841,
          18408,
          19054,
          241,
          741,
          9587,
          1126,
          864,
          355,
          21134,
          3862,
          804,
          23,
          35705,
          2401,
          568,
          12486,
          565,
          338,
          51,
          167,
          134056,
          260,
          1506,
          71485,
          1490,
          95,
          5895,
          12486,
          1700,
          1412,
          545147,
          133,
          31515,
          10256,
          7430,
          5760,
          653,
          595,
          140,
          229,
          1241364,
          1453,
          116001,
          2078,
          725,
          3224,
          2368,
          50835,
          4512,
          4090,
          134056,
          1312922,
          348,
          276896,
          1656,
          104396,
          94014,
          1749,
          1480,
          2089,
          760,
          295,
          663,
          50489,
          128,
          30770,
          92043,
          2906700,
          1100,
          2607,
          92985,
          1241364,
          1789,
          687276,
          1930,
          46944,
          509,
          4589,
          564,
          1850,
          2328,
          241,
          242,
          206,
          2856,
          4845,
          350,
          397,
          795,
          214703,
          470,
          2501,
          14783,
          1263321,
          163415,
          2395,
          2971,
          1089,
          3699,
          21125,
          3224,
          910148,
          2368,
          7155,
          19090,
          1858,
          95,
          1038,
          270712,
          21902,
          103927,
          19408,
          2526,
          20478,
          31394,
          2263,
          718,
          123373,
          489,
          743,
          5512,
          478,
          14075,
          1925,
          254282,
          73,
          116001,
          2376,
          376,
          832,
          427,
          92608,
          5621,
          18182,
          106,
          242,
          1382480,
          606,
          3805,
          248858,
          6713,
          1087,
          1201,
          2148,
          1324,
          518429,
          798,
          4354,
          804,
          355,
          313,
          836,
          964,
          540,
          602,
          178,
          653,
          9165,
          165556,
          1472,
          255,
          6284,
          1725,
          673342,
          23045,
          1595797,
          3096,
          673342,
          817312,
          4172,
          124967,
          9815,
          45303,
          5619,
          2526,
          1190,
          519,
          163415,
          13835,
          928,
          2906700,
          5903,
          370,
          71463,
          3766,
          4474,
          2870,
          2872,
          5760,
          1443,
          75903,
          1679,
          16183,
          1312,
          911,
          13061,
          1383,
          3487,
          2148,
          15647,
          1383,
          5895,
          124967,
          1689,
          73,
          124967,
          1078,
          270712,
          122111,
          1979,
          2836,
          5548,
          3279,
          922,
          378909,
          128354,
          14783,
          1988,
          1770,
          749635,
          45100,
          1493,
          7155,
          1063,
          372,
          1078,
          3688,
          272134,
          824,
          349,
          2906700,
          5621,
          1689,
          19685,
          1019,
          5875,
          1202,
          91,
          84106,
          69793,
          4589,
          2317,
          5438,
          9594,
          2368,
          9594,
          172817,
          158701,
          1228,
          3688,
          1263321,
          864,
          376,
          51427,
          47,
          365,
          248,
          647,
          3495,
          864,
          341,
          68211,
          1760,
          2368,
          4664,
          47249,
          836,
          761,
          516,
          2661,
          1446,
          2304,
          77,
          973849,
          321,
          914,
          466,
          276896,
          5161,
          5512,
          4653,
          6434,
          139,
          467,
          22191,
          2872,
          344,
          7646,
          14742,
          95015,
          6951,
          269,
          2383912,
          33804,
          46944,
          3096,
          4512,
          166081,
          286,
          3684,
          895,
          1789,
          2376,
          142,
          198,
          1363,
          795,
          149,
          1420,
          93193,
          1892,
          1334,
          331,
          4993,
          27971,
          198,
          258,
          589,
          2523,
          71463,
          6951,
          722,
          1946,
          914,
          34882,
          4161,
          2304,
          1512,
          970,
          2263,
          9815,
          2060,
          128354,
          1412,
          163415,
          1139,
          145,
          19685,
          118,
          310,
          1617,
          1970,
          47249,
          166081,
          1288,
          2036,
          2504700,
          270712,
          181438,
          168,
          214703,
          2135,
          116001,
          3684,
          46563,
          258,
          1791,
          2317,
          16183,
          4508,
          338,
          134056,
          1241364,
          5211,
          4074,
          5621,
          3833,
          467,
          47772,
          4081,
          4653,
          741,
          3458,
          2872,
          42619,
          238602,
          1595797,
          841711,
          1261,
          525713,
          139,
          765,
          92608,
          3451,
          2836,
          3104,
          1946,
          389246,
          269,
          13422,
          1970,
          307,
          6629,
          3833,
          2872,
          3395,
          2303,
          77,
          2526,
          46944,
          10295,
          328,
          135332,
          365,
          1725,
          248,
          1791,
          5732,
          389246,
          753116,
          4367,
          276896,
          1841,
          13835,
          493,
          260,
          241,
          5621,
          116001,
          348,
          1970,
          47211,
          153,
          7565,
          3495,
          1847,
          129,
          1368,
          350,
          50489,
          19054,
          639,
          1312922,
          230,
          9594,
          2916,
          4354,
          1132,
          7268,
          186140,
          528,
          1019,
          5161,
          545147,
          757530,
          45100,
          765,
          824,
          86954,
          3688,
          230,
          601723,
          2526,
          254,
          270712,
          519,
          50489,
          6951,
          19054,
          1228,
          9034,
          632,
          641349,
          5760,
          19054,
          95015,
          1770,
          9565,
          137,
          34882,
          263,
          69,
          6120,
          589,
          1263321,
          2328,
          6581,
          1228,
          1228,
          149,
          19408,
          355,
          564,
          6508,
          307,
          321,
          3289,
          192805,
          1760,
          55345,
          5507,
          1804,
          321,
          20478,
          753116,
          5662,
          198,
          3343,
          519,
          239,
          1263321,
          27971,
          1631,
          7420,
          21902,
          151785,
          17867,
          63,
          888,
          144160,
          16163,
          71335,
          4653,
          9051,
          308,
          2456,
          463,
          1760,
          4090,
          828,
          242,
          1324,
          828,
          4677,
          1178,
          2408,
          28278,
          20478,
          54287,
          3688,
          3395,
          895,
          28278,
          118,
          3805,
          498,
          337,
          5657,
          23,
          18182,
          149,
          8333,
          86954,
          276896,
          59744,
          795,
          34153,
          67082,
          1909,
          69793,
          526,
          18408,
          540,
          269,
          31515,
          885,
          106,
          145,
          632,
          1423,
          134056,
          5778,
          744,
          2328,
          3688,
          2408,
          2456,
          5875,
          302,
          2258,
          635,
          733,
          10256,
          3833,
          2304,
          602,
          35371,
          16183,
          129,
          1022298,
          11256,
          55581,
          46,
          276896,
          1595797,
          3495,
          4005,
          1252,
          5621,
          413574,
          626,
          4367,
          137067,
          21902,
          50835,
          218,
          545147,
          14075,
          4533,
          21125,
          47772,
          606,
          647,
          832,
          68211,
          3096,
          4354,
          4015,
          760,
          3807,
          828,
          76383,
          973849,
          24840,
          4677,
          4878,
          911,
          28425,
          5619,
          1643,
          1804,
          630,
          94014,
          31394,
          6508,
          344,
          1453,
          3699,
          9815,
          23045,
          1850,
          149,
          32891,
          1656,
          194500,
          50835,
          759,
          8830,
          324,
          545147,
          753116,
          378909,
          1766,
          99,
          92608,
          20478,
          5451,
          5457,
          254282,
          346,
          378909,
          2607,
          163415,
          46944,
          15647,
          21125,
          2304,
          53,
          673342,
          647,
          765,
          30770,
          35371,
          1139,
          642,
          5512,
          885,
          5791,
          5512,
          140,
          21902,
          172247,
          1897,
          13973,
          13422,
          1970,
          271,
          18408,
          19090,
          565,
          4913,
          964,
          1312922,
          2092,
          861,
          1195,
          207,
          4895,
          343,
          1089,
          5354,
          2135,
          4895,
          13973,
          5760,
          4895,
          338,
          67082,
          1749,
          341043,
          105638,
          568,
          937,
          2408,
          35371,
          34496,
          190178,
          3224,
          2456,
          765,
          798,
          8007,
          606,
          606,
          1810,
          5989,
          1420,
          1656,
          27971,
          606,
          5548,
          399,
          1831,
          331,
          1946,
          1563,
          1131,
          28739,
          49,
          302,
          532,
          167,
          218,
          1453,
          6841,
          378909,
          1504,
          647,
          85,
          2644,
          1909,
          1426,
          4074,
          413574,
          151785,
          134056,
          28425,
          2456,
          163415,
          2971,
          1196,
          2078,
          673342,
          614,
          475,
          2644,
          606,
          34882,
          213,
          75830,
          3279,
          59744,
          409656,
          695,
          673342,
          136,
          972,
          2368,
          1760,
          1461,
          26551,
          478,
          15269,
          1228,
          1075,
          761,
          1423,
          1288,
          725,
          3487,
          84106,
          2566,
          378909,
          1892,
          493806,
          1577385,
          4367,
          320420,
          765,
          276002,
          47211,
          1178,
          3805,
          32891,
          663,
          743,
          343,
          1577385,
          4729,
          46563,
          804,
          3279,
          191096,
          14783,
          344,
          307,
          111,
          34882,
          11432,
          733,
          346,
          237282,
          2290,
          316665,
          1807,
          307,
          2258,
          59744,
          1643,
          255,
          258,
          3343,
          47249,
          397,
          2395,
          910148,
          22191,
          932,
          2518,
          2078,
          14228,
          1490,
          1841,
          24645,
          1526206,
          4913,
          17867,
          2906700,
          1656,
          149,
          2383912,
          633,
          2223,
          895,
          70,
          489,
          35371,
          1686,
          1810,
          5354,
          7297,
          71463,
          320420,
          1770,
          186140,
          1190,
          1493,
          1831,
          25459,
          725,
          92294,
          722,
          2906700,
          885,
          346,
          95015,
          381459,
          1261,
          895,
          34882,
          1490,
          640470,
          276,
          276896,
          1645,
          86954,
          564,
          1789,
          498,
          489,
          45100,
          134056,
          178,
          743,
          2395,
          207,
          1271,
          217,
          18128,
          5927,
          84106,
          1892,
          6460,
          241,
          23727,
          50835,
          836,
          463,
          177,
          217,
          238602,
          11751,
          970,
          628,
          13835,
          1810,
          105549,
          413574,
          479994,
          737,
          59705,
          530,
          19054,
          475,
          1841,
          33804,
          136,
          224256,
          14742,
          42817,
          2870,
          3224,
          1533,
          215,
          3255,
          551,
          27020,
          214703,
          7268,
          192805,
          3807,
          1334,
          5908,
          2523,
          4878,
          743,
          350,
          2304,
          43,
          7430,
          129,
          1645,
          86954,
          828,
          270712,
          198,
          140,
          1038,
          105549,
          134056,
          123,
          642,
          5903,
          54287,
          391389,
          470,
          798,
          346,
          19054,
          370,
          2518,
          24536,
          34882,
          2872,
          478,
          1909,
          1643,
          1271,
          1312,
          1271,
          2443,
          910148,
          516,
          1850,
          2856,
          526,
          1131,
          470,
          1925,
          1271,
          6469,
          1847,
          2607,
          346,
          520,
          3699,
          4575,
          276896,
          1126,
          24536,
          1679,
          34882,
          5895,
          828,
          54767,
          136,
          673342,
          5895,
          9679,
          1725,
          391389,
          1131,
          493806,
          105549,
          1051,
          260,
          137,
          33917,
          391389,
          276002,
          320420,
          606,
          129,
          1075,
          258,
          2661,
          105549,
          23727,
          5621,
          528,
          1075,
          241,
          1423,
          3688,
          1423,
          286,
          55581,
          5512,
          5778,
          18408,
          602,
          5161,
          9496,
          1143,
          1749,
          32891,
          641349,
          144160,
          24840,
          663,
          5657,
          123,
          1126,
          310,
          55345,
          18408,
          6841,
          1360,
          269,
          4056,
          743,
          1426,
          376,
          5438,
          1577385,
          568,
          5908,
          2408,
          663,
          1700,
          595,
          5791,
          3994,
          123,
          397,
          105638,
          13973,
          427,
          760,
          2971,
          1241364,
          545147,
          60,
          1979,
          100,
          717255,
          1595797,
          238602,
          46944,
          502,
          571,
          55581,
          12335,
          1312922,
          50835,
          67082,
          18408,
          365,
          378909,
          151022,
          105549,
          3684,
          13602,
          129,
          370,
          71485,
          1789,
          104396,
          1675,
          836,
          350,
          407,
          1645,
          85,
          409656,
          1271,
          1766,
          1426,
          602,
          20328,
          1791,
          811,
          526,
          1925,
          530,
          5950,
          87124,
          3451,
          48194,
          263,
          626,
          365,
          14783,
          530,
          673342,
          2523,
          1858,
          885,
          4056,
          2304,
          5211,
          6460,
          1506,
          69,
          2328,
          3279,
          45303,
          47249,
          4159,
          3395,
          149,
          1089,
          885,
          1022298,
          20478,
          4653,
          2872,
          5901,
          186140,
          1766,
          7565,
          1789,
          1841,
          630,
          14871,
          21635,
          260,
          922,
          1423,
          509,
          673342,
          1571,
          230,
          9496,
          34496,
          165556,
          21902,
          271,
          12335,
          1789,
          77,
          10717,
          43,
          1645,
          1201,
          10295,
          272,
          571,
          137,
          413574,
          626,
          10717,
          1382480,
          165,
          632,
          103927,
          346,
          4074,
          333497,
          59744,
          158701,
          1766,
          308,
          2691,
          85,
          25459,
          349,
          20478,
          166081,
          1263321,
          18182,
          106,
          533,
          3451,
          59744,
          94325,
          732,
          2456,
          218,
          156391,
          5548,
          1186,
          1493,
          1700,
          4664,
          3833,
          172817,
          1749,
          7155,
          35299,
          137067,
          928,
          1766,
          5354,
          2206,
          32891,
          1412,
          24645,
          2054,
          1595797,
          341,
          15647,
          176,
          99,
          124967,
          4575,
          454,
          86954,
          4726,
          1749,
          248,
          1178,
          207410,
          1165,
          4677,
          140,
          92608,
          9815,
          2471,
          828,
          1628,
          1271,
          128715,
          3876,
          123373,
          86954,
          1306,
          2135,
          86954,
          9679,
          1228,
          71463,
          1807,
          2317,
          5903,
          1312922,
          828,
          9587,
          190178,
          55345,
          545147,
          158701,
          2395,
          823,
          1228,
          504,
          1166,
          88735,
          230,
          16183,
          92985,
          795,
          1271,
          6120,
          241,
          3451,
          23045,
          743,
          509,
          467,
          270712,
          7268,
          42817,
          5848,
          12486,
          116155,
          71485,
          338,
          222785,
          46563,
          590,
          11256,
          25459,
          631,
          111,
          341,
          2307,
          71463,
          35439,
          1271,
          8097,
          633,
          3104,
          2856,
          2607,
          258,
          123373,
          178,
          20478,
          34882,
          8512,
          3255,
          9034,
          75830,
          478,
          7268,
          606,
          832,
          158701,
          23,
          695,
          1063,
          10717,
          7268,
          1760,
          2408,
          718,
          4677,
          207,
          31515,
          8097,
          1749,
          878,
          124967,
          800,
          2148,
          759,
          6841,
          1565,
          346,
          2786,
          1126,
          302,
          1892,
          1126,
          1512,
          3395,
          328,
          1643,
          8830,
          136,
          23727,
          2526,
          190178,
          54767,
          7646,
          1628,
          84106,
          46,
          3224,
          718,
          513,
          3508,
          1051,
          92985,
          224256,
          2290,
          94325,
          13835,
          602,
          76383,
          1139,
          28739,
          99,
          922,
          217,
          376,
          626,
          5927,
          99,
          134056,
          37,
          1680,
          1078,
          493806,
          2443,
          663,
          34496,
          9034,
          118,
          1087,
          1288,
          4533,
          381459,
          4778,
          6006,
          3402,
          836,
          241,
          765,
          4993,
          4056,
          3279,
          4367,
          35299,
          31394,
          5950,
          116001,
          213,
          4993,
          1804,
          153,
          5548,
          43102,
          186140,
          1383,
          13422,
          124967,
          21902,
          2135,
          124967,
          4542,
          895,
          6120,
          1139,
          134056,
          192,
          475,
          338,
          241,
          14871,
          2135,
          302,
          1523,
          1631,
          3279,
          1526206,
          7297,
          753116,
          75830,
          42619,
          11256,
          4677,
          91,
          1363,
          4542,
          19685,
          1382480,
          8333,
          467,
          1420,
          321490,
          645,
          1360,
          630,
          237282,
          92106,
          1988,
          308,
          35299,
          1186,
          254282,
          1126,
          1334,
          111,
          331,
          1324,
          8830,
          841711,
          1423,
          2408,
          1312922,
          7297,
          34496,
          1293,
          10076,
          230,
          263,
          134056,
          725,
          2836,
          1523,
          79008,
          163415,
          2504700,
          83,
          3279,
          3805,
          5161,
          9034,
          378909,
          1631,
          47772,
          4074,
          686,
          1892,
          46,
          798,
          248,
          1302,
          1190,
          30770,
          2263,
          248,
          1925,
          153,
          217,
          128354,
          71335,
          28278,
          606,
          7565,
          911,
          34882,
          1583,
          1334,
          606,
          4074,
          15623,
          85,
          67082,
          177,
          771,
          270712,
          15269,
          1304,
          35439,
          419,
          1312,
          5507,
          1195,
          2870,
          2870,
          1312,
          198,
          1804,
          528,
          1766,
          5216,
          1288,
          581,
          3285,
          42619,
          1166,
          370,
          477,
          765,
          5507,
          1532,
          397,
          91,
          28739,
          15426,
          3688,
          1312,
          344,
          2395,
          45303,
          85,
          71485,
          3202,
          680,
          34882,
          184,
          2807,
          3096,
          450,
          12335,
          71485,
          6120,
          24645,
          6120,
          1526206,
          1760,
          1766,
          864,
          1306,
          99,
          878,
          601723,
          782,
          31394,
          2526,
          5507,
          1363,
          5908,
          4664,
          95015,
          776,
          687276,
          42817,
          16183,
          27020,
          35371,
          348,
          1656,
          1423,
          4090,
          7155,
          823,
          158701,
          7268,
          116155,
          324,
          271,
          513,
          817312,
          1126,
          581,
          156391,
          914,
          1970,
          4653,
          5903,
          16183,
          878,
          9815,
          269,
          1628,
          2456,
          349,
          7155,
          1420,
          1574,
          1577385,
          145,
          1190,
          156391,
          3289,
          54287,
          42384,
          5895,
          21125,
          7565,
          1312922,
          163415,
          263,
          2870,
          1241364,
          53,
          391389,
          22305,
          1051,
          3766,
          7646,
          631,
          8007,
          7297,
          467,
          85,
          137067,
          828,
          42817,
          8269,
          7268,
          165556,
          757530,
          823,
          1661,
          2290,
          635,
          1925,
          601723,
          17867,
          341,
          27020,
          145,
          1228,
          11432,
          50489,
          1078,
          1087,
          5621,
          2307,
          1850,
          192,
          1443,
          2317,
          1631,
          1302,
          92043,
          3224,
          128,
          308,
          5507,
          757530,
          1423,
          725,
          47772,
          1606,
          135332,
          1631,
          1312922,
          2456,
          207,
          11751,
          3119,
          255,
          972,
          4878,
          1078,
          126,
          1131,
          381459,
          823,
          888,
          5507,
          1532,
          2456,
          3096,
          320420,
          2526,
          4542,
          759,
          1850,
          21125,
          1087,
          409656,
          1143,
          969,
          2799,
          4542,
          493,
          571,
          22930,
          75830,
          69,
          530,
          4354,
          99,
          914,
          2518,
          828,
          13835,
          45100,
          190178,
          116155,
          128715,
          1850,
          27971,
          2526,
          1923,
          365,
          20328,
          1686,
          153,
          190178,
          2661,
          2054,
          1453,
          153,
          471,
          601723,
          5354,
          13717,
          149,
          595,
          1293,
          1472,
          718,
          744,
          18128,
          149,
          639,
          27971,
          2916,
          206,
          601723,
          937,
          68211,
          4878,
          151785,
          1271,
          663,
          1261,
          222785,
          54287,
          878,
          55345,
          105549,
          2317,
          5161,
          2856,
          5950,
          1533,
          744,
          635,
          3096,
          3684,
          5950,
          79613,
          100,
          26551,
          970,
          9034,
          1810,
          69,
          11256,
          23,
          520,
          105549,
          1645,
          1645,
          14871,
          105549,
          1312,
          76383,
          6841,
          51,
          1132,
          172817,
          3224,
          7646,
          601723,
          6581,
          407,
          124967,
          76,
          248858,
          21902,
          77,
          1446,
          653,
          1858,
          2870,
          349,
          1512,
          53,
          237282,
          1970,
          725,
          224256,
          241,
          1312,
          242,
          1666,
          1766,
          5621,
          53,
          68211,
          5875,
          5507,
          36438,
          1139,
          32891,
          194500,
          168,
          254282,
          16183,
          7430,
          176,
          1679,
          1645,
          34153,
          3395,
          1523,
          269,
          663,
          258,
          5577,
          2870,
          407,
          1749,
          3289,
          53,
          181438,
          2395,
          85,
          722,
          2526,
          4542,
          1334,
          31515,
          13422,
          22191,
          22305,
          69,
          167,
          7646,
          22930,
          20478,
          328,
          16163,
          18128,
          4471,
          645,
          3699,
          263,
          645,
          828,
          186140,
          8019,
          3085,
          343,
          1383,
          128715,
          564,
          140,
          680,
          1892,
          4575,
          1725,
          1383,
          1563,
          79008,
          7297,
          1420,
          217,
          207,
          206,
          158701,
          795,
          76,
          27971,
          3343,
          163415,
          2408,
          4729,
          153,
          1858,
          9506,
          19090,
          914,
          13973,
          71335,
          344,
          13422,
          3688,
          2870,
          899,
          223,
          3684,
          741,
          744,
          2916,
          635,
          899,
          355,
          8333,
          10256,
          270712,
          190178,
          1019,
          116155,
          111,
          3224,
          94014,
          124967,
          1363,
          1675,
          6951,
          687276,
          25459,
          4005,
          35705,
          224256,
          493806,
          2328,
          198,
          687276,
          601723,
          5512,
          23,
          911,
          1312922,
          828,
          7163,
          765,
          1051,
          28425,
          1563,
          1850,
          276,
          1274,
          1126,
          6581,
          804,
          1841,
          76383,
          3805,
          2644,
          79008,
          31394,
          1446,
          79008,
          639,
          67082,
          2290,
          718,
          1532,
          95,
          2036,
          2691,
          3451,
          230,
          509,
          922,
          24645,
          1675,
          21125,
          276,
          3996,
          466,
          76383,
          1526206,
          5657,
          68211,
          7565,
          910148,
          178,
          341043,
          163415,
          5438,
          1126,
          5895,
          1789,
          239,
          267,
          242,
          771,
          1288,
          69793,
          1563,
          741,
          6951,
          3876,
          54287,
          198,
          1493,
          3279,
          765,
          1766,
          3224,
          969,
          35371,
          5662,
          2016,
          5760,
          568,
          1022298,
          2304,
          116001,
          516,
          20328,
          1507,
          370,
          24645,
          1565,
          25459,
          1970,
          1166,
          190,
          158701,
          509,
          1523,
          3996,
          3289,
          35439,
          2395,
          397,
          24536,
          722,
          378909,
          116001,
          1563,
          551,
          2148,
          34153,
          21902,
          53,
          2092,
          1565,
          42384,
          31970,
          2856,
          1577385,
          2036,
          118,
          725,
          1241364,
          344,
          736284,
          1414,
          7268,
          633,
          3699,
          912,
          805,
          46,
          1453,
          532,
          61,
          2054,
          2526,
          42817,
          19054,
          1577385,
          258,
          782,
          626,
          2971,
          1526206,
          24840,
          759,
          320420,
          1577385,
          92043,
          2379,
          686,
          3766,
          1810,
          466,
          60,
          5950,
          50835,
          5901,
          3279,
          6629,
          26551,
          136,
          477,
          27829,
          2906700,
          1966,
          4993,
          85,
          5512,
          71485,
          1523,
          302,
          9521,
          1312922,
          276002,
          21134,
          43,
          140,
          1423,
          470,
          3766,
          1512,
          2135,
          1758,
          757530,
          28425,
          1271,
          2872,
          718,
          222785,
          3119,
          105549,
          641,
          1271,
          630,
          275,
          291,
          1493,
          1760,
          5341,
          1909,
          276896,
          172817,
          76,
          647,
          6469,
          1241364,
          190249,
          454,
          18182,
          641349,
          413574,
          824,
          34153,
          1831,
          184,
          1186,
          1334,
          5211,
          3684,
          53,
          2304,
          31394,
          1504,
          1643,
          1512,
          6581,
          45100,
          2644,
          528,
          2121,
          2786,
          67082,
          291,
          1302,
          391389,
          1228,
          34153,
          824,
          532,
          1766,
          932,
          1766,
          687276,
          3458,
          1166,
          6841,
          45303,
          1523,
          4895,
          3289,
          276002,
          2036,
          4290,
          76383,
          31394,
          2408,
          9815,
          753116,
          1762,
          759,
          825,
          165556,
          54767,
          1078,
          1051,
          1019,
          1892,
          1241364,
          471,
          222785,
          49,
          540,
          43,
          632,
          3699,
          128354,
          54767,
          3224,
          1791,
          571,
          753116,
          222,
          54287,
          1443,
          1766,
          409656,
          1412,
          2807,
          3096,
          1201,
          207410,
          8007,
          2501,
          21134,
          254282,
          1263321,
          9587,
          163415,
          1063,
          156391,
          798,
          2644,
          9034,
          136,
          79613,
          124967,
          59705,
          1858,
          695,
          3862,
          1577385,
          1383,
          50835,
          3688,
          718,
          5875,
          237282,
          1312,
          116001,
          23045,
          2328,
          6006,
          378909,
          1490,
          2142,
          5778,
          1523,
          648,
          241,
          331,
          498,
          4354,
          177,
          372,
          372,
          45100,
          1132,
          760,
          61,
          47249,
          2443,
          237282,
          532,
          1324,
          5161,
          3096,
          5662,
          1139,
          6006,
          836,
          811,
          2211,
          2303,
          17047,
          765,
          571,
          6951,
          626,
          2376,
          3289,
          645,
          181438,
          346,
          302,
          8097,
          54287,
          1131,
          2121,
          60,
          128,
          6703,
          642,
          1139,
          1271,
          1923,
          1925,
          2290,
          104,
          124967,
          324,
          5927,
          526,
          1847,
          302,
          218,
          824,
          1925,
          34882,
          54767,
          2807,
          51,
          4471,
          1789,
          92608,
          1446,
          23727,
          743,
          84106,
          128,
          365,
          937,
          192,
          18182,
          4367,
          5666,
          1595797,
          145,
          804,
          78968,
          47211,
          5211,
          606,
          628,
          276002,
          608,
          46,
          1423,
          46563,
          1847,
          3458,
          218,
          4729,
          1363,
          606,
          6951,
          885,
          277,
          2202,
          302,
          642,
          5507,
          2317,
          9521,
          1139,
          104396,
          116001,
          1523,
          1022298,
          1446,
          337,
          134056,
          502,
          647,
          116155,
          128,
          2303,
          509,
          276896,
          1363,
          5760,
          139650,
          61,
          1577385,
          1770,
          5791,
          743,
          276002,
          269,
          1178,
          321,
          14783,
          828,
          140,
          1643,
          77,
          466,
          964,
          5950,
          3807,
          647,
          55345,
          1051,
          7155,
          601723,
          1241364,
          92043,
          272134,
          1684,
          1745,
          1530,
          1100,
          9594,
          409656,
          493806,
          61,
          836,
          31394,
          348,
          1382480,
          817312,
          3285,
          19090,
          21902,
          663,
          1766,
          2807,
          2870,
          1628,
          172817,
          46563,
          5619,
          18182,
          35439,
          4198,
          9565,
          9587,
          20328,
          1261,
          19054,
          695,
          3096,
          3066,
          928,
          1312922,
          4508,
          176,
          1563,
          19685,
          1312,
          1312,
          1583,
          2307,
          7646,
          530,
          2383912,
          110,
          9772,
          1261,
          509,
          910148,
          50835,
          2263,
          111,
          36438,
          2089,
          52126,
          2870,
          69,
          34496,
          224256,
          258,
          798,
          795,
          2691,
          50489,
          47211,
          2328,
          3228,
          2202,
          1178,
          6703,
          118,
          9565,
          589,
          14742,
          519,
          178,
          1493,
          14228,
          633,
          817312,
          493806,
          1686,
          14871,
          5621,
          3766,
          128354,
          14228,
          17867,
          3730,
          5950,
          4729,
          4090,
          3343,
          817312,
          341,
          184,
          241,
          372,
          1847,
          69793,
          11751,
          140,
          2317,
          1930,
          391389,
          5950,
          4653,
          136,
          520,
          498,
          4542,
          22930,
          1363,
          3766,
          805,
          885,
          757530,
          151785,
          48194,
          1925,
          1789,
          1063,
          79613,
          1304,
          498,
          832,
          71335,
          1892,
          1847,
          1382480,
          1051,
          1139,
          6434,
          597,
          16163,
          601723,
          17867,
          277,
          1412,
          17867,
          771,
          4090,
          910148,
          1051,
          2644,
          5548,
          6508,
          4090,
          811,
          3223,
          2607,
          328,
          8512,
          1075,
          3688,
          338,
          55345,
          18459,
          7297,
          52126,
          3224,
          5989,
          178,
          269,
          61,
          229,
          123373,
          4726,
          26120,
          71485,
          1939,
          139,
          4512,
          21134,
          1909,
          88735,
          12747,
          2016,
          397,
          2906700,
          222,
          321,
          79613,
          69,
          1363,
          191096,
          320,
          914,
          4290,
          3833,
          1442,
          1019,
          5354,
          34882,
          5760,
          3684,
          2661,
          8097,
          8874,
          19685,
          171170,
          341043,
          258,
          11751,
          95015,
          910148,
          5848,
          1201,
          13973,
          1288,
          899,
          224256,
          136,
          2258,
          205,
          76383,
          194500,
          2518,
          741,
          51,
          21437,
          86954,
          140,
          1426,
          34882,
          122111,
          1758,
          34153,
          3255,
          673342,
          123,
          1841,
          7163,
          1504,
          914,
          606,
          4512,
          5161,
          1526206,
          864,
          6951,
          841711,
          8333,
          673342,
          1228,
          823,
          151022,
          269,
          233060,
          4664,
          47211,
          190249,
          635,
          343,
          397,
          1312922,
          1514,
          1213,
          641349,
          5791,
          3766,
          602,
          635,
          99,
          18760,
          1178,
          1643,
          230,
          136,
          83,
          1195,
          9051,
          95,
          27971,
          23045,
          761,
          111,
          1970,
          24536,
          606,
          13602,
          823,
          129,
          20328,
          1420,
          1312,
          640470,
          153,
          528,
          17867,
          532,
          1195,
          43102,
          2644,
          1288,
          22191,
          736284,
          1087,
          5161,
          1196,
          20328,
          35371,
          28739,
          5354,
          771,
          1178,
          1909,
          19090,
          885,
          142,
          635,
          3684,
          725,
          31515,
          3289,
          263,
          1102,
          1312922,
          100,
          4090,
          128,
          35299,
          5989,
          1745,
          1271,
          137067,
          5507,
          165556,
          1745,
          450,
          509,
          36784,
          2054,
          18459,
          5548,
          928,
          276002,
          34882,
          1368,
          5760,
          337,
          1892,
          3096,
          4154,
          96942,
          4726,
          18408,
          7155,
          1102,
          51,
          1690,
          43,
          158701,
          137067,
          71335,
          17867,
          8830,
          163415,
          263,
          1514,
          20328,
          19408,
          42619,
          43,
          338,
          1241364,
          5196,
          94325,
          158701,
          1841,
          190,
          17867,
          3766,
          21125,
          633,
          4895,
          1679,
          895,
          606,
          391389,
          1166,
          6006,
          198,
          3684,
          137067,
          504,
          136,
          31970,
          104396,
          3395,
          92043,
          17867,
          6841,
          1382480,
          450,
          28739,
          1196,
          92106,
          34496,
          3202,
          922,
          217,
          301,
          128715,
          20328,
          1241364,
          1414,
          895,
          151815,
          2691,
          427,
          635,
          11751,
          7297,
          1661,
          2661,
          2135,
          54287,
          35299,
          824,
          129,
          3688,
          6469,
          19685,
          4172,
          53,
          3833,
          35299,
          4726,
          1675,
          13983,
          1383,
          328,
          937,
          260,
          1758,
          20478,
          502,
          99,
          1126,
          1126,
          140,
          502,
          530,
          276896,
          632,
          70,
          626,
          606,
          190178,
          680,
          5666,
          15426,
          2263,
          1789,
          7268,
          53,
          34496,
          6508,
          1628,
          22930,
          2471,
          34153,
          973849,
          964,
          1078,
          1680,
          123,
          1423,
          123373,
          1536,
          471,
          1760,
          4354,
          1186,
          1679,
          4512,
          153,
          4677,
          1252,
          1684,
          27971,
          1661,
          3223,
          6469,
          4913,
          19685,
          194500,
          77,
          1766,
          470,
          1847,
          172247,
          1892,
          128,
          1841,
          43,
          77,
          207410,
          824,
          753116,
          94014,
          267,
          1022298,
          2092,
          313,
          1970,
          2208,
          75830,
          190178,
          158701,
          4306,
          1412,
          1689,
          124967,
          21902,
          606,
          606,
          172817,
          45100,
          3066,
          4138,
          140,
          370,
          1140,
          2258,
          263,
          1745,
          267,
          1293,
          626,
          1930,
          343,
          43102,
          190178,
          331,
          348,
          828,
          320,
          308,
          1120,
          48194,
          341043,
          1334,
          1383,
          6469,
          84861,
          471,
          540,
          18760,
          1383,
          1925,
          3096,
          1126,
          99,
          633,
          124967,
          4895,
          1565,
          176,
          50489,
          1690,
          863,
          1139,
          836,
          454,
          595,
          5507,
          5901,
          722,
          1412,
          1228,
          5621,
          1263321,
          3451,
          1847,
          4090,
          2223,
          25459,
          8830,
          2518,
          3833,
          413574,
          34882,
          4575,
          1847,
          5901,
          6951,
          1892,
          2379,
          372,
          198,
          263,
          760,
          5619,
          640470,
          7646,
          76383,
          163415,
          888,
          910148,
          1563,
          4354,
          3228,
          1196,
          1228,
          75830,
          52,
          71463,
          1858,
          722,
          337,
          1666,
          144160,
          551,
          355,
          2368,
          21125,
          765,
          5457,
          1423,
          47772,
          1196,
          571,
          207,
          8333,
          1324,
          192805,
          14075,
          695,
          565,
          4424,
          337,
          7155,
          795,
          2408,
          1909,
          3684,
          3805,
          74,
          338,
          2368,
          427,
          509,
          722,
          642,
          94014,
          32891,
          95035,
          71485,
          343,
          94325,
          2135,
          687276,
          1132,
          93193,
          105549,
          602,
          1970,
          5621,
          1089,
          9679,
          1563,
          1263321,
          301,
          254282,
          969,
          52126,
          632,
          100,
          5901,
          743,
          2607,
          4512,
          493806,
          522,
          20478,
          1312922,
          271,
          9784,
          110,
          4542,
          11250,
          11256,
          343,
          165,
          9772,
          215,
          100,
          4726,
          4074,
          1666,
          67858,
          43,
          5901,
          2870,
          413574,
          673342,
          3032,
          270712,
          565,
          1760,
          3495,
          76,
          2607,
          741,
          224256,
          8874,
          1970,
          79008,
          1574,
          489,
          272,
          341,
          28739,
          123,
          757530,
          632,
          137,
          2501,
          1725,
          34882,
          2060,
          1383,
          238602,
          2526,
          217,
          50835,
          53,
          222785,
          1480,
          4542,
          923,
          297,
          5577,
          5457,
          832,
          46,
          878,
          321,
          43102,
          540,
          2471,
          4589,
          467,
          471,
          2408,
          1312,
          4913,
          606,
          564,
          1766,
          932,
          3395,
          1686,
          5778,
          3684,
          71335,
          172817,
          741,
          1383,
          1749,
          5161,
          87124,
          42817,
          71335,
          1684,
          878,
          493806,
          910148,
          18182,
          46944,
          765,
          564,
          1810,
          123373,
          128715,
          964,
          166081,
          198,
          2135,
          92985,
          1770,
          2906700,
          10256,
          14742,
          13835,
          922,
          4138,
          1213,
          744,
          1979,
          564,
          2092,
          1186,
          2395,
          695,
          30770,
          3862,
          27020,
          238602,
          149,
          1288,
          1102,
          30770,
          276002,
          1139,
          320420,
          27829,
          1617,
          970,
          1847,
          92043,
          9784,
          571,
          343,
          5666,
          47772,
          4533,
          22930,
          260,
          71485,
          207,
          19054,
          2836,
          18128,
          475,
          1241364,
          344,
          68211,
          73,
          313,
          5901,
          63,
          888,
          21125,
          2526,
          6284,
          163415,
          237282,
          46,
          128,
          2135,
          338,
          129,
          13717,
          53,
          76383,
          158701,
          12335,
          74,
          551,
          14742,
          470,
          28425,
          4575,
          272,
          1766,
          1595797,
          346,
          1271,
          3032,
          123,
          31515,
          233717,
          50835,
          532,
          34496,
          1288,
          4198,
          128354,
          71463,
          2870,
          18459,
          3285,
          24536,
          21125,
          42817,
          1019,
          32891,
          343,
          7268,
          53,
          1089,
          459921,
          1512,
          2408,
          964,
          18408,
          140,
          55345,
          1302,
          5341,
          606,
          13835,
          413574,
          1831,
          3776,
          68211,
          163415,
          37,
          165,
          9034,
          3776,
          237282,
          2456,
          1595797,
          1506,
          749635,
          166081,
          295,
          602,
          184,
          759,
          341043,
          94325,
          632,
          1675,
          25459,
          35371,
          5548,
          2856,
          798,
          2872,
          123373,
          76383,
          128715,
          1312,
          798,
          1078,
          2518,
          5211,
          341,
          2036,
          54767,
          3032,
          3699,
          165556,
          184,
          3994,
          331,
          743,
          269,
          1087,
          277,
          1312,
          7155,
          2290,
          145,
          1493,
          526,
          1360,
          75830,
          1684,
          743,
          17867,
          5950,
          1324,
          5507,
          732,
          370,
          737,
          1312,
          34882,
          1595797,
          43,
          1530,
          6469,
          759,
          1523,
          1423,
          1241364,
          1490,
          34882,
          104396,
          7155,
          912,
          2307,
          5895,
          498,
          2258,
          5196,
          1382480,
          647,
          346,
          2368,
          54287,
          3508,
          139650,
          695,
          93193,
          1360,
          4542,
          7692,
          1423,
          52126,
          471,
          1504,
          43,
          7297,
          3807,
          910148,
          741,
          1979,
          601723,
          1478,
          6018,
          128,
          59744,
          878,
          1022298,
          4726,
          1490,
          77,
          888,
          795,
          3996,
          19054,
          1628,
          1517,
          1666,
          2471,
          302,
          3119,
          717255,
          291,
          1190,
          172817,
          5989,
          176,
          376,
          33917,
          1051,
          49,
          1271,
          571,
          888,
          601723,
          5901,
          397,
          5666,
          4726,
          28278,
          722,
          753116,
          509,
          53,
          34882,
          344,
          92294,
          3032,
          888,
          100,
          2036,
          1654,
          1725,
          614,
          346,
          1760,
          267,
          2376,
          1504,
          207,
          95,
          800,
          21134,
          6006,
          5161,
          4729,
          630,
          2097,
          9815,
          1075,
          18182,
          198,
          1412,
          965,
          7155,
          532,
          71485,
          99,
          565,
          470,
          2135,
          922,
          7268,
          568,
          276,
          601723,
          22305,
          86954,
          1288,
          1312922,
          6713,
          1689,
          242,
          6460,
          213,
          5950,
          910148,
          16183,
          241,
          722,
          75830,
          77,
          450,
          2307,
          1523,
          42619,
          1261,
          241,
          105549,
          341,
          23045,
          258,
          823,
          2566,
          71335,
          1360,
          1791,
          1100,
          5666,
          1493,
          914,
          1312922,
          741,
          42384,
          11256,
          118,
          1656,
          4306,
          1075,
          45100,
          673342,
          19408,
          595,
          184,
          1631,
          166081,
          184,
          69,
          7420,
          1022298,
          46563,
          50489,
          1051,
          626,
          725,
          743,
          1526206,
          346,
          601723,
          1288,
          4424,
          1533,
          145,
          4074,
          238602,
          717255,
          1102,
          77,
          35705,
          5512,
          2078,
          4573,
          1850,
          3807,
          14871,
          24645,
          76,
          589,
          4664,
          3402,
          2121,
          22191,
          1577385,
          471,
          372,
          190,
          30770,
          1063,
          4198,
          647,
          471,
          1252,
          3699,
          895,
          6581,
          1679,
          134056,
          298,
          1789,
          1810,
          741,
          52,
          1574,
          1762,
          4895,
          5621,
          5161,
          504,
          84106,
          2401,
          743,
          223,
          1288,
          470,
          22305,
          2518,
          493,
          27971,
          276002,
          6469,
          277,
          551,
          10076,
          5791,
          5451,
          2092,
          3688,
          3458,
          54185,
          222785,
          3066,
          18760,
          3688,
          1892,
          123373,
          2504700,
          19054,
          5211,
          1725,
          4653,
          1132,
          18408,
          32891,
          2078,
          1051,
          350,
          3451,
          606,
          540,
          118,
          35371,
          42384,
          2211,
          2501,
          5577,
          1423,
          43102,
          129,
          1420,
          242,
          590,
          87124,
          310,
          4090,
          7430,
          46563,
          35439,
          1946,
          551,
          1725,
          71463,
          378909,
          18182,
          823,
          2317,
          1360,
          5512,
          640470,
          4074,
          443,
          3807,
          4508,
          128715,
          2906700,
          710,
          9594,
          606,
          832,
          6581,
          1446,
          9506,
          139650,
          190,
          241,
          75903,
          5719,
          1022298,
          123,
          1022298,
          4878,
          1261,
          46944,
          1841,
          233060,
          177,
          25459,
          917,
          78968,
          464,
          3343,
          1789,
          95,
          2504700,
          4138,
          10717,
          213,
          24840,
          1453,
          137,
          128,
          1656,
          1532,
          12747,
          757530,
          673342,
          192,
          817312,
          78968,
          61,
          3766,
          17867,
          595,
          1789,
          6469,
          4542,
          3255,
          45303,
          17867,
          13835,
          1312922,
          601723,
          7297,
          158701,
          331,
          26551,
          1847,
          2836,
          7987,
          1789,
          2607,
          3495,
          718,
          504,
          172247,
          1679,
          151022,
          144160,
          18459,
          47211,
          5666,
          10076,
          128,
          1850,
          722,
          717255,
          328,
          16305,
          7163,
          759,
          153,
          124967,
          1019,
          372,
          606,
          302,
          2836,
          5548,
          22930,
          895,
          1146,
          1810,
          964,
          391389,
          878,
          18760,
          1791,
          151815,
          260,
          172817,
          3430,
          4081,
          313,
          71485,
          811,
          5719,
          241,
          1075,
          2518,
          5196,
          3451,
          178,
          75830,
          32891,
          172817,
          31515,
          42817,
          1190,
          7987,
          32891,
          94325,
          4172,
          76383,
          2263,
          7155,
          166081,
          680,
          27971,
          741,
          493,
          595,
          478,
          10256,
          5666,
          118,
          291,
          532,
          1595797,
          13717,
          5507,
          19090,
          530,
          192,
          878,
          463,
          1241364,
          743,
          17867,
          214703,
          14075,
          1490,
          525713,
          927396,
          1263321,
          320420,
          4895,
          78968,
          743,
          413574,
          1195,
          4138,
          3224,
          1423,
          1228,
          47211,
          1583,
          1382480,
          9565,
          760,
          513,
          18128,
          343,
          1946,
          464,
          71463,
          5875,
          100,
          1334,
          885,
          520,
          1075,
          337,
          4778,
          86954,
          92337,
          2368,
          55581,
          4677,
          5341,
          1725,
          409656,
          1745,
          1263321,
          2148,
          5895,
          50835,
          1263321,
          1312,
          1760,
          6841,
          1988,
          493806,
          1631,
          178,
          184,
          34882,
          7268,
          1966,
          18128,
          1019,
          648,
          184,
          1426,
          276002,
          9565,
          6713,
          2328,
          5848,
          1939,
          391389,
          969,
          51427,
          1423,
          28739,
          5778,
          96942,
          471,
          190178,
          372,
          2691,
          267,
          1228,
          1446,
          2304,
          1523,
          647,
          4729,
          922,
          478,
          149,
          46944,
          5778,
          194500,
          3451,
          466,
          13835,
          640470,
          922,
          419,
          2807,
          192,
          237282,
          31394,
          2258,
          20478,
          331,
          2526,
          1196,
          144160,
          343,
          28739,
          7646,
          680,
          104396,
          3766,
          28739,
          128,
          914,
          4154,
          145,
          928,
          1461,
          7297,
          248,
          24645,
          238602,
          5507,
          123,
          350,
          320420,
          67858,
          519,
          272,
          564,
          15623,
          3766,
          3833,
          911,
          34153,
          828,
          1925,
          450,
          1526206,
          1368,
          653,
          16183,
          149,
          372,
          198,
          123,
          324,
          190178,
          4677,
          964,
          1923,
          409656,
          136,
          479994,
          3688,
          1312,
          184,
          459921,
          73,
          1533,
          6629,
          1178,
          184,
          1523,
          149,
          606,
          10295,
          1526206,
          1680,
          1078,
          34882,
          1089,
          35439,
          124967,
          1847,
          885,
          2872,
          530,
          895,
          502,
          77,
          1261,
          2016,
          77,
          753116,
          241,
          895,
          2807,
          1261,
          1139,
          1725,
          297,
          765,
          595,
          864,
          4508,
          467,
          53,
          2303,
          328,
          34153,
          1571,
          237282,
          341,
          93193,
          11751,
          365,
          18760,
          24536,
          85,
          92608,
          502,
          104396,
          163415,
          139650,
          328,
          532,
          1526206,
          77,
          2263,
          1766,
          1442,
          18408,
          565,
          302,
          291,
          277,
          509,
          24645,
          32891,
          17047,
          34153,
          5341,
          722,
          207,
          1645,
          43,
          630,
          6120,
          43,
          1304,
          79613,
          51427,
          137067,
          54767,
          4056,
          470,
          1383,
          133,
          331,
          427,
          206,
          725,
          2078,
          99,
          136,
          134056,
          1213,
          459921,
          4005,
          4593,
          191096,
          124967,
          8269,
          725,
          1770,
          2395,
          4603,
          47772,
          241,
          427,
          1988,
          1263321,
          10717,
          1190,
          1363,
          2092,
          4508,
          5908,
          116155,
          21902,
          1490,
          516,
          19685,
          7692,
          4074,
          163415,
          16163,
          450,
          165,
          343,
          571,
          910148,
          1979,
          628,
          972,
          7155,
          1201,
          3495,
          5875,
          645,
          35705,
          1179,
          602,
          888,
          6006,
          190178,
          753116,
          46563,
          4424,
          95035,
          19090,
          128715,
          218,
          2870,
          165556,
          7565,
          2263,
          2906700,
          1749,
          19408,
          899,
          1810,
          85,
          1643,
          13422,
          3876,
          3766,
          1140,
          710,
          6469,
          1617,
          525713,
          516,
          33917,
          118,
          34496,
          1530,
          10295,
          1533,
          43102,
          5895,
          95,
          269,
          124967,
          71485,
          17867,
          1666,
          1645,
          71485,
          248,
          718,
          60,
          38912,
          965,
          1979,
          1143,
          733,
          186140,
          2223,
          1382480,
          493806,
          52126,
          324,
          2317,
          1252,
          7646,
          5512,
          4542,
          5577,
          203571,
          190178,
          241,
          5354,
          804,
          1312,
          124967,
          2135,
          568,
          6713,
          1263321,
          123,
          6581,
          498,
          144160,
          1892,
          128354,
          276002,
          48194,
          757530,
          151815,
          2092,
          186140,
          4172,
          19408,
          1909,
          6006,
          2470,
          34496,
          84106,
          6841,
          2054,
          3487,
          75830,
          337,
          606,
          6460,
          11432,
          471,
          1666,
          27971,
          270712,
          836,
          321,
          648,
          1970,
          1228,
          5666,
          1645,
          1909,
          737,
          381459,
          2870,
          2971,
          2258,
          1791,
          17867,
          1766,
          3684,
          207,
          35705,
          263,
          584,
          163415,
          1139,
          313,
          12335,
          5760,
          1679,
          836,
          1689,
          2317,
          1274,
          4512,
          46563,
          128715,
          545147,
          27020,
          217,
          178,
          1382480,
          298,
          9679,
          1186,
          222,
          5341,
          836,
          50835,
          276896,
          1831,
          166081,
          722,
          134056,
          1165,
          470,
          4015,
          139,
          192805,
          545147,
          1666,
          1850,
          828,
          4729,
          606,
          1312,
          466,
          1512,
          2036,
          269,
          4913,
          1324,
          631,
          695,
          530,
          84106,
          4720,
          71335,
          6006,
          239,
          1312922,
          116155,
          1897,
          1791,
          95015,
          4993,
          78968,
          128,
          28425,
          765,
          639,
          4005,
          194500,
          8097,
          320420,
          964,
          753116,
          27020,
          3996,
          686,
          87124,
          1789,
          5341,
          17867,
          3202,
          34153,
          391389,
          805,
          238602,
          1675,
          1302,
          3876,
          2523,
          136,
          1946,
          1583,
          3402,
          895,
          1970,
          631,
          184,
          87124,
          54185,
          2644,
          878,
          686,
          35371,
          1202,
          606,
          24536,
          47249,
          1766,
          6629,
          467,
          149,
          409656,
          718,
          46,
          1443,
          214703,
          885,
          134056,
          1493,
          1841,
          18128,
          14783,
          140,
          1089,
          710,
          43,
          863,
          23805,
          365,
          92608,
          1190,
          391389,
          722,
          9594,
          7297,
          1051,
          464,
          2644,
          6713,
          88735,
          192805,
          4354,
          190178,
          156391,
          207,
          238602,
          3684,
          1523,
          276896,
          17867,
          1789,
          1490,
          1892,
          10295,
          602,
          722,
          899,
          1643,
          87124,
          333497,
          566,
          759,
          46944,
          2870,
          630,
          6951,
          551,
          217,
          2518,
          470,
          3495,
          695,
          47249,
          2435,
          477,
          477,
          13717,
          1595797,
          217,
          647,
          513,
          6469,
          2135,
          337,
          1228,
          15623,
          10076,
          55345,
          910148,
          2870,
          9815,
          21902,
          163415,
          123,
          2408,
          6469,
          328,
          3688,
          1946,
          795,
          255,
          1533,
          757530,
          344,
          2856,
          795,
          964,
          687276,
          922,
          743,
          718,
          1453,
          3066,
          12335,
          1201,
          276896,
          341,
          2304,
          9594,
          31515,
          1661,
          85,
          3487,
          397,
          2526,
          450,
          135332,
          478,
          31515,
          3402,
          673342,
          137,
          2304,
          673342,
          2607,
          5875,
          3402,
          3096,
          47249,
          645,
          7268,
          2328,
          832,
          743,
          626,
          743,
          1847,
          3223,
          128715,
          43102,
          1595797,
          186140,
          2457,
          1493,
          1383,
          26551,
          1530,
          376,
          128354,
          413574,
          241,
          836,
          48194,
          1334,
          3224,
          168,
          258,
          134056,
          5901,
          1507,
          817312,
          241,
          1022298,
          71485,
          626,
          381459,
          9993,
          540,
          106,
          836,
          270712,
          320420,
          166081,
          695,
          632,
          331,
          498,
          922,
          22305,
          128354,
          2644,
          84861,
          47249,
          302,
          190178,
          75830,
          545147,
          1363,
          344,
          1261,
          3688,
          260,
          308,
          2457,
          4049,
          1970,
          295,
          466,
          635,
          1810,
          899,
          13717,
          606,
          630,
          47211,
          191096,
          2208,
          427,
          18408,
          372,
          69,
          1595797,
          489,
          7692,
          69,
          378909,
          35439,
          6018,
          509,
          190178,
          22930,
          18182,
          4056,
          1563,
          964,
          737,
          4161,
          467,
          258,
          165556,
          4198,
          4074,
          198,
          509,
          5901,
          95035,
          1563,
          836,
          606,
          140,
          771,
          71485,
          595,
          1512,
          18760,
          5211,
          1078,
          2304,
          47,
          27020,
          167,
          760,
          84861,
          237282,
          2906700,
          105549,
          1760,
          11751,
          6841,
          7155,
          467,
          313,
          69,
          836,
          391389,
          2158,
          1789,
          635,
          55345,
          3263,
          413574,
          6841,
          84106,
          42619,
          4161,
          165,
          1532,
          77,
          276896,
          54287,
          4508,
          6469,
          1686,
          230,
          5621,
          1089,
          828,
          2304,
          4589,
          5875,
          932,
          99,
          450,
          346,
          346,
          1190,
          19685,
          2121,
          1617,
          276002,
          493806,
          153,
          2016,
          248,
          190178,
          5895,
          10076,
          241,
          4575,
          38912,
          13422,
          46563,
          69793,
          1363,
          34496,
          32891,
          134056,
          2906700,
          34153,
          972,
          2317,
          1645,
          213,
          18182,
          73,
          6434,
          722,
          2408,
          7268,
          595,
          525713,
          1725,
          30770,
          13061,
          2303,
          3996,
          1512,
          123,
          1178,
          973849,
          1186,
          28739,
          67082,
          673342,
          899,
          1126,
          798,
          96942,
          242,
          2376,
          43,
          28739,
          2807,
          9815,
          51,
          642,
          343,
          46,
          365,
          47249,
          1132,
          267,
          932,
          2054,
          1019,
          633,
          4172,
          267,
          4729,
          302,
          467,
          1241364,
          71335,
          191096,
          647,
          4653,
          1131,
          178,
          241,
          743,
          888,
          8269,
          31394,
          3688,
          76383,
          24840,
          169,
          51,
          832,
          75830,
          3289,
          11253,
          571,
          1700,
          28739,
          1766,
          28425,
          5648,
          673342,
          532,
          3395,
          391389,
          248858,
          509,
          46563,
          606,
          1645,
          4913,
          5621,
          832,
          46563,
          1241364,
          1791,
          105549,
          832,
          3104,
          3495,
          12335,
          166081,
          53,
          53,
          149,
          1979,
          15647,
          5989,
          589,
          1988,
          67082,
          77,
          149,
          6713,
          54287,
          516,
          1679,
          733,
          450,
          895,
          28739,
          2097,
          83,
          601723,
          50835,
          190178,
          601723,
          15426,
          2870,
          7987,
          68211,
          25459,
          964,
          242,
          736284,
          1195,
          1426,
          77,
          1807,
          168,
          85,
          376,
          1577385,
          71335,
          1892,
          1758,
          1190,
          19054,
          2401,
          1493,
          16183,
          5791,
          1988,
          673342,
          333497,
          532,
          55345,
          1078,
          1507,
          99,
          1126,
          737,
          10256,
          5791,
          198,
          459921,
          1536,
          717255,
          248858,
          1675,
          144160,
          2142,
          158701,
          1507,
          1022298,
          299480,
          18128,
          836,
          213,
          22930,
          1131,
          590,
          910148,
          75903,
          92043,
          276002,
          1382480,
          1595797,
          6018,
          55581,
          2016,
          13422,
          2471,
          106,
          1461,
          1925,
          1263321,
          602,
          238602,
          6841,
          2376,
          1271,
          14871,
          59744,
          23727,
          2401,
          2328,
          3996,
          1271,
          63,
          143,
          341043,
          328,
          140,
          1165,
          111,
          686,
          5341,
          299480,
          606,
          186140,
          1512,
          163415,
          2523,
          1312922,
          471,
          5161,
          31394,
          276002,
          247,
          18408,
          19090,
          1506,
          47249,
          3104,
          3458,
          16163,
          95035,
          1324,
          2379,
          757530,
          1368,
          165556,
          190,
          1841,
          2258,
          63,
          4056,
          2135,
          467,
          459921,
          186140,
          198,
          626,
          107941,
          4049,
          1178,
          927396,
          270712,
          2504700,
          2078,
          608,
          144160,
          224256,
          5512,
          687276,
          25459,
          116001,
          7646,
          35705,
          24645,
          36784,
          308,
          23,
          804,
          1571,
          2148,
          23,
          46563,
          46944,
          1022298,
          836,
          477,
          1493,
          378909,
          328,
          5875,
          1051,
          589,
          37,
          269,
          6284,
          4512,
          841711,
          5726,
          167,
          34496,
          1512,
          12335,
          32891,
          3766,
          13983,
          23727,
          2870,
          18760,
          630,
          3343,
          43,
          99,
          1810,
          181438,
          48194,
          10295,
          35371,
          928,
          17867,
          26551,
          4677,
          3876,
          1383,
          6434,
          1847,
          5619,
          23,
          165,
          595,
          964,
          695,
          35299,
          19685,
          2443,
          7268,
          324,
          695,
          4508,
          214703,
          568,
          16163,
          564,
          9594,
          95,
          55345,
          1850,
          47211,
          310,
          242,
          641,
          743,
          1271,
          391389,
          242,
          75830,
          1480,
          9034,
          477,
          213,
          241,
          1446,
          1412,
          186140,
          1766,
          710,
          733,
          878,
          771,
          192805,
          1847,
          112,
          4573,
          2258,
          100,
          2206,
          5666,
          1131,
          525713,
          1506,
          1758,
          2644,
          21437,
          129,
          765,
          760,
          2526,
          1453,
          1368,
          3458,
          4306,
          545147,
          165,
          31394,
          1383,
          737,
          754,
          2368,
          217,
          1725,
          4542,
          2691,
          2328,
          32891,
          647,
          1925,
          970,
          2870,
          34496,
          22191,
          343,
          9772,
          35371,
          832,
          1645,
          94014,
          1966,
          165,
          31515,
          276,
          370,
          11250,
          3833,
          272,
          1661,
          1841,
          1617,
          237282,
          3776,
          568,
          4845,
          571,
          18128,
          969,
          3343,
          15269,
          16183,
          7268,
          14228,
          13422,
          1645,
          427,
          31394,
          16183,
          333497,
          2148,
          899,
          54287,
          94014,
          343,
          217,
          1841,
          69,
          21902,
          328,
          248,
          12486,
          1749,
          2317,
          795,
          1312,
          47772,
          51,
          1178,
          2376,
          139,
          95,
          7430,
          137067,
          1334,
          75830,
          2691,
          2317,
          1382480,
          69,
          632,
          133,
          24840,
          5341,
          106,
          91,
          545147,
          36784,
          7430,
          28739,
          1970,
          828,
          743,
          5341,
          6120,
          214703,
          71485,
          369,
          969,
          7692,
          18128,
          3119,
          1446,
          2376,
          2870,
          836,
          107941,
          1725,
          169,
          140,
          128354,
          1019,
          765,
          3876,
          7163,
          241,
          1680,
          2303,
          10076,
          722,
          18128,
          3451,
          4474,
          4680,
          17867,
          2408,
          5354,
          540,
          55581,
          2208,
          13835,
          78968,
          911,
          878,
          5512,
          1143,
          6006,
          140,
          23,
          49,
          687276,
          467,
          6508,
          32891,
          3996,
          1526206,
          94014,
          237282,
          895,
          321,
          1480,
          5760,
          68211,
          3343,
          1271,
          9587,
          302,
          736284,
          836,
          13602,
          663,
          530,
          10295,
          1051,
          370,
          7155,
          1312922,
          128715,
          1423,
          77,
          4074,
          85,
          3766,
          5512,
          103927,
          1506,
          914,
          254282,
          2856,
          823,
          1352,
          427,
          27829,
          413574,
          1645,
          78968,
          917,
          2036,
          1847,
          1274,
          571,
          3451,
          1102,
          640470,
          207,
          5989,
          1988,
          917,
          7155,
          372,
          139650,
          20478,
          17867,
          1089,
          276002,
          3202,
          630,
          1051,
          581,
          171170,
          5848,
          267,
          42384,
          2054,
          34153,
          1089,
          11432,
          137,
          427,
          782,
          639,
          77,
          158701,
          795,
          38912,
          9521,
          1504,
          2401,
          17867,
          310,
          10717,
          1360,
          9784,
          1261,
          471,
          61,
          928,
          1312922,
          4913,
          276896,
          9587,
          11250,
          2870,
          27829,
          581,
          1383,
          6581,
          470,
          94014,
          6006,
          2401,
          123,
          1930,
          6629,
          10256,
          757530,
          376,
          145,
          165556,
          1523,
          46563,
          1583,
          35299,
          3395,
          8830,
          4074,
          5621,
          937,
          526,
          2523,
          471,
          564,
          630,
          1480,
          545147,
          1789,
          3684,
          8097,
          75903,
          9506,
          1363,
          34882,
          1312922,
          1523,
          1654,
          12486,
          28425,
          3395,
          136,
          191096,
          190249,
          4593,
          46,
          7987,
          2304,
          639,
          4159,
          1412,
          673342,
          1979,
          11432,
          14228,
          16305,
          885,
          237282,
          153,
          3730,
          1675,
          86954,
          1536,
          4895,
          3451,
          16183,
          260,
          1288,
          137067,
          13973,
          85,
          104,
          13973,
          158701,
          276002,
          1453,
          4049,
          16183,
          276002,
          1679,
          2443,
          2054,
          61,
          3688,
          48194,
          2304,
          6460,
          4512,
          320420,
          3996,
          632,
          333497,
          1446,
          15426,
          46944,
          302,
          823,
          4172,
          5211,
          407,
          5196,
          5619,
          1019,
          224256,
          737,
          910148,
          804,
          571,
          85,
          722,
          55345,
          2317,
          1274,
          7987,
          34496,
          11250,
          269,
          8007,
          757530,
          2443,
          520,
          76,
          4056,
          800,
          123373,
          22191,
          1810,
          27829,
          19685,
          1202,
          21902,
          30770,
          757530,
          28739,
          602,
          142,
          27020,
          1195,
          6284,
          35705,
          92043,
          724,
          5908,
          743,
          68211,
          1645,
          1166,
          1201,
          1165,
          2906700,
          11250,
          277,
          2870,
          129,
          1274,
          863,
          1654,
          104,
          190,
          2836,
          338,
          1526206,
          78968,
          1178,
          743,
          2263,
          14783,
          46563,
          759,
          168,
          7646,
          828,
          83,
          1132,
          1725,
          1684,
          471,
          206,
          2258,
          3395,
          46944,
          1461,
          123,
          9587,
          641349,
          3508,
          932,
          2135,
          177,
          1382480,
          111,
          149,
          1645,
          333497,
          94325,
          1271,
          9034,
          276896,
          409656,
          1288,
          2395,
          407,
          1131,
          207410,
          878,
          348,
          166081,
          7646,
          111,
          805,
          2135,
          1126,
          489,
          5438,
          1423,
          1988,
          46,
          2097,
          158701,
          3228,
          6841,
          276002,
          59705,
          93193,
          123,
          5895,
          741,
          254282,
          5908,
          91,
          973849,
          263,
          76383,
          215,
          765,
          6581,
          77,
          5507,
          15426,
          760,
          824,
          94325,
          10256,
          307,
          4354,
          2870,
          1461,
          137067,
          4677,
          1631,
          328,
          69793,
          823,
          1766,
          1689,
          16183,
          5577,
          365,
          28425,
          34496,
          4542,
          9815,
          18182,
          42817,
          1263321,
          1312922,
          313,
          551,
          190178,
          3451,
          9772,
          184,
          99,
          321,
          1766,
          71335,
          55345,
          61,
          16305,
          3096,
          477,
          5211,
          3996,
          1019,
          222785,
          1089,
          590,
          178,
          276896,
          7268,
          2376,
          663,
          34882,
          166081,
          4474,
          50835,
          30770,
          218,
          2054,
          1412,
          301,
          116001,
          1312922,
          9594,
          6120,
          1472,
          34882,
          1595797,
          213,
          3289,
          1126,
          5875,
          1645,
          13983,
          48194,
          248,
          11751,
          213,
          137,
          286,
          970,
          409656,
          134056,
          5211,
          970,
          2456,
          533,
          7297,
          1645,
          18408,
          1766,
          1988,
          647,
          5726,
          5760,
          1078,
          172817,
          2060,
          1075,
          3766,
          477,
          269,
          6284,
          1271,
          186140,
          602,
          308,
          8097,
          5548,
          571,
          1139,
          2395,
          22305,
          551,
          464,
          836,
          1789,
          69793,
          13835,
          5341,
          606,
          77,
          2408,
          1166,
          1684,
          5621,
          18760,
          1789,
          2078,
          269,
          718,
          178,
          9512,
          229,
          2054,
          530,
          50489,
          84106,
          1571,
          4913,
          765,
          92608,
          1063,
          248,
          824,
          165556,
          54287,
          3766,
          1190,
          645,
          502,
          1201,
          899,
          18408,
          5760,
          1512,
          230,
          4677,
          1126,
          2916,
          47249,
          260,
          1595797,
          1382480,
          5760,
          269,
          743,
          34882,
          1089,
          1126,
          254282,
          4575,
          54767,
          71335,
          54767,
          9034,
          5927,
          741,
          33804,
          581,
          241,
          118,
          1789,
          2644,
          1847,
          4074,
          641349,
          1423,
          21134,
          302,
          5354,
          1131,
          100,
          530,
          100,
          722,
          460,
          134056,
          673342,
          53,
          7297,
          1132,
          16163,
          320420,
          5216,
          2036,
          75903,
          190178,
          42384,
          92985,
          92294,
          3862,
          23,
          71335,
          136,
          687276,
          645,
          163415,
          5507,
          4603,
          1078,
          498,
          1595797,
          5662,
          1312,
          3066,
          571,
          1909,
          5196,
          5927,
          1506,
          2307,
          71485,
          606,
          1190,
          76,
          409656,
          24536,
          1461,
          3487,
          324,
          1675,
          2799,
          11432,
          139,
          1414,
          258,
          606,
          795,
          10256,
          3104,
          14228,
          320420,
          635,
          22930,
          1766,
          237282,
          771,
          1804,
          5196,
          571,
          1360,
          878,
          1563,
          824,
          55345,
          733,
          42817,
          5895,
          33917,
          71335,
          2328,
          2916,
          3104,
          754,
          525713,
          24840,
          1595797,
          18760,
          313,
          5760,
          4074,
          20478,
          350,
          28425,
          647,
          1766,
          798,
          36784,
          3487,
          4729,
          2263,
          1526206,
          4573,
          3833,
          5666,
          1414,
          118,
          832,
          4290,
          2376,
          2526,
          464,
          530,
          2368,
          1675,
          22930,
          1850,
          1565,
          477,
          2206,
          1078,
          525713,
          4161,
          1892,
          229,
          3343,
          46944,
          4664,
          1892,
          1271,
          5927,
          47249,
          2135,
          260,
          163415,
          1617,
          372,
          355,
          1493,
          5438,
          145,
          5908,
          8512,
          1504,
          7297,
          6460,
          123,
          75830,
          3684,
          4677,
          124967,
          7297,
          95035,
          564,
          969,
          1131,
          6713,
          686,
          2135,
          1263321,
          51,
          722,
          4290,
          4005,
          2807,
          6284,
          2518,
          3684,
          1532,
          276002,
          79613,
          24645,
          1766,
          1446,
          467,
          695,
          151022,
          1143,
          1563,
          841711,
          6581,
          776,
          163415,
          1140,
          2526,
          1946,
          1766,
          166081,
          964,
          3495,
          16183,
          1532,
          5211,
          95015,
          2202,
          91,
          1120,
          4056,
          1312922,
          47249,
          198,
          928,
          76383,
          2807,
          12335,
          4664,
          247,
          194500,
          1461,
          76,
          94014,
          3495,
          1120,
          17047,
          128354,
          804,
          722,
          48194,
          52126,
          1213,
          6508,
          2368,
          14228,
          4729,
          811,
          899,
          324,
          427,
          4664,
          67082,
          151785,
          471,
          8007,
          42384,
          1382480,
          14871,
          3066,
          4512,
          771,
          1228,
          1312922,
          937,
          4913,
          427,
          640470,
          376,
          214703,
          3343,
          46563,
          320420,
          1684,
          11250,
          525713,
          9034,
          2395,
          5354,
          467,
          7430,
          725,
          5341,
          350,
          584,
          526,
          27971,
          645,
          3495,
          824,
          5726,
          9521,
          27971,
          5438,
          973849,
          43,
          277,
          754,
          895,
          828,
          4056,
          1126,
          2872,
          1312922,
          156391,
          48194,
          1831,
          1312922,
          1606,
          3224,
          1892,
          2471,
          50835,
          1970,
          61,
          463,
          217,
          69793,
          258,
          28425,
          16183,
          5341,
          35371,
          205,
          663,
          526,
          4056,
          1766,
          409656,
          129,
          136,
          1847,
          923,
          6713,
          1228,
          626,
          346,
          1858,
          2263,
          205,
          741,
          2304,
          28425,
          2870,
          192805,
          21902,
          1461,
          912,
          166081,
          129,
          23,
          310,
          4729,
          459921,
          2607,
          12335,
          2263,
          1453,
          1847,
          3684,
          5619,
          2501,
          647,
          15269,
          6469,
          1139,
          1892,
          229,
          498,
          1536,
          35371,
          1383,
          1656,
          3994,
          28739,
          3279,
          817312,
          687276,
          36784,
          5621,
          489,
          895,
          2135,
          337,
          184,
          2258,
          744,
          1504,
          551,
          69793,
          695,
          467,
          722,
          498,
          4729,
          341,
          313,
          186140,
          3285,
          973849,
          27971,
          269,
          6951,
          2328,
          50835,
          1645,
          355,
          79008,
          1263321,
          2317,
          378909,
          223,
          31394,
          7420,
          30770,
          3862,
          118,
          166081,
          633,
          79613,
          95015,
          502,
          10295,
          163415,
          5666,
          804,
          237282,
          70,
          269,
          2148,
          648,
          680,
          470,
          92985,
          343,
          1131,
          732,
          238602,
          255,
          207,
          190178,
          272,
          828,
          5791,
          718,
          502,
          520,
          5211,
          5621,
          743,
          88735,
          895,
          1628,
          1970,
          203571,
          6469,
          530,
          932,
          341043,
          1507,
          2368,
          413574,
          238602,
          743,
          493806,
          1700,
          1352,
          71485,
          233717,
          276896,
          1178,
          365,
          4778,
          128354,
          3776,
          601723,
          568,
          2906700,
          54287,
          6460,
          836,
          55581,
          2368,
          248,
          4677,
          35439,
          964,
          4081,
          9815,
          378909,
          467,
          2906700,
          302,
          7987,
          184,
          832,
          478,
          20478,
          5161,
          79008,
          969,
          5161,
          1274,
          87124,
          153,
          19685,
          5548,
          832,
          2807,
          1352,
          6006,
          7268,
          1312922,
          372,
          365,
          937,
          276896,
          630,
          409656,
          1628,
          27020,
          378909,
          271,
          2328,
          1195,
          687276,
          3688,
          1766,
          242,
          79008,
          1271,
          190178,
          532,
          2870,
          343,
          36438,
          54767,
          888,
          3766,
          6006,
          3684,
          540,
          71463,
          937,
          104396,
          1679,
          171170,
          104396,
          30770,
          1504,
          725,
          18128,
          3402,
          602,
          54767,
          136,
          25459,
          811,
          167,
          2054,
          530,
          1766,
          2870,
          76,
          3343,
          5354,
          686,
          1595797,
          50489,
          1478,
          46,
          11250,
          19408,
          3495,
          2408,
          9594,
          1263321,
          6120,
          2906700,
          255,
          863,
          8333,
          67082,
          128,
          378909,
          1274,
          122111,
          1446,
          7155,
          4729,
          71335,
          110,
          2148,
          6713,
          100,
          601723,
          378909,
          5657,
          104396,
          4680,
          1506,
          73,
          9594,
          63,
          1847,
          224256,
          277,
          263,
          1078,
          3766,
          237282,
          3224,
          4677,
          1617,
          321,
          260,
          215,
          493806,
          504,
          5901,
          1312,
          18408,
          67082,
          207410,
          1263321,
          1504,
          76,
          3994,
          1132,
          129,
          606,
          914,
          2290,
          972,
          3285,
          21902,
          1312,
          1089,
          11250,
          224256,
          1461,
          320420,
          48194,
          516,
          286,
          878,
          3104,
          1758,
          9496,
          601723,
          60,
          73,
          2435,
          2971,
          31515,
          836,
          589,
          1780,
          156391,
          1574,
          3807,
          1841,
          1758,
          969,
          1022298,
          1146,
          17867,
          1514,
          84861,
          1847,
          190,
          2799,
          641,
          301,
          47249,
          27971,
          277,
          1368,
          1493,
          2906700,
          22305,
          198,
          372,
          123,
          1453,
          757530,
          568,
          176,
          4895,
          1892,
          343,
          116155,
          260,
          217,
          349,
          24840,
          3343,
          3096,
          1131,
          1526206,
          96942,
          13422,
          118,
          254282,
          344,
          3996,
          2379,
          324,
          2457,
          92608,
          381459,
          782,
          413574,
          241,
          2376,
          184,
          2443,
          635,
          10076,
          2092,
          1312922,
          136,
          828,
          69,
          218,
          291,
          258,
          8007,
          409656,
          99,
          14228,
          4306,
          4575,
          4508,
          498,
          7155,
          757530,
          18459,
          34153,
          50835,
          633,
          18408,
          2290,
          489,
          545147,
          381459,
          55345,
          7692,
          1263321,
          71485,
          639,
          76383,
          129,
          11250,
          51427,
          1850,
          21902,
          1196,
          5621,
          910148,
          331,
          42384,
          5875,
          885,
          165556,
          1213,
          15269,
          427,
          172247,
          1656,
          759,
          1946,
          59744,
          695,
          3688,
          25459,
          50835,
          1831,
          92337,
          42817,
          158701,
          7163,
          526,
          14783,
          27971,
          18128,
          932,
          1190,
          888,
          1666,
          7163,
          7646,
          78968,
          242,
          1261,
          31394,
          1443,
          2836,
          1762,
          5512,
          190178,
          307,
          8830,
          1563,
          4005,
          413574,
          258,
          233717,
          5341,
          2304,
          129,
          647,
          49,
          737,
          321,
          1645,
          568,
          54287,
          37,
          3343,
          1675,
          123373,
          50489,
          151815,
          1312922,
          192,
          1131,
          1512,
          1512,
          31515,
          736284,
          27020,
          7565,
          346,
          36438,
          760,
          42619,
          344,
          94014,
          137,
          95,
          3343,
          910148,
          1645,
          732,
          1745,
          3224,
          100,
          207,
          86954,
          3805,
          1131,
          10295,
          136895,
          741,
          1923,
          69,
          6629,
          69,
          680,
          502,
          50489,
          1302,
          471,
          3104,
          1517,
          3119,
          45100,
          47772,
          7268,
          841711,
          1762,
          20328,
          233717,
          2304,
          17047,
          145,
          1302,
          861,
          409656,
          343,
          601723,
          878,
          551,
          5989,
          116001,
          177,
          601723,
          320420,
          242,
          1271,
          1063,
          413574,
          5927,
          504,
          680,
          46563,
          1423,
          4589,
          1925,
          50835,
          184,
          564,
          4138,
          795,
          1979,
          46944,
          37,
          95035,
          878,
          1363,
          53,
          3032,
          198,
          324,
          365,
          3684,
          123373,
          1493,
          16163,
          214703,
          1923,
          1645,
          18459,
          9594,
          1523,
          223,
          1195,
          135332,
          450,
          1178,
          381459,
          2092,
          2395,
          2054,
          22305,
          3228,
          2435,
          20478,
          3430,
          3430,
          10717,
          899,
          76383,
          346,
          3862,
          20328,
          1563,
          92294,
          910148,
          378909,
          1504,
          51,
          343,
          1334,
          2501,
          2906700,
          1075,
          804,
          8269,
          1530,
          540,
          302,
          105638,
          2376,
          59705,
          248,
          12335,
          165556,
          765,
          23,
          1080,
          722,
          520,
          1645,
          4603,
          1643,
          2054,
          1263321,
          3279,
          242,
          258,
          12335,
          467,
          3279,
          23,
          5211,
          878,
          798,
          145,
          1656,
          19054,
          13717,
          571,
          571,
          863,
          24645,
          1645,
          825,
          1196,
          914,
          2435,
          1063,
          2307,
          128715,
          3289,
          3096,
          878,
          9815,
          1943,
          198,
          6629,
          516,
          725,
          4542,
          19054,
          1631,
          18760,
          74,
          76,
          2274,
          1766,
          1563,
          3343,
          99,
          198,
          8830,
          601723,
          302,
          4056,
          5875,
          743,
          749635,
          248,
          601723,
          771,
          128715,
          172817,
          2054,
          640470,
          1725,
          878,
          3684,
          11250,
          2054,
          2807,
          566,
          237282,
          28739,
          2526,
          782,
          1643,
          172817,
          38912,
          302,
          17867,
          2471,
          530,
          190178,
          972,
          7987,
          28739,
          59744,
          34153,
          1312,
          320420,
          3224,
          391389,
          23045,
          18128,
          1506,
          95,
          1089,
          2518,
          1078,
          1583,
          320420,
          1804,
          68211,
          2148,
          1512,
          642,
          1423,
          26551,
          46,
          79613,
          928,
          2644,
          149,
          471,
          5989,
          3996,
          168,
          3430,
          223,
          5989,
          1684,
          165556,
          409656,
          647,
          198,
          571,
          192805,
          413574,
          276896,
          2054,
          5341,
          757530,
          213,
          223,
          86954,
          5196,
          18408,
          24536,
          757530,
          1666,
          9993,
          1078,
          42384,
          12349,
          28739,
          71485,
          2408,
          16163,
          3451,
          21902,
          1988,
          2872,
          1263321,
          178,
          52126,
          427,
          1577385,
          16305,
          4138,
          20328,
          34153,
          626,
          337,
          30770,
          1847,
          478,
          277,
          1263321,
          878,
          128354,
          2135,
          69793,
          92294,
          207,
          722,
          178,
          230,
          42817,
          1925,
          1507,
          6951,
          687276,
          1526206,
          399,
          178,
          92043,
          320420,
          10717,
          84106,
          5161,
          3430,
          1131,
          8830,
          1749,
          128,
          6284,
          198,
          295,
          1847,
          376,
          6581,
          67858,
          3066,
          863,
          5211,
          8019,
          687276,
          313,
          389246,
          190,
          254,
          4056,
          11250,
          7692,
          2470,
          28425,
          23,
          6120,
          513,
          1684,
          571,
          46563,
          172817,
          9815,
          1858,
          254282,
          5989,
          71485,
          2607,
          337,
          13602,
          321,
          47,
          489,
          50489,
          43,
          3684,
          355,
          914,
          710,
          5791,
          1930,
          914,
          4056,
          2471,
          718,
          7646,
          341,
          21635,
          156391,
          828,
          8097,
          741,
          4729,
          71335,
          9587,
          190,
          33804,
          1909,
          568,
          5341,
          795,
          5196,
          3451,
          2870,
          2644,
          642,
          28739,
          1412,
          2691,
          123,
          11256,
          4367,
          568,
          525713,
          30770,
          2036,
          165,
          190178,
          888,
          8007,
          55345,
          137067,
          725,
          21902,
          18182,
          911,
          2906700,
          686,
          118,
          526,
          313,
          911,
          237282,
          237282,
          2443,
          2906700,
          1186,
          247,
          606,
          1312,
          85,
          4593,
          77,
          4533,
          1595797,
          54767,
          2263,
          3508,
          7297,
          459921,
          79613,
          230,
          191096,
          149,
          1850,
          1645,
          8007,
          932,
          350,
          2395,
          54287,
          1760,
          2906700,
          606,
          1201,
          95035,
          365,
          24840,
          5619,
          795,
          43,
          158701,
          6006,
          237282,
          1643,
          320420,
          965,
          241,
          4542,
          6508,
          23,
          1363,
          18760,
          516,
          516,
          79008,
          7430,
          178,
          5457,
          1770,
          198,
          50835,
          224256,
          105549,
          1789,
          59744,
          1645,
          191096,
          1517,
          1412,
          43,
          111,
          46563,
          5875,
          270712,
          937,
          1533,
          247,
          2408,
          158701,
          134056,
          4664,
          129,
          2290,
          545147,
          4542,
          1324,
          1766,
          7646,
          10295,
          239,
          6284,
          1909,
          137,
          2368,
          3996,
          811,
          530,
          14871,
          1252,
          313,
          92608,
          331,
          973849,
          2872,
          8874,
          1288,
          137067,
          100,
          263,
          217,
          14871,
          19090,
          2870,
          1758,
          54185,
          3862,
          1051,
          77,
          229,
          13835,
          320,
          76,
          23045,
          6469,
          61,
          149,
          463,
          937,
          1675,
          9034,
          753116,
          165,
          5211,
          3862,
          99,
          1643,
          190,
          218,
          1051,
          258,
          4603,
          899,
          270712,
          124967,
          489,
          2872,
          14871,
          7268,
          69,
          165556,
          743,
          370,
          42619,
          26551,
          4056,
          137067,
          1196,
          836,
          153,
          93193,
          1312922,
          7565,
          47249,
          184,
          776,
          502,
          68211,
          4508,
          34882,
          4090,
          11751,
          5901,
          722,
          27971,
          828,
          17867,
          7155,
          9815,
          2328,
          922,
          1263321,
          765,
          899,
          2870,
          2158,
          391389,
          378909,
          5908,
          118,
          4729,
          5657,
          224256,
          630,
          564,
          18128,
          642,
          238602,
          17047,
          498,
          75830,
          6951,
          222785,
          863,
          1666,
          2971,
          1360,
          238602,
          1195,
          47249,
          1241364,
          24840,
          158701,
          1725,
          1858,
          1261,
          331,
          10076,
          804,
          2870,
          276,
          124967,
          337,
          528,
          16163,
          1263321,
          493806,
          2368,
          207,
          2135,
          2501,
          139,
          1423,
          110,
          71485,
          409656,
          47249,
          1577385,
          5216,
          1858,
          1423,
          493,
          15269,
          464,
          20328,
          134056,
          1831,
          46,
          34153,
          46944,
          9815,
          22305,
          1789,
          2504700,
          427,
          3684,
          134056,
          42817,
          3202,
          4542,
          687276,
          42817,
          9496,
          4074,
          914,
          21134,
          509,
          606,
          3279,
          606,
          7268,
          153,
          1930,
          33804,
          86954,
          341043,
          1526206,
          899,
          4677,
          1312922,
          520,
          10076,
          192,
          4474,
          3495,
          52,
          1507,
          217,
          3684,
          633,
          626,
          59744,
          1019,
          15623,
          743,
          724,
          493806,
          92608,
          1241364,
          4993,
          1595797,
          1686,
          8512,
          2036,
          753116,
          143,
          1382480,
          2304,
          910148,
          391389,
          2054,
          27971,
          67082,
          95015,
          1420,
          4653,
          4198,
          736284,
          24645,
          28425,
          1762,
          129,
          3833,
          2518,
          26551,
          1645,
          95015,
          21902,
          1132,
          832,
          190249,
          92608,
          26120,
          372,
          502,
          348,
          2016,
          291,
          1563,
          389246,
          1523,
          516,
          1383,
          1645,
          3684,
          2456,
          2872,
          4290,
          18182,
          1791,
          466,
          753116,
          269,
          2317,
          105638,
          13973,
          167,
          6025,
          348,
          7268,
          2607,
          69,
          52126,
          9521,
          3096,
          20328,
          571,
          47249,
          1102,
          1766,
          2786,
          1745,
          1288,
          1831,
          1228,
          198,
          498,
          9772,
          67082,
          1645,
          218,
          140,
          83,
          2290,
          571,
          7163,
          6469,
          46944,
          5354,
          163415,
          11751,
          2872,
          899,
          3202,
          276002,
          4533,
          2328,
          135332,
          641,
          46563,
          136,
          1368,
          46,
          519,
          5903,
          3495,
          1190,
          149,
          648,
          1532,
          4367,
          525713,
          1680,
          1595797,
          140,
          5211,
          76,
          1725,
          1228,
          737,
          540,
          632,
          1312922,
          5161,
          20478,
          47249,
          782,
          4729,
          14871,
          1523,
          87124,
          1526206,
          5895,
          1453,
          1766,
          255,
          19685,
          1078,
          42619,
          270712,
          166081,
          4198,
          1139,
          2971,
          478,
          7268,
          717255,
          71463,
          1526206,
          1263321,
          2258,
          1645,
          111,
          4306,
          3766,
          258,
          914,
          1804,
          395,
          1684,
          3862,
          46563,
          1412,
          1100,
          1453,
          571,
          372,
          5577,
          69793,
          1766,
          899,
          1666,
          47249,
          899,
          34882,
          4573,
          194500,
          1645,
          9815,
          5901,
          1453,
          798,
          1022298,
          166081,
          4913,
          1089,
          94014,
          4993,
          2906700,
          571,
          4653,
          299480,
          4542,
          5895,
          725,
          86954,
          1583,
          1679,
          26551,
          1645,
          48194,
          1526206,
          6006,
          504,
          12335,
          551,
          4005,
          36438,
          73,
          18128,
          5196,
          9772,
          4074,
          27020,
          861,
          2504700,
          450,
          899,
          104396,
          142,
          6006,
          753116,
          828,
          17867,
          92043,
          1841,
          1078,
          3996,
          5161,
          9815,
          1532,
          3996,
          111,
          2208,
          14783,
          376,
          765,
          3343,
          4575,
          61,
          2148,
          5732,
          92337,
          276002,
          864,
          2607,
          1533,
          110,
          4138,
          85,
          5621,
          520,
          99,
          1684,
          46944,
          17867,
          333497,
          217,
          1745,
          298,
          4074,
          1087,
          333497,
          895,
          1126,
          166081,
          43102,
          230,
          972,
          3343,
          3684,
          302,
          139,
          540,
          471,
          92608,
          1847,
          680,
          7268,
          258,
          5875,
          11250,
          222,
          71463,
          9815,
          217,
          6713,
          2121,
          1383,
          3096,
          6469,
          137,
          5903,
          4778,
          207,
          1412,
          3104,
          2644,
          928,
          4677,
          2526,
          35371,
          518429,
          663,
          260,
          7163,
          1089,
          233717,
          1022298,
          46,
          717255,
          302,
          3343,
          1725,
          1263321,
          639,
          16183,
          1577385,
          4542,
          5211,
          9165,
          321,
          1412,
          823,
          12335,
          338,
          530,
          9993,
          502,
          276896,
          520,
          8830,
          828,
          2401,
          7163,
          5989,
          222785,
          93193,
          4159,
          626,
          3688,
          158701,
          2304,
          5760,
          3996,
          69793,
          7268,
          10256,
          24840,
          2691,
          718,
          608,
          832,
          4993,
          4306,
          502,
          107941,
          647,
          1760,
          54767,
          3066,
          76,
          4895,
          88735,
          581,
          165,
          520,
          589,
          19408,
          3104,
          1841,
          2786,
          137,
          9993,
          1645,
          1847,
          76,
          85,
          3684,
          184,
          571,
          1504,
          1132,
          324,
          50489,
          341043,
          224256,
          1523,
          1909,
          71463,
          1478,
          3805,
          92985,
          76383,
          1075,
          49,
          1810,
          31394,
          75903,
          71463,
          21134,
          24840,
          129,
          165,
          3833,
          308,
          118,
          26120,
          601723,
          61,
          241,
          3279,
          687276,
          96942,
          3104,
          479994,
          641349,
          140,
          459921,
          5908,
          757530,
          1563,
          504,
          320420,
          464,
          450,
          1312922,
          217,
          5950,
          54185,
          804,
          3495,
          3495,
          3684,
          69,
          190178,
          47772,
          1241364,
          5438,
          1766,
          237282,
          25459,
          910148,
          725,
          464,
          3876,
          717255,
          1645,
          545147,
          16163,
          230,
          9993,
          302,
          1804,
          2258,
          5732,
          3395,
          118,
          194500,
          207410,
          237282,
          348,
          3032,
          1675,
          4720,
          760,
          1675,
          71463,
          4005,
          198,
          190,
          910148,
          76383,
          21437,
          459921,
          5662,
          741,
          3032,
          35705,
          31394,
          3085,
          525713,
          128715,
          48194,
          5848,
          69,
          92043,
          409656,
          33804,
          1970,
          1089,
          105549,
          5438,
          888,
          5196,
          149,
          67082,
          4664,
          16305,
          5726,
          47249,
          2435,
          343,
          1139,
          270712,
          7155,
          5341,
          22305,
          4575,
          5196,
          35439,
          973849,
          165,
          46,
          4677,
          2135,
          2607,
          551,
          4198,
          479994,
          76383,
          741,
          1526206,
          3285,
          71463,
          123,
          276002,
          2307,
          1480,
          276,
          110,
          1656,
          14228,
          836,
          478,
          14783,
          19408,
          1766,
          230,
          30770,
          71485,
          899,
          5211,
          7646,
          1563,
          632,
          378909,
          1925,
          166081,
          2526,
          695,
          163415,
          6841,
          5577,
          1102,
          116001,
          15623,
          4138,
          1563,
          9512,
          753116,
          1271,
          217,
          4575,
          1143,
          532,
          215,
          198,
          3395,
          23805,
          1831,
          741,
          59744,
          443,
          59744,
          633,
          8019,
          198,
          14228,
          26120,
          190178,
          639,
          242,
          128715,
          964,
          5438,
          320,
          1261,
          1925,
          760,
          276002,
          118,
          2376,
          186140,
          19090,
          3766,
          1196,
          134056,
          35299,
          33804,
          73,
          1420,
          4056,
          4056,
          7646,
          31394,
          2290,
          18182,
          409656,
          198,
          757530,
          54287,
          32891,
          1195,
          2872,
          7430,
          927396,
          7430,
          4729,
          4138,
          2607,
          218,
          21902,
          2501,
          5989,
          765,
          823,
          1201,
          687276,
          21902,
          21134,
          493,
          2368,
          639,
          2078,
          99,
          207,
          106,
          42817,
          1789,
          1443,
          61,
          3032,
          1241364,
          207,
          73,
          3766,
          35439,
          899,
          3807,
          5908,
          116001,
          9772,
          267,
          269,
          3279,
          137,
          1140,
          2870,
          1383,
          2872,
          165,
          5341,
          579,
          530,
          123373,
          6006,
          1645,
          275,
          760,
          3688,
          213,
          1131,
          13983,
          737,
          2060,
          1690,
          302,
          31394,
          7646,
          1666,
          3451,
          254282,
          1312,
          7430,
          4074,
          258,
          5875,
          18760,
          23805,
          937,
          1595797,
          343,
          2566,
          137,
          2566,
          21134,
          31394,
          10717,
          3684,
          3343,
          328,
          1363,
          1577385,
          2408,
          718,
          21635,
          166081,
          1166,
          291,
          21902,
          1382480,
          673342,
          13717,
          13835,
          419,
          1523,
          14871,
          13973,
          614,
          6120,
          736284,
          7163,
          163415,
          4542,
          888,
          32891,
          4542,
          804,
          128,
          1166,
          1645,
          50489,
          3766,
          3402,
          1453,
          344,
          568,
          95,
          795,
          1780,
          2691,
          2368,
          33917,
          6951,
          1583,
          53,
          238602,
          765,
          795,
          55581,
          77,
          2307,
          1532,
          964,
          4603,
          686,
          105638,
          1382480,
          450,
          811,
          177,
          9815,
          532,
          1252,
          94014,
          1228,
          1858,
          5908,
          551,
          4090,
          639,
          168,
          782,
          630,
          1241364,
          2872,
          1675,
          7646,
          21902,
          241,
          6841,
          123373,
          2304,
          824,
          1923,
          149,
          795,
          589,
          477,
          95,
          4090,
          2807,
          969,
          1190,
          1850,
          1443,
          3451,
          21125,
          78968,
          7692,
          7268,
          50835,
          1749,
          632,
          1382480,
          824,
          2258,
          48194,
          1186,
          43,
          407,
          95,
          50835,
          520,
          4424,
          2317,
          1360,
          2408,
          717255,
          238602,
          3699,
          2971,
          899,
          136,
          1939,
          545147,
          2644,
          331,
          1897,
          1132,
          489,
          888,
          14871,
          718,
          31394,
          190178,
          595,
          25459,
          54287,
          22305,
          123373,
          2906700,
          798,
          2836,
          135332,
          55581,
          2443,
          20328,
          20478,
          1228,
          163415,
          1526206,
          590,
          5662,
          3994,
          93193,
          1745,
          3699,
          4573,
          1595797,
          1617,
          48194,
          19090,
          158701,
          5895,
          47249,
          378909,
          2263,
          110,
          74,
          241,
          10717,
          3730,
          213,
          776,
          4290,
          601723,
          271,
          343,
          864,
          2526,
          639,
          16183,
          59744,
          782,
          1493,
          595,
          5161,
          836,
          74,
          471,
          2504700,
          37,
          2135,
          2328,
          1725,
          45303,
          1360,
          331,
          1022298,
          1512,
          71335,
          11250,
          47211,
          20328,
          378909,
          52126,
          782,
          381459,
          134056,
          5161,
          1195,
          338,
          84106,
          163415,
          238602,
          1831,
          194500,
          1261,
          19408,
          466,
          190178,
          836,
          3776,
          804,
          47772,
          1563,
          46944,
          18128,
          176,
          313,
          24840,
          493806,
          504,
          2368,
          504,
          2501,
          1412,
          518429,
          344,
          105549,
          320,
          1196,
          467,
          1689,
          454,
          376,
          350,
          76383,
          1850,
          94014,
          5719,
          9772,
          2202,
          753116,
          520,
          3395,
          409656,
          222785,
          459921,
          291,
          520,
          19054,
          1643,
          1196,
          192805,
          1087,
          6951,
          737,
          581,
          407,
          1700,
          13717,
          24840,
          1263321,
          1595797,
          100,
          337,
          15647,
          1213,
          741,
          94014,
          725,
          3996,
          344,
          59705,
          1263321,
          1051,
          6841,
          376,
          2135,
          46,
          3684,
          137,
          8333,
          2135,
          19054,
          111,
          5950,
          142,
          564,
          13061,
          645,
          640470,
          2089,
          163415,
          1804,
          7163,
          313,
          20478,
          331,
          2097,
          470,
          3684,
          1201,
          5908,
          165556,
          1760,
          140,
          1263321,
          10295,
          104396,
          1461,
          2870,
          1925,
          5726,
          2307,
          9815,
          581,
          16183,
          100,
          198,
          136,
          1412,
          11432,
          178,
          104,
          1139,
          1490,
          5512,
          1923,
          5354,
          937,
          2607,
          2661,
          18182,
          10256,
          1850,
          38912,
          1979,
          2566,
          1700,
          248,
          92608,
          186140,
          47772,
          139,
          116001,
          2135,
          99,
          8333,
          3224,
          1690,
          30770,
          31515,
          50489,
          3688,
          4367,
          836,
          3224,
          2274,
          11256,
          21134,
          642,
          1263321,
          291,
          911,
          2526,
          2691,
          1858,
          5726,
          11250,
          19685,
          761,
          18128,
          30770,
          349,
          95035,
          19408,
          321,
          571,
          2258,
          888,
          1661,
          1490,
          3066,
          6508,
          6841,
          78968,
          581,
          142,
          12335,
          52126,
          6284,
          2290,
          5354,
          5211,
          269,
          207,
          724,
          847,
          46944,
          7646,
          1078,
          302,
          177,
          229,
          59744,
          3996,
          663,
          2135,
          165,
          118,
          47249,
          459921,
          530,
          20478,
          91,
          59744,
          4074,
          1574,
          2870,
          242,
          254,
          307,
          137,
          153,
          513,
          248,
          136,
          914,
          124967,
          1745,
          467,
          1892,
          50835,
          71463,
          1595797,
          172247,
          626,
          601723,
          79613,
          5662,
          92106,
          46563,
          69,
          2501,
          192,
          5196,
          3805,
          28425,
          1324,
          3862,
          647,
          1766,
          67082,
          27971,
          1271,
          409656,
          2290,
          1631,
          111,
          172817,
          59705,
          104,
          540,
          215,
          1126,
          5666,
          33804,
          166081,
          134056,
          31515,
          5507,
          24840,
          344,
          19685,
          110,
          1643,
          355,
          6581,
          4512,
          545147,
          741,
          863,
          376,
          11250,
          5719,
          158701,
          5903,
          163415,
          6713,
          4589,
          8007,
          2456,
          1512,
          626,
          526,
          823,
          1970,
          606,
          370,
          11250,
          630,
          2870,
          1063,
          493,
          4677,
          13973,
          19408,
          92106,
          836,
          92106,
          36784,
          23805,
          736284,
          776,
          1089,
          3766,
          509,
          165556,
          602,
          6841,
          34496,
          3766,
          4090,
          3495,
          639,
          45303,
          1324,
          218,
          307,
          1526206,
          313,
          1360,
          365,
          213,
          2148,
          3862,
          885,
          50489,
          30770,
          7268,
          509,
          7268,
          134056,
          1684,
          5438,
          3996,
          3684,
          107941,
          63,
          606,
          911,
          50489,
          648,
          47249,
          372,
          3255,
          100,
          3343,
          1745,
          136,
          128715,
          13422,
          8830,
          1943,
          1263321,
          1131,
          48194,
          2607,
          122111,
          471,
          313,
          2036,
          1274,
          3451,
          23727,
          217,
          504,
          1892,
          271,
          5619,
          1261,
          8874,
          1063,
          2121,
          1304,
          765,
          1131,
          51427,
          1970,
          69,
          571,
          106,
          2526,
          207410,
          1666,
          1252,
          34496,
          1656,
          1700,
          5341,
          6841,
          12335,
          100,
          263,
          804,
          3776,
          2526,
          4074,
          493,
          21125,
          7268,
          4367,
          222785,
          5901,
          663,
          606,
          76,
          5548,
          823,
          277,
          32891,
          2395,
          1841,
          2092,
          695,
          23,
          92985,
          217,
          5211,
          1970,
          1228,
          27829,
          1472,
          69,
          2661,
          46,
          184,
          4172,
          571,
          169,
          1288,
          1241364,
          1190,
          237282,
          2304,
          1766,
          1725,
          642,
          2526,
          7430,
          153,
          5927,
          2470,
          673342,
          1446,
          7268,
          7565,
          286,
          2368,
          239,
          6951,
          328,
          46563,
          34153,
          46,
          1423,
          2870,
          863,
          1791,
          1789,
          471,
          67082,
          28739,
          99,
          1666,
          241,
          4049,
          1847,
          9594,
          1420,
          741,
          2401,
          1628,
          1595797,
          1735,
          836,
          28739,
          18760,
          399,
          2135,
          128715,
          1213,
          571,
          2786,
          6951,
          153,
          14783,
          754,
          2142,
          206,
          1201,
          378909,
          823,
          4542,
          1228,
          540,
          910148,
          34496,
          2401,
          973849,
          545147,
          1512,
          77,
          3032,
          3395,
          1228,
          123,
          350,
          5438,
          914,
          516,
          1831,
          320420,
          93193,
          1480,
          19090,
          2870,
          242,
          836,
          3684,
          1490,
          12335,
          1595797,
          93193,
          42384,
          1426,
          13973,
          1791,
          765,
          5778,
          70,
          528,
          1263321,
          828,
          530,
          191096,
          9772,
          1412,
          5196,
          532,
          427,
          328,
          922,
          753116,
          4878,
          166081,
          34496,
          50489,
          6841,
          85,
          4575,
          1506,
          5901,
          128715,
          761,
          564,
          3451,
          471,
          27020,
          47772,
          5791,
          198,
          516,
          242,
          2092,
          3104,
          9496,
          277,
          471,
          4354,
          116155,
          2307,
          760,
          1725,
          144160,
          20478,
          695,
          31970,
          1412,
          1841,
          338,
          324,
          841711,
          1478,
          71463,
          760,
          1679,
          23727,
          84861,
          95,
          2443,
          1263321,
          2518,
          3495,
          864,
          68211,
          135332,
          77,
          1628,
          1595797,
          24536,
          1595797,
          69,
          1892,
          9815,
          3289,
          313,
          343,
          1666,
          3876,
          165556,
          34153,
          75903,
          7692,
          571,
          601723,
          1146,
          2523,
          277,
          3996,
          606,
          471,
          2408,
          3096,
          241,
          331,
          3255,
          328,
          6581,
          6460,
          24645,
          134056,
          419,
          48194,
          92106,
          46,
          23045,
          13983,
          722,
          76,
          3224,
          3776,
          46563,
          1423,
          239,
          4367,
          718,
          186140,
          224256,
          1595797,
          3202,
          103927,
          6508,
          321490,
          1368,
          190178,
          372,
          1089,
          1382480,
          589,
          601723,
          540,
          760,
          55345,
          973849,
          2135,
          331,
          1261,
          4056,
          1363,
          5619,
          5875,
          21902,
          258,
          277,
          2206,
          16305,
          128,
          1480,
          104396,
          1178,
          1490,
          1312922,
          1760,
          341,
          5577,
          1478,
          5927,
          13422,
          895,
          15269,
          1675,
          832,
          14075,
          93193,
          14871,
          6951,
          269,
          60,
          1461,
          1617,
          1271,
          4367,
          1841,
          1263321,
          2307,
          1661,
          2607,
          1946,
          4729,
          571,
          7646,
          910148,
          1512,
          673342,
          526,
          4729,
          12747,
          4154,
          270712,
          48194,
          1595797,
          192805,
          4575,
          241,
          648,
          1166,
          28739,
          34496,
          31515,
          9506,
          3104,
          149,
          1263321,
          1606,
          5341,
          2906700,
          1654,
          149,
          1517,
          1022298,
          1577385,
          313,
          5196,
          1126,
          59744,
          566,
          222785,
          1645,
          341,
          471,
          341,
          346,
          19685,
          2523,
          895,
          1923,
          1923,
          516,
          1766,
          67082,
          2443,
          1690,
          4198,
          3224,
          695,
          466,
          110,
          8830,
          149,
          4778,
          9594,
          1804,
          263,
          198,
          1680,
          1178,
          77,
          467,
          158701,
          409656,
          198,
          6629,
          1504,
          144160,
          23045,
          320420,
          46944,
          2786,
          53,
          15647,
          205,
          46,
          277,
          910148,
          478,
          516,
          1126,
          6951,
          760,
          17867,
          614,
          1766,
          493806,
          878,
          2872,
          1533,
          217,
          571,
          571,
          1595797,
          7268,
          1645,
          878,
          6581,
          4161,
          145,
          9594,
          2906700,
          3766,
          463,
          28739,
          1263321,
          1288,
          18128,
          95,
          346,
          1201,
          310,
          277,
          2456,
          1643,
          140,
          608,
          1679,
          94014,
          601723,
          19408,
          275,
          1382480,
          123373,
          50835,
          899,
          502,
          67858,
          2016,
          964,
          606,
          489,
          608,
          759,
          46,
          459921,
          1532,
          16163,
          84861,
          2135,
          6120,
          53,
          276002,
          1293,
          828,
          540,
          1190,
          5161,
          19685,
          6703,
          2148,
          165556,
          1186,
          16183,
          310,
          823,
          61,
          8512,
          4533,
          3807,
          85,
          6018,
          186140,
          2470,
          17047,
          718,
          21902,
          222785,
          1858,
          198,
          5903,
          970,
          1102,
          1847,
          166081,
          2504700,
          6629,
          49,
          184,
          18760,
          2328,
          841711,
          1766,
          118,
          313,
          36784,
          16305,
          2518,
          1288,
          2471,
          504,
          832,
          3458,
          298,
          1909,
          6508,
          407,
          237282,
          825,
          214703,
          6508,
          1196,
          76,
          736284,
          1791,
          2395,
          1526206,
          6629,
          6841,
          3833,
          1946,
          1831,
          1087,
          15426,
          23,
          1261,
          532,
          92608,
          316665,
          372,
          10717,
          635,
          632,
          2158,
          316665,
          776,
          92608,
          5760,
          5791,
          203571,
          1892,
          207,
          1228,
          413574,
          320420,
          914,
          267,
          1263321,
          13061,
          5901,
          270712,
          1383,
          6951,
          46,
          223,
          1126,
          124967,
          632,
          3202,
          24840,
          254282,
          519,
          498,
          4664,
          3688,
          28739,
          3224,
          1241364,
          3495,
          1368,
          972,
          136895,
          741,
          13717,
          1689,
          1446,
          320420,
          2501,
          19685,
          16305,
          76383,
          2644,
          2202,
          2304,
          927396,
          513,
          606,
          1725,
          28739,
          2870,
          372,
          823,
          389246,
          5989,
          1178,
          9587,
          647,
          2870,
          2408,
          1480,
          832,
          258,
          165556,
          2092,
          4424,
          1102,
          277,
          1760,
          1131,
          2368,
          5760,
          1780,
          54185,
          551,
          190178,
          343,
          863,
          589,
          595,
          736284,
          118,
          4913,
          136,
          7297,
          2644,
          92294,
          2258,
          269,
          7987,
          5875,
          242,
          105549,
          47249,
          525713,
          92608,
          238602,
          1577385,
          218,
          3104,
          206,
          2526,
          2223,
          22191,
          48194,
          743,
          100,
          237282,
          18182,
          2328,
          11256,
          2971,
          9993,
          3224,
          8097,
          194500,
          718,
          31515,
          34882,
          1595797,
          782,
          123,
          1423,
          589,
          493806,
          3688,
          106,
          1241364,
          6581,
          1571,
          3224,
          9784,
          1420,
          525713,
          71485,
          6581,
          571,
          45303,
          3395,
          92608,
          5875,
          642,
          911,
          1478,
          276002,
          140,
          1666,
          1271,
          76,
          46563,
          71463,
          1196,
          1925,
          2526,
          11751,
          1791,
          7297,
          7430,
          126,
          3395,
          1446,
          47772,
          128,
          564,
          413574,
          34496,
          1656,
          4664,
          31394,
          1312922,
          1631,
          54185,
          910148,
          172817,
          2395,
          475,
          3395,
          28739,
          1909,
          409656,
          1442,
          20328,
          1858,
          1700,
          6951,
          1766,
          34882,
          1412,
          927396,
          2526,
          158701,
          9815,
          4533,
          3279,
          190178,
          635,
          18760,
          85,
          743,
          5354,
          20478,
          504,
          341043,
          7268,
          21134,
          100,
          1274,
          2526,
          1334,
          1810,
          116001,
          277,
          7692,
          136,
          911,
          795,
          214703,
          1930,
          798,
          5760,
          168,
          34496,
          128354,
          645,
          10076,
          5791,
          5927,
          9521,
          498,
          1506,
          4056,
          260,
          4542,
          1533,
          190,
          1363,
          166081,
          4726,
          34153,
          2691,
          2856,
          736284,
          163415,
          475,
          260,
          2258,
          19054,
          271,
          1645,
          307,
          34882,
          172817,
          5621,
          151785,
          43,
          737,
          1166,
          673342,
          136,
          207410,
          94325,
          647,
          1909,
          471,
          4474,
          6951,
          3285,
          217,
          741,
          67082,
          13973,
          395,
          14783,
          190178,
          5577,
          1312,
          291,
          149,
          1022298,
          16183,
          86954,
          1022298,
          1523,
          46563,
          795,
          33917,
          1089,
          450,
          4056,
          878,
          391389,
          47249,
          4138,
          910148,
          1892,
          1791,
          4729,
          1146,
          165,
          217,
          427,
          2504700,
          48194,
          190,
          71485,
          2368,
          4056,
          355,
          467,
          504,
          128354,
          1263321,
          28278,
          42817,
          21902,
          3766,
          540,
          6460,
          3776,
          4056,
          76383,
          43,
          344,
          5901,
          222785,
          9772,
          2290,
          673342,
          1368,
          30770,
          1363,
          67082,
          93193,
          217,
          1789,
          276002,
          20328,
          337,
          5875,
          899,
          144160,
          4726,
          1263321,
          1574,
          825,
          54767,
          277,
          222785,
          7163,
          4845,
          79613,
          27971,
          116001,
          9784,
          1324,
          286,
          272134,
          1293,
          828,
          48194,
          1334,
          11256,
          2906700,
          427,
          222785,
          4653,
          771,
          348,
          2304,
          255,
          1051,
          341043,
          376,
          343,
          1666,
          76383,
          914,
          824,
          1766,
          1443,
          800,
          85,
          1241364,
          242,
          61,
          1051,
          1810,
          1526206,
          1493,
          291,
          69793,
          92043,
          69,
          3805,
          10295,
          917,
          589,
          233717,
          419,
          2607,
          413574,
          1770,
          5621,
          4653,
          2456,
          263,
          145,
          2408,
          9512,
          12486,
          513,
          863,
          878,
          502,
          1102,
          743,
          272,
          207,
          741,
          584,
          31394,
          111,
          134056,
          301,
          828,
          7646,
          16183,
          695,
          1526206,
          528,
          9815,
          151022,
          1847,
          3395,
          54185,
          3430,
          35371,
          144160,
          140,
          106,
          53,
          205,
          6018,
          67858,
          1241364,
          1536,
          111,
          2807,
          5512,
          14871,
          333497,
          759,
          338,
          1126,
          71463,
          46,
          2443,
          33804,
          341043,
          1195,
          7268,
          917,
          248,
          328,
          376,
          1179,
          190178,
          21125,
          601723,
          1063,
          4653,
          128,
          28425,
          718,
          914,
          863,
          1080,
          628,
          276002,
          641349,
          970,
          673342,
          166081,
          2258,
          71485,
          5211,
          168,
          718,
          912,
          18760,
          331,
          4090,
          73,
          20478,
          530,
          1841,
          1577385,
          128354,
          313,
          316665,
          397,
          1526206,
          2807,
          272134,
          828,
          167,
          2368,
          5548,
          1360,
          35371,
          1078,
          760,
          370,
          128,
          299480,
          54767,
          11250,
          17867,
          2317,
          19054,
          321490,
          27971,
          601723,
          466,
          1075,
          847,
          1228,
          1892,
          17867,
          1617,
          9815,
          93193,
          33804,
          540,
          4161,
          18459,
          1019,
          3766,
          116001,
          378909,
          3255,
          4138,
          395,
          76,
          653,
          5648,
          2303,
          824,
          2786,
          680,
          450,
          313,
          832,
          5512,
          744,
          75830,
          1478,
          17867,
          184,
          4542,
          222785,
          153,
          635,
          24840,
          1131,
          24536,
          177,
          34496,
          5903,
          1078,
          92043,
          540,
          1078,
          1132,
          19685,
          471,
          489,
          2395,
          1241364,
          5161,
          413574,
          641349,
          4508,
          2526,
          3279,
          1383,
          836,
          4664,
          1656,
          1789,
          248,
          53,
          1472,
          3119,
          2016,
          376,
          1102,
          4090,
          99,
          1679,
          2607,
          391389,
          391389,
          1089,
          350,
          254282,
          1745,
          471,
          10717,
          3807,
          75903,
          4729,
          551,
          2691,
          1574,
          973849,
          565,
          3289,
          331,
          70,
          74,
          190178,
          42817,
          1645,
          52126,
          1645,
          2211,
          24840,
          55581,
          4664,
          2368,
          71335,
          3684,
          26551,
          970,
          823,
          498,
          3688,
          53,
          207,
          5196,
          5161,
          22305,
          3279,
          1166,
          267,
          2870,
          3876,
          1261,
          67082,
          3279,
          2290,
          3766,
          324,
          13717,
          151815,
          8830,
          140,
          2408,
          1758,
          2872,
          5548,
          4664,
          914,
          1617,
          95035,
          1190,
          736284,
          964,
          5875,
          602,
          5732,
          1186,
          861,
          69,
          1979,
          805,
          1643,
          15426,
          5548,
          718,
          2097,
          153,
          47249,
          1190,
          1807,
          4729,
          471,
          470,
          4993,
          1970,
          105638,
          2661,
          2523,
          27971,
          973849,
          16305,
          1897,
          9815,
          111,
          9034,
          564,
          1078,
          258,
          2328,
          241,
          47211,
          4542,
          1312,
          724,
          7987,
          3688,
          5760,
          7430,
          22305,
          765,
          817312,
          467,
          54287,
          1490,
          258,
          35439,
          1804,
          355,
          516,
          5908,
          14742,
          7420,
          222785,
          28739,
          741,
          450,
          530,
          136895,
          349,
          12335,
          17867,
          1288,
          13717,
          35299,
          741,
          571,
          1631,
          136895,
          4729,
          321490,
          71485,
          13422,
          207410,
          5354,
          1302,
          79613,
          118,
          35439,
          106,
          4729,
          198,
          1850,
          35371,
          239,
          277,
          725,
          16305,
          1363,
          2135,
          1574,
          168,
          2971,
          5196,
          630,
          1334,
          6841,
          5927,
          2395,
          28739,
          369,
          7565,
          6629,
          847,
          737,
          5908,
          71485,
          1565,
          4913,
          7268,
          464,
          207,
          198,
          7155,
          6025,
          5211,
          5791,
          258,
          4895,
          741,
          271,
          2368,
          2443,
          1506,
          3807,
          1645,
          94014,
          571,
          258,
          532,
          144160,
          5341,
          22191,
          372,
          84861,
          9815,
          35371,
          316665,
          1690,
          70,
          341043,
          67082,
          1766,
          106,
          568,
          71463,
          1139,
          59705,
          1312922,
          3395,
          1241364,
          140,
          263,
          3876,
          75903,
          1446,
          5196,
          6629,
          2607,
          395,
          10717,
          736284,
          6018,
          6120,
          2368,
          328,
          14871,
          4895,
          55345,
          1766,
          1725,
          241,
          105549,
          123,
          321490,
          836,
          899,
          190178,
          3032,
          395,
          413574,
          1420,
          391389,
          1038,
          3807,
          213,
          5512,
          149,
          7268,
          229,
          1312922,
          493806,
          2258,
          878,
          927396,
          34496,
          104,
          2097,
          87124,
          5548,
          3996,
          13983,
          77,
          641349,
          1526206,
          2872,
          5875,
          260,
          3263,
          313,
          1201,
          1446,
          2258,
          30770,
          2121,
          3458,
          105549,
          237282,
          28739,
          27971,
          1412,
          6284,
          222785,
          1645,
          28739,
          4589,
          2328,
          27971,
          267,
          509,
          18408,
          270712,
          12335,
          346,
          4198,
          50835,
          6120,
          77,
          35439,
          533,
          4664,
          1810,
          409656,
          355,
          516,
          6581,
          2054,
          841711,
          7565,
          2401,
          828,
          914,
          1382480,
          1178,
          1186,
          565,
          1725,
          105638,
          922,
          3699,
          606,
          6841,
          1426,
          12335,
          16183,
          128,
          190178,
          190178,
          1263321,
          2870,
          391389,
          99,
          760,
          1414,
          972,
          722,
          2135,
          267,
          5726,
          116001,
          2303,
          878,
          413574,
          718,
          1970,
          19054,
          163415,
          136,
          331,
          832,
          34882,
          1512,
          3395,
          1312922,
          477,
          137,
          12335,
          3495,
          736284,
          1850,
          2501,
          1304,
          116155,
          263,
          1063,
          4542,
          144160,
          5507,
          1360,
          4056,
          1196,
          2401,
          4474,
          409656,
          545147,
          1302,
          137,
          43102,
          172247,
          1675,
          3430,
          795,
          21902,
          3684,
          743,
          530,
          9034,
          1725,
          59744,
          973849,
          213,
          1810,
          69793,
          9165,
          178,
          207,
          2258,
          391389,
          4512,
          91,
          128354,
          50835,
          1139,
          2906700,
          163415,
          695,
          409656,
          2501,
          2836,
          2304,
          632,
          2304,
          99,
          718,
          238602,
          307,
          16305,
          1766,
          1563,
          7646,
          4677,
          2456,
          3807,
          7163,
          198,
          922,
          215,
          14783,
          2258,
          4542,
          20478,
          478,
          224256,
          291,
          2456,
          4653,
          19090,
          6469,
          218,
          10295,
          680,
          589,
          321490,
          378909,
          158701,
          2135,
          680,
          1923,
          1490,
          1656,
          11253,
          139650,
          1645,
          50489,
          409656,
          2408,
          568,
          61,
          932,
          74,
          1139,
          186140,
          20478,
          92106,
          626,
          470,
          5895,
          5848,
          6284,
          3684,
          50489,
          7692,
          308,
          1241364,
          313,
          1595797,
          493,
          46563,
          79613,
          177,
          7646,
          493,
          1791,
          291,
          5950,
          1412,
          241,
          467,
          2870,
          272134,
          14228,
          2435,
          1841,
          7155,
          2607,
          964,
          502,
          602,
          21902,
          165556,
          134056,
          238602,
          493806,
          1512,
          520,
          639,
          158701,
          502,
          1526206,
          302,
          11256,
          3119,
          3807,
          320420,
          71463,
          136895,
          91,
          687276,
          3032,
          5657,
          1461,
          6006,
          782,
          35371,
          11256,
          233717,
          718,
          1858,
          27020,
          828,
          7987,
          1583,
          71335,
          4653,
          123,
          861,
          33804,
          128354,
          1271,
          6469,
          1368,
          1533,
          804,
          1970,
          782,
          932,
          895,
          4074,
          269,
          13835,
          1075,
          1426,
          1847,
          590,
          3085,
          895,
          863,
          1423,
          123,
          74,
          198,
          509,
          217,
          190249,
          67082,
          9815,
          276896,
          9496,
          736284,
          67082,
          1334,
          4677,
          601723,
          4090,
          206,
          20328,
          1725,
          10256,
          2303,
          389246,
          5507,
          1523,
          463,
          1735,
          95035,
          5196,
          3096,
          647,
          229,
          17867,
          104396,
          54767,
          53,
          136,
          1725,
          522,
          45303,
          123373,
          1383,
          13983,
          526,
          2395,
          1186,
          1725,
          91,
          111,
          914,
          248,
          5619,
          35439,
          107941,
          519,
          6508,
          239,
          407,
          4878,
          551,
          606,
          33917,
          673342,
          1179,
          165556,
          372,
          460,
          1271,
          489,
          1766,
          269,
          2092,
          3807,
          190,
          7163,
          71463,
          4720,
          343,
          78968,
          378909,
          4575,
          104396,
          52,
          324,
          372,
          13973,
          12335,
          1078,
          324,
          922,
          8269,
          1446,
          248,
          522,
          50489,
          2368,
          910148,
          753116,
          346,
          23727,
          11250,
          3688,
          743,
          3119,
          16183,
          533,
          1228,
          4474,
          516,
          87124,
          14742,
          718,
          4664,
          2148,
          973849,
          551,
          46563,
          17867,
          77,
          77,
          1195,
          19054,
          19408,
          27971,
          116001,
          1689,
          104,
          1178,
          1087,
          1178,
          88735,
          241,
          1946,
          3228,
          2607,
          24536,
          34882,
          85,
          969,
          18459,
          5901,
          92985,
          7646,
          71485,
          34496,
          50835,
          5875,
          28739,
          346,
          2208,
          824,
          230,
          2135,
          6581,
          782,
          718,
          467,
          50489,
          14742,
          3688,
          1831,
          1472,
          1352,
          6460,
          343,
          910148,
          686,
          1196,
          149,
          1766,
          1078,
          571,
          817312,
          606,
          51427,
          190178,
          2092,
          47772,
          6025,
          100,
          2317,
          645,
          165556,
          1493,
          229,
          92294,
          5760,
          1442,
          5341,
          836,
          647,
          1970,
          344,
          145,
          2303,
          595,
          247,
          863,
          1075,
          21134,
          1661,
          1102,
          1789,
          338,
          3996,
          128354,
          105638,
          5950,
          184,
          1241364,
          1909,
          1443,
          16183,
          1228,
          3289,
          1504,
          1228,
          14871,
          3766,
          5354,
          217,
          276,
          526,
          5507,
          103927,
          7268,
          1666,
          4542,
          350,
          1617,
          725,
          45303,
          48194,
          7268,
          2836,
          922,
          1970,
          5619,
          5875,
          3487,
          630,
          1312922,
          910148,
          6460,
          836,
          71463,
          94014,
          1201,
          5161,
          230,
          14783,
          20478,
          47772,
          1078,
          10076,
          18459,
          895,
          248,
          16305,
          46563,
          7565,
          1363,
          899,
          50835,
          972,
          413574,
          1847,
          34496,
          753116,
          124967,
          54287,
          224256,
          165556,
          899,
          1512,
          759,
          4090,
          628,
          1263321,
          1178,
          15426,
          5903,
          647,
          1166,
          378909,
          641349,
          34882,
          191096,
          2872,
          1631,
          75903,
          2916,
          71463,
          85,
          1523,
          2317,
          9565,
          4074,
          765,
          1312922,
          4677,
          9512,
          54185,
          2523,
          69793,
          53,
          1684,
          1196,
          35705,
          5438,
          1533,
          2456,
          198,
          1565,
          3402,
          520,
          2501,
          94325,
          47249,
          106,
          217,
          365,
          1791,
          628,
          540,
          528,
          124967,
          79613,
          1179,
          602,
          1304,
          5950,
          47249,
          91,
          1143,
          579,
          459921,
          2435,
          9565,
          16183,
          77,
          184,
          4508,
          10076,
          13835,
          2644,
          53,
          49,
          5760,
          21125,
          34496,
          4575,
          1312922,
          632,
          824,
          502,
          1078,
          695,
          1847,
          2836,
          275,
          35705,
          198,
          25459,
          19685,
          18182,
          35439,
          46563,
          2644,
          606,
          34496,
          181438,
          409656,
          5341,
          516,
          186140,
          32891,
          35439,
          760,
          759,
          217,
          1201,
          475,
          271,
          1988,
          107941,
          18128,
          222,
          163415,
          470,
          10076,
          3776,
          1078,
          222785,
          31515,
          163415,
          4913,
          1080,
          166081,
          1533,
          1679,
          1126,
          3688,
          277,
          1760,
          341,
          31515,
          467,
          5507,
          355,
          1841,
          166081,
          5512,
          12335,
          4090,
          1443,
          836,
          1412,
          5791,
          1420,
          12335,
          10256,
          648,
          233717,
          2518,
          673342,
          489,
          1146,
          271,
          504,
          2328,
          137067,
          597,
          2523,
          640470,
          23727,
          4049,
          5161,
          8269,
          475,
          76383,
          15426,
          5621,
          2290,
          595,
          427,
          1574,
          95035,
          5908,
          11250,
          192,
          5457,
          341,
          642,
          32891,
          1617,
          4542,
          1414,
          5451,
          1831,
          54767,
          91,
          5662,
          551,
          258,
          824,
          83,
          191096,
          5507,
          47249,
          3402,
          581,
          7565,
          2054,
          2786,
          3487,
          1850,
          92608,
          2906700,
          878,
          1453,
          198,
          1102,
          378909,
          1532,
          3104,
          3263,
          590,
          601723,
          344,
          71485,
          163415,
          1946,
          1131,
          7163,
          1565,
          9815,
          3085,
          8333,
          795,
          263,
          103927,
          13835,
          722,
          2016,
          61,
          23727,
          18408,
          3699,
          4542,
          223,
          2644,
          2518,
          1022298,
          34882,
          1263321,
          4081,
          973849,
          6025,
          163415,
          18182,
          99,
          1131,
          23045,
          1532,
          571,
          1228,
          606,
          765,
          717255,
          2661,
          1304,
          1360,
          13973,
          2691,
          504,
          1762,
          55345,
          4090,
          4138,
          1631,
          7163,
          602,
          3343,
          2799,
          95,
          100,
          3807,
          248,
          46,
          260,
          95035,
          4542,
          128,
          1526206,
          1443,
          5621,
          140,
          198,
          526,
          1271,
          76,
          95035,
          641349,
          2317,
          158701,
          178,
          1363,
          1631,
          34882,
          207410,
          641,
          3876,
          2078,
          134056,
          3066,
          1089,
          832,
          1507,
          467,
          6508,
          107941,
          795,
          233060,
          1089,
          1383,
          5989,
          23,
          2872,
          6951,
          5901,
          224256,
          718,
          2856,
          217,
          518429,
          532,
          270712,
          1453,
          3688,
          914,
          1312922,
          320420,
          1228,
          5548,
          1453,
          632,
          1480,
          307,
          568,
          4653,
          2304,
          4474,
          409656,
          1504,
          4573,
          2368,
          1022298,
          320,
          247,
          123373,
          1271,
          344,
          7430,
          1324,
          2376,
          391389,
          54287,
          105549,
          1725,
          2607,
          1631,
          1595797,
          1324,
          79613,
          8007,
          7987,
          26551,
          139650,
          4533,
          269,
          17047,
          4056,
          18182,
          129,
          214703,
          267,
          5791,
          1563,
          2607,
          338,
          10717,
          1939,
          10717,
          502,
          2054,
          3096,
          191096,
          4720,
          540,
          1490,
          4074,
          27020,
          564,
          207,
          13835,
          71335,
          14783,
          914,
          2566,
          333497,
          276896,
          13061,
          275,
          6841,
          42384,
          320420,
          85,
          1725,
          5438,
          23727,
          3096,
          602,
          4512,
          910148,
          248,
          258,
          123,
          973849,
          45100,
          1382480,
          540,
          2470,
          75903,
          2504700,
          2401,
          313,
          2856,
          237282,
          1102,
          630,
          21134,
          301,
          14228,
          149,
          1617,
          888,
          94014,
          2971,
          3255,
          2471,
          30770,
          5341,
          7565,
          397,
          589,
          84106,
          765,
          836,
          927396,
          42817,
          1442,
          4172,
          302,
          1970,
          86954,
          34153,
          69,
          1263321,
          2206,
          94014,
          22305,
          504,
          106,
          927396,
          3224,
          4677,
          2607,
          15647,
          477,
          710,
          4474,
          156391,
          504,
          9594,
          5512,
          1019,
          5621,
          9587,
          7268,
          579,
          134056,
          493806,
          21902,
          1533,
          172817,
          1514,
          1324,
          258,
          545147,
          516,
          11751,
          1745,
          229,
          4512,
          2317,
          841711,
          207,
          1420,
          207,
          1766,
          2872,
          673342,
          1412,
          3805,
          641,
          192,
          5577,
          230,
          1645,
          6951,
          1725,
          52126,
          471,
          1139,
          5211,
          5211,
          1195,
          218,
          95035,
          467,
          1563,
          743,
          79008,
          110,
          1841,
          910148,
          31515,
          54287,
          5507,
          1679,
          7163,
          205,
          42619,
          13717,
          28425,
          103927,
          207,
          1577385,
          540,
          302,
          489,
          9679,
          3279,
          1102,
          3996,
          263,
          14742,
          606,
          1478,
          2691,
          1930,
          203571,
          836,
          5895,
          3495,
          320420,
          1324,
          581,
          673342,
          564,
          680,
          337,
          1126,
          3688,
          427,
          313,
          6703,
          489,
          571,
          124967,
          343,
          741,
          20478,
          2872,
          60,
          163415,
          348,
          888,
          525713,
          760,
          804,
          1749,
          192805,
          7268,
          899,
          25459,
          5895,
          1228,
          1563,
          885,
          4993,
          129,
          5903,
          111,
          10256,
          1595797,
          140,
          28425,
          1617,
          134056,
          1679,
          17867,
          601723,
          376,
          31970,
          1979,
          564,
          381459,
          2395,
          2135,
          31394,
          680,
          4354,
          50835,
          3766,
          1804,
          2870,
          2054,
          76383,
          782,
          50489,
          632,
          5791,
          1063,
          459921,
          760,
          4512,
          1766,
          1810,
          341,
          5760,
          68211,
          509,
          45100,
          2148,
          224256,
          344,
          100,
          566,
          5548,
          741,
          1631,
          52,
          1760,
          11250,
          1675,
          74,
          639,
          1789,
          1360,
          6284,
          2504700,
          20478,
          4474,
          1368,
          68211,
          647,
          413574,
          348,
          5341,
          28278,
          122111,
          467,
          19054,
          105549,
          2518,
          37,
          565,
          2456,
          741,
          2135,
          391389,
          1165,
          743,
          1791,
          1139,
          24536,
          450,
          1512,
          761,
          372,
          895,
          1666,
          1288,
          530,
          899,
          478,
          5451,
          9815,
          11250,
          6284,
          571,
          176,
          493806,
          1089,
          133,
          724,
          3688,
          320420,
          2872,
          5895,
          79613,
          79008,
          198,
          18408,
          271,
          1897,
          7297,
          509,
          545147,
          172817,
          186140,
          45303,
          673342,
          595,
          1089,
          1302,
          320,
          267,
          19090,
          1533,
          341,
          3395,
          606,
          248858,
          1261,
          128,
          2906700,
          1577385,
          477,
          3395,
          2060,
          4056,
          1506,
          217,
          606,
          45303,
          470,
          5726,
          6629,
          463,
          307,
          272134,
          2457,
          589,
          765,
          320420,
          836,
          1312922,
          2836,
          71335,
          32891,
          804,
          19054,
          910148,
          1617,
          8830,
          137,
          526,
          3805,
          3862,
          61,
          105549,
          9587,
          530,
          2661,
          45303,
          4677,
          2518,
          1078,
          308,
          2504700,
          13422,
          4993,
          642,
          1263321,
          9993,
          4138,
          2526,
          2368,
          922,
          1051,
          337,
          1645,
          71335,
          1745,
          346,
          798,
          302,
          733,
          35371,
          1807,
          104396,
          4593,
          1791,
          798,
          145,
          1892,
          1533,
          8874,
          3688,
          2607,
          5895,
          30770,
          67082,
          5726,
          4993,
          213,
          4575,
          3395,
          17867,
          302,
          258,
          895,
          760,
          275,
          1532,
          128354,
          4677,
          11256,
          14871,
          168,
          23,
          1512,
          2661,
          551,
          6120,
          1446,
          595,
          6469,
          5512,
          207,
          92294,
          6951,
          899,
          239,
          50489,
          1745,
          1412,
          4664,
          888,
          350,
          31394,
          863,
          153,
          1186,
          467,
          276,
          493806,
          116001,
          4575,
          370,
          13602,
          3730,
          475,
          12486,
          75903,
          1504,
          964,
          1780,
          321,
          2435,
          46944,
          3688,
          166081,
          6120,
          1526206,
          1228,
          1523,
          328,
          28739,
          31515,
          888,
          1480,
          2872,
          1078,
          530,
          3805,
          1617,
          5438,
          2290,
          71463,
          105638,
          1312922,
          759,
          1461,
          10295,
          1858,
          19090,
          1143,
          184,
          6469,
          571,
          30770,
          1563,
          27020,
          595,
          589,
          470,
          4367,
          123373,
          1383,
          4367,
          128715,
          18128,
          409656,
          140,
          302,
          4290,
          10256,
          450,
          46563,
          116155,
          532,
          20478,
          2135,
          2135,
          680,
          525713,
          2870,
          137,
          2054,
          19054,
          5161,
          1075,
          42817,
          2208,
          18182,
          910148,
          19685,
          190,
          635,
          2872,
          337,
          2158,
          1574,
          1263321,
          7565,
          79008,
          759,
          6284,
          463,
          6841,
          686,
          832,
          276002,
          5619,
          50835,
          2518,
          4845,
          530,
          20328,
          47249,
          307,
          2208,
          269,
          16163,
          192,
          1617,
          194500,
          1679,
          2368,
          1643,
          176,
          450,
          606,
          1574,
          741,
          722,
          20478,
          732,
          1312922,
          123,
          4720,
          5791,
          165556,
          1478,
          8007,
          1263321,
          302,
          59744,
          10295,
          3996,
          3458,
          30770,
          2906700,
          1526206,
          2376,
          116001,
          1766,
          331,
          2054,
          2148,
          76,
          6581,
          270712,
          1689,
          630,
          917,
          198,
          136,
          737,
          1565,
          1080,
          5512,
          595,
          4198,
          370,
          1312922,
          140,
          22930,
          2368,
          516,
          5438,
          16163,
          1334,
          190178,
          1420,
          341,
          5621,
          640470,
          105638,
          370,
          46,
          782,
          222785,
          5512,
          16305,
          470,
          1831,
          333497,
          3096,
          601723,
          207,
          7646,
          2317,
          45303,
          1970,
          107941,
          475,
          85,
          324,
          124967,
          5895,
          757530,
          122111,
          7646,
          53,
          10717,
          5848,
          10717,
          1760,
          21902,
          73,
          1923,
          2856,
          1656,
          1847,
          153,
          1504,
          633,
          11256,
          1442,
          565,
          86954,
          54287,
          3833,
          828,
          828,
          11256,
          198,
          5211,
          4367,
          450,
          378909,
          313,
          75830,
          6508,
          5989,
          5778,
          1288,
          4533,
          3096,
          7646,
          348,
          8874,
          2644,
          6018,
          1970,
          6006,
          3688,
          743,
          1565,
          2872,
          6508,
          1178,
          23727,
          17867,
          79613,
          648,
          5211,
          1274,
          804,
          932,
          1970,
          4603,
          110,
          1909,
          370,
          2368,
          1810,
          914,
          1847,
          233717,
          207,
          4090,
          1725,
          3684,
          321,
          1139,
          237282,
          136,
          11253,
          663,
          1442,
          519,
          137067,
          502,
          7646,
          5507,
          1178,
          341,
          16183,
          633,
          5901,
          341,
          824,
          84106,
          5903,
          1453,
          1526206,
          4474,
          84106,
          129,
          470,
          1228,
          478,
          3776,
          1271,
          4090,
          1970,
          471,
          9565,
          2661,
          30770,
          1190,
          4056,
          1970,
          71485,
          1749,
          626,
          178,
          1536,
          166081,
          34496,
          85,
          732,
          725,
          3289,
          1523,
          3343,
          71485,
          608,
          11432,
          606,
          1382480,
          460,
          2121,
          7565,
          1850,
          1530,
          324,
          2504700,
          54767,
          19090,
          1970,
          1352,
          241,
          5341,
          14075,
          722,
          190,
          276002,
          1241364,
          321490,
          18408,
          687276,
          6713,
          1780,
          1063,
          10076,
          46563,
          54287,
          47249,
          2457,
          5341,
          965,
          1979,
          1420,
          21902,
          376,
          1617,
          140,
          79613,
          2786,
          22305,
          111,
          153,
          21902,
          540,
          37,
          71335,
          14783,
          1725,
          1532,
          31394,
          3699,
          899,
          19054,
          134056,
          1643,
          757530,
          5216,
          4575,
          149,
          832,
          26551,
          2607,
          1051,
          1517,
          1689,
          1453,
          67082,
          502,
          606,
          94014,
          1195,
          270712,
          1643,
          337,
          479994,
          3202,
          308,
          1201,
          478,
          16183,
          258,
          28425,
          1051,
          52126,
          771,
          5989,
          1178,
          5778,
          22191,
          509,
          1426,
          110,
          7163,
          7155,
          895,
          22305,
          7692,
          4081,
          757530,
          1766,
          139650,
          4198,
          2661,
          3119,
          376,
          337,
          5354,
          1766,
          466,
          207410,
          19685,
          19685,
          34882,
          589,
          5950,
          2526,
          795,
          140,
          736284,
          1970,
          5341,
          1493,
          4542,
          71335,
          267,
          1363,
          832,
          7420,
          4895,
          765,
          2870,
          104396,
          590,
          1324,
          3996,
          1131,
          22305,
          74,
          35371,
          34882,
          11256,
          3119,
          4533,
          105549,
          19054,
          1261,
          5989,
          365,
          673342,
          42817,
          19090,
          1577385,
          2526,
          1804,
          2148,
          530,
          165556,
          6006,
          4913,
          3876,
          24536,
          6581,
          1970,
          4154,
          2317,
          1288,
          1022298,
          5875,
          516,
          639,
          2208,
          1100,
          61,
          5908,
          2456,
          673342,
          3508,
          2395,
          1126,
          19408,
          13973,
          389246,
          163415,
          186140,
          17867,
          50835,
          128715,
          233060,
          564,
          9772,
          1680,
          1970,
          2518,
          464,
          1271,
          910148,
          71463,
          1925,
          973849,
          12349,
          2303,
          1831,
          642,
          895,
          5791,
          2607,
          128,
          47772,
          142,
          50835,
          10076,
          104396,
          105549,
          828,
          601723,
          276002,
          5512,
          69,
          87124,
          427,
          6713,
          798,
          1892,
          6469,
          1532,
          23727,
          1063,
          2092,
          14871,
          1293,
          863,
          1196,
          11256,
          5657,
          863,
          186140,
          21134,
          9587,
          21635,
          94014,
          1241364,
          3255,
          725,
          99,
          9565,
          19054,
          725,
          1745,
          2054,
          5507,
          71335,
          1762,
          2089,
          34153,
          7987,
          7430,
          54185,
          267,
          630,
          2435,
          3032,
          478,
          2307,
          5901,
          94014,
          15623,
          99,
          5908,
          1126,
          5657,
          69,
          847,
          972,
          190178,
          18408,
          1532,
          1925,
          71485,
          350,
          248858,
          832,
          459921,
          15647,
          2263,
          2290,
          34882,
          589,
          369,
          1631,
          33917,
          4090,
          301,
          4664,
          17867,
          222,
          92294,
          2408,
          1324,
          19685,
          4471,
          1506,
          92985,
          100,
          2856,
          917,
          5161,
          864,
          4993,
          134056,
          45100,
          34153,
          17867,
          10717,
          1241364,
          832,
          828,
          1139,
          1132,
          1472,
          42817,
          307,
          50489,
          104396,
          46,
          450,
          1461,
          32891,
          168,
          46,
          795,
          972,
          302,
          55581,
          5548,
          4729,
          1595797,
          92608,
          1075,
          350,
          530,
          192805,
          1363,
          166081,
          350,
          1517,
          817312,
          76,
          145,
          467,
          207,
          47249,
          1132,
          46,
          502,
          49,
          241,
          70,
          1532,
          1363,
          116155,
          2456,
          255,
          140,
          149,
          105549,
          4542,
          328,
          1261,
          722,
          27829,
          1131,
          4015,
          5548,
          263,
          4512,
          5548,
          26551,
          1178,
          5648,
          32891,
          10076,
          153,
          2317,
          71463,
          76383,
          5989,
          1143,
          167,
          5791,
          1645,
          1271,
          22930,
          378909,
          139650,
          502,
          46944,
          1645,
          1446,
          238602,
          502,
          51427,
          1228,
          76383,
          10717,
          276896,
          1442,
          1252,
          753116,
          1312922,
          346,
          7430,
          128,
          153,
          1749,
          9993,
          21134,
          224256,
          21902,
          23045,
          687276,
          489,
          99,
          530,
          1480,
          5161,
          4664,
          743,
          55581,
          145,
          1512,
          601723,
          5901,
          2317,
          911,
          20328,
          4542,
          2607,
          686,
          331,
          1288,
          648,
          51427,
          19054,
          5778,
          5621,
          1480,
          13835,
          1383,
          5548,
          6951,
          207,
          14871,
          1261,
          6841,
          34882,
          489,
          765,
          427,
          25459,
          1725,
          71485,
          4589,
          23805,
          1643,
          320,
          134056,
          365,
          606,
          149,
          459921,
          139650,
          760,
          43,
          14783,
          3862,
          276,
          741,
          67082,
          1526206,
          2456,
          564,
          331,
          3279,
          3684,
          6629,
          6006,
          4575,
          217,
          4603,
          75830,
          741,
          7268,
          23,
          722,
          391389,
          5196,
          241,
          169,
          923,
          1645,
          1504,
          158701,
          2135,
          1080,
          568,
          395,
          79613,
          1312,
          217,
          2457,
          1766,
          320,
          753116,
          207410,
          832,
          47772,
          298,
          1595797,
          3255,
          43102,
          224256,
          151815,
          207410,
          258,
          397,
          124967,
          308,
          7692,
          4653,
          1472,
          50835,
          207,
          9679,
          5791,
          71485,
          255,
          128,
          254,
          5657,
          111,
          178,
          1970,
          276002,
          540,
          1261,
          46563,
          4367,
          13422,
          333497,
          581,
          18182,
          70,
          241,
          4090,
          4154,
          99,
          192,
          5875,
          38912,
          276002,
          648,
          230,
          222785,
          158701,
          21902,
          21134,
          229,
          308,
          79008,
          4074,
          970,
          798,
          3766,
          376,
          540,
          895,
          13422,
          258,
          3395,
          2691,
          6006,
          14075,
          5196,
          741,
          540,
          45303,
          42817,
          91,
          471,
          642,
          92985,
          85,
          77,
          30770,
          1791,
          99,
          75830,
          341043,
          191096,
          69,
          43102,
          1089,
          2036,
          74,
          13717,
          2856,
          241,
          50835,
          2501,
          68211,
          2408,
          3279,
          3224,
          4542,
          35371,
          836,
          9815,
          2092,
          14871,
          151785,
          372,
          10295,
          355,
          899,
          341,
          94325,
          7646,
          733,
          1810,
          222785,
          1324,
          324,
          54287,
          372,
          22930,
          372,
          2135,
          1213,
          653,
          1126,
          1532,
          2307,
          348,
          136,
          6951,
          1689,
          828,
          647,
          1228,
          9594,
          13835,
          597,
          28425,
          1478,
          1791,
          35439,
          2872,
          1988,
          4653,
          2290,
          4090,
          1923,
          509,
          1302,
          6469,
          376,
          23,
          118,
          19054,
          46563,
          4074,
          972,
          427,
          493806,
          3224,
          50835,
          1686,
          530,
          509,
          2408,
          2290,
          525713,
          757530,
          192,
          68211,
          765,
          237282,
          27971,
          7420,
          1382480,
          1143,
          1087,
          743,
          533,
          134056,
          1526206,
          54287,
          460,
          1523,
          1190,
          22191,
          214703,
          1909,
          757530,
          3119,
          1970,
          741,
          3688,
          1126,
          92985,
          744,
          2202,
          3684,
          602,
          172817,
          9521,
          757530,
          123373,
          10256,
          1078,
          504,
          647,
          1166,
          3688,
          1970,
          144160,
          2906700,
          126,
          1131,
          2135,
          530,
          1847,
          1563,
          276002,
          725,
          673342,
          1571,
          804,
          149,
          47211,
          1512,
          2208,
          151785,
          258,
          61,
          1102,
          23,
          885,
          5621,
          1446,
          247,
          2471,
          741,
          3451,
          9587,
          307,
          169,
          10256,
          5791,
          8019,
          397,
          4074,
          504,
          4081,
          771,
          30770,
          1804,
          1063,
          5507,
          4542,
          471,
          4081,
          3684,
          337,
          34153,
          2518,
          2501,
          498,
          1966,
          1228,
          1360,
          2504700,
          16163,
          105638,
          5927,
          3688,
          680,
          5438,
          267,
          2135,
          176,
          1087,
          4512,
          973849,
          502,
          571,
          302,
          198,
          1766,
          276002,
          2870,
          832,
          2691,
          165556,
          1453,
          391389,
          177,
          407,
          136,
          5507,
          504,
          9993,
          1131,
          1631,
          3684,
          5901,
          513,
          2078,
          24645,
          641,
          1925,
          4090,
          3487,
          241,
          1628,
          1131,
          47249,
          11256,
          4895,
          630,
          105549,
          4542,
          5791,
          4542,
          3202,
          509,
          233717,
          640470,
          1446,
          606,
          1368,
          1453,
          888,
          42817,
          12486,
          7155,
          2258,
          759,
          1892,
          798,
          2328,
          1583,
          6581,
          177,
          1512,
          18128,
          5577,
          639,
          5908,
          3224,
          397,
          6434,
          237282,
          2456,
          198,
          1533,
          828,
          5211,
          1324,
          736284,
          13717,
          895,
          1126,
          5895,
          530,
          2328,
          463,
          571,
          3285,
          19685,
          509,
          1102,
          71463,
          18128,
          516,
          191096,
          1478,
          2060,
          140,
          1228,
          1078,
          163415,
          1850,
          525713,
          12747,
          520,
          1306,
          5791,
          911,
          759,
          1526206,
          3224,
          6469,
          43,
          134056,
          2206,
          248858,
          270712,
          1504,
          409656,
          42384,
          545147,
          3805,
          1770,
          2661,
          1577385,
          1645,
          71485,
          207410,
          1504,
          191096,
          1925,
          269,
          1089,
          71463,
          19054,
          4542,
          5662,
          37,
          302,
          2376,
          2368,
          14742,
          267,
          493,
          9506,
          321490,
          11250,
          932,
          741,
          1493,
          4993,
          71485,
          1412,
          107941,
          1360,
          565,
          11250,
          35439,
          123,
          885,
          823,
          741,
          277,
          1186,
          191096,
          12747,
          328,
          139650,
          737,
          10256,
          911,
          139,
          1461,
          136,
          910148,
          899,
          25459,
          3495,
          9772,
          516,
          3495,
          1178,
          128354,
          2036,
          70,
          163415,
          12335,
          1196,
          824,
          413574,
          741,
          217,
          4081,
          1360,
          84106,
          18408,
          391389,
          1507,
          12335,
          3688,
          1228,
          3833,
          568,
          2206,
          564,
          167,
          297,
          427,
          4090,
          350,
          1412,
          832,
          18182,
          5989,
          55581,
          4367,
          112,
          2395,
          3776,
          1684,
          34882,
          276896,
          31394,
          35371,
          50489,
          648,
          888,
          470,
          2799,
          680,
          1383,
          128354,
          31394,
          520,
          1288,
          31394,
          1078,
          2906700,
          798,
          9815,
          254282,
          2799,
          2368,
          1075,
          4138,
          922,
          198,
          238602,
          55581,
          20328,
          50489,
          213,
          502,
          191096,
          1507,
          341,
          270712,
          11256,
          5161,
          1166,
          71335,
          71335,
          972,
          2092,
          399,
          2097,
          1166,
          5903,
          4172,
          79613,
          242,
          1420,
          771,
          736284,
          124967,
          320420,
          166081,
          95,
          1261,
          365,
          1139,
          545147,
          1241364,
          10076,
          922,
          5621,
          1847,
          370,
          1383,
          9993,
          151785,
          365,
          31515,
          3279,
          464,
          589,
          1760,
          106,
          581,
          2135,
          213,
          10717,
          1684,
          31515,
          3104,
          166081,
          673342,
          2317,
          21902,
          828,
          744,
          710,
          276002,
          2158,
          104,
          1263321,
          242,
          276896,
          2135,
          28739,
          1178,
          269,
          1201,
          8007,
          207,
          3766,
          229,
          34882,
          753116,
          518429,
          4508,
          493,
          530,
          606,
          85,
          4878,
          2526,
          151785,
          1312922,
          454,
          6025,
          516,
          2661,
          765,
          2206,
          91,
          76,
          969,
          1526206,
          1725,
          2644,
          9679,
          504,
          34496,
          1892,
          142,
          1131,
          632,
          4090,
          710,
          1228,
          42384,
          248,
          3776,
          3487,
          4056,
          1892,
          7268,
          2092,
          1766,
          324,
          77,
          3996,
          571,
          2054,
          224256,
          111,
          1078,
          1766,
          14228,
          43,
          1288,
          73,
          4575,
          1831,
          37,
          899,
          331,
          4138,
          2518,
          198,
          5438,
          192,
          349,
          1078,
          1850,
          60,
          4074,
          4056,
          2206,
          832,
          191096,
          5989,
          2303,
          68211,
          2456,
          4542,
          2906700,
          1334,
          1563,
          269,
          1412,
          1749,
          2016,
          1196,
          24645,
          647,
          19685,
          260,
          12349,
          1595797,
          7268,
          206,
          2870,
          888,
          413574,
          341,
          17867,
          1645,
          1617,
          9815,
          229,
          1201,
          341,
          338,
          10076,
          528,
          6951,
          6469,
          518429,
          111,
          143,
          1263321,
          5621,
          1178,
          276896,
          331,
          5666,
          4474,
          142,
          1789,
          5507,
          1892,
          1089,
          545147,
          149,
          6469,
          165,
          3487,
          601723,
          31515,
          337,
          6460,
          606,
          540,
          237282,
          5760,
          276896,
          741,
          36438,
          1897,
          17867,
          1480,
          205,
          28425,
          419,
          502,
          276896,
          9815,
          92985,
          3119,
          12747,
          2607,
          759,
          135332,
          2304,
          16183,
          680,
          177,
          1804,
          2263,
          34496,
          31970,
          43,
          1426,
          736284,
          475,
          18128,
          69,
          77,
          136,
          525713,
          50489,
          75830,
          104,
          4508,
          1196,
          450,
          3807,
          2501,
          128,
          1725,
          224256,
          673342,
          5211,
          378909,
          5760,
          732,
          1892,
          1791,
          1019,
          2916,
          310,
          54767,
          26120,
          1190,
          1979,
          95035,
          190,
          1523,
          1213,
          722,
          861,
          5507,
          372,
          519,
          1656,
          92294,
          1078,
          258,
          1453,
          761,
          128,
          22930,
          1595797,
          828,
          76383,
          899,
          741,
          91,
          239,
          21134,
          134056,
          134056,
          258,
          628,
          129,
          21134,
          5901,
          601723,
          540,
          313,
          1478,
          722,
          140,
          687276,
          4090,
          28739,
          21902,
          52126,
          186140,
          836,
          84106,
          765,
          1679,
          4154,
          1679,
          1789,
          92985,
          22305,
          1675,
          626,
          2376,
          602,
          4575,
          761,
          1383,
          218,
          222785,
          5211,
          864,
          68211,
          19408,
          5927,
          217,
          2471,
          878,
          223,
          165556,
          134056,
          3289,
          564,
          24840,
          3104,
          95035,
          4993,
          134056,
          1201,
          73,
          233717,
          606,
          1766,
          128715,
          53,
          378909,
          7297,
          6469,
          241,
          5161,
          320420,
          1563,
          206,
          899,
          973849,
          1939,
          1019,
          4074,
          1925,
          888,
          75830,
          888,
          648,
          178,
          1139,
          112,
          15426,
          1426,
          8097,
          77,
          973849,
          338,
          2258,
          32891,
          502,
          1643,
          269,
          2870,
          1831,
          1766,
          795,
          95,
          88735,
          22305,
          16183,
          3451,
          1196,
          3805,
          1360,
          9512,
          1126,
          207,
          663,
          37,
          255,
          3096,
          346,
          2870,
          502,
          663,
          4653,
          571,
          718,
          601723,
          4895,
          136,
          5950,
          15623,
          23727,
          222785,
          1102,
          564,
          302,
          21902,
          36438,
          1645,
          31394,
          18459,
          27971,
          450,
          581,
          4533,
          1766,
          824,
          1654,
          1841,
          9034,
          391389,
          1700,
          8830,
          276896,
          129,
          2836,
          2906700,
          3066,
          308,
          171170,
          1504,
          337,
          969,
          34153,
          1745,
          12335,
          3487,
          798,
          67082,
          1126,
          1423,
          1274,
          1461,
          427,
          407,
          9587,
          263,
          4005,
          1363,
          1758,
          50489,
          9587,
          13422,
          34153,
          1675,
          673342,
          94014,
          2376,
          895,
          171170,
          145,
          2786,
          1412,
          1312922,
          5927,
          1517,
          140,
          3279,
          4354,
          1271,
          7646,
          836,
          2368,
          407,
          1526206,
          2036,
          1758,
          172817,
          1423,
          564,
          27020,
          8007,
          59705,
          895,
          478,
          478,
          1196,
          34153,
          9594,
          46563,
          608,
          96942,
          8007,
          8007,
          1526206,
          1762,
          207410,
          2661,
          1139,
          1324,
          673342,
          749635,
          776,
          50489,
          4653,
          32891,
          165556,
          725,
          686,
          725,
          10256,
          2016,
          128715,
          31515,
          722,
          222785,
          59744,
          2135,
          158701,
          1858,
          581,
          137067,
          5989,
          3343,
          635,
          2290,
          635,
          6951,
          2504700,
          1261,
          8874,
          6120,
          28425,
          737,
          118,
          28739,
          1461,
          888,
          798,
          165,
          3096,
          1087,
          1442,
          6713,
          307,
          895,
          21902,
          753116,
          341043,
          1490,
          722,
          1271,
          11250,
          1190,
          3699,
          2328,
          828,
          3430,
          2856,
          137,
          1745,
          84106,
          795,
          1925,
          5791,
          2504700,
          970,
          910148,
          1306,
          9512,
          824,
          1196,
          4589,
          34882,
          8830,
          93193,
          6951,
          1080,
          2307,
          12335,
          2054,
          1132,
          13422,
          641,
          885,
          2304,
          77,
          722,
          460,
          566,
          166081,
          76383,
          1075,
          2786,
          67858,
          1228,
          800,
          24536,
          1595797,
          31515,
          824,
          2456,
          3119,
          927396,
          589,
          5548,
          530,
          124967,
          642,
          1758,
          5778,
          1132,
          71463,
          3402,
          2307,
          1075,
          7268,
          378909,
          22191,
          26551,
          19685,
          3119,
          540,
          863,
          4729,
          863,
          331,
          11256,
          34153,
          46,
          71485,
          7297,
          263,
          1758,
          1140,
          2470,
          911,
          641349,
          140,
          749635,
          1577385,
          5512,
          1970,
          276,
          224256,
          525713,
          478,
          20478,
          42817,
          1019,
          50835,
          1453,
          343,
          5457,
          3876,
          804,
          30770,
          1766,
          23,
          8874,
          217,
          1312922,
          3402,
          3684,
          365,
          93193,
          349,
          725,
          863,
          1228,
          1533,
          34496,
          2807,
          736284,
          42619,
          3776,
          73,
          1190,
          1897,
          6469,
          134056,
          14871,
          1680,
          341043,
          477,
          532,
          899,
          2258,
          310,
          291,
          140,
          1201,
          663,
          46,
          4474,
          725,
          28425,
          1382480,
          2376,
          3343,
          31970,
          378909,
          5875,
          2607,
          3224,
          5196,
          343,
          1909,
          1274,
          828,
          14783,
          970,
          124967,
          631,
          391389,
          321490,
          372,
          7268,
          2379,
          4306,
          922,
          21134,
          450,
          710,
          59744,
          176,
          972,
          190178,
          1850,
          2906700,
          2408,
          9496,
          1271,
          15647,
          1202,
          502,
          1478,
          3224,
          5778,
          3066,
          18128,
          218,
          165,
          92294,
          836,
          571,
          1689,
          972,
          1606,
          22930,
          1288,
          76383,
          1675,
          2263,
          222785,
          1577385,
          5875,
          2566,
          3730,
          4542,
          258,
          341,
          343,
          1228,
          71335,
          1684,
          238602,
          1810,
          5341,
          601723,
          74,
          4542,
          21902,
          86954,
          222785,
          1414,
          267,
          1645,
          11751,
          2644,
          530,
          95,
          4198,
          489,
          76383,
          1078,
          1565,
          123,
          25459,
          1512,
          297,
          237282,
          1453,
          149,
          471,
          1078,
          3688,
          217,
          3684,
          7646,
          477,
          737,
          171170,
          2870,
          34496,
          3224,
          895,
          7646,
          687276,
          1645,
          32891,
          2317,
          71485,
          1970,
          1686,
          324,
          1274,
          176,
          9512,
          2456,
          2016,
          1523,
          493806,
          11751,
          7155,
          165,
          172817,
          391389,
          95015,
          4172,
          910148,
          1213,
          76,
          899,
          3395,
          92294,
          630,
          937,
          718,
          895,
          601723,
          276896,
          17867,
          6951,
          99,
          4056,
          17047,
          21134,
          718,
          5950,
          470,
          631,
          333497,
          381459,
          1075,
          34153,
          355,
          686,
          391389,
          1139,
          10076,
          84106,
          4074,
          7565,
          626,
          888,
          86954,
          75830,
          2263,
          343,
          910148,
          695,
          10717,
          3119,
          973849,
          595,
          1514,
          10717,
          811,
          15269,
          5161,
          910148,
          206,
          413574,
          35371,
          470,
          2368,
          59744,
          181438,
          4573,
          2872,
          1512,
          218,
          1312922,
          1453,
          3255,
          6469,
          477,
          19408,
          100,
          14871,
          254282,
          191096,
          337,
          100,
          7297,
          1490,
          973849,
          1909,
          381459,
          5161,
          139,
          2368,
          276896,
          153,
          84861,
          4542,
          1571,
          1523,
          836,
          1078,
          104396,
          149,
          732,
          1897,
          3684,
          2518,
          105549,
          36438,
          2202,
          18459,
          177,
          24645,
          320420,
          1643,
          4895,
          509,
          355,
          214518,
          2060,
          6469,
          55345,
          1512,
          2328,
          47249,
          804,
          2457,
          761,
          378909,
          687276,
          1241364,
          673342,
          190249,
          5760,
          2395,
          407,
          144160,
          1490,
          5621,
          5648,
          341,
          21437,
          19090,
          95,
          540,
          5778,
          343,
          2872,
          695,
          2661,
          832,
          68211,
          1363,
          4198,
          341043,
          24840,
          18182,
          239,
          5512,
          513,
          320420,
          23727,
          275,
          760,
          1334,
          885,
          1126,
          601723,
          798,
          3202,
          291,
          84106,
          463,
          172817,
          43102,
          71485,
          1725,
          151022,
          313,
          2870,
          47211,
          13602,
          3032,
          60,
          13717,
          1923,
          7155,
          2526,
          224256,
          4074,
          13973,
          2870,
          9772,
          471,
          1324,
          207410,
          3104,
          836,
          85,
          2501,
          192,
          841711,
          19408,
          450,
          1312,
          6951,
          632,
          1526206,
          2148,
          3996,
          53,
          463,
          9165,
          1577385,
          55581,
          3495,
          12335,
          3807,
          11253,
          23,
          601723,
          84106,
          248858,
          653,
          320420,
          3395,
          128715,
          3807,
          4913,
          632,
          136,
          172247,
          1841,
          932,
          207,
          3202,
          1512,
          4159,
          217,
          18408,
          3876,
          106,
          1271,
          1126,
          1196,
          140,
          4172,
          55345,
          1606,
          602,
          215,
          79008,
          20478,
          3451,
          110,
          2317,
          302,
          258,
          333497,
          5778,
          2135,
          1089,
          123,
          5161,
          14228,
          267,
          4542,
          722,
          9815,
          6581,
          4354,
          595,
          324,
          47772,
          34882,
          313,
          3285,
          606,
          31515,
          9521,
          885,
          4090,
          2376,
          1791,
          743,
          3066,
          4664,
          631,
          3202,
          4056,
          22305,
          1526206,
          69793,
          1190,
          5354,
          79613,
          632,
          4074,
          1063,
          1925,
          207410,
          191096,
          269,
          276896,
          737,
          2870,
          2092,
          759,
          9051,
          1595797,
          413574,
          172817,
          2691,
          741,
          277,
          207,
          198,
          16183,
          1577385,
          43,
          50835,
          2304,
          2501,
          1679,
          687276,
          5760,
          1517,
          1423,
          137,
          718,
          2906700,
          1360,
          6460,
          136,
          1126,
          5621,
          376,
          94325,
          248,
          21125,
          310,
          464,
          2456,
          16305,
          571,
          463,
          1745,
          2135,
          71335,
          2408,
          6951,
          73,
          343,
          2328,
          1810,
          59744,
          4575,
          1453,
          31394,
          2504700,
          3996,
          19685,
          233060,
          391389,
          1654,
          276896,
          3487,
          74,
          376,
          1442,
          4542,
          2408,
          178,
          263,
          331,
          10076,
          2906700,
          922,
          628,
          6120,
          37,
          17047,
          74,
          4589,
          1517,
          35439,
          725,
          895,
          92106,
          19408,
          885,
          759,
          4726,
          1645,
          18128,
          6951,
          2456,
          85,
          276896,
          54287,
          4512,
          163415,
          308,
          823,
          137,
          21125,
          645,
          1847,
          1312922,
          564,
          1988,
          263,
          1195,
          1228,
          277,
          269,
          2290,
          19090,
          2435,
          737,
          46,
          163415,
          4090,
          1139,
          338,
          1312922,
          137,
          137,
          888,
          3263,
          836,
          545147,
          2456,
          45100,
          123373,
          470,
          1360,
          1523,
          106,
          5895,
          5726,
          2263,
          18760,
          2607,
          348,
          4508,
          59744,
          2317,
          28739,
          885,
          1507,
          471,
          828,
          35371,
          316665,
          8874,
          51,
          1143,
          427,
          4729,
          824,
          337,
          71485,
          190178,
          647,
          17867,
          7646,
          1684,
          248,
          33804,
          642,
          9815,
          324,
          186140,
          3395,
          4049,
          823,
          20478,
          1446,
          214703,
          343,
          601723,
          389246,
          471,
          269,
          35371,
          372,
          46563,
          28739,
          320420,
          165556,
          215,
          2158,
          302,
          722,
          8097,
          5211,
          12335,
          722,
          12335,
          493806,
          5512,
          1089,
          5354,
          4074,
          639,
          459921,
          5354,
          1507,
          964,
          308,
          34882,
          84106,
          1847,
          341,
          295,
          139650,
          307,
          198,
          910148,
          55345,
          3776,
          1595797,
          43102,
          1312922,
          313,
          2916,
          3228,
          1680,
          601723,
          190178,
          207410,
          42817,
          520,
          2457,
          237282,
          1892,
          55581,
          54287,
          21134,
          35439,
          26551,
          1368,
          248858,
          1656,
          118,
          9034,
          16183,
          824,
          741,
          92043,
          551,
          128,
          10295,
          76383,
          1302,
          217,
          1563,
          344,
          4198,
          4474,
          71485,
          1324,
          895,
          4993,
          20328,
          100,
          606,
          5908,
          239,
          1666,
          123,
          1507,
          54287,
          9772,
          271,
          42619,
          67858,
          2089,
          376,
          540,
          50489,
          11432,
          4161,
          5908,
          5927,
          3766,
          328,
          5950,
          466,
          1019,
          718,
          4720,
          61,
          391389,
          328,
          28739,
          4354,
          1186,
          1643,
          2661,
          2078,
          673342,
          346,
          606,
          84106,
          2916,
          1791,
          5621,
          1654,
          14742,
          16183,
          1661,
          165,
          139650,
          349,
          15426,
          647,
          42817,
          343,
          6951,
          149,
          50835,
          129,
          4508,
          100,
          166081,
          1595797,
          272,
          736284,
          213,
          2304,
          94325,
          6629,
          409656,
          589,
          184,
          242,
          647,
          2317,
          2263,
          2906700,
          1617,
          645,
          129,
          166081,
          832,
          139650,
          5341,
          1970,
          100,
          498,
          110,
          540,
          2368,
          824,
          459921,
          338,
          5161,
          2121,
          1617,
          76383,
          333497,
          3487,
          75830,
          927396,
          47211,
          1472,
          608,
          1526206,
          502,
          1758,
          1841,
          641349,
          27971,
          1526206,
          4290,
          75830,
          1661,
          759,
          2661,
          341,
          519,
          12486,
          2501,
          1179,
          2290,
          213,
          4542,
          1536,
          899,
          7987,
          165556,
          2607,
          313,
          1946,
          413574,
          3807,
          566,
          1195,
          1426,
          1766,
          1312922,
          5791,
          4172,
          92043,
          397,
          18182,
          4603,
          2274,
          198,
          1166,
          910148,
          2368,
          378909,
          3289,
          105638,
          1274,
          5989,
          5211,
          94325,
          14228,
          18408,
          832,
          13717,
          3807,
          964,
          276896,
          4729,
          2368,
          105638,
          972,
          14742,
          1979,
          27971,
          100,
          17867,
          20328,
          2457,
          824,
          140,
          3776,
          1850,
          316665,
          3833,
          6469,
          3395,
          1679,
          165,
          35439,
          427,
          76383,
          320420,
          3451,
          459921,
          328,
          71485,
          1517,
          149,
          184,
          493806,
          502,
          648,
          8097,
          1725,
          2872,
          7155,
          21635,
          3684,
          172817,
          11256,
          277,
          302,
          836,
          1312922,
          71485,
          47211,
          7268,
          254282,
          5875,
          1791,
          1186,
          93193,
          16305,
          1583,
          137,
          237282,
          2836,
          757530,
          321490,
          1363,
          3996,
          11253,
          123,
          77,
          2691,
          23,
          565,
          718,
          1312,
          11253,
          743,
          737,
          55345,
          2304,
          828,
          6006,
          123373,
          3289,
          642,
          158701,
          203571,
          92043,
          3402,
          50489,
          19054,
          136,
          215,
          1686,
          551,
          54767,
          331,
          2142,
          24536,
          104396,
          519,
          222,
          123,
          771,
          302,
          123,
          895,
          19685,
          590,
          722,
          144160,
          129,
          741,
          1360,
          217,
          798,
          1201,
          2607,
          230,
          10717,
          77,
          964,
          2408,
          349,
          647,
          134056,
          914,
          1512,
          341,
          341043,
          5161,
          2036,
          2401,
          5989,
          760,
          477,
          571,
          2202,
          2526,
          1461,
          7297,
          163415,
          498,
          972,
          163415,
          166081,
          27020,
          95,
          601723,
          970,
          828,
          2135,
          270712,
          46,
          1312922,
          134056,
          190178,
          23727,
          1261,
          163415,
          13717,
          372,
          248858,
          614,
          1654,
          4508,
          601723,
          247,
          9784,
          687276,
          2408,
          718,
          5791,
          4081,
          1686,
          5621,
          163415,
          105549,
          2054,
          12747,
          4575,
          504,
          1078,
          46944,
          214703,
          6434,
          2526,
          4049,
          626,
          4090,
          5196,
          733,
          1725,
          1909,
          136,
          12747,
          71485,
          233717,
          229,
          695,
          590,
          1261,
          741,
          45303,
          13835,
          47772,
          2471,
          1749,
          1770,
          811,
          349,
          922,
          137067,
          725,
          4354,
          1930,
          49,
          22930,
          1360,
          753116,
          5196,
          17867,
          3279,
          73,
          5927,
          5989,
          94014,
          1412,
          1412,
          79613,
          77,
          530,
          471,
          21134,
          21134,
          95015,
          1126,
          149,
          123,
          86954,
          3996,
          1725,
          18128,
          165556,
          1517,
          26551,
          275,
          1512,
          475,
          475,
          42817,
          10717,
          123,
          4508,
          320,
          1360,
          1725,
          427,
          94325,
          2872,
          190178,
          69,
          540,
          71335,
          1274,
          1679,
          31394,
          248,
          2211,
          310,
          526,
          344,
          10076,
          804,
          1577385,
          628,
          888,
          399,
          105638,
          1271,
          1102,
          1241364,
          70,
          1536,
          3289,
          341,
          365,
          151815,
          223,
          399,
          4056,
          23045,
          1675,
          626,
          2036,
          6951,
          399,
          43,
          2456,
          139,
          1760,
          1804,
          222785,
          116001,
          4729,
          479994,
          1617,
          863,
          5354,
          123,
          4677,
          54287,
          2836,
          9679,
          1617,
          75830,
          302,
          504,
          782,
          1645,
          21125,
          4172,
          645,
          1263321,
          1446,
          2328,
          5726,
          3451,
          6713,
          8830,
          18408,
          1523,
          3766,
          824,
          1571,
          42384,
          581,
          1628,
          970,
          1195,
          54767,
          601723,
          516,
          5451,
          13422,
          163415,
          2290,
          4074,
          3996,
          1595797,
          2523,
          13422,
          344,
          673342,
          1532,
          5657,
          4471,
          2607,
          13422,
          7430,
          207,
          736284,
          2401,
          606,
          2368,
          1178,
          277,
          241,
          1526206,
          1946,
          1019,
          165556,
          242,
          969,
          7430,
          606,
          263,
          680,
          145,
          50835,
          302,
          93193,
          11751,
          824,
          2566,
          6713,
          795,
          5666,
          1675,
          1126,
          3430,
          123,
          20478,
          1979,
          341,
          85,
          2258,
          2456,
          1583,
          601723,
          5760,
          198,
          324,
          77,
          49,
          286,
          743,
          42817,
          238602,
          67082,
          3776,
          530,
          2870,
          85,
          67082,
          1631,
          139650,
          36438,
          2395,
          19090,
          1850,
          158701,
          502,
          328,
          5927,
          52126,
          1165,
          76,
          129,
          1645,
          471,
          1190,
          111,
          2504700,
          2523,
          341,
          391389,
          595,
          24840,
          2376,
          76,
          530,
          864,
          1909,
          242,
          2691,
          123373,
          7155,
          885,
          6120,
          1186,
          478,
          4354,
          1426,
          4290,
          343,
          5895,
          3402,
          75830,
          540,
          4729,
          217,
          6951,
          18408,
          3495,
          16163,
          370,
          530,
          95035,
          365,
          55345,
          145,
          6120,
          1966,
          2258,
          836,
          965,
          24645,
          116155,
          4474,
          5438,
          45303,
          276002,
          1178,
          1666,
          71335,
          564,
          2036,
          443,
          673342,
          2607,
          331,
          167,
          106,
          2328,
          50489,
          142,
          19685,
          27971,
          4573,
          95035,
          686,
          177,
          732,
          275,
          5791,
          2906700,
          899,
          2526,
          863,
          1195,
          1063,
          2906700,
          965,
          1892,
          1643,
          2661,
          1274,
          298,
          124967,
          276,
          22191,
          1923,
          2036,
          9521,
          1312922,
          1979,
          3096,
          111,
          4081,
          564,
          1190,
          1725,
          1102,
          407,
          172817,
          272,
          1241364,
          20478,
          18760,
          1146,
          823,
          2208,
          7565,
          8269,
          36784,
          1382480,
          2092,
          172817,
          241,
          3085,
          348,
          6120,
          5760,
          241,
          263,
          1453,
          823,
          686,
          922,
          79613,
          1970,
          19090,
          2258,
          5161,
          6713,
          1760,
          13973,
          26551,
          128715,
          1686,
          123,
          1943,
          4845,
          1261,
          1804,
          46,
          9594,
          13422,
          92985,
          1530,
          9521,
          68211,
          565,
          1654,
          76,
          471,
          2836,
          545147,
          76,
          2036,
          391389,
          2906700,
          151785,
          321,
          2872,
          2121,
          1201,
          6120,
          1762,
          54185,
          1324,
          276002,
          10256,
          4542,
          5548,
          914,
          112,
          4474,
          343,
          2504700,
          1766,
          695,
          1512,
          14871,
          973849,
          94325,
          5621,
          863,
          18408,
          16183,
          43,
          467,
          242,
          128354,
          4056,
          128,
          1766,
          229,
          91,
          54767,
          5848,
          50489,
          1312922,
          513,
          258,
          1745,
          1925,
          5760,
          861,
          32891,
          2054,
          516,
          4895,
          969,
          34882,
          6581,
          478,
          25459,
          184,
          76383,
          105638,
          642,
          84106,
          2290,
          725,
          68211,
          6951,
          25459,
          1478,
          5666,
          4056,
          255,
          267,
          71485,
          28425,
          3684,
          502,
          633,
          4677,
          129,
          176,
          1617,
          642,
          648,
          757530,
          153,
          48194,
          215,
          3224,
          493,
          965,
          765,
          1617,
          3430,
          13717,
          33917,
          172817,
          1523,
          76383,
          5438,
          21134,
          28739,
          77,
          5577,
          823,
          530,
          207,
          18760,
          186140,
          22930,
          1478,
          466,
          11256,
          1126,
          7297,
          158701,
          1946,
          4090,
          140,
          1675,
          910148,
          54767,
          6469,
          450,
          18408,
          111,
          18408,
          1563,
          79613,
          1196,
          320420,
          63,
          365,
          186140,
          6951,
          19685,
          2135,
          237282,
          1131,
          217,
          9512,
          1324,
          828,
          551,
          1228,
          743,
          1078,
          413574,
          564,
          45303,
          5621,
          50835,
          1178,
          1988,
          346,
          475,
          100,
          17867,
          1577385,
          976,
          19685,
          7155,
          427,
          1302,
          642,
          165,
          4512,
          970,
          167,
          1979,
          823,
          1565,
          24645,
          328,
          4542,
          8874,
          520,
          52126,
          302,
          38912,
          1745,
          4056,
          302,
          519,
          749635,
          641,
          277,
          21902,
          21125,
          6841,
          27971,
          3224,
          158701,
          5577,
          1087,
          355,
          11256,
          13973,
          1442,
          93193,
          1423,
          35439,
          4878,
          3430,
          71485,
          76383,
          55581,
          4056,
          13717,
          104396,
          1228,
          116155,
          23727,
          7565,
          970,
          1478,
          2906700,
          9815,
          104396,
          7646,
          166081,
          5875,
          73,
          133,
          116155,
          4729,
          36438,
          3451,
          427,
          2368,
          4474,
          276896,
          21134,
          19685,
          276002,
          798,
          3776,
          76,
          4138,
          847,
          520,
          54287,
          238602,
          20328,
          1679,
          1858,
          6841,
          1766,
          4074,
          4172,
          1263321,
          1261,
          124967,
          224256,
          270712,
          3223,
          73,
          1988,
          969,
          6841,
          85,
          237282,
          42384,
          313,
          2121,
          717255,
          313,
          502,
          28739,
          71463,
          1970,
          663,
          238602,
          14742,
          470,
          888,
          376,
          271,
          10256,
          937,
          2202,
          6841,
          7430,
          520,
          1571,
          3224,
          1979,
          194500,
          1666,
          9772,
          9587,
          2872,
          732,
          6120,
          1274,
          828,
          6284,
          520,
          69,
          32891,
          92337,
          7430,
          1472,
          2368,
          8874,
          20478,
          32891,
          9772,
          1383,
          73,
          100,
          4913,
          1252,
          964,
          519,
          324,
          4474,
          350,
          3730,
          13602,
          1523,
          18182,
          111,
          3684,
          6120,
          45303,
          1078,
          817312,
          427,
          4589,
          1241364,
          899,
          1166,
          2526,
          94014,
          6469,
          804,
          479994,
          5341,
          722,
          6018,
          4074,
          2258,
          86954,
          2148,
          5895,
          10717,
          464,
          92985,
          502,
          513,
          31515,
          1847,
          217,
          18128,
          4090,
          1019,
          757530,
          9496,
          522,
          27020,
          7155,
          2661,
          71485,
          378909,
          16163,
          158701,
          184,
          4056,
          190178,
          165,
          964,
          18128,
          233717,
          60,
          5196,
          1892,
          70,
          276896,
          737,
          530,
          248,
          3289,
          13973,
          2092,
          27971,
          1165,
          695,
          765,
          1263321,
          1679,
          798,
          4677,
          3862,
          3807,
          5196,
          79613,
          1979,
          749635,
          4653,
          970,
          1324,
          1514,
          50489,
          1453,
          277,
          203571,
          349,
          1680,
          128,
          7155,
          1078,
          134056,
          5989,
          93193,
          9587,
          2786,
          673342,
          92043,
          744,
          203571,
          302,
          498,
          513,
          648,
          21134,
          8830,
          4729,
          2121,
          1725,
          276896,
          3279,
          207,
          67082,
          165,
          571,
          6018,
          863,
          687276,
          1312,
          33804,
          1645,
          663,
          467,
          1087,
          12335,
          163415,
          276,
          128715,
          5438,
          5989,
          5341,
          6006,
          1507,
          346,
          1680,
          4512,
          718,
          6120,
          2092,
          344,
          111,
          378909,
          172817,
          4729,
          100,
          1645,
          85,
          1288,
          76383,
          2328,
          254,
          328,
          3285,
          2504700,
          2504700,
          27971,
          1453,
          1666,
          475,
          5451,
          298,
          1526206,
          184,
          1583,
          55581,
          313,
          7297,
          7646,
          1656,
          205,
          1019,
          31394,
          2401,
          276896,
          6629,
          8097,
          24536,
          5621,
          626,
          5895,
          3032,
          741,
          1201,
          1228,
          493,
          242,
          192805,
          255,
          2148,
          1178,
          156391,
          4575,
          344,
          215,
          1766,
          3833,
          5621,
          5895,
          1252,
          888,
          1766,
          1643,
          190178,
          564,
          2303,
          1988,
          1241364,
          78968,
          92985,
          2307,
          1304,
          663,
          817312,
          100,
          128,
          805,
          888,
          3119,
          5507,
          1201,
          1423,
          1140,
          5875,
          2304,
          4198,
          13973,
          2223,
          4589,
          31970,
          35439,
          1858,
          158701,
          343,
          2607,
          88735,
          158701,
          22305,
          3833,
          45303,
          564,
          6581,
          471,
          9679,
          1178,
          316665,
          365,
          798,
          695,
          20328,
          34882,
          2158,
          2906700,
          1324,
          343,
          467,
          2135,
          1745,
          3202,
          391389,
          163415,
          467,
          85,
          6713,
          632,
          5895,
          77,
          1274,
          333497,
          647,
          54767,
          395,
          1195,
          3805,
          3202,
          1841,
          1131,
          84106,
          6006,
          722,
          757530,
          79008,
          54185,
          1490,
          3688,
          1423,
          760,
          223,
          673342,
          1925,
          6508,
          3807,
          2376,
          885,
          1423,
          645,
          965,
          276002,
          22930,
          2036,
          2607,
          140,
          95,
          2435,
          648,
          55581,
          11250,
          27971,
          7297,
          1132,
          1892,
          26551,
          3255,
          321,
          11751,
          630,
          13061,
          459921,
          2807,
          601723,
          46,
          75830,
          124967,
          1563,
          2408,
          23,
          467,
          5895,
          972,
          1595797,
          1766,
          13717,
          34882,
          633,
          2135,
          85,
          1360,
          1190,
          76383,
          6629,
          477,
          597,
          732,
          276002,
          800,
          1087,
          1606,
          248,
          92985,
          24840,
          139,
          1304,
          601723,
          134056,
          741,
          5927,
          6434,
          695,
          680,
          5341,
          28278,
          84106,
          33804,
          5927,
          647,
          518429,
          4074,
          5621,
          10717,
          584,
          969,
          4542,
          2092,
          46563,
          88735,
          71463,
          504,
          4074,
          100,
          2504700,
          4993,
          15647,
          95035,
          67858,
          602,
          88735,
          192,
          2317,
          344,
          302,
          1166,
          932,
          128,
          2691,
          75830,
          2435,
          9594,
          20328,
          454,
          95,
          324,
          18182,
          1360,
          530,
          2526,
          1446,
          964,
          969,
          1078,
          5760,
          1831,
          176,
          927396,
          1190,
          12335,
          105549,
          4575,
          413574,
          1493,
          3032,
          12335,
          1490,
          116155,
          2054,
          348,
          21134,
          233060,
          10256,
          14742,
          16305,
          93193,
          6469,
          2401,
          165556,
          59744,
          2135,
          302,
          733,
          6951,
          601723,
          3451,
          237282,
          14228,
          75830,
          6120,
          67082,
          824,
          4913,
          2906700,
          969,
          18760,
          836,
          3730,
          12335,
          96942,
          1078,
          4512,
          46563,
          2121,
          2408,
          149,
          2328,
          804,
          595,
          2304,
          9034,
          642,
          1523,
          1923,
          811,
          59744,
          73,
          46,
          565,
          1423,
          753116,
          1850,
          6951,
          1526206,
          1791,
          7987,
          107941,
          59744,
          4074,
          724,
          376,
          937,
          2092,
          493,
          2971,
          4354,
          3766,
          277,
          45303,
          1810,
          6951,
          753116,
          263,
          338,
          328,
          4172,
          4161,
          27971,
          1988,
          1195,
          3994,
          1312922,
          54287,
          4680,
          1228,
          969,
          1089,
          757530,
          811,
          92608,
          67082,
          475,
          1690,
          1979,
          2303,
          111,
          2135,
          2408,
          8007,
          14871,
          6460,
          530,
          24840,
          1412,
          1532,
          2408,
          6120,
          2092,
          2807,
          2691,
          489,
          1089,
          7565,
          3224,
          5161,
          3684,
          2971,
          5903,
          18182,
          532,
          4533,
          2435,
          43,
          1979,
          116001,
          5950,
          61,
          149,
          5901,
          427,
          4090,
          337,
          134056,
          198,
          389246,
          878,
          695,
          601723,
          172817,
          34153,
          213,
          564,
          128715,
          79613,
          1661,
          128,
          43,
          6841,
          765,
          320,
          718,
          899,
          184,
          76,
          470,
          568,
          6460,
          4056,
          595,
          1577385,
          3766,
          27971,
          2092,
          214518,
          5196,
          1360,
          206,
          2691,
          9512,
          16183,
          99,
          3343,
          795,
          2872,
          2807,
          5950,
          21134,
          509,
          3508,
          1791,
          7297,
          2368,
          69,
          4913,
          9784,
          24645,
          346,
          1745,
          165,
          581,
          602,
          54767,
          18408,
          324,
          3994,
          648,
          178,
          9496,
          14075,
          260,
          198,
          3876,
          606,
          5438,
          1760,
          744,
          743,
          3451,
          271,
          34882,
          743,
          54767,
          910148,
          1443,
          718,
          1271,
          14783,
          13835,
          1766,
          27020,
          4015,
          5161,
          3085,
          1131,
          93193,
          191096,
          2523,
          75830,
          673342,
          571,
          34153,
          467,
          4542,
          5161,
          1745,
          7297,
          765,
          832,
          2328,
          2526,
          1577385,
          5791,
          238602,
          123,
          5901,
          4542,
          4056,
          149,
          2376,
          1426,
          1684,
          9815,
          84106,
          28278,
          255,
          782,
          95015,
          1684,
          5211,
          23,
          564,
          276002,
          1426,
          270712,
          4542,
          5548,
          1368,
          976,
          105638,
          1446,
          3766,
          92985,
          331,
          7565,
          828,
          9587,
          2054,
          20478,
          20478,
          71463,
          1271,
          3996,
          331,
          1312922,
          343,
          242,
          54287,
          313,
          43,
          5760,
          1563,
          6460,
          177,
          1689,
          5726,
          333497,
          2870,
          1858,
          338,
          4542,
          736284,
          16163,
          241,
          269,
          2518,
          1841,
          5507,
          1420,
          47249,
          687276,
          470,
          19408,
          13835,
          1263321,
          824,
          31394,
          3032,
          16305,
          2872,
          12335,
          242,
          3224,
          14075,
          5161,
          241,
          540,
          911,
          2408,
          1897,
          1446,
          2376,
          133,
          1766,
          269,
          635,
          1302,
          269,
          151815,
          22930,
          4778,
          663,
          6951,
          4198,
          3104,
          6006,
          4090,
          964,
          811,
          140,
          263,
          545147,
          397,
          2872,
          302,
          28739,
          53,
          899,
          186140,
          53,
          932,
          4913,
          8512,
          545147,
          2504700,
          302,
          645,
          5662,
          2526,
          324,
          2566,
          419,
          1645,
          2092,
          1645,
          743,
          571,
          1078,
          116001,
          1909,
          4354,
          4878,
          533,
          1923,
          540,
          8830,
          370,
          1166,
          1453,
          673342,
          1304,
          13835,
          3119,
          1583,
          123373,
          51,
          46944,
          269,
          32891,
          2148,
          71485,
          258,
          1312,
          2383912,
          1293,
          1675,
          38912,
          158701,
          207,
          92043,
          4677,
          166081,
          34496,
          165556,
          5726,
          11256,
          6006,
          55581,
          286,
          1420,
          2263,
          84106,
          229,
          4074,
          233717,
          116155,
          5621,
          94014,
          12486,
          12335,
          1078,
          248,
          276,
          116001,
          9587,
          122111,
          3766,
          42619,
          5621,
          737,
          463,
          224256,
          606,
          92043,
          45100,
          237282,
          970,
          3876,
          181438,
          1645,
          493,
          190178,
          5989,
          343,
          343,
          1089,
          409656,
          43,
          2870,
          1446,
          3289,
          2092,
          5875,
          5719,
          5512,
          217,
          19054,
          4074,
          53,
          2644,
          973849,
          166081,
          633,
          4603,
          970,
          277,
          478,
          5457,
          4653,
          18182,
          771,
          74,
          166081,
          932,
          493806,
          895,
          129,
          343,
          5196,
          116001,
          5875,
          372,
          5211,
          321490,
          1892,
          222785,
          372,
          581,
          1051,
          4306,
          1979,
          2523,
          301,
          1595797,
          1850,
          1196,
          459921,
          7268,
          4354,
          2148,
          24645,
          895,
          5548,
          263,
          321,
          129,
          1563,
          7155,
          10717,
          18128,
          1760,
          1791,
          1087,
          4005,
          13973,
          276002,
          316665,
          13973,
          378909,
          163415,
          737,
          1140,
          10256,
          1946,
          75830,
          9496,
          19685,
          73,
          177,
          9496,
          1312922,
          369,
          186140,
          271,
          248858,
          427,
          34153,
          1078,
          525713,
          1749,
          46563,
          2504700,
          43,
          1126,
          233060,
          1022298,
          128354,
          15269,
          564,
          176,
          269,
          9521,
          11256,
          11253,
          35299,
          2121,
          647,
          267,
          277,
          136,
          20478,
          26551,
          2376,
          518429,
          6120,
          2016,
          2097,
          1186,
          142,
          343,
          1925,
          13717,
          722,
          19685,
          718,
          823,
          59744,
          91,
          1897,
          680,
          28425,
          1760,
          717255,
          3862,
          1383,
          6284,
          568,
          71485,
          302,
          1507,
          6006,
          85,
          123,
          74,
          1228,
          30770,
          21125,
          19054,
          1201,
          167,
          1288,
          128354,
          765,
          13983,
          43,
          6841,
          4056,
          163415,
          2408,
          24645,
          602,
          3202,
          642,
          79613,
          895,
          110,
          885,
          149,
          1504,
          648,
          427,
          75830,
          2526,
          18128,
          365,
          31515,
          502,
          1925,
          260,
          9772,
          4172,
          192805,
          737,
          581,
          106,
          1252,
          241,
          648,
          248,
          2395,
          2799,
          7646,
          172817,
          5760,
          241,
          1382480,
          116001,
          1078,
          145,
          3451,
          1563,
          153,
          1453,
          1186,
          477,
          2504700,
          9521,
          145,
          4290,
          60,
          24536,
          54767,
          1132,
          346,
          42619,
          320420,
          564,
          973849,
          15426,
          341,
          2135,
          50835,
          493,
          5989,
          156391,
          85,
          888,
          2290,
          551,
          13602,
          493,
          528,
          530,
          144160,
          5908,
          804,
          1532,
          1858,
          346,
          337,
          899,
          302,
          1526206,
          343,
          530,
          571,
          489,
          725,
          365,
          2092,
          632,
          463,
          832,
          1766,
          460,
          92337,
          2016,
          964,
          1923,
          571,
          2691,
          229,
          911,
          686,
          5666,
          551,
          3343,
          14871,
          186140,
          13973,
          46944,
          1051,
          1563,
          76,
          2092,
          932,
          94325,
          310,
          639,
          1656,
          35371,
          263,
          823,
          2471,
          10076,
          1382480,
          744,
          1628,
          1196,
          1858,
          21125,
          93193,
          743,
          151785,
          2906700,
          258,
          3202,
          76,
          601723,
          123,
          4895,
          1312922,
          269,
          1022298,
          3996,
          581,
          67082,
          6025,
          528,
          166081,
          42384,
          84106,
          1807,
          1490,
          207,
          24536,
          68211,
          1766,
          911,
          3833,
          1228,
          376,
          3202,
          1631,
          782,
          9034,
          540,
          7268,
          532,
          606,
          413574,
          6469,
          2135,
          165556,
          5341,
          206,
          466,
          320420,
          1789,
          12486,
          47211,
          69,
          3104,
          2089,
          502,
          6434,
          4677,
          391389,
          467,
          302,
          158701,
          5619,
          2290,
          1909,
          1423,
          964,
          343,
          1078,
          3430,
          3451,
          337,
          128715,
          1312922,
          328,
          5778,
          344,
          1766,
          2501,
          1414,
          331,
          427,
          1512,
          1490,
          124967,
          489,
          1368,
          116155,
          932,
          139650,
          686,
          14871,
          2456,
          5901,
          540,
          5216,
          2872,
          3684,
          198,
          2376,
          1368,
          192805,
          35371,
          308,
          137,
          75903,
          2856,
          35299,
          761,
          9565,
          6951,
          2092,
          888,
          129,
          832,
          9034,
          1988,
          427,
          5161,
          863,
          88735,
          3996,
          3487,
          589,
          863,
          2518,
          6460,
          6120,
          1302,
          118,
          1304,
          222,
          5507,
          1749,
          181438,
          320,
          18408,
          116001,
          1414,
          1363,
          34882,
          2223,
          36438,
          8512,
          2443,
          233717,
          47249,
          640470,
          1645,
          8830,
          3451,
          381459,
          99,
          626,
          1979,
          99,
          4729,
          192,
          2395,
          3833,
          5848,
          24840,
          12335,
          632,
          328,
          1745,
          4090,
          13602,
          2158,
          19408,
          1617,
          5211,
          20478,
          68211,
          566,
          463,
          761,
          1288,
          6629,
          3263,
          144160,
          171170,
          17867,
          54767,
          1563,
          532,
          238602,
          642,
          123373,
          171170,
          1126,
          106,
          520,
          771,
          737,
          513,
          8830,
          92043,
          686,
          11751,
          237282,
          277,
          104396,
          1897,
          18408,
          3833,
          6469,
          493806,
          645,
          343,
          863,
          190178,
          50489,
          378909,
          3096,
          864,
          5875,
          2054,
          1263321,
          1426,
          2807,
          222785,
          277,
          328,
          134056,
          190178,
          1979,
          276002,
          564,
          391389,
          78968,
          10256,
          224256,
          3833,
          4533,
          2317,
          54287,
          6469,
          3996,
          2435,
          7646,
          1512,
          530,
          525713,
          823,
          46563,
          1274,
          1506,
          15623,
          4878,
          1472,
          1252,
          1412,
          346,
          139,
          2870,
          7268,
          6018,
          11250,
          5895,
          3495,
          34496,
          3766,
          760,
          4474,
          3487,
          18408,
          8007,
          493806,
          3096,
          1643,
          276002,
          3085,
          687276,
          1446,
          741,
          191096,
          5778,
          5726,
          8830,
          203571,
          190178,
          861,
          1943,
          1126,
          5196,
          302,
          589,
          1847,
          248,
          467,
          571,
          1909,
          6713,
          3279,
          3487,
          2456,
          3766,
          5927,
          568,
          1312,
          732,
          194500,
          50489,
          4074,
          320420,
          765,
          198,
          95,
          2290,
          172817,
          3343,
          85,
          695,
          399,
          4778,
          153,
          215,
          3066,
          15647,
          365,
          1271,
          254282,
          2304,
          2408,
          207,
          5760,
          34882,
          673342,
          1504,
          140,
          477,
          10256,
          6469,
          964,
          680,
          34882,
          2135,
          1923,
          571,
          2523,
          46,
          43102,
          61,
          4138,
          9772,
          18182,
          1595797,
          836,
          8874,
          5211,
          973849,
          75830,
          1666,
          158701,
          1302,
          337,
          1506,
          4424,
          3343,
          571,
          238602,
          255,
          1312922,
          1791,
          258,
          878,
          743,
          5903,
          21902,
          24645,
          5726,
          642,
          467,
          6841,
          4664,
          7163,
          11250,
          464,
          190178,
          328,
          13602,
          647,
          4653,
          1970,
          2376,
          270712,
          922,
          10256,
          899,
          1725,
          1078,
          222785,
          248858,
          79613,
          94325,
          3688,
          31515,
          1363,
          1271,
          1577385,
          6841,
          1574,
          1480,
          54767,
          372,
          1360,
          1382480,
          54767,
          1689,
          67082,
          129,
          4090,
          5438,
          344,
          1202,
          139,
          1139,
          214703,
          191096,
          493806,
          145,
          198,
          28278,
          753116,
          271,
          320420,
          911,
          23,
          5666,
          68211,
          1423,
          184,
          4664,
          2807,
          5161,
          55581,
          172247,
          673342,
          1051,
          8333,
          4367,
          460,
          4172,
          686,
          105638,
          165,
          647,
          2906700,
          69793,
          190178,
          192805,
          1165,
          718,
          1363,
          6951,
          248,
          725,
          6951,
          6006,
          37,
          92985,
          4653,
          207,
          20328,
          79008,
          1383,
          267,
          530,
          95015,
          1645,
          1523,
          11250,
          601723,
          18408,
          5927,
          606,
          21125,
          811,
          427,
          1563,
          1360,
          151022,
          18182,
          1745,
          633,
          4161,
          475,
          724,
          33917,
          46563,
          198,
          372,
          1087,
          513,
          346,
          1595797,
          184,
          17867,
          124967,
          1306,
          5895,
          5457,
          10717,
          686,
          337,
          2799,
          1178,
          725,
          190178,
          717255,
          753116,
          23,
          1979,
          478,
          71335,
          302,
          525713,
          54185,
          16305,
          2408,
          4575,
          263,
          504,
          4172,
          372,
          6018,
          28425,
          17047,
          76383,
          7268,
          1532,
          1089,
          95,
          184,
          1363,
          47249,
          969,
          134056,
          632,
          214703,
          2443,
          337,
          504,
          165,
          1725,
          1758,
          31394,
          21902,
          1563,
          21134,
          93193,
          551,
          1201,
          4290,
          54287,
          1383,
          1075,
          743,
          1312,
          7163,
          11250,
          53,
          479994,
          2223,
          3228,
          6841,
          832,
          60,
          3224,
          470,
          1577385,
          18408,
          1684,
          1102,
          328,
          76383,
          1930,
          11256,
          1770,
          5927,
          1643,
          509,
          43102,
          9772,
          1420,
          3684,
          632,
          5341,
          648,
          341043,
          92043,
          5438,
          142,
          1970,
          2471,
          1631,
          24840,
          4677,
          602,
          811,
          128715,
          471,
          5875,
          2036,
          1423,
          7155,
          50489,
          1480,
          6120,
          3096,
          2376,
          45100,
          3994,
          3876,
          1523,
          31970,
          50835,
          14228,
          255,
          647,
          35439,
          899,
          5778,
          302,
          22305,
          551,
          12335,
          2526,
          213,
          836,
          99,
          1804,
          3688,
          145,
          743,
          5512,
          910148,
          18760,
          5211,
          923,
          4913,
          1745,
          3096,
          320,
          378909,
          7565,
          1132,
          2258,
          77,
          139,
          2121,
          241,
          71463,
          1293,
          15426,
          136,
          540,
          1126,
          270712,
          493806,
          247,
          25459,
          118,
          1089,
          2786,
          2317,
          641349,
          2148,
          203571,
          286,
          1897,
          1563,
          5950,
          1791,
          295,
          571,
          217,
          466,
          2368,
          52126,
          973849,
          71485,
          5196,
          13602,
          1745,
          471,
          76,
          31394,
          341043,
          5196,
          964,
          276896,
          2016,
          718,
          18182,
          4542,
          48194,
          331,
          12335,
          69,
          324,
          1426,
          135332,
          5216,
          35299,
          836,
          1749,
          528,
          13602,
          1312,
          1970,
          1523,
          1382480,
          1512,
          2471,
          184,
          1139,
          1312922,
          2872,
          2836,
          782,
          1022298,
          832,
          276896,
          1368,
          467,
          9594,
          695,
          116155,
          277,
          910148,
          4729,
          601723,
          407,
          885,
          2518,
          4729,
          18408,
          5760,
          1643,
          105549,
          87124,
          88735,
          530,
          46,
          467,
          832,
          1453,
          4154,
          5577,
          1939,
          5908,
          324,
          1190,
          207410,
          1063,
          761,
          321,
          7155,
          771,
          489,
          1749,
          2317,
          35299,
          3255,
          4653,
          520,
          333497,
          1274,
          42619,
          3430,
          54185,
          2408,
          753116,
          355,
          7163,
          641,
          1892,
          214518,
          128354,
          1078,
          6006,
          5196,
          5507,
          1360,
          2566,
          13717,
          21902,
          757530,
          571,
          166081,
          136,
          123,
          519,
          798,
          1892,
          17867,
          2501,
          885,
          584,
          9815,
          5577,
          741,
          9815,
          218,
          1526206,
          3994,
          320420,
          914,
          2870,
          5512,
          1312,
          7646,
          11256,
          1228,
          307,
          509,
          24840,
          67082,
          96942,
          743,
          248858,
          741,
          798,
          184,
          213,
          4074,
          337,
          276896,
          4575,
          35371,
          54767,
          27020,
          970,
          5657,
          2799,
          4653,
          1595797,
          14228,
          1131,
          595,
          5548,
          1766,
          686,
          759,
          2607,
          2856,
          800,
          5901,
          493,
          798,
          372,
          92337,
          276,
          2395,
          1453,
          3104,
          46,
          1631,
          149,
          912,
          3684,
          4056,
          267,
          489,
          324,
          2208,
          1334,
          5666,
          736284,
          2906700,
          1166,
          69,
          239,
          12335,
          267,
          6713,
          50489,
          338,
          60,
          937,
          255,
          238602,
          28425,
          736284,
          30770,
          680,
          932,
          2607,
          1749,
          17867,
          863,
          545147,
          601723,
          3495,
          7646,
          478,
          19408,
          370,
          99,
          100,
          1080,
          3096,
          520,
          31394,
          21134,
          191096,
          1302,
          3343,
          178,
          1571,
          972,
          344,
          18408,
          1241364,
          277,
          4729,
          94014,
          5666,
          85,
          602,
          181438,
          477,
          1661,
          450,
          828,
          564,
          95035,
          5950,
          4074,
          3104,
          23727,
          95,
          1178,
          2303,
          321,
          24645,
          42817,
          798,
          50835,
          722,
          1195,
          928,
          45100,
          192,
          811,
          1312,
          493806,
          5908,
          579,
          5875,
          9587,
          1302,
          5512,
          217,
          1504,
          69793,
          5666,
          3395,
          3684,
          1892,
          3776,
          230,
          104396,
          1166,
          1241364,
          99,
          1810,
          18182,
          299480,
          1412,
          1102,
          34496,
          341043,
          1382480,
          76383,
          888,
          99,
          321490,
          5791,
          145,
          14783,
          7430,
          11256,
          4138,
          530,
          1645,
          28739,
          6713,
          2376,
          737,
          1645,
          1213,
          2148,
          2206,
          4680,
          914,
          863,
          176,
          1831,
          663,
          16183,
          207410,
          1583,
          828,
          27971,
          532,
          6284,
          1312922,
          30770,
          178,
          4603,
          922,
          1139,
          2501,
          7297,
          530,
          84106,
          23727,
          238602,
          53,
          16183,
          910148,
          4508,
          1595797,
          1312922,
          381459,
          31515,
          3202,
          640470,
          341,
          5895,
          5901,
          151022,
          110,
          19408,
          9815,
          6581,
          15269,
          28425,
          782,
          2644,
          92337,
          165556,
          1631,
          3263,
          645,
          1617,
          4138,
          13602,
          46,
          343,
          313,
          206,
          1577385,
          2408,
          914,
          1970,
          4074,
          737,
          595,
          5507,
          1261,
          2290,
          1850,
          5950,
          346,
          2872,
          277,
          828,
          1758,
          1089,
          168,
          2258,
          5950,
          765,
          443,
          8874,
          4290,
          1617,
          3395,
          107941,
          151022,
          27971,
          2258,
          427,
          4074,
          8269,
          341,
          1426,
          79008,
          1304,
          1383,
          878,
          1423,
          6951,
          50835,
          4542,
          78968,
          4726,
          1749,
          14783,
          1760,
          5354,
          2376,
          520,
          1507,
          158701,
          95,
          3451,
          1645,
          313,
          86954,
          13602,
          192805,
          378909,
          3766,
          27020,
          3066,
          409656,
          1143,
          606,
          7163,
          969,
          167,
          4508,
          4081,
          2906700,
          4474,
          1526206,
          3395,
          47249,
          20328,
          27971,
          663,
          640470,
          35299,
          1595797,
          203571,
          321,
          3119,
          1654,
          5760,
          4074,
          927396,
          321,
          5895,
          171170,
          1241364,
          184,
          964,
          645,
          15647,
          863,
          1241364,
          355,
          2408,
          4074,
          1132,
          899,
          136895,
          158701,
          718,
          2148,
          4471,
          124967,
          19090,
          1252,
          1526206,
          241,
          718,
          1810,
          1360,
          782,
          13422,
          736284,
          10256,
          6120,
          172817,
          725,
          1178,
          165,
          5161,
          397,
          355,
          2328,
          1178,
          639,
          10076,
          136,
          2376,
          1146,
          2870,
          3996,
          965,
          427,
          247,
          1051,
          4056,
          118,
          5791,
          53,
          595,
          1654,
          27020,
          1126,
          71463,
          36438,
          1420,
          1228,
          36438,
          78968,
          7646,
          76,
          34496,
          7692,
          331,
          7155,
          2607,
          291,
          1312922,
          213,
          116001,
          1512,
          136,
          551,
          640470,
          105549,
          4090,
          242,
          2317,
          20478,
          1102,
          1762,
          12335,
          493,
          203571,
          163415,
          732,
          247,
          34153,
          21134,
          95015,
          4542,
          1383,
          378909,
          4878,
          471,
          143,
          1577385,
          156391,
          177,
          2607,
          92043,
          1442,
          269,
          3495,
          50835,
          1526206,
          76383,
          551,
          4471,
          824,
          1563,
          673342,
          471,
          149,
          4198,
          1078,
          129,
          3228,
          224256,
          566,
          922,
          489,
          1684,
          4653,
          313,
          15426,
          7297,
          6629,
          3684,
          11751,
          673342,
          823,
          5196,
          302,
          27971,
          1089,
          70,
          137,
          181438,
          4878,
          217,
          27020,
          6120,
          5989,
          1631,
          2786,
          1512,
          1925,
          7163,
          165556,
          269,
          1201,
          2504700,
          46,
          1654,
          271,
          6025,
          1847,
          207410,
          1858,
          533,
          1261,
          5216,
          3119,
          2691,
          832,
          136,
          2872,
          105638,
          1517,
          5908,
          718,
          42619,
          172817,
          10256,
          653,
          16183,
          87124,
          241,
          1263321,
          258,
          513,
          23045,
          85,
          972,
          7163,
          137067,
          1595797,
          532,
          35705,
          233060,
          2691,
          1312922,
          5666,
          308,
          733,
          205,
          825,
          4653,
          7987,
          1446,
          4726,
          124967,
          6284,
          1654,
          145,
          1420,
          218,
          11256,
          3876,
          53,
          19054,
          3688,
          328,
          717255,
          1179,
          571,
          757530,
          5438,
          3730,
          53,
          3862,
          687276,
          737,
          4508,
          1689,
          77,
          34882,
          276,
          571,
          1789,
          297,
          144160,
          1139,
          276002,
          1412,
          969,
          3402,
          71463,
          1075,
          504,
          324,
          140,
          1686,
          910148,
          4575,
          14228,
          6629,
          7155,
          166081,
          724,
          965,
          632,
          1504,
          471,
          144160,
          965,
          222785,
          4845,
          270712,
          13602,
          9679,
          4729,
          328,
          169,
          9165,
          645,
          1536,
          2607,
          100,
          8874,
          28739,
          59744,
          4512,
          1526206,
          24840,
          3688,
          653,
          198,
          910148,
          28425,
          95035,
          8512,
          1666,
          2304,
          1312922,
          2206,
          1684,
          5211,
          2523,
          733,
          271,
          34153,
          1288,
          450,
          9772,
          3807,
          836,
          5901,
          2836,
          1595797,
          6120,
          718,
          151022,
          1382480,
          4367,
          1131,
          10295,
          36784,
          743,
          19685,
          2368,
          1645,
          28739,
          1943,
          2379,
          4726,
          1563,
          1850,
          2135,
          817312,
          260,
          50835,
          5875,
          50835,
          105638,
          4573,
          937,
          267,
          1051,
          254,
          68211,
          922,
          639,
          6006,
          928,
          24840,
          6006,
          1504,
          276002,
          276002,
          19090,
          765,
          1228,
          21902,
          18128,
          93193,
          1645,
          5791,
          206,
          46,
          828,
          267,
          1925,
          341,
          95015,
          1166,
          50835,
          1178,
          3699,
          2906700,
          640470,
          526,
          471,
          144160,
          5901,
          1617,
          35299,
          2807,
          104396,
          532,
          34496,
          663,
          3684,
          241,
          128354,
          11256,
          1909,
          47772,
          2526,
          111,
          1850,
          798,
          4508,
          71485,
          753116,
          92608,
          106,
          566,
          190178,
          589,
          46944,
          478,
          149,
          466,
          2158,
          19090,
          1770,
          178,
          6508,
          2523,
          2328,
          687276,
          8830,
          626,
          118,
          9594,
          178,
          2856,
          105549,
          771,
          1643,
          1523,
          4729,
          899,
          16305,
          5512,
          2607,
          606,
          136,
          272134,
          1312922,
          2916,
          1789,
          1577385,
          1274,
          3104,
          302,
          1165,
          59705,
          6841,
          1383,
          186140,
          1312922,
          1766,
          5950,
          111,
          528,
          36784,
          1725,
          84106,
          15623,
          5196,
          18182,
          5875,
          2456,
          1631,
          270712,
          13717,
          743,
          23045,
          166081,
          479994,
          1442,
          1526206,
          184,
          2799,
          277,
          878,
          765,
          1412,
          498,
          70,
          4677,
          1930,
          2158,
          1526206,
          134056,
          163415,
          471,
          11751,
          1360,
          341,
          759,
          242,
          2036,
          2518,
          86954,
          184,
          601723,
          2054,
          1512,
          42817,
          1420,
          16183,
          233060,
          2408,
          2317,
          6284,
          2078,
          165,
          1139,
          3202,
          168,
          1087,
          134056,
          21902,
          20478,
          817312,
          100,
          878,
          248858,
          177,
          291,
          241,
          1022298,
          1263321,
          1606,
          186140,
          6120,
          9815,
          1666,
          5211,
          3255,
          673342,
          69,
          4090,
          31394,
          2036,
          129,
          2208,
          2290,
          2906700,
          478,
          504,
          2208,
          5901,
          1412,
          1631,
          1606,
          20478,
          34496,
          93193,
          635,
          50489,
          54287,
          14783,
          255,
          741,
          13717,
          686,
          31394,
          276002,
          217,
          1190,
          23727,
          471,
          7268,
          551,
          3805,
          76,
          93193,
          258,
          149,
          4074,
          1423,
          467,
          92608,
          545147,
          14871,
          254282,
          192,
          1126,
          1324,
          140,
          230,
          3032,
          4056,
          1063,
          59744,
          169,
          1186,
          2518,
          1512,
          13422,
          158701,
          1442,
          2644,
          528,
          237282,
          5211,
          343,
          725,
          346,
          595,
          2526,
          1038,
          43,
          1925,
          4913,
          1089,
          276,
          1288,
          601723,
          50835,
          1490,
          2786,
          502,
          632,
          602,
          1807,
          28739,
          467,
          1523,
          628,
          413574,
          895,
          3402,
          910148,
          9051,
          316665,
          92608,
          1725,
          17047,
          104,
          43,
          3688,
          12486,
          106,
          1583,
          760,
          28278,
          71463,
          31394,
          217,
          5341,
          355,
          6951,
          320,
          248,
          378909,
          18760,
          4575,
          5341,
          190178,
          2501,
          1791,
          13973,
          1453,
          78968,
          54185,
          1078,
          54767,
          34882,
          307,
          1126,
          95015,
          70,
          241,
          519,
          5950,
          349,
          137,
          7268,
          647,
          3776,
          84106,
          95,
          471,
          470,
          1925,
          134056,
          214518,
          602,
          18760,
          1363,
          2870,
          151785,
          6841,
          355,
          467,
          798,
          2644,
          2395,
          12335,
          14742,
          626,
          12747,
          470,
          135332,
          149,
          964,
          2870,
          69,
          1472,
          2368,
          3684,
          1178,
          76,
          805,
          765,
          6713,
          21635,
          3066,
          1789,
          238602,
          1507,
          116155,
          4090,
          771,
          4074,
          3451,
          163415,
          5875,
          6703,
          276002,
          1312922,
          725,
          5875,
          53,
          207410,
          2870,
          725,
          1745,
          2856,
          1383,
          5848,
          1789,
          841711,
          2307,
          1131,
          42384,
          2368,
          413574,
          1131,
          177,
          105638,
          3263,
          4056,
          7646,
          207410,
          10717,
          241,
          795,
          307,
          493806,
          2408,
          308,
          1288,
          722,
          5161,
          3495,
          6581,
          276002,
          760,
          269,
          1532,
          5621,
          2906700,
          3487,
          378909,
          23727,
          467,
          1383,
          427,
          477,
          2607,
          6951,
          35371,
          1700,
          1725,
          3699,
          467,
          1970,
          206,
          271,
          718,
          6713,
          12335,
          910148,
          911,
          888,
          2872,
          263,
          23,
          478,
          502,
          2054,
          337,
          73,
          229,
          7297,
          248,
          378909,
          15426,
          2054,
          776,
          3688,
          15426,
          33804,
          1988,
          1970,
          222785,
          48194,
          478,
          427,
          186140,
          645,
          695,
          1770,
          23727,
          2368,
          184,
          397,
          21902,
          77,
          321,
          817312,
          5908,
          4575,
          321,
          899,
          3451,
          648,
          761,
          165556,
          166081,
          11250,
          50489,
          1766,
          23,
          1228,
          168,
          49,
          722,
          606,
          171170,
          5621,
          198,
          2906700,
          223,
          1923,
          276002,
          5341,
          673342,
          6120,
          346,
          964,
          320420,
          847,
          571,
          37,
          3776,
          5903,
          5621,
          213,
          1850,
          61,
          4653,
          95035,
          1186,
          206,
          337,
          78968,
          167,
          502,
          2872,
          21125,
          46563,
          341043,
          1420,
          673342,
          207,
          606,
          4081,
          595,
          4090,
          475,
          1762,
          1360,
          8333,
          824,
          276002,
          47,
          647,
          2376,
          20328,
          99,
          922,
          23805,
          51427,
          602,
          12335,
          1360,
          1841,
          673342,
          1909,
          4005,
          5648,
          2408,
          17047,
          1684,
          4533,
          94325,
          1271,
          2054,
          565,
          1426,
          5507,
          757530,
          4778,
          798,
          932,
          3279,
          6469,
          1666,
          46944,
          2307,
          782,
          276002,
          378909,
          5760,
          753116,
          1684,
          341043,
          1228,
          6713,
          9784,
          1645,
          7297,
          320,
          75903,
          1051,
          9594,
          1526206,
          2036,
          129,
          71335,
          753116,
          1382480,
          1360,
          1679,
          55345,
          229,
          1595797,
          277,
          1643,
          5548,
          71463,
          970,
          1126,
          888,
          198,
          75830,
          50489,
          123373,
          6951,
          18760,
          12349,
          9679,
          1461,
          6841,
          741,
          95,
          1423,
          59744,
          172817,
          1453,
          307,
          5161,
          4049,
          23,
          9772,
          5657,
          1186,
          2258,
          2135,
          2504700,
          48194,
          378909,
          413574,
          1530,
          2471,
          1312922,
          156391,
          28278,
          8512,
          110,
          409656,
          1051,
          3862,
          765,
          71335,
          733,
          51,
          19685,
          341,
          3766,
          4653,
          864,
          1166,
          35439,
          67082,
          2395,
          4090,
          17867,
          59744,
          372,
          1606,
          3263,
          4533,
          276896,
          76383,
          642,
          166081,
          5927,
          1312922,
          73,
          18182,
          1132,
          20328,
          4542,
          2368,
          754,
          2906700,
          19054,
          741,
          5666,
          1577385,
          545147,
          2258,
          19054,
          1102,
          71485,
          1241364,
          355,
          4677,
          32891,
          6025,
          630,
          20328,
          118,
          2328,
          3032,
          158701,
          20328,
          23045,
          7297,
          5548,
          1051,
          1666,
          4367,
          137067,
          47211,
          718,
          737,
          128,
          16183,
          1166,
          99,
          885,
          128715,
          46563,
          1178,
          478,
          606,
          1631,
          1758,
          178,
          2304,
          4172,
          158701,
          47249,
          91,
          213,
          4161,
          79613,
          269,
          686,
          25459,
          110,
          53,
          2408,
          1140,
          395,
          247,
          2836,
          76,
          4005,
          673342,
          118,
          4474,
          308,
          509,
          5577,
          16183,
          2906700,
          1126,
          9772,
          413574,
          633,
          272,
          798,
          4895,
          1766,
          11751,
          645,
          10717,
          2304,
          632,
          743,
          95,
          493806,
          3833,
          4913,
          165,
          50489,
          5211,
          3096,
          151785,
          1241364,
          475,
          2872,
          34882,
          18182,
          1847,
          687276,
          4664,
          804,
          46,
          349,
          3487,
          595,
          163415,
          6703,
          6581,
          1780,
          186140,
          9815,
          4542,
          2607,
          10717,
          129,
          2457,
          6581,
          4895,
          6713,
          344,
          75830,
          2208,
          149,
          6460,
          4895,
          307,
          687276,
          1532,
          1760,
          31394,
          1363,
          376,
          14783,
          1645,
          77,
          602,
          673342,
          71335,
          743,
          105549,
          639,
          1334,
          129,
          1507,
          186140,
          5457,
          1241364,
          1126,
          4726,
          3224,
          1304,
          178,
          2148,
          276002,
          378909,
          1577385,
          1939,
          1201,
          4056,
          4993,
          297,
          4664,
          4138,
          10295,
          85,
          828,
          11256,
          258,
          54287,
          34882,
          8830,
          191096,
          725,
          25459,
          158701,
          18408,
          38912,
          757530,
          5791,
          530,
          2078,
          104,
          509,
          520,
          18408,
          427,
          258,
          94325,
          391389,
          630,
          9165,
          4198,
          2368,
          267,
          427,
          123,
          13422,
          878,
          589,
          3066,
          1645,
          2456,
          165556,
          18182,
          1517,
          3684,
          11751,
          191096,
          186140,
          84106,
          932,
          2501,
          218,
          94325,
          516,
          19090,
          291,
          19090,
          46944,
          836,
          238602,
          718,
          1847,
          48194,
          1166,
          5901,
          551,
          13422,
          4664,
          46944,
          35439,
          376,
          276002,
          571,
          2691,
          24840,
          151785,
          4729,
          2870,
          20478,
          1383,
          413574,
          1533,
          118,
          1725,
          4474,
          61,
          1506,
          11253,
          4664,
          5760,
          7297,
          1190,
          2504700,
          23,
          1063,
          1089,
          4354,
          344,
          2661,
          566,
          1051,
          248,
          192,
          922,
          92608,
          27971,
          241,
          137,
          590,
          1443,
          2456,
          13835,
          378909,
          111,
          37,
          169,
          106,
          1684,
          3279,
          633,
          48194,
          2368,
          13061,
          5161,
          760,
          128715,
          1038,
          1970,
          530,
          1019,
          320420,
          2328,
          254282,
          67082,
          18182,
          194500,
          2135,
          20478,
          104,
          1312,
          1847,
          344,
          5760,
          602,
          653,
          3451,
          1700,
          24840,
          3224,
          165556,
          3032,
          2504700,
          144160,
          84106,
          1791,
          1196,
          895,
          324,
          647,
          92043,
          1261,
          15269,
          24840,
          1102,
          4508,
          248858,
          3699,
          910148,
          3495,
          6713,
          757530,
          74,
          5760,
          460,
          1661,
          4138,
          525713,
          269,
          4474,
          2501,
          1480,
          42817,
          545147,
          518429,
          1228,
          50489,
          19090,
          601723,
          92043,
          34153,
          381459,
          3343,
          673342,
          1690,
          6713,
          8097,
          743,
          3776,
          136,
          1909,
          1383,
          34496,
          722,
          3487,
          151022,
          28425,
          3263,
          6951,
          230,
          137,
          222,
          910148,
          5512,
          1631,
          1970,
          100,
          207,
          5760,
          302,
          76,
          4512,
          718,
          1595797,
          46563,
          581,
          969,
          1679,
          530,
          17867,
          365,
          1126,
          733,
          2395,
          6508,
          1831,
          229,
          79008,
          106,
          2661,
          3279,
          4542,
          2395,
          718,
          828,
          123373,
          92985,
          3495,
          564,
          6841,
          349,
          14742,
          1507,
          92608,
          1725,
          92294,
          1925,
          137067,
          771,
          3994,
          1631,
          1789,
          190249,
          1019,
          149,
          823,
          169,
          172817,
          2290,
          571,
          92294,
          2786,
          628,
          337,
          3119,
          50489,
          75830,
          10717,
          1022298,
          1453,
          5791,
          1810,
          16183,
          571,
          1019,
          630,
          269,
          341043,
          2158,
          3495,
          7268,
          1063,
          589,
          178,
          5577,
          502,
          139,
          224256,
          163415,
          1261,
          190,
          3430,
          4074,
          2644,
          973849,
          686,
          307,
          248858,
          6508,
          1725,
          1595797,
          16183,
          895,
          718,
          4056,
          641349,
          970,
          191096,
          2906700,
          276002,
          2078,
          5621,
          1850,
          270712,
          19090,
          136895,
          54287,
          1504,
          307,
          5621,
          1089,
          1804,
          134056,
          1583,
          1420,
          2290,
          94014,
          804,
          5950,
          31394,
          92043,
          233717,
          348,
          463,
          639,
          1606,
          302,
          18128,
          551,
          969,
          111,
          237282,
          238602,
          11751,
          55581,
          320,
          11432,
          1051,
          104,
          71485,
          9815,
          7268,
          1595797,
          1725,
          9496,
          1789,
          20328,
          2016,
          9496,
          1019,
          5161,
          2368,
          3996,
          77,
          1089,
          5621,
          3776,
          718,
          9594,
          1063,
          1178,
          149,
          4056,
          3032,
          299480,
          50489,
          346,
          630,
          1426,
          18182,
          653,
          895,
          3996,
          2263,
          899,
          338,
          178,
          22191,
          477,
          93193,
          3766,
          3343,
          1725,
          1312922,
          37,
          51,
          2317,
          54767,
          4471,
          3996,
          267,
          61,
          3255,
          69793,
          927396,
          601723,
          2526,
          568,
          241,
          192805,
          761,
          1512,
          642,
          6581,
          6006,
          626,
          885,
          798,
          454,
          1770,
          2526,
          4074,
          18182,
          8830,
          27020,
          3066,
          1523,
          271,
          771,
          922,
          1804,
          1087,
          206,
          632,
          9594,
          1523,
          5791,
          85,
          165556,
          61,
          832,
          2906700,
          269,
          509,
          470,
          71485,
          1577385,
          4542,
          2566,
          47772,
          11751,
          69793,
          6581,
          16183,
          5512,
          255,
          341,
          407,
          2401,
          632,
          191096,
          2523,
          3066,
          1563,
          1725,
          632,
          1075,
          53,
          43,
          71463,
          5875,
          11250,
          736284,
          9679,
          17867,
          964,
          5732,
          4074,
          276,
          22930,
          203571,
          836,
          6120,
          242,
          1970,
          111,
          328,
          7163,
          51427,
          632,
          79613,
          5791,
          1810,
          165,
          378909,
          376,
          9679,
          1679,
          520,
          277,
          270712,
          1241364,
          27971,
          217,
          3688,
          176,
          8333,
          4354,
          3343,
          134056,
          16183,
          276896,
          134056,
          743,
          217,
          25459,
          1533,
          1139,
          2661,
          1804,
          67082,
          116155,
          606,
          9993,
          1847,
          1507,
          153,
          207,
          11250,
          1656,
          2304,
          1263321,
          5438,
          186140,
          158701,
          123373,
          823,
          4653,
          1228,
          4575,
          3255,
          134056,
          1293,
          355,
          1766,
          899,
          341,
          471,
          67082,
          71485,
          911,
          519,
          9521,
          166081,
          2395,
          5577,
          107941,
          31970,
          166081,
          467,
          805,
          99,
          1760,
          645,
          166081,
          4290,
          9506,
          760,
          176,
          1850,
          2078,
          9594,
          16305,
          190178,
          5548,
          1186,
          1334,
          230,
          2504700,
          686,
          509,
          50489,
          36784,
          493806,
          6951,
          1512,
          1684,
          1382480,
          177,
          254282,
          19090,
          229,
          276002,
          1446,
          1252,
          1078,
          1725,
          128354,
          9051,
          230,
          230,
          4056,
          912,
          450,
          128,
          50489,
          5512,
          565,
          34153,
          3451,
          3862,
          9587,
          828,
          489,
          6018,
          346,
          606,
          6713,
          1909,
          4653,
          2870,
          6469,
          1312,
          1271,
          724,
          2258,
          198,
          116001,
          1131,
          2208,
          632,
          736284,
          743,
          2501,
          43,
          105638,
          17867,
          369,
          653,
          341043,
          77,
          18408,
          105638,
          1139,
          489,
          1132,
          165556,
          77,
          4573,
          92043,
          3688,
          15623,
          590,
          48194,
          5621,
          3730,
          1970,
          3776,
          2691,
          136,
          1078,
          5161,
          350,
          34153,
          1063,
          4895,
          3202,
          5161,
          4367,
          828,
          4573,
          4533,
          645,
          3202,
          46,
          5726,
          55581,
          128354,
          78968,
          470,
          9772,
          247,
          695,
          2258,
          1078,
          9034,
          10076,
          276,
          687276,
          5666,
          92043,
          207,
          50489,
          1383,
          47211,
          4512,
          614,
          3223,
          2408,
          1461,
          316665,
          13983,
          33917,
          2836,
          198,
          471,
          3279,
          970,
          59705,
          9815,
          493806,
          1312922,
          95,
          95035,
          123373,
          5161,
          7297,
          165556,
          2435,
          67082,
          3876,
          372,
          1675,
          976,
          519,
          2263,
          2457,
          2807,
          969,
          2328,
          5457,
          1841,
          241,
          341043,
          6469,
          2906700,
          3263,
          6120,
          673342,
          1504,
          1131,
          28739,
          1925,
          1749,
          1490,
          321,
          217,
          15426,
          69,
          3495,
          163415,
          42817,
          2526,
          99,
          324,
          105638,
          969,
          1595797,
          1666,
          5512,
          2607,
          85,
          69,
          533,
          1970,
          215,
          194500,
          4161,
          639,
          5621,
          5901,
          8874,
          92043,
          18128,
          1271,
          218,
          128,
          2906700,
          12747,
          19685,
          184,
          308,
          128715,
          217,
          1228,
          344,
          1745,
          2135,
          207410,
          1190,
          1930,
          1512,
          5621,
          248858,
          1617,
          372,
          365,
          450,
          241,
          70,
          399,
          110,
          647,
          73,
          2317,
          3085,
          1423,
          31515,
          71335,
          5875,
          7155,
          4005,
          680,
          3289,
          215,
          2148,
          1423,
          4573,
          7692,
          337,
          922,
          1324,
          413574,
          4354,
          824,
          1725,
          2223,
          172817,
          301,
          478,
          242,
          6460,
          479994,
          31515,
          2036,
          1334,
          722,
          409656,
          4154,
          9772,
          269,
          3104,
          20328,
          263,
          5666,
          5161,
          2304,
          1897,
          242,
          100,
          149,
          1143,
          19054,
          2526,
          1324,
          1228,
          3805,
          27971,
          6284,
          3224,
          6703,
          43,
          123,
          2607,
          4542,
          31394,
          782,
          1051,
          129,
          277,
          590,
          4542,
          502,
          22305,
          1126,
          42619,
          271,
          2872,
          571,
          4575,
          1426,
          8007,
          2501,
          964,
          1847,
          1645,
          2504700,
          299480,
          4198,
          895,
          61,
          743,
          478,
          2644,
          1858,
          74,
          328,
          276002,
          1312922,
          6025,
          1493,
          3289,
          135332,
          1288,
          238602,
          7297,
          5662,
          53,
          9521,
          595,
          1686,
          5621,
          765,
          532,
          254,
          5778,
          736284,
          35705,
          606,
          1334,
          71485,
          653,
          19408,
          7692,
          718,
          12335,
          1766,
          798,
          2290,
          73,
          5512,
          1645,
          172817,
          1810,
          564,
          5196,
          46,
          50835,
          260,
          248858,
          69,
          92294,
          1595797,
          270712,
          158701,
          1139,
          2263,
          31394,
          1577385,
          206,
          10717,
          14871,
          11256,
          6629,
          10076,
          1087,
          640470,
          3032,
          1022298,
          46,
          2368,
          94014,
          1523,
          34496,
          2368,
          571,
          642,
          71485,
          1412,
          493806,
          71485,
          1679,
          3032,
          5895,
          46944,
          4512,
          320,
          718,
          1195,
          5791,
          15647,
          184,
          1089,
          88735,
          1686,
          181438,
          1780,
          1606,
          686,
          1666,
          1507,
          15623,
          6018,
          267,
          2906700,
          832,
          239,
          1383,
          194500,
          5760,
          1970,
          1228,
          275,
          328,
          1490,
          302,
          1312922,
          54767,
          1897,
          771,
          9034,
          1526206,
          1858,
          6629,
          463,
          1201,
          1490,
          1312922,
          54185,
          9784,
          3996,
          3228,
          13061,
          1831,
          9521,
          158701,
          1923,
          43102,
          255,
          136,
          8007,
          601723,
          1263321,
          27971,
          337,
          5161,
          53,
          258,
          213,
          1446,
          42817,
          302,
          828,
          2317,
          648,
          42817,
          1970,
          805,
          551,
          42384,
          186140,
          2691,
          123373,
          26551,
          888,
          107941,
          1263321,
          9993,
          337,
          795,
          73,
          276002,
          2408,
          2368,
          1766,
          4677,
          153,
          75830,
          5848,
          4159,
          269,
          5548,
          5875,
          970,
          5908,
          7297,
          1178,
          551,
          1274,
          6629,
          178,
          186140,
          397,
          1334,
          248,
          13422,
          409656,
          1666,
          5507,
          172247,
          718,
          1382480,
          551,
          581,
          1804,
          320420,
          680,
          3104,
          4138,
          878,
          2060,
          328,
          207,
          74,
          77,
          6951,
          477,
          6508,
          13973,
          1196,
          19685,
          26551,
          1595797,
          324,
          1504,
          54287,
          54287,
          922,
          129,
          7420,
          14871,
          15426,
          7155,
          128,
          798,
          836,
          391389,
          687276,
          741,
          718,
          52,
          217,
          165556,
          1241364,
          91,
          841711,
          467,
          260,
          5719,
          1201,
          190,
          166081,
          140,
          20328,
          241,
          1565,
          1523,
          4845,
          381459,
          269,
          92608,
          3066,
          910148,
          526,
          3224,
          242,
          116155,
          722,
          470,
          3730,
          59744,
          110,
          1563,
          37,
          35439,
          128715,
          28739,
          2368,
          1442,
          27020,
          4508,
          6120,
          198,
          111,
          540,
          13422,
          695,
          178,
          22191,
          475,
          18408,
          34882,
          134056,
          241,
          2395,
          186140,
          10717,
          3730,
          2202,
          475,
          1791,
          1970,
          824,
          477,
          71463,
          3395,
          126,
          47772,
          1645,
          2303,
          50489,
          1897,
          391389,
          5161,
          190,
          601723,
          207410,
          595,
          365,
          928,
          145,
          248,
          1563,
          1140,
          972,
          172817,
          454,
          2223,
          206,
          19090,
          1679,
          128354,
          1760,
          341,
          526,
          100,
          1306,
          1063,
          836,
          224256,
          1571,
          376,
          13602,
          1504,
          12747,
          2526,
          308,
          18128,
          3279,
          3994,
          92337,
          218,
          1126,
          158701,
          899,
          530,
          224256,
          1645,
          42817,
          927396,
          1574,
          276002,
          9512,
          313,
          2526,
          1312922,
          21125,
          24536,
          139,
          502,
          92985,
          4913,
          969,
          8512,
          1762,
          1689,
          94014,
          4664,
          1140,
          75903,
          45303,
          206,
          2661,
          3066,
          242,
          3684,
          765,
          19685,
          4049,
          237282,
          520,
          1312,
          888,
          910148,
          1675,
          6841,
          782,
          14783,
          888,
          18128,
          20478,
          1420,
          86954,
          20478,
          74,
          378909,
          1442,
          48194,
          5848,
          5196,
          1595797,
          7646,
          23,
          8874,
          1312922,
          67082,
          71463,
          1022298,
          4081,
          3430,
          124967,
          2807,
          158701,
          606,
          2471,
          45303,
          46563,
          718,
          63,
          551,
          18128,
          737,
          139650,
          190249,
          606,
          969,
          206,
          11256,
          3833,
          10076,
          30770,
          321,
          1758,
          564,
          23805,
          1202,
          4913,
          1063,
          218,
          320420,
          31394,
          407,
          878,
          7268,
          741,
          54287,
          69,
          736284,
          346,
          5875,
          1228,
          241,
          5341,
          270712,
          4593,
          471,
          207,
          34153,
          2457,
          1679,
          3996,
          2471,
          647,
          177,
          3395,
          107941,
          178,
          10076,
          805,
          84106,
          4508,
          1504,
          4074,
          124967,
          116001,
          192,
          48194,
          528,
          365,
          1661,
          1166,
          186140,
          378909,
          1766,
          888,
          2526,
          1850,
          595,
          337,
          1302,
          31394,
          19685,
          276,
          36438,
          13973,
          7646,
          519,
          1360,
          241,
          3032,
          276002,
          78968,
          186140,
          427,
          776,
          328,
          2435,
          2607,
          7987,
          530,
          18182,
          172817,
          45303,
          1523,
          1689,
          3833,
          24840,
          31970,
          1241364,
          3876,
          99,
          158701,
          1810,
          20478,
          4090,
          3096,
          795,
          381459,
          1725,
          1735,
          3688,
          765,
          14871,
          663,
          695,
          502,
          269,
          35299,
          630,
          8333,
          4993,
          34496,
          1089,
          2317,
          1446,
          54287,
          1679,
          224256,
          270712,
          5950,
          5760,
          45303,
          248858,
          376,
          4056,
          5507,
          737,
          753116,
          5161,
          222785,
          5512,
          17867,
          42384,
          302,
          760,
          341043,
          782,
          7268,
          1302,
          687276,
          42384,
          23045,
          16183,
          76383,
          2054,
          1925,
          895,
          21134,
          378909,
          498,
          4993,
          1263321,
          16163,
          973849,
          4664,
          272,
          95035,
          4664,
          28739,
          4367,
          4138,
          33917,
          276896,
          10295,
          8874,
          13061,
          590,
          1102,
          15426,
          1363,
          459921,
          153,
          229,
          328,
          9587,
          324,
          4056,
          571,
          478,
          33917,
          11253,
          5989,
          1656,
          532,
          9679,
          937,
          2870,
          1758,
          55581,
          606,
          1453,
          493806,
          1312922,
          391389,
          128,
          341,
          899,
          581,
          2906700,
          581,
          1563,
          579,
          307,
          3833,
          3766,
          85,
          217,
          2661,
          178,
          753116,
          107941,
          1925,
          4575,
          107941,
          1312922,
          2856,
          733,
          54185,
          6434,
          910148,
          20328,
          899,
          258,
          589,
          76383,
          2526,
          1526206,
          3495,
          7163,
          4074,
          606,
          1988,
          75830,
          718,
          1831,
          1252,
          695,
          378909,
          343,
          2435,
          28739,
          427,
          2054,
          878,
          22930,
          10076,
          43,
          798,
          355,
          186140,
          1925,
          31515,
          568,
          743,
          21134,
          2135,
          2661,
          207410,
          687276,
          1577385,
          4049,
          27971,
          378909,
          7692,
          14871,
          759,
          348,
          106,
          71463,
          1423,
          9587,
          6581,
          1517,
          1679,
          129,
          5666,
          37,
          878,
          4653,
          6581,
          172817,
          140,
          1595797,
          76383,
          551,
          145,
          1252,
          198,
          7420,
          3085,
          427,
          372,
          3730,
          106,
          1897,
          391389,
          1675,
          50835,
          238602,
          308,
          1453,
          5211,
          606,
          687276,
          4878,
          140,
          863,
          1758,
          878,
          135332,
          2408,
          4895,
          302,
          937,
          16183,
          206,
          602,
          3032,
          464,
          1517,
          75903,
          1493,
          55581,
          922,
          493,
          1617,
          571,
          276002,
          804,
          151785,
          378909,
          207,
          19408,
          888,
          71485,
          571,
          1810,
          143,
          568,
          224256,
          84106,
          3224,
          3684,
          1412,
          254,
          6469,
          2368,
          260,
          276002,
          1970,
          760,
          532,
          54287,
          24536,
          1089,
          20478,
          2807,
          3395,
          2644,
          1643,
          2443,
          68211,
          2060,
          30770,
          343,
          4090,
          2501,
          1533,
          836,
          1909,
          895,
          55581,
          7692,
          1656,
          628,
          761,
          36438,
          31515,
          5354,
          7430,
          76,
          10295,
          8830,
          2523,
          248858,
          471,
          477,
          7155,
          14742,
          1679,
          1507,
          1725,
          4533,
          17867,
          1675,
          337,
          3279,
          94325,
          1131,
          50489,
          6120,
          2078,
          910148,
          2121,
          291,
          459921,
          149,
          7646,
          2661,
          13422,
          2376,
          355,
          1412,
          198,
          95,
          167,
          878,
          7987,
          8874,
          969,
          337,
          88735,
          645,
          753116,
          105549,
          1631,
          35299,
          331,
          338,
          1645,
          1453,
          885,
          207,
          18182,
          965,
          27971,
          5662,
          4508,
          158701,
          828,
          1858,
          1979,
          217,
          863,
          1631,
          1700,
          4074,
          4664,
          9772,
          6006,
          489,
          6581,
          4138,
          6018,
          1166,
          205,
          5778,
          116001,
          8874,
          1019,
          5895,
          771,
          9165,
          1131,
          2092,
          3402,
          2148,
          53,
          6713,
          51427,
          1334,
          409656,
          129,
          9034,
          804,
          267,
          276896,
          19090,
          757530,
          632,
          85,
          267,
          1102,
          564,
          19685,
          144160,
          7268,
          87124,
          504,
          186140,
          190,
          718,
          308,
          3402,
          107941,
          378909,
          9565,
          6025,
          19054,
          2121,
          2471,
          2307,
          12335,
          6120,
          1443,
          4573,
          320420,
          169,
          9772,
          520,
          467,
          1363,
          743,
          47249,
          84106,
          3255,
          632,
          545147,
          186140,
          135332,
          18128,
          17867,
          1126,
          3395,
          4074,
          7646,
          84106,
          1530,
          878,
          5666,
          759,
          1139,
          7420,
          140,
          1656,
          172817,
          1306,
          759,
          1196,
          687276,
          7987,
          15426,
          6713,
          9772,
          24840,
          1841,
          6841,
          258,
          1274,
          1442,
          5778,
          885,
          4653,
          606,
          128715,
          459921,
          24840,
          275,
          365,
          1645,
          263,
          5950,
          23,
          51,
          35371,
          5657,
          1631,
          836,
          14742,
          1139,
          1810,
          516,
          1770,
          1078,
          92043,
          912,
          1939,
          5908,
          25459,
          302,
          3104,
          71463,
          47249,
          4542,
          7163,
          6284,
          71335,
          43102,
          1847,
          513,
          530,
          105638,
          1577385,
          381459,
          5621,
          23,
          94325,
          276896,
          7155,
          5507,
          9051,
          885,
          5621,
          973849,
          107941,
          973849,
          1228,
          878,
          276002,
          597,
          222,
          910148,
          18128,
          3862,
          5457,
          2135,
          79613,
          54287,
          214703,
          467,
          4542,
          1766,
          1480,
          407,
          565,
          493806,
          2872,
          372,
          1770,
          9993,
          207,
          6629,
          477,
          3684,
          49,
          1195,
          190178,
          409656,
          3996,
          1201,
          222785,
          128715,
          1923,
          105549,
          34153,
          3224,
          630,
          528,
          74,
          84106,
          5457,
          1631,
          413574,
          1312,
          4993,
          9772,
          5989,
          50835,
          3395,
          3776,
          2786,
          1631,
          2395,
          151785,
          172817,
          1533,
          55345,
          3451,
          5341,
          33917,
          237282,
          795,
          9772,
          2290,
          19054,
          76383,
          1252,
          198,
          5927,
          2307,
          3430,
          467,
          27829,
          910148,
          18408,
          520,
          83,
          5791,
          20478,
          4049,
          45303,
          6951,
          478,
          337,
          782,
          413574,
          68211,
          3066,
          1363,
          6581,
          471,
          733,
          3458,
          471,
          35439,
          519,
          207,
          3684,
          365,
          343,
          1443,
          687276,
          530,
          104396,
          1261,
          241,
          3066,
          895,
          128715,
          22305,
          4542,
          128715,
          1533,
          5719,
          493806,
          9034,
          1423,
          128715,
          95035,
          267,
          6460,
          2518,
          7297,
          6841,
          45303,
          823,
          48194,
          1078,
          798,
          4778,
          2274,
          1847,
          2872,
          112,
          1943,
          1675,
          34153,
          139,
          3343,
          633,
          804,
          346,
          23,
          3289,
          376,
          540,
          13835,
          1139,
          4542,
          1595797,
          6713,
          4664,
          4895,
          19090,
          1293,
          321,
          237282,
          43,
          3699,
          34882,
          76383,
          1312,
          1810,
          2290,
          1946,
          530,
          1760,
          911,
          1909,
          14228,
          4172,
          4729,
          258,
          4367,
          9506,
          653,
          20478,
          1892,
          17867,
          741,
          18182,
          526,
          1019,
          1628,
          92294,
          104396,
          528,
          471,
          84106,
          1271,
          42817,
          378909,
          3032,
          463,
          1847,
          144160,
          493806,
          25459,
          1766,
          2317,
          166081,
          6508,
          136895,
          8874,
          5438,
          1675,
          50835,
          1383,
          247,
          1423,
          1789,
          241,
          218,
          466,
          71463,
          395,
          2504700,
          922,
          18408,
          6841,
          272,
          92106,
          3096,
          564,
          276896,
          2036,
          4154,
          276002,
          5895,
          1523,
          16305,
          2135,
          9993,
          129,
          832,
          31394,
          2158,
          1334,
          18128,
          811,
          2872,
          409656,
          213,
          71485,
          759,
          663,
          23045,
          46,
          1126,
          545147,
          42817,
          545147,
          194500,
          4056,
          207,
          241,
          1120,
          128715,
          2304,
          1087,
          6951,
          269,
          18760,
          105549,
          277,
          765,
          9587,
          302,
          276,
          2471,
          976,
          77,
          695,
          4726,
          3766,
          84106,
          1923,
          47,
          76383,
          4664,
          467,
          32891,
          21902,
          151785,
          76383,
          10076,
          238602,
          27971,
          2307,
          1126,
          932,
          105549,
          168,
          6284,
          4542,
          100,
          1970,
          7430,
          355,
          1684,
          642,
          104,
          3096,
          214518,
          71463,
          94014,
          1970,
          55345,
          5507,
          34882,
          5875,
          3224,
          4508,
          254282,
          70,
          663,
          568,
          13717,
          680,
          466,
          1480,
          230,
          2836,
          6120,
          533,
          15426,
          1666,
          55345,
          2376,
          4913,
          5507,
          381459,
          144160,
          106,
          2836,
          50835,
          626,
          378909,
          1892,
          13422,
          1201,
          2607,
          258,
          911,
          123,
          397,
          724,
          5760,
          111,
          19685,
          6508,
          35371,
          5903,
          1760,
          3202,
          2691,
          1675,
          372,
          551,
          1595797,
          1190,
          144160,
          3495,
          263,
          129,
          965,
          1686,
          5196,
          647,
          3104,
          346,
          4354,
          4589,
          1970,
          18760,
          270712,
          595,
          136,
          1939,
          190178,
          1909,
          509,
          782,
          5989,
          139650,
          718,
          525713,
          571,
          1979,
          1847,
          258,
          79613,
          1241364,
          413574,
          1382480,
          1841,
          1770,
          239,
          20478,
          530,
          3279,
          571,
          1426,
          3032,
          673342,
          365,
          4512,
          1241364,
          1051,
          1925,
          21902,
          2971,
          248,
          177,
          28739,
          31394,
          1302,
          2518,
          5895,
          754,
          973849,
          673342,
          222785,
          186140,
          34882,
          928,
          18128,
          12335,
          270712,
          2408,
          136,
          798,
          239,
          5760,
          2395,
          4015,
          2092,
          2060,
          301,
          1523,
          564,
          5619,
          6469,
          1352,
          798,
          519,
          34496,
          350,
          565,
          5161,
          260,
          4726,
          7297,
          6018,
          568,
          525713,
          71485,
          270712,
          92985,
          2060,
          932,
          165556,
          34496,
          1051,
          32891,
          3996,
          743,
          85,
          269,
          45100,
          276,
          144160,
          2518,
          5341,
          9815,
          75830,
          341043,
          31515,
          530,
          645,
          128715,
          680,
          35299,
          823,
          5726,
          85,
          1923,
          1382480,
          743,
          241,
          217,
          805,
          718,
          811,
          828,
          1923,
          1897,
          2383912,
          912,
          642,
          832,
          372,
          35439,
          7420,
          238602,
          51,
          9772,
          878,
          94014,
          298,
          30770,
          1939,
          4508,
          413574,
          631,
          1493,
          540,
          139,
          263,
          1666,
          760,
          2526,
          73,
          718,
          2456,
          5621,
          9772,
          192,
          190178,
          9815,
          1760,
          73,
          3119,
          22305,
          520,
          1178,
          5507,
          5621,
          551,
          2304,
          2518,
          1858,
          46,
          645,
          313,
          2526,
          477,
          68211,
          217,
          1791,
          1087,
          198,
          3451,
          128,
          5196,
          136,
          95035,
          1089,
          3224,
          275,
          645,
          381459,
          1201,
          6469,
          24645,
          463,
          888,
          11256,
          463,
          1847,
          3451,
          1645,
          167,
          470,
          25459,
          346,
          1213,
          2856,
          9512,
          525713,
          5548,
          765,
          341,
          24840,
          2872,
          509,
          23,
          21125,
          2872,
          217,
          355,
          20478,
          1075,
          43,
          6951,
          1252,
          601723,
          1595797,
          46944,
          372,
          71463,
          5908,
          4424,
          198,
          1745,
          33917,
          158701,
          276002,
          247,
          21902,
          11256,
          2691,
          1443,
          973849,
          1654,
          4878,
          1382480,
          263,
          606,
          1446,
          5354,
          9815,
          1490,
          413574,
          144160,
          5438,
          2836,
          1766,
          888,
          1810,
          92608,
          1909,
          1923,
          5548,
          23,
          568,
          229,
          4542,
          467,
          1654,
          24840,
          1675,
          1606,
          237282,
          5507,
          50489,
          5216,
          1526206,
          116155,
          471,
          1847,
          606,
          172247,
          6951,
          129,
          5341,
          1178,
          743,
          1126,
          68211,
          4154,
          267,
          798,
          99,
          5927,
          6469,
          498,
          19685,
          4542,
          190249,
          516,
          653,
          579,
          633,
          4778,
          1312,
          10717,
          1063,
          172817,
          1946,
          24536,
          2290,
          276002,
          2368,
          91,
          597,
          21134,
          1324,
          123373,
          134056,
          4573,
          258,
          3996,
          1574,
          1195,
          3224,
          198,
          71335,
          2401,
          107941,
          606,
          172817,
          7268,
          50489,
          4895,
          804,
          3223,
          23,
          99,
          1526206,
          4081,
          1766,
          1810,
          13717,
          61,
          1363,
          4533,
          753116,
          1139,
          516,
          2328,
          67082,
          207,
          1324,
          38912,
          95,
          7155,
          7987,
          54287,
          1178,
          4367,
          804,
          3402,
          67082,
          680,
          3876,
          21902,
          343,
          186140,
          2836,
          71463,
          648,
          376,
          1760,
          1530,
          277,
          34153,
          111,
          321490,
          272,
          99,
          7163,
          84106,
          27971,
          343,
          105549,
          43,
          509,
          1201,
          590,
          100,
          13717,
          4593,
          545147,
          895,
          602,
          3279,
          6951,
          42817,
          2971,
          1126,
          601723,
          1274,
          3833,
          63,
          1022298,
          3730,
          2206,
          190,
          9815,
          1195,
          1196,
          186140,
          782,
          372,
          1131,
          337,
          614,
          828,
          47772,
          52126,
          133,
          198,
          2526,
          1574,
          302,
          10076,
          19090,
          333497,
          4653,
          84106,
          2408,
          972,
          1523,
          13983,
          7646,
          137,
          749635,
          3807,
          13973,
          584,
          302,
          2135,
          1446,
          85,
          888,
          5778,
          608,
          50835,
          1909,
          498,
          1165,
          1446,
          647,
          9587,
          378909,
          1412,
          4512,
          4154,
          258,
          782,
          1966,
          6951,
          1363,
          5875,
          5619,
          242,
          35439,
          3807,
          51427,
          99,
          601723,
          237282,
          11751,
          832,
          5791,
          7155,
          1228,
          1565,
          2644,
          5875,
          12335,
          79613,
          337,
          6469,
          308,
          1426,
          6469,
          9772,
          206,
          241,
          606,
          94014,
          34496,
          1446,
          217,
          4720,
          27020,
          30770,
          686,
          722,
          413574,
          106,
          10076,
          8830,
          95035,
          198,
          222,
          633,
          1252,
          489,
          686,
          33917,
          1442,
          1038,
          10295,
          46563,
          21902,
          564,
          969,
          516,
          21902,
          118,
          172817,
          513,
          16183,
          165556,
          286,
          2457,
          2328,
          1595797,
          13983,
          2097,
          1446,
          277,
          1810,
          467,
          680,
          1925,
          4154,
          753116,
          910148,
          1263321,
          749635,
          106,
          355,
          1689,
          1078,
          1530,
          1426,
          6025,
          1523,
          34882,
          37,
          8007,
          1689,
          136,
          910148,
          79008,
          95015,
          1656,
          99,
          1179,
          5875,
          923,
          584,
          545147,
          3766,
          2471,
          328,
          50835,
          16305,
          899,
          271,
          46,
          3279,
          4056,
          602,
          50835,
          1446,
          391389,
          1661,
          70,
          718,
          832,
          77,
          123,
          2121,
          92608,
          2691,
          1631,
          51427,
          118,
          2906700,
          12349,
          237282,
          15647,
          2303,
          565,
          409656,
          19685,
          1288,
          337,
          59705,
          888,
          1656,
          22191,
          3104,
          1334,
          1762,
          242,
          1302,
          10717,
          3224,
          313,
          3395,
          2518,
          1228,
          564,
          376,
          19054,
          2135,
          741,
          498,
          2211,
          286,
          254282,
          914,
          545147,
          1595797,
          6284,
          741,
          5760,
          48194,
          601723,
          3487,
          1100,
          470,
          467,
          17867,
          67082,
          79008,
          54287,
          4573,
          1563,
          3776,
          215,
          2135,
          5895,
          10076,
          2304,
          77,
          350,
          71335,
          595,
          6841,
          1102,
          2786,
          639,
          1645,
          1363,
          1087,
          1446,
          28739,
          463,
          26551,
          23,
          836,
          1666,
          1507,
          376,
          313,
          276002,
          1274,
          1102,
          46,
          911,
          1382480,
          760,
          2807,
          128354,
          71463,
          805,
          9679,
          238602,
          136,
          3279,
          11751,
          198,
          6018,
          37,
          6469,
          964,
          9784,
          3224,
          540,
          722,
          2401,
          5621,
          1304,
          2661,
          11256,
          248858,
          795,
          134056,
          2457,
          1686,
          33917,
          1925,
          69793,
          1749,
          2526,
          163415,
          910148,
          2456,
          123,
          50835,
          4726,
          4542,
          532,
          895,
          123373,
          176,
          139,
          545147,
          626,
          6120,
          1689,
          1563,
          1131,
          1075,
          92043,
          178,
          4533,
          15647,
          163415,
          1766,
          5901,
          910148,
          71335,
          258,
          4726,
          4993,
          128,
          341043,
          165556,
          391389,
          46563,
          1850,
          804,
          153,
          237282,
          381459,
          4056,
          307,
          136,
          241,
          493806,
          725,
          13717,
          31515,
          1446,
          782,
          14742,
          409656,
          568,
          2223,
          34882,
          321490,
          2258,
          2456,
          493806,
          836,
          530,
          3487,
          489,
          338,
          328,
          20478,
          149,
          19685,
          241,
          5989,
          1631,
          454,
          6841,
          229,
          3255,
          20478,
          85,
          5895,
          2135,
          84106,
          4074,
          297,
          198,
          2786,
          1383,
          158701,
          2317,
          79613,
          2263,
          206,
          63,
          4573,
          5760,
          136,
          168,
          136,
          6284,
          3202,
          509,
          71463,
          237282,
          271,
          4354,
          20328,
          75903,
          276002,
          832,
          5354,
          498,
          321490,
          186140,
          1368,
          4081,
          1847,
          9679,
          328,
          190249,
          1847,
          2872,
          475,
          413574,
          504,
          67082,
          140,
          230,
          718,
          817312,
          3776,
          1858,
          169,
          795,
          2906700,
          7155,
          1274,
          581,
          2036,
          2317,
          276896,
          1523,
          3395,
          771,
          9594,
          647,
          1847,
          71335,
          899,
          533,
          30770,
          320,
          92043,
          14871,
          4677,
          16305,
          626,
          686,
          911,
          16183,
          823,
          110,
          137,
          95035,
          328,
          344,
          532,
          247,
          513,
          186140,
          18128,
          13835,
          10717,
          255,
          765,
          165556,
          5512,
          19054,
          230,
          2368,
          2263,
          36438,
          2916,
          24536,
          1423,
          2328,
          1789,
          5507,
          8512,
          1897,
          190,
          1504,
          2258,
          91,
          276002,
          107941,
          1563,
          1131,
          5341,
          653,
          1766,
          59744,
          525713,
          1656,
          11432,
          38912,
          2518,
          269,
          9679,
          50489,
          3996,
          805,
          8874,
          31515,
          71463,
          4542,
          1504,
          828,
          276,
          2328,
          1263321,
          419,
          5791,
          391389,
          795,
          136,
          1780,
          19408,
          760,
          1690,
          85,
          7297,
          191096,
          149,
          395,
          878,
          4074,
          84106,
          1360,
          1324,
          504,
          5875,
          1892,
          8512,
          28278,
          1202,
          841711,
          687276,
          254,
          4172,
          4161,
          1841,
          4015,
          798,
          275,
          795,
          144160,
          1201,
          502,
          1749,
          1087,
          2644,
          1274,
          970,
          207,
          7987,
          1190,
          3495,
          10076,
          795,
          564,
          11256,
          190,
          333497,
          9587,
          3684,
          1383,
          718,
          5666,
          1186,
          2691,
          46,
          99,
          71485,
          2379,
          795,
          718,
          1988,
          972,
          3688,
          736284,
          381459,
          5512,
          841711,
          123373,
          2148,
          1478,
          2148,
          3699,
          258,
          149,
          355,
          4354,
          4508,
          378909,
          2258,
          2092,
          4913,
          275,
          1131,
          1966,
          564,
          3279,
          270712,
          823,
          4664,
          77,
          888,
          460,
          18408,
          8874,
          4913,
          43,
          267,
          14783,
          3202,
          5196,
          26551,
          6460,
          3876,
          9521,
          1274,
          427,
          1426,
          1970,
          5161,
          647,
          134056,
          84106,
          2121,
          71335,
          13973,
          5895,
          2807,
          502,
          341043,
          2501,
          1617,
          4512,
          5216,
          302,
          75830,
          1577385,
          229,
          258,
          186140,
          7297,
          3994,
          1850,
          1858,
          1089,
          525713,
          1791,
          258,
          307,
          1700,
          5621,
          23727,
          917,
          6469,
          471,
          602,
          328,
          85,
          1382480,
          2408,
          863,
          163415,
          134056,
          2401,
          13835,
          217,
          3684,
          5726,
          3495,
          19408,
          2148,
          2856,
          1532,
          2435,
          1126,
          94325,
          344,
          647,
          7646,
          4680,
          1595797,
          376,
          129,
          61,
          18182,
          308,
          78968,
          15426,
          7565,
          1078,
          5666,
          824,
          194500,
          2644,
          861,
          111,
          18182,
          2971,
          105638,
          6581,
          885,
          267,
          71485,
          13602,
          184,
          885,
          2148,
          269,
          190178,
          459921,
          46944,
          21134,
          20478,
          4471,
          31394,
          3996,
          606,
          316665,
          7155,
          3805,
          1666,
          811,
          16183,
          888,
          104,
          1766,
          1563,
          1423,
          324,
          107941,
          20328,
          4542,
          346,
          12335,
          1897,
          3119,
          224256,
          134056,
          566,
          22305,
          910148,
          22305,
          718,
          3994,
          276896,
          321,
          2526,
          1312922,
          1526206,
          331,
          571,
          172817,
          722,
          124967,
          31515,
          9772,
          743,
          134056,
          922,
          1577385,
          116001,
          602,
          84106,
          1126,
          737,
          191096,
          241,
          341043,
          718,
          5901,
          61,
          2258,
          1923,
          258,
          1089,
          2856,
          5927,
          1087,
          1745,
          21902,
          1892,
          606,
          836,
          118,
          471,
          59705,
          1675,
          139,
          31515,
          964,
          217,
          1383,
          1847,
          571,
          753116,
          302,
          84106,
          1089,
          276896,
          12335,
          4895,
          47772,
          516,
          413574,
          470,
          571,
          166081,
          9034,
          124967,
          3833,
          378909,
          192,
          5507,
          641,
          1478,
          1228,
          5648,
          1383,
          20478,
          43,
          509,
          105549,
          346,
          11256,
          3684,
          372,
          498,
          1595797,
          217,
          5619,
          2135,
          885,
          1507,
          1089,
          20478,
          118,
          3451,
          2518,
          1293,
          376,
          478,
          1988,
          1075,
          2870,
          1631,
          24840,
          96942,
          17867,
          2916,
          1595797,
          5196,
          14742,
          172817,
          24645,
          391389,
          10717,
          3807,
          3202,
          3862,
          372,
          118,
          1758,
          630,
          217,
          1312,
          88735,
          1946,
          1749,
          1760,
          2870,
          14742,
          718,
          2376,
          1490,
          2368,
          6951,
          85,
          454,
          642,
          532,
          341,
          198,
          135332,
          1645,
          19685,
          5657,
          475,
          341043,
          61,
          27971,
          2307,
          47772,
          409656,
          18182,
          218,
          14871,
          88735,
          1532,
          1850,
          493806,
          35371,
          4533,
          136,
          718,
          4474,
          165,
          9034,
          1789,
          276,
          6006,
          7297,
          1791,
          1190,
          6951,
          1574,
          743,
          5512,
          5216,
          3279,
          2526,
          238602,
          1841,
          673342,
          77,
          3202,
          45303,
          2526,
          2036,
          910148,
          6120,
          2376,
          502,
          911,
          836,
          399,
          99,
          1312922,
          540,
          15269,
          3684,
          378909,
          970,
          122111,
          18408,
          9993,
          632,
          153,
          911,
          741,
          1766,
          144160,
          54287,
          776,
          2206,
          2456,
          1686,
          238602,
          1577385,
          59705,
          427,
          128354,
          776,
          571,
          13717,
          2258,
          1745,
          741,
          471,
          137067,
          3684,
          43102,
          2518,
          31394,
          864,
          15426,
          10717,
          568,
          1228,
          502,
          38912,
          46,
          4542,
          5512,
          4575,
          165556,
          263,
          3224,
          4367,
          26120,
          3279,
          242,
          217,
          1523,
          4726,
          493806,
          5732,
          5875,
          276896,
          269,
          3495,
          224256,
          3343,
          964,
          626,
          737,
          25459,
          4474,
          1760,
          118,
          269,
          184,
          910148,
          2408,
          832,
          8097,
          832,
          270712,
          69,
          84106,
          673342,
          973849,
          134056,
          3451,
          54185,
          1312922,
          5621,
          276,
          2078,
          124967,
          2258,
          407,
          31515,
          4575,
          46563,
          140,
          5657,
          1831,
          493806,
          28425,
          725,
          1686,
          1368,
          61,
          63,
          1241364,
          139,
          192,
          14228,
          530,
          927396,
          145,
          5438,
          606,
          1261,
          1089,
          1923,
          11256,
          378909,
          365,
          1334,
          1577385,
          12335,
          18459,
          1126,
          76,
          23045,
          263,
          1766,
          5161,
          3805,
          4090,
          2872,
          888,
          928,
          214703,
          1988,
          73,
          139,
          378909,
          48194,
          67082,
          2036,
          1140,
          123373,
          69,
          477,
          1760,
          4512,
          817312,
          313,
          3807,
          13835,
          4074,
          2376,
          10717,
          20328,
          5161,
          4172,
          395,
          74,
          277,
          733,
          1261,
          9594,
          6581,
          140,
          6018,
          1360,
          13061,
          229,
          3279,
          824,
          5927,
          79008,
          5161,
          12486,
          828,
          2121,
          2872,
          16183,
          4056,
          478,
          540,
          238602,
          337,
          276002,
          272,
          736284,
          545147,
          1617,
          105549,
          1595797,
          324,
          695,
          43102,
          5875,
          7646,
          13835,
          95035,
          832,
          1645,
          10076,
          471,
          2304,
          1302,
          1532,
          571,
          4575,
          4056,
          1263321,
          20328,
          1263321,
          1414,
          2148,
          2135,
          140,
          9496,
          736284,
          964,
          409656,
          581,
          2471,
          1078,
          122111,
          743,
          782,
          2383912,
          18408,
          928,
          376,
          13061,
          1446,
          1970,
          1443,
          1442,
          1312922,
          1666,
          1478,
          3766,
          1312,
          7987,
          6120,
          4471,
          969,
          95,
          1645,
          2457,
          140,
          2395,
          42384,
          1443,
          6951,
          302,
          1841,
          1563,
          2408,
          642,
          269,
          2607,
          84106,
          2870,
          105549,
          355,
          630,
          1261,
          76,
          2607,
          4664,
          4198,
          5726,
          1789,
          186140,
          75830,
          2368,
          2054,
          2054,
          932,
          213,
          23,
          718,
          78968,
          2304,
          6120,
          1426,
          3224,
          1078,
          5895,
          20478,
          15269,
          17047,
          9815,
          149,
          19408,
          63,
          331,
          663,
          1363,
          2258,
          105638,
          1426,
          198,
          46,
          1241364,
          176,
          1312922,
          178,
          493,
          20328,
          5903,
          1766,
          149,
          94014,
          48194,
          13422,
          79613,
          4533,
          217,
          63,
          365,
          207410,
          1461,
          22305,
          1841,
          518429,
          2607,
          2807,
          530,
          1453,
          53,
          4845,
          413574,
          1684,
          687276,
          3289,
          372,
          1102,
          190,
          565,
          192,
          9993,
          6713,
          128,
          409656,
          302,
          601723,
          413574,
          1423,
          1675,
          230,
          7565,
          1414,
          1453,
          5760,
          1312922,
          532,
          9506,
          3279,
          9815,
          2691,
          129,
          513,
          254,
          1195,
          92106,
          17867,
          409656,
          71463,
          1196,
          217,
          5726,
          71485,
          3996,
          1791,
          69,
          3202,
          1201,
          17047,
          128715,
          4729,
          744,
          2471,
          2078,
          134056,
          817312,
          23727,
          337,
          1201,
          798,
          1228,
          12349,
          6006,
          343,
          376,
          165556,
          31394,
          10076,
          1970,
          6508,
          31394,
          9587,
          198,
          2607,
          717255,
          167,
          67082,
          2307,
          641,
          14871,
          427,
          504,
          99,
          207,
          291,
          1606,
          10256,
          4138,
          642,
          95035,
          27971,
          85,
          1689,
          46,
          601723,
          21902,
          28278,
          639,
          606,
          725,
          606,
          13422,
          337,
          9815,
          206,
          224256,
          5161,
          53,
          2443,
          1680,
          308,
          350,
          1858,
          2383912,
          3688,
          2691,
          172817,
          7163,
          26551,
          14871,
          20328,
          2368,
          841711,
          1352,
          1700,
          1140,
          128354,
          24536,
          6434,
          223,
          337,
          628,
          88735,
          2304,
          46,
          4542,
          910148,
          4542,
          6025,
          107941,
          11250,
          2408,
          270712,
          52,
          4575,
          606,
          5548,
          11250,
          190178,
          237282,
          137067,
          18408,
          828,
          4542,
          190178,
          718,
          1725,
          2036,
          166081,
          341043,
          1490,
          341,
          2870,
          3994,
          1196,
          1102,
          3395,
          36784,
          46,
          239,
          5875,
          2036,
          1363,
          123,
          1140,
          70,
          11256,
          258,
          344,
          9815,
          111,
          239,
          2304,
          1689,
          21125,
          6508,
          3119,
          2443,
          765,
          6018,
          217,
          4074,
          976,
          15647,
          206,
          2435,
          1530,
          46944,
          116001,
          105638,
          116001,
          5161,
          1617,
          128,
          71335,
          276002,
          2456,
          186140,
          1312922,
          407,
          77,
          4056,
          606,
          1139,
          129,
          33804,
          1970,
          725,
          782,
          5662,
          168,
          1563,
          2263,
          16183,
          498,
          1675,
          6508,
          1143,
          1841,
          673342,
          4729,
          5512,
          43102,
          673342,
          895,
          105549,
          932,
          1930,
          1312922,
          1595797,
          1565,
          3343,
          2395,
          478,
          46,
          192,
          23,
          2395,
          413574,
          307,
          5211,
          760,
          565,
          18182,
          166081,
          54287,
          3495,
          2456,
          1789,
          1139,
          1595797,
          663,
          27971,
          53,
          520,
          2376,
          19054,
          516,
          19685,
          258,
          1679,
          1760,
          1847,
          313,
          24536,
          9512,
          33917,
          832,
          630,
          18128,
          673342,
          19054,
          407,
          899,
          6469,
          47772,
          1645,
          31515,
          12335,
          176,
          932,
          3776,
          4056,
          42817,
          2206,
          2856,
          248858,
          1078,
          79008,
          1312,
          14871,
          595,
          71485,
          1804,
          540,
          2526,
          84106,
          3289,
          45100,
          1201,
          22305,
          463,
          927396,
          51427,
          1165,
          142,
          3688,
          46563,
          272,
          1412,
          16183,
          324,
          639,
          16183,
          2526,
          302,
          5548,
          18128,
          4074,
          6284,
          1563,
          223,
          47,
          6469,
          320420,
          1423,
          34496,
          75830,
          2304,
          321,
          4542,
          551,
          885,
          75830,
          378909,
          77,
          27020,
          28278,
          864,
          297,
          2304,
          129,
          269,
          343,
          606,
          571,
          7163,
          34882,
          372,
          34496,
          19408,
          888,
          1324,
          519,
          5760,
          5211,
          7692,
          1302,
          7646,
          93193,
          1051,
          970,
          14871,
          1666,
          1675,
          153,
          545147,
          1925,
          9815,
          725,
          302,
          341043,
          134056,
          74,
          2526,
          111,
          626,
          110,
          642,
          530,
          1536,
          1943,
          1595797,
          513,
          21902,
          861,
          186140,
          454,
          51,
          836,
          3343,
          493806,
          2368,
          18760,
          4845,
          324,
          478,
          18182,
          1686,
          725,
          5196,
          964,
          1680,
          389246,
          35371,
          328,
          59744,
          885,
          6841,
          2457,
          1075,
          1523,
          710,
          71463,
          4575,
          1382480,
          222785,
          14871,
          16183,
          302,
          9521,
          1504,
          140,
          1140,
          99,
          27020,
          3996,
          736284,
          513,
          5621,
          1442,
          10717,
          2258,
          19054,
          1363,
          885,
          635,
          52,
          824,
          6469,
          321,
          687276,
          1271,
          1532,
          123373,
          5196,
          107941,
          1179,
          74,
          238602,
          33804,
          242,
          237282,
          1186,
          1241364,
          1186,
          545147,
          3085,
          922,
          9815,
          137,
          824,
          238602,
          19090,
          5341,
          1196,
          1574,
          31394,
          888,
          969,
          2368,
          545147,
          19090,
          24536,
          804,
          181438,
          1139,
          5196,
          7155,
          2054,
          207,
          302,
          1312922,
          34882,
          1766,
          7155,
          27020,
          878,
          606,
          47249,
          42384,
          85,
          331,
          139,
          409656,
          836,
          663,
          1490,
          1196,
          545147,
          1139,
          498,
          836,
          2304,
          133,
          3096,
          686,
          42619,
          5657,
          1643,
          5621,
          1087,
          1504,
          7646,
          214703,
          77,
          5657,
          878,
          4993,
          1847,
          2376,
          19685,
          914,
          111,
          70,
          258,
          2906700,
          765,
          272,
          313,
          836,
          46,
          136,
          320,
          76,
          11253,
          13983,
          343,
          1478,
          134056,
          910148,
          19685,
          606,
          4090,
          5161,
          761,
          1925,
          176,
          12747,
          895,
          92106,
          7155,
          973849,
          248,
          136,
          4090,
          3684,
          927396,
          1132,
          6469,
          1472,
          2872,
          1051,
          271,
          878,
          1577385,
          4542,
          247,
          6025,
          1312922,
          31515,
          99,
          1807,
          568,
          828,
          1847,
          1512,
          832,
          5662,
          47249,
          140,
          389246,
          198,
          35299,
          647,
          276896,
          1897,
          35299,
          606,
          3996,
          124967,
          581,
          75830,
          198,
          1760,
          129,
          1595797,
          5791,
          888,
          1051,
          6951,
          1858,
          9506,
          1643,
          1791,
          3119,
          528,
          32891,
          1063,
          55581,
          71463,
          680,
          92043,
          2054,
          269,
          263,
          969,
          5341,
          45100,
          687276,
          1288,
          13422,
          207,
          427,
          9034,
          2121,
          99,
          1656,
          11432,
          673342,
          1507,
          76,
          1506,
          7646,
          4895,
          15269,
          5895,
          276002,
          17047,
          969,
          190178,
          470,
          224256,
          313,
          67082,
          35439,
          276,
          545147,
          724,
          67082,
          910148,
          1324,
          759,
          581,
          628,
          1897,
          149,
          467,
          4367,
          52,
          471,
          645,
          32891,
          606,
          493,
          5760,
          5778,
          467,
          2644,
          124967,
          1165,
          376,
          1507,
          467,
          163415,
          1807,
          9496,
          77,
          35439,
          8874,
          2135,
          9772,
          2092,
          1324,
          5341,
          863,
          50489,
          13717,
          19054,
          355,
          28739,
          1324,
          139,
          8333,
          5901,
          3224,
          2142,
          2870,
          885,
          123373,
          828,
          413574,
          5512,
          1735,
          895,
          10076,
          9051,
          333497,
          17867,
          673342,
          5621,
          391389,
          86954,
          6460,
          1571,
          509,
          759,
          1858,
          140,
          2142,
          3395,
          331,
          1412,
          631,
          1252,
          760,
          238602,
          2135,
          11250,
          6469,
          477,
          1684,
          911,
          48194,
          343,
          184,
          14228,
          4049,
          722,
          695,
          5778,
          45303,
          129,
          103927,
          3833,
          49,
          111,
          254,
          1131,
          165,
          533,
          190178,
          95,
          828,
          2906700,
          6120,
          1946,
          151785,
          2607,
          1078,
          1675,
          910148,
          653,
          647,
          1847,
          725,
          737,
          459921,
          85,
          509,
          1312922,
          2121,
          2211,
          111,
          9772,
          344,
          878,
          5662,
          5196,
          10717,
          5726,
          1530,
          151022,
          771,
          54287,
          207,
          1089,
          4575,
          13973,
          5791,
          2036,
          832,
          1288,
          970,
          771,
          2504700,
          864,
          78968,
          722,
          149,
          248,
          18182,
          237282,
          177,
          595,
          7163,
          27020,
          105549,
          99,
          863,
          77,
          5196,
          717255,
          26551,
          568,
          589,
          545147,
          2856,
          239,
          5760,
          167,
          107941,
          1075,
          71485,
          165,
          1850,
          2872,
          49,
          223,
          272,
          608,
          128715,
          1507,
          77,
          116001,
          116001,
          5548,
          92043,
          55345,
          686,
          2036,
          302,
          2526,
          2304,
          718,
          601723,
          47772,
          467,
          1643,
          397,
          467,
          86954,
          23,
          31515,
          32891,
          271,
          172817,
          23727,
          47249,
          19685,
          9815,
          241,
          31515,
          76383,
          1089,
          59744,
          606,
          1791,
          3996,
          13717,
          2135,
          111,
          718,
          178,
          2304,
          158701,
          47772,
          571,
          1196,
          52,
          459921,
          242,
          166081,
          1841,
          1312,
          3202,
          6951,
          128715,
          717255,
          863,
          7155,
          1762,
          502,
          1595797,
          215,
          687276,
          27971,
          489,
          1892,
          2258,
          184,
          217,
          1143,
          31394,
          313,
          149,
          1507,
          1631,
          899,
          493,
          1102,
          910148,
          11253,
          7646,
          754,
          100,
          27971,
          192,
          530,
          21125,
          69793,
          1139,
          5895,
          759,
          77,
          95035,
          687276,
          192805,
          5621,
          532,
          9521,
          355,
          34153,
          2872,
          601723,
          99,
          530,
          2607,
          24840,
          8269,
          3833,
          5507,
          13422,
          34153,
          5908,
          1213,
          589,
          313,
          391389,
          136895,
          267,
          207410,
          10717,
          647,
          18760,
          207410,
          516,
          255,
          124967,
          310,
          937,
          5875,
          35439,
          18182,
          11256,
          349,
          128,
          24840,
          13835,
          328,
          324,
          1892,
          1645,
          105549,
          759,
          139,
          92043,
          1766,
          9521,
          19685,
          85,
          3451,
          1132,
          9034,
          1019,
          10717,
          3224,
          116155,
          34882,
          606,
          17867,
          673342,
          3699,
          43,
          4542,
          1758,
          18408,
          71485,
          79613,
          9506,
          6120,
          3119,
          165556,
          922,
          31394,
          27020,
          1360,
          545147,
          177,
          10717,
          139,
          337,
          2211,
          2307,
          888,
          4575,
          647,
          4993,
          178,
          633,
          258,
          1847,
          341043,
          27020,
          242,
          4306,
          92043,
          35371,
          43,
          218,
          123373,
          11256,
          7268,
          192805,
          2395,
          111,
          1517,
          744,
          50489,
          4306,
          2304,
          158701,
          276002,
          564,
          1532,
          77,
          9993,
          337,
          601723,
          10076,
          530,
          972,
          718,
          3224,
          248858,
          2092,
          136,
          910148,
          888,
          27020,
          15426,
          1312922,
          3279,
          477,
          2872,
          9815,
          828,
          1507,
          828,
          1472,
          14783,
          2501,
          77,
          5196,
          601723,
          1789,
          349,
          163415,
          2856,
          1988,
          213,
          765,
          34882,
          3224,
          7163,
          23727,
          6951,
          470,
          100,
          1102,
          1478,
          1063,
          1139,
          2836,
          13422,
          1019,
          24840,
          5196,
          337,
          1241364,
          525713,
          1271,
          19685,
          2376,
          5512,
          237282,
          7268,
          50489,
          60,
          6469,
          1656,
          190178,
          27971,
          976,
          459921,
          77,
          4729,
          969,
          2054,
          1643,
          47249,
          67082,
          1563,
          27020,
          2523,
          464,
          238602,
          4512,
          1526206,
          973849,
          5161,
          1574,
          218,
          1666,
          2135,
          836,
          1178,
          79613,
          23,
          276896,
          5354,
          4993,
          104,
          54287,
          18408,
          3255,
          493806,
          1791,
          5161,
          1075,
          23,
          92608,
          237282,
          811,
          741,
          520,
          3487,
          16183,
          673342,
          4653,
          71335,
          1725,
          8007,
          217,
          313,
          525713,
          43102,
          1126,
          1686,
          911,
          3495,
          129,
          4074,
          5989,
          3688,
          1583,
          1446,
          341,
          1770,
          71463,
          3807,
          1675,
          1312922,
          606,
          136895,
          4575,
          1213,
          13983,
          10076,
          258,
          9521,
          3684,
          4593,
          1190,
          1490,
          1617,
          3289,
          118,
          590,
          5903,
          3223,
          21134,
          743,
          1363,
          389246,
          743,
          19685,
          632,
          128715,
          828,
          899,
          47249,
          123,
          584,
          76,
          2906700,
          744,
          133,
          1770,
          471,
          9587,
          16305,
          133,
          9679,
          3776,
          19054,
          241,
          198,
          2457,
          3224,
          9496,
          1143,
          35371,
          165,
          2317,
          19054,
          1334,
          111,
          3066,
          4664,
          61,
          910148,
          885,
          248,
          1051,
          71463,
          1126,
          2872,
          15647,
          1423,
          2870,
          192805,
          128,
          1789,
          759,
          9512,
          118,
          3487,
          237282,
          18408,
          3402,
          343,
          23,
          3224,
          320420,
          24536,
          3776,
          513,
          4653,
          49,
          2870,
          1847,
          343,
          20328,
          14228,
          222785,
          190178,
          13717,
          1063,
          22930,
          1512,
          9165,
          1656,
          3451,
          11256,
          399,
          14075,
          269,
          9815,
          2856,
          5778,
          19408,
          6434,
          861,
          320420,
          341,
          1414,
          467,
          217,
          640470,
          206,
          765,
          1324,
          372,
          276002,
          2258,
          5512,
          48194,
          22930,
          116155,
          313,
          725,
          46944,
          18408,
          35439,
          165556,
          6434,
          1847,
          6951,
          1312922,
          124967,
          84106,
          737,
          258,
          639,
          111,
          13973,
          2395,
          4680,
          2906700,
          137,
          3766,
          3402,
          606,
          964,
          14871,
          5161,
          885,
          551,
          741,
          1762,
          3255,
          2457,
          1617,
          1201,
          2054,
          2872,
          6120,
          21902,
          99,
          4729,
          190178,
          128354,
          1979,
          1930,
          5657,
          5875,
          2870,
          376,
          4074,
          454,
          1523,
          2036,
          1412,
          2457,
          606,
          2304,
          43102,
          427,
          7163,
          19090,
          3096,
          1089,
          5507,
          17867,
          74,
          1517,
          804,
          9496,
          1126,
          112,
          695,
          1583,
          1420,
          16183,
          343,
          248,
          77,
          15426,
          186140,
          2906700,
          2607,
          35371,
          6841,
          965,
          75830,
          1472,
          4512,
          22305,
          106,
          1760,
          5760,
          2304,
          241,
          10256,
          346,
          2304,
          1766,
          13835,
          241,
          2526,
          297,
          186140,
          10717,
          2401,
          93193,
          370,
          346,
          395,
          1146,
          595,
          520,
          2395,
          3096,
          104,
          302,
          1186,
          395,
          4729,
          178,
          1766,
          27020,
          1132,
          24536,
          864,
          6629,
          8019,
          19054,
          3224,
          275,
          59744,
          3224,
          79008,
          9496,
          1195,
          6120,
          263,
          1051,
          50489,
          1758,
          9815,
          1745,
          878,
          2135,
          54185,
          21125,
          645,
          717255,
          413574,
          1923,
          743,
          14742,
          601723,
          3402,
          23,
          276896,
          2395,
          3833,
          5512,
          1140,
          7268,
          277,
          19054,
          910148,
          1858,
          1810,
          10717,
          4664,
          149,
          1758,
          663,
          565,
          55345,
          2368,
          230,
          4720,
          77,
          136,
          1472,
          1725,
          899,
          269,
          3684,
          76383,
          1858,
          673342,
          686,
          7155,
          502,
          77,
          5161,
          140,
          922,
          7646,
          2036,
          2290,
          477,
          3776,
          238602,
          2304,
          571,
          5732,
          602,
          5161,
          477,
          912,
          1412,
          532,
          136,
          1132,
          3996,
          1186,
          348,
          76,
          381459,
          910148,
          6120,
          307,
          224256,
          31394,
          642,
          2148,
          192,
          343,
          1892,
          68211,
          5760,
          20478,
          111,
          4424,
          910148,
          27971,
          95,
          1810,
          5875,
          1643,
          914,
          21134,
          910148,
          5619,
          6284,
          79613,
          255,
          190,
          1382480,
          3684,
          237282,
          2158,
          3395,
          595,
          1165,
          31515,
          4074,
          341043,
          1686,
          1493,
          2906700,
          1988,
          601723,
          276002,
          7155,
          186140,
          6120,
          633,
          242,
          181438,
          128715,
          137,
          341,
          1749,
          1078,
          59744,
          324,
          6006,
          324,
          2836,
          308,
          641,
          565,
          9594,
          1089,
          48194,
          1201,
          184,
          116001,
          54767,
          551,
          123373,
          824,
          42384,
          50489,
          3730,
          217,
          92608,
          9594,
          84106,
          754,
          133,
          7692,
          1810,
          247,
          1760,
          825,
          22305,
          13422,
          307,
          233717,
          248858,
          8007,
          2368,
          18128,
          171170,
          50489,
          22305,
          255,
          32891,
          151785,
          759,
          6120,
          21902,
          10717,
          123,
          2202,
          647,
          4542,
          737,
          276002,
          5512,
          71335,
          1970,
          24536,
          140,
          1443,
          4172,
          1414,
          218,
          2523,
          5760,
          530,
          4533,
          409656,
          1574,
          178,
          43,
          972,
          172817,
          1423,
          427,
          333497,
          47249,
          565,
          602,
          722,
          717255,
          1190,
          378909,
          910148,
          722,
          626,
          10717,
          52126,
          1504,
          94014,
          888,
          653,
          123,
          1577385,
          37,
          1493,
          1923,
          1334,
          6018,
          5507,
          13973,
          191096,
          736284,
          969,
          1679,
          2317,
          69,
          1228,
          34153,
          1684,
          4895,
          520,
          513,
          5341,
          471,
          324,
          2078,
          2060,
          258,
          149,
          4354,
          376,
          177,
          18128,
          2457,
          47249,
          302,
          5989,
          717255,
          2443,
          165,
          67082,
          3688,
          970,
          50835,
          5895,
          4367,
          3807,
          6581,
          134056,
          722,
          765,
          7268,
          50489,
          4159,
          71335,
          1132,
          969,
          13973,
          75830,
          313,
          111,
          5908,
          186140,
          2368,
          36438,
          824,
          229,
          4895,
          214518,
          1512,
          1442,
          686,
          11256,
          54287,
          192,
          124967,
          2906700,
          4090,
          1841,
          782,
          214518,
          710,
          1850,
          52126,
          725,
          76,
          18408,
          7297,
          1909,
          1810,
          1675,
          633,
          128,
          1420,
          376,
          190178,
          139,
          687276,
          1680,
          95,
          2395,
          76383,
          198,
          3224,
          1063,
          13602,
          1241364,
          899,
          85,
          1725,
          3096,
          502,
          95015,
          2307,
          761,
          13422,
          50835,
          242,
          277,
          36784,
          248,
          3688,
          1089,
          3224,
          165,
          3862,
          20478,
          3066,
          2906700,
          106,
          597,
          4367,
          307,
          520,
          328,
          3451,
          28739,
          736284,
          158701,
          13835,
          1383,
          308,
          1679,
          5875,
          5211,
          1166,
          493,
          1645,
          1675,
          878,
          271,
          4090,
          595,
          6460,
          7297,
          1909,
          645,
          5548,
          1186,
          192805,
          258,
          6006,
          3688,
          123,
          18128,
          2457,
          3807,
          1925,
          413574,
          63,
          33804,
          49,
          320420,
          1661,
          973849,
          1970,
          313,
          1263321,
          43102,
          1263321,
          4575,
          270712,
          258,
          641349,
          601723,
          795,
          133,
          565,
          1789,
          2135,
          5760,
          1988,
          346,
          242,
          2691,
          1571,
          23727,
          397,
          1850,
          63,
          378909,
          47772,
          3289,
          110,
          1897,
          5341,
          47249,
          5901,
          471,
          2518,
          165556,
          84106,
          176,
          663,
          4508,
          765,
          207,
          123373,
          888,
          10076,
          12486,
          172817,
          932,
          2870,
          337,
          14783,
          100,
          608,
          1804,
          1766,
          566,
          1791,
          1679,
          238602,
          3224,
          427,
          37,
          31394,
          2054,
          321,
          1517,
          302,
          1263321,
          1312922,
          1179,
          128,
          151022,
          970,
          1019,
          2906700,
          48194,
          626,
          3776,
          1131,
          2408,
          328,
          828,
          2906700,
          5848,
          4542,
          1946,
          47,
          214518,
          743,
          59705,
          470,
          4512,
          5507,
          238602,
          725,
          6581,
          1186,
          1190,
          248,
          771,
          313,
          77,
          1532,
          765,
          241,
          771,
          2471,
          459921,
          1288,
          3776,
          3279,
          350,
          1063,
          470,
          3688,
          4653,
          899,
          1735,
          1019,
          176,
          13422,
          365,
          2607,
          5908,
          13602,
          1930,
          5666,
          276,
          632,
          42384,
          32891,
          4542,
          33804,
          27971,
          1412,
          19685,
          5341,
          166081,
          4993,
          6713,
          1302,
          1178,
          932,
          4726,
          2142,
          276896,
          181438,
          92985,
          863,
          18128,
          42817,
          1684,
          626,
          2408,
          2661,
          94325,
          1412,
          4993,
          4354,
          230,
          372,
          5895,
          34496,
          378909,
          237282,
          34496,
          9815,
          759,
          753116,
          1312922,
          1645,
          136,
          3104,
          4575,
          48194,
          519,
          6120,
          46,
          50835,
          372,
          48194,
          2317,
          286,
          520,
          1565,
          551,
          5211,
          1078,
          4354,
          276002,
          471,
          76,
          67082,
          26120,
          54185,
          47772,
          217,
          530,
          459921,
          32891,
          4573,
          1126,
          795,
          105638,
          3688,
          230,
          181438,
          2304,
          710,
          149,
          2303,
          217,
          92337,
          1089,
          276002,
          391389,
          910148,
          8512,
          4049,
          186140,
          341043,
          302,
          328,
          1804,
          145,
          34882,
          1643,
          1689,
          341,
          3032,
          1563,
          509,
          258,
          78968,
          722,
          3508,
          9594,
          4913,
          344,
          93193,
          2078,
          759,
          70,
          151815,
          1526206,
          23045,
          230,
          1656,
          687276,
          1563,
          642,
          10076,
          328,
          895,
          4074,
          12486,
          509,
          12747,
          15269,
          123373,
          184,
          1195,
          5927,
          5901,
          4913,
          2435,
          47249,
          222,
          7646,
          18128,
          133,
          1606,
          1493,
          4198,
          1923,
          12335,
          9772,
          6284,
          1749,
          1923,
          139,
          247,
          965,
          2856,
          732,
          276896,
          84861,
          6951,
          19685,
          238602,
          964,
          277,
          18128,
          2691,
          1684,
          4512,
          5196,
          16183,
          78968,
          46,
          55345,
          52126,
          454,
          2078,
          932,
          85,
          5791,
          7155,
          158701,
          291,
          9679,
          2523,
          632,
          4198,
          765,
          84106,
          2376,
          5875,
          178,
          2148,
          3495,
          823,
          77,
          267,
          217,
          3451,
          4508,
          331,
          7155,
          27020,
          1493,
          320,
          1263321,
          123,
          254282,
          1446,
          291,
          888,
          291,
          128,
          1970,
          338,
          18408,
          427,
          2208,
          184,
          602,
          343,
          1925,
          50835,
          2060,
          2263,
          477,
          32891,
          885,
          2644,
          337,
          207410,
          5619,
          100,
          1078,
          13422,
          3202,
          5619,
          267,
          263,
          1789,
          3032,
          910148,
          1766,
          1414,
          1490,
          885,
          1261,
          4729,
          1523,
          973849,
          13422,
          2408,
          3263,
          1302,
          4729,
          22305,
          1178,
          647,
          43,
          214518,
          320420,
          5989,
          608,
          1970,
          270712,
          1490,
          106,
          4081,
          23727,
          260,
          18408,
          140,
          92043,
          1631,
          12747,
          3688,
          23,
          263,
          733,
          3876,
          5666,
          1675,
          11253,
          77,
          137,
          144160,
          95,
          165556,
          2523,
          151022,
          313,
          172247,
          493806,
          663,
          932,
          381459,
          969,
          673342,
          215,
          105549,
          1228,
          2206,
          1804,
          606,
          140,
          247,
          460,
          5621,
          3688,
          2856,
          922,
          1166,
          836,
          1533,
          22191,
          1324,
          8830,
          2135,
          964,
          2443,
          687276,
          149,
          27971,
          1019,
          71463,
          2607,
          1725,
          2607,
          1526206,
          1791,
          45303,
          1075,
          776,
          1274,
          2036,
          12486,
          11256,
          118,
          1725,
          5760,
          15269,
          145,
          22930,
          1139,
          23727,
          4664,
          123,
          4573,
          178,
          3684,
          899,
          190178,
          324,
          645,
          1532,
          6284,
          1312922,
          307,
          4542,
          3279,
          307,
          1526206,
          9772,
          3224,
          2368,
          15623,
          46,
          320,
          4090,
          320,
          55581,
          3032,
          817312,
          1988,
          270712,
          601723,
          914,
          1312,
          2408,
          5507,
          26551,
          841711,
          74,
          276,
          2135,
          2856,
          841711,
          333497,
          1241364,
          328,
          23045,
          1679,
          51,
          134056,
          30770,
          1363,
          70,
          4913,
          242,
          23045,
          9815,
          1120,
          13422,
          817312,
          2916,
          124967,
          4074,
          270712,
          3395,
          475,
          7155,
          5548,
          46,
          55581,
          192805,
          5760,
          20328,
          1617,
          4354,
          1228,
          178,
          1019,
          128,
          2303,
          4081,
          237282,
          1760,
          276002,
          551,
          34496,
          804,
          1791,
          2036,
          344,
          2906700,
          94325,
          4074,
          653,
          116001,
          35439,
          222785,
          5507,
          614,
          5760,
          2092,
          695,
          75830,
          190249,
          601723,
          128715,
          1595797,
          92985,
          11751,
          88735,
          427,
          3876,
          1360,
          504,
          313,
          86954,
          2368,
          7565,
          13422,
          207410,
          55581,
          34882,
          647,
          741,
          2870,
          337,
          254282,
          122111,
          1661,
          695,
          1051,
          254,
          69,
          478,
          1201,
          680,
          106,
          3202,
          116001,
          878,
          308,
          9594,
          6629,
          123,
          4729,
          95035,
          2457,
          1700,
          84106,
          2303,
          2036,
          25459,
          466,
          4533,
          1725,
          88735,
          124967,
          757530,
          427,
          743,
          2135,
          4653,
          753116,
          1360,
          463,
          242,
          230,
          509,
          911,
          1661,
          91,
          28739,
          7163,
          3508,
          21902,
          176,
          2395,
          337,
          922,
          4005,
          22305,
          21134,
          6006,
          271,
          6841,
          1288,
          4895,
          76,
          128354,
          2303,
          337,
          16305,
          4720,
          2526,
          1063,
          100,
          18760,
          370,
          128715,
          606,
          1643,
          832,
          2408,
          11253,
          149,
          1841,
          932,
          1675,
          84106,
          1063,
          153,
          3224,
          3495,
          1453,
          302,
          861,
          186140,
          139650,
          516,
          4878,
          743,
          1363,
          5950,
          190178,
          233060,
          128715,
          1645,
          14783,
          3458,
          4895,
          6841,
          4993,
          653,
          2872,
          4512,
          1165,
          79008,
          28425,
          1831,
          1132,
          4664,
          3996,
          76383,
          94325,
          3202,
          11432,
          7646,
          1051,
          2456,
          899,
          54767,
          5657,
          911,
          914,
          467,
          7987,
          2872,
          1606,
          313,
          18760,
          166081,
          6713,
          68211,
          6841,
          1022298,
          725,
          105638,
          71485,
          5875,
          99,
          76,
          137,
          276896,
          5760,
          632,
          207,
          118,
          144160,
          601723,
          2121,
          46,
          2328,
          5211,
          3395,
          129,
          817312,
          5507,
          21134,
          205,
          1360,
          47249,
          1312922,
          1760,
          140,
          177,
          207,
          2148,
          5666,
          104396,
          50835,
          2456,
          94325,
          1412,
          4508,
          213,
          372,
          381459,
          21125,
          606,
          35371,
          13422,
          1334,
          2644,
          346,
          11250,
          928,
          100,
          43,
          21134,
          1523,
          5732,
          4664,
          83,
          1302,
          20478,
          69793,
          71335,
          2328,
          2870,
          88735,
          836,
          606,
          165556,
          4512,
          1075,
          16183,
          885,
          466,
          571,
          20328,
          4993,
          1725,
          718,
          78968,
          214703,
          1925,
          333497,
          190178,
          149,
          344,
          13602,
          828,
          3684,
          12486,
          46944,
          6006,
          1533,
          1563,
          21902,
          2317,
          687276,
          1228,
          1850,
          12335,
          686,
          116155,
          5648,
          14742,
          12747,
          28739,
          33804,
          470,
          717255,
          85,
          1288,
          3862,
          1140,
          194500,
          4726,
          760,
          519,
          498,
          589,
          4138,
          313,
          710,
          1643,
          878,
          5848,
          571,
          95,
          1038,
          1196,
          419,
          328,
          94014,
          237282,
          2786,
          42817,
          27971,
          241,
          395,
          15426,
          9993,
          932,
          710,
          34882,
          105549,
          3495,
          192,
          1745,
          5791,
          128,
          28425,
          2263,
          1791,
          899,
          4664,
          172817,
          4575,
          4508,
          145,
          169,
          1078,
          489,
          2691,
          6120,
          647,
          626,
          20328,
          116001,
          165,
          20478,
          94014,
          969,
          42384,
          1526206,
          798,
          686,
          134056,
          825,
          31970,
          96942,
          2368,
          370,
          2523,
          20478,
          630,
          2691,
          153,
          1684,
          2870,
          2089,
          96942,
          144160,
          307,
          6006,
          1120,
          3807,
          1970,
          530,
          1595797,
          344,
          545147,
          54287,
          3684,
          53,
          270712,
          45100,
          34153,
          2607,
          7646,
          3343,
          1923,
          1762,
          2435,
          7163,
          54185,
          4878,
          14742,
          26551,
          1442,
          2518,
          320420,
          55581,
          95035,
          911,
          795,
          92294,
          337,
          46,
          76383,
          687276,
          1530,
          76383,
          128715,
          9772,
          878,
          5791,
          653,
          18182,
          8830,
          50835,
          355,
          320,
          168,
          581,
          551,
          757530,
          5619,
          8874,
          1178,
          391389,
          3224,
          606,
          206,
          47249,
          59744,
          1675,
          51,
          1423,
          214703,
          964,
          337,
          6841,
          888,
          2691,
          5512,
          1577385,
          169,
          4005,
          1312922,
          533,
          13422,
          18128,
          2435,
          70,
          5791,
          2870,
          11432,
          17047,
          743,
          516,
          5908,
          4306,
          467,
          302,
          106,
          2135,
          75903,
          5903,
          3395,
          1423,
          42384,
          46,
          4533,
          71485,
          1725,
          92608,
          7297,
          3451,
          51,
          1126,
          427,
          22305,
          1241364,
          2307,
          47,
          5908,
          1512,
          1472,
          34496,
          129,
          59744,
          832,
          5895,
          337,
          1804,
          5989,
          3807,
          31515,
          1762,
          2121,
          277,
          471,
          565,
          1075,
          28739,
          165556,
          1850,
          35299,
          1526206,
          725,
          1532,
          737,
          1523,
          571,
          24840,
          1666,
          1363,
          965,
          6120,
          172247,
          530,
          73,
          207410,
          736284,
          271,
          104,
          1847,
          4878,
          26551,
          2148,
          970,
          1383,
          545147,
          341043,
          5950,
          1735,
          3684,
          2208,
          5901,
          190,
          1504,
          1126,
          965,
          139,
          3104,
          8019,
          237282,
          47772,
          910148,
          6120,
          307,
          2456,
          6120,
          184,
          378909,
          760,
          137,
          493,
          817312,
          237282,
          565,
          27020,
          258,
          4354,
          471,
          6469,
          5621,
          1533,
          270712,
          103927,
          1490,
          207,
          116001,
          85,
          1804,
          4845,
          4172,
          4074,
          32891,
          1847,
          687276,
          3395,
          320420,
          4778,
          69793,
          1414,
          765,
          21437,
          16183,
          7155,
          1196,
          94325,
          1526206,
          1897,
          19685,
          1583,
          2135,
          5354,
          932,
          365,
          31394,
          53,
          3833,
          771,
          71463,
          970,
          888,
          2036,
          3688,
          321490,
          1038,
          35439,
          28425,
          302,
          33917,
          116001,
          3688,
          454,
          606,
          1631,
          1656,
          1810,
          28425,
          11256,
          3766,
          222785,
          1979,
          1780,
          85,
          45100,
          100,
          1382480,
          6508,
          1745,
          1762,
          28739,
          316665,
          4049,
          91,
          276,
          25459,
          6120,
          1725,
          3508,
          28425,
          217,
          1228,
          782,
          2258,
          269,
          1420,
          1312922,
          34496,
          153,
          1126,
          828,
          3776,
          1766,
          32891,
          71485,
          2368,
          129,
          20328,
          205,
          520,
          140,
          50835,
          736284,
          198,
          341043,
          11250,
          601723,
          77,
          4913,
          338,
          7646,
          11432,
          467,
          378909,
          5950,
          9587,
          1312,
          1766,
          32891,
          229,
          2644,
          151785,
          743,
          932,
          828,
          1850,
          1089,
          14783,
          5354,
          1131,
          320420,
          1766,
          61,
          504,
          184,
          7297,
          639,
          31515,
          18128,
          2121,
          84106,
          606,
          413574,
          18760,
          753116,
          1461,
          222785,
          836,
          128,
          4005,
          910148,
          87124,
          1892,
          17867,
          4542,
          520,
          341043,
          46944,
          7155,
          1165,
          1909,
          2211,
          1293,
          964,
          31970,
          134056,
          18128,
          12335,
          27020,
          230,
          48194,
          647,
          348,
          95015,
          19685,
          732,
          1595797,
          695,
          1360,
          32891,
          14871,
          9815,
          1526206,
          4138,
          54287,
          151785,
          1506,
          1789,
          626,
          972,
          647,
          270712,
          516,
          628,
          922,
          1850,
          760,
          532,
          8830,
          6469,
          5895,
          6120,
          222785,
          1263321,
          338,
          206,
          743,
          128715,
          129,
          1666,
          1810,
          2443,
          13835,
          11250,
          75830,
          149,
          1324,
          782,
          13973,
          378909,
          214703,
          59744,
          348,
          3224,
          1645,
          1789,
          69,
          2916,
          1241364,
          504,
          1453,
          69,
          43,
          568,
          74,
          10076,
          19685,
          28278,
          16163,
          5903,
          128715,
          606,
          1847,
          1102,
          589,
          128715,
          632,
          493,
          100,
          519,
          11751,
          69,
          15269,
          1628,
          124967,
          233717,
          237282,
          1241364,
          2807,
          12335,
          5621,
          2456,
          885,
          1892,
          338,
          922,
          4172,
          1512,
          4720,
          19054,
          460,
          128715,
          137,
          92985,
          75830,
          922,
          6841,
          12335,
          116001,
          343,
          349,
          1423,
          2376,
          3430,
          95035,
          258,
          69,
          28278,
          2644,
          8830,
          899,
          1810,
          6120,
          632,
          2401,
          263,
          471,
          1271,
          11253,
          136,
          22191,
          313,
          7420,
          19054,
          116001,
          8874,
          397,
          6629,
          4573,
          291,
          1306,
          614,
          1532,
          761,
          5196,
          2807,
          167,
          16183,
          566,
          1423,
          11751,
          1745,
          9815,
          8007,
          313,
          4049,
          19090,
          3104,
          5577,
          145,
          1946,
          798,
          3807,
          59744,
          237282,
          1063,
          519,
          272,
          149,
          178,
          1334,
          595,
          466,
          477,
          653,
          112,
          601723,
          782,
          118,
          128715,
          771,
          1571,
          84106,
          9815,
          26120,
          291,
          206,
          3684,
          42619,
          21902,
          313,
          914,
          111,
          1565,
          341043,
          4589,
          673342,
          964,
          1758,
          50489,
          50835,
          6469,
          1102,
          237282,
          105549,
          389246,
          12486,
          4993,
          687276,
          267,
          320,
          1412,
          1075,
          260,
          4154,
          1966,
          198,
          5875,
          9051,
          743,
          4895,
          37,
          695,
          263,
          43102,
          811,
          633,
          4533,
          47249,
          1923,
          1087,
          13717,
          276002,
          1201,
          530,
          4090,
          1760,
          754,
          35371,
          1126,
          4677,
          545147,
          1166,
          4074,
          1022298,
          4664,
          17867,
          9594,
          493,
          4090,
          3402,
          3451,
          299480,
          128,
          3487,
          1166,
          158701,
          313,
          320420,
          571,
          4049,
          4726,
          53,
          45303,
          7297,
          391389,
          1749,
          782,
          2036,
          184,
          137067,
          1442,
          1139,
          71335,
          13835,
          5619,
          215,
          1423,
          765,
          1089,
          530,
          642,
          5901,
          7163,
          1139,
          32891,
          1831,
          5341,
          1745,
          1760,
          744,
          181438,
          3688,
          1523,
          1306,
          686,
          77,
          1178,
          54287,
          1810,
          1571,
          54767,
          11256,
          9512,
          71485,
          2307,
          5950,
          6508,
          137,
          21134,
          123,
          310,
          8830,
          241,
          190178,
          910148,
          2501,
          54185,
          224256,
          744,
          5662,
          14228,
          93193,
          673342,
          601723,
          1288,
          5196,
          222,
          2401,
          167,
          489,
          1970,
          13061,
          498,
          1762,
          498,
          597,
          743,
          601723,
          811,
          5989,
          2054,
          1178,
          2148,
          3776,
          263,
          1241364,
          7646,
          2304,
          5719,
          863,
          31394,
          2607,
          687276,
          129,
          1360,
          1514,
          92337,
          20328,
          923,
          307,
          186140,
          233717,
          95035,
          2054,
          260,
          2526,
          328,
          970,
          31394,
          1263321,
          1306,
          8512,
          3289,
          302,
          68211,
          3805,
          19054,
          277,
          214703,
          50835,
          1583,
          172817,
          291,
          35371,
          20478,
          3688,
          2307,
          107941,
          1274,
          144160,
          34153,
          4993,
          470,
          3833,
          190178,
          34153,
          88735,
          237282,
          73,
          76383,
          1446,
          19090,
          134056,
          6581,
          99,
          1453,
          522,
          427,
          34153,
          1132,
          3430,
          5760,
          3430,
          16163,
          1190,
          100,
          17867,
          54287,
          1383,
          1680,
          9034,
          8874,
          4653,
          165556,
          1595797,
          2368,
          84106,
          3096,
          673342,
          964,
          30770,
          888,
          1966,
          798,
          151815,
          31394,
          1493,
          2807,
          24536,
          176,
          111,
          564,
          471,
          540,
          1804,
          67082,
          1762,
          50489,
          1306,
          37,
          272,
          4729,
          6841,
          895,
          42817,
          128715,
          1631,
          589,
          110,
          4575,
          9594,
          42619,
          1595797,
          76383,
          5760,
          30770,
          1536,
          1102,
          6284,
          165,
          31394,
          68211,
          1595797,
          2807,
          5778,
          18408,
          3202,
          509,
          10256,
          5354,
          3776,
          475,
          743,
          885,
          10717,
          3766,
          1423,
          595,
          824,
          21125,
          2870,
          277,
          276002,
          525713,
          4474,
          741,
          48194,
          105549,
          532,
          186140,
          18408,
          5791,
          878,
          3451,
          50835,
          378909,
          3343,
          645,
          260,
          139,
          718,
          270712,
          1536,
          885,
          5901,
          49,
          466,
          10076,
          321,
          43102,
          5161,
          1261,
          190178,
          4603,
          2518,
          467,
          1595797,
          2457,
          1383,
          2078,
          28739,
          757530,
          1680,
          2501,
          1583,
          2644,
          914,
          551,
          5621,
          759,
          1461,
          2457,
          12486,
          4729,
          3343,
          1675,
          2607,
          3223,
          828,
          18128,
          828,
          413574,
          277,
          3451,
          18182,
          6469,
          18760,
          3451,
          267,
          9772,
          6018,
          6508,
          111,
          107941,
          4542,
          355,
          4424,
          206,
          2036,
          413574,
          190178,
          9815,
          15647,
          1288,
          1102,
          8333,
          69,
          5619,
          3224,
          7565,
          5548,
          4726,
          4074,
          1190,
          475,
          502,
          47249,
          1334,
          965,
          297,
          5927,
          1925,
          95015,
          34882,
          1274,
          914,
          413574,
          1263321,
          2401,
          1766,
          744,
          2906700,
          168,
          5619,
          2376,
          118,
          5161,
          71335,
          595,
          153,
          1304,
          2258,
          725,
          299480,
          1507,
          94014,
          1263321,
          69,
          759,
          504,
          18459,
          1563,
          139,
          99,
          2457,
          172817,
          15426,
          795,
          47249,
          4074,
          69,
          5512,
          49,
          4720,
          1841,
          2471,
          198,
          532,
          932,
          1274,
          1446,
          94014,
          75830,
          79008,
          463,
          122111,
          247,
          93193,
          4056,
          478,
          493806,
          18408,
          85,
          46944,
          1789,
          741,
          59705,
          6120,
          2317,
          372,
          2078,
          333497,
          95015,
          1100,
          4354,
          50835,
          105638,
          3688,
          899,
          1126,
          134056,
          1565,
          459921,
          6581,
          477,
          247,
          50835,
          9506,
          134056,
          47,
          50835,
          76,
          571,
          757530,
          1126,
          23045,
          1526206,
          128715,
          3202,
          1271,
          6629,
          376,
          298,
          186140,
          647,
          5726,
          21125,
          1443,
          50835,
          443,
          3766,
          73,
          718,
          11250,
          4653,
          528,
          6841,
          2054,
          35299,
          2317,
          680,
          6951,
          1490,
          230,
          343,
          722,
          11250,
          22305,
          836,
          1831,
          551,
          341,
          1426,
          5216,
          1789,
          1523,
          836,
          6841,
          42817,
          680,
          7163,
          1700,
          4474,
          832,
          24536,
          18182,
          540,
          680,
          1766,
          341043,
          413574,
          19685,
          307,
          4474,
          932,
          1631,
          1019,
          355,
          10076,
          4542,
          4074,
          2872,
          493,
          2526,
          648,
          238602,
          313,
          771,
          525713,
          178,
          24536,
          11256,
          863,
          9815,
          92608,
          4542,
          443,
          343,
          470,
          4056,
          105549,
          1804,
          530,
          151815,
          9772,
          8019,
          3085,
          60,
          129,
          6581,
          92608,
          970,
          2644,
          6469,
          51427,
          241,
          3996,
          1523,
          8874,
          92985,
          606,
          190178,
          4533,
          4680,
          471,
          69,
          158701,
          1263321,
          46,
          817312,
          1858,
          6581,
          3684,
          6629,
          1186,
          1791,
          5901,
          79613,
          450,
          4159,
          194500,
          68211,
          4090,
          589,
          163415,
          878,
          3688,
          54767,
          166081,
          888,
          34882,
          493806,
          498,
          1631,
          3289,
          1679,
          2158,
          502,
          391389,
          50835,
          532,
          4081,
          1078,
          2121,
          307,
          4172,
          191096,
          3430,
          51,
          242,
          151785,
          2401,
          9034,
          479994,
          895,
          18459,
          214518,
          1533,
          21134,
          11250,
          267,
          255,
          207410,
          36784,
          836,
          5875,
          2456,
          632,
          224256,
          2523,
          5354,
          348,
          47249,
          1383,
          3032,
          5989,
          192805,
          42619,
          1472,
          1263321,
          1312922,
          5901,
          1228,
          11256,
          77,
          1472,
          137,
          489,
          2379,
          237282,
          4589,
          272134,
          5895,
          1312,
          13717,
          5895,
          5875,
          1472,
          4056,
          1228,
          7163,
          186140,
          2368,
          320420,
          5726,
          93193,
          54767,
          6713,
          2870,
          34882,
          20478,
          911,
          7297,
          1089,
          28739,
          75903,
          20328,
          478,
          565,
          1312922,
          389246,
          551,
          757530,
          92043,
          1312922,
          606,
          647,
          144160,
          71463,
          47211,
          31970,
          753116,
          1271,
          888,
          2526,
          92985,
          186140,
          1583,
          42817,
          9051,
          2307,
          2395,
          6469,
          680,
          25459,
          95035,
          687276,
          95,
          4653,
          722,
          1312922,
          1725,
          5354,
          313,
          782,
          301,
          1923,
          302,
          1166,
          1382480,
          4575,
          1051,
          680,
          192,
          34496,
          213,
          1988,
          528,
          10256,
          6951,
          2383912,
          1512,
          14871,
          1383,
          18408,
          825,
          509,
          69,
          530,
          71485,
          269,
          1075,
          186140,
          247,
          1617,
          2211,
          2906700,
          139,
          10295,
          128,
          2401,
          99,
          241,
          1195,
          686,
          310,
          69,
          53,
          137067,
          519,
          302,
          241,
          910148,
          2304,
          2872,
          9165,
          74,
          237282,
          133,
          1139,
          369,
          895,
          509,
          23,
          760,
          34882,
          21902,
          1532,
          310,
          3279,
          760,
          7268,
          811,
          6508,
          581,
          568,
          5621,
          5875,
          7297,
          137,
          92608,
          1686,
          601723,
          51427,
          1966,
          248,
          178,
          238602,
          663,
          4138,
          4159,
          6581,
          5791,
          128,
          895,
          6713,
          192805,
          9679,
          21134,
          2142,
          21902,
          118,
          395,
          4542,
          75830,
          626,
          1645,
          633,
          633,
          3032,
          35705,
          23727,
          3255,
          1512,
          759,
          687276,
          525713,
          970,
          765,
          378909,
          2607,
          5732,
          757530,
          343,
          1943,
          2836,
          9587,
          238602,
          241,
          54287,
          4895,
          885,
          381459,
          5908,
          1789,
          92294,
          1102,
          4895,
          95015,
          51,
          15623,
          1271,
          1078,
          10076,
          391389,
          2807,
          1807,
          2317,
          302,
          276002,
          899,
          1165,
          1078,
          1261,
          571,
          2408,
          46944,
          4198,
          25459,
          51427,
          5548,
          42817,
          532,
          46563,
          4512,
          1324,
          9496,
          8512,
          42817,
          3202,
          9034,
          888,
          2523,
          27020,
          5950,
          4161,
          3805,
          35371,
          4290,
          151785,
          1063,
          1645,
          5648,
          832,
          178,
          832,
          1051,
          3458,
          134056,
          100,
          493806,
          1789,
          759,
          269,
          391389,
          878,
          3688,
          1675,
          241,
          346,
          24645,
          9815,
          836,
          1675,
          493,
          1263321,
          2526,
          46563,
          241,
          760,
          1442,
          3688,
          134056,
          242,
          1847,
          23045,
          302,
          1766,
          71485,
          2408,
          18760,
          964,
          270712,
          18760,
          888,
          75830,
          686,
          2607,
          137,
          87124,
          241,
          478,
          1789,
          35371,
          642,
          647,
          2379,
          186140,
          71335,
          95,
          1766,
          3395,
          1261,
          4895,
          932,
          2383912,
          648,
          1897,
          467,
          1324,
          498,
          134056,
          207,
          5621,
          222785,
          493,
          6951,
          324,
          741,
          23727,
          5621,
          128715,
          1700,
          21134,
          687276,
          248,
          5354,
          5341,
          12335,
          48194,
          177,
          2258,
          34496,
          223,
          9521,
          1661,
          19685,
          1051,
          165,
          45303,
          192,
          695,
          55345,
          328,
          1536,
          3684,
          626,
          94014,
          5619,
          50835,
          272134,
          18408,
          413574,
          2644,
          165556,
          1850,
          206,
          28425,
          53,
          761,
          346,
          9165,
          4049,
          158701,
          346,
          1684,
          847,
          24840,
          2211,
          753116,
          2644,
          3224,
          1725,
          450,
          218,
          198,
          206,
          320,
          493806,
          365,
          1766,
          4172,
          134056,
          46944,
          55581,
          76,
          5989,
          5760,
          95,
          346,
          741,
          47249,
          606,
          18128,
          2644,
          5621,
          92985,
          1186,
          606,
          3395,
          5989,
          1645,
          427,
          9594,
          1970,
          836,
          27971,
          467,
          18128,
          149,
          151022,
          192805,
          489,
          123373,
          3495,
          2208,
          269,
          222785,
          276896,
          753116,
          73,
          3996,
          964,
          3862,
          2456,
          267,
          509,
          4159,
          192,
          95035,
          910148,
          917,
          19090,
          4056,
          798,
          7268,
          2395,
          5161,
          1089,
          5903,
          2092,
          4573,
          158701,
          6284,
          136,
          99,
          673342,
          25459,
          337,
          11432,
          804,
          21902,
          673342,
          11432,
          7692,
          1595797,
          2408,
          4913,
          805,
          640470,
          2644,
          118,
          5662,
          9772,
          9565,
          2135,
          260,
          686,
          46944,
          1892,
          263,
          1288,
          1760,
          2395,
          581,
          4593,
          626,
          1271,
          112,
          22305,
          84106,
          1022298,
          143,
          71485,
          8333,
          276002,
          36438,
          10295,
          2408,
          1656,
          1507,
          6006,
          717255,
          1228,
          680,
          841711,
          409656,
          1789,
          18182,
          158701,
          28739,
          370,
          4575,
          2401,
          320420,
          4653,
          230,
          1383,
          222785,
          1760,
          35299,
          1909,
          6841,
          633,
          233060,
          888,
          5341,
          4653,
          38912,
          765,
          134056,
          302,
          128715,
          9815,
          1228,
          2456,
          134056,
          1970,
          32891,
          3202,
          922,
          213,
          83,
          1563,
          21902,
          1288,
          2097,
          14228,
          11751,
          3224,
          1645,
          149,
          1383,
          184,
          6120,
          1925,
          7987,
          2135,
          3104,
          237282,
          21437,
          271,
          2368,
          365,
          397,
          84106,
          136895,
          765,
          271,
          1526206,
          7155,
          5908,
          1789,
          370,
          248,
          568,
          19408,
          116001,
          1577385,
          53,
          6508,
          5666,
          60,
          34496,
          123,
          53,
          143,
          308,
          75830,
          3495,
          1807,
          376,
          51,
          2368,
          134056,
          5577,
          333497,
          2054,
          2395,
          376,
          3096,
          5760,
          5848,
          1195,
          42817,
          328,
          409656,
          310,
          2054,
          313,
          79613,
          50489,
          2870,
          1166,
          1352,
          74,
          1617,
          493806,
          3776,
          237282,
          1412,
          2054,
          1804,
          3451,
          1202,
          3451,
          198,
          28425,
          21134,
          18760,
          2456,
          1263321,
          3458,
          540,
          333497,
          5161,
          145,
          85,
          4005,
          1577385,
          9993,
          878,
          18128,
          136,
          172817,
          760,
          223,
          2607,
          642,
          922,
          324,
          5354,
          5760,
          50489,
          759,
          116001,
          184,
          50835,
          571,
          17867,
          5548,
          969,
          1758,
          6469,
          2872,
          1195,
          6713,
          1680,
          10256,
          3279,
          1656,
          192,
          3032,
          927396,
          3289,
          2906700,
          568,
          165556,
          9815,
          7646,
          571,
          10256,
          5875,
          4913,
          19685,
          128715,
          3994,
          1831,
          1979,
          928,
          1979,
          9034,
          823,
          18128,
          153,
          2206,
          5161,
          1063,
          70,
          1643,
          158701,
          9772,
          341,
          2644,
          4542,
          2607,
          23727,
          771,
          145,
          397,
          1725,
          5662,
          165,
          885,
          3343,
          1679,
          17867,
          111,
          525713,
          4603,
          736284,
          2307,
          5908,
          346,
          753116,
          532,
          1241364,
          4542,
          718,
          69,
          1526206,
          85,
          134056,
          565,
          2457,
          218,
          1461,
          128354,
          2328,
          1131,
          2501,
          1363,
          1725,
          571,
          639,
          20478,
          686,
          6951,
          1780,
          1195,
          1363,
          2206,
          5216,
          413574,
          1304,
          6951,
          1831,
          8874,
          31970,
          5760,
          194500,
          346,
          140,
          43102,
          105549,
          77,
          1666,
          4074,
          365,
          52126,
          45303,
          1461,
          21437,
          9587,
          11256,
          263,
          673342,
          153,
          2401,
          823,
          7155,
          1504,
          1178,
          6018,
          10076,
          5161,
          172247,
          33917,
          1666,
          254282,
          92985,
          489,
          2566,
          601723,
          2303,
          732,
          631,
          321490,
          1970,
          1631,
          4913,
          11751,
          1360,
          504,
          140,
          1383,
          3395,
          753116,
          1186,
          2135,
          2408,
          15647,
          5211,
          1132,
          1126,
          203571,
          237282,
          914,
          2456,
          1288,
          910148,
          276896,
          1261,
          2523,
          2307,
          5196,
          2916,
          248858,
          2872,
          3776,
          4878,
          863,
          4090,
          123,
          1563,
          4056,
          34153,
          95035,
          47249,
          653,
          3430,
          7420,
          4056,
          1923,
          493,
          2307,
          1186,
          21635,
          1078,
          2906700,
          1019,
          1383,
          4512,
          140,
          276002,
          258,
          1360,
          1988,
          5648,
          165556,
          478,
          2395,
          6284,
          34496,
          2408,
          20328,
          7163,
          3833,
          123,
          23727,
          126,
          77,
          5621,
          4726,
          2471,
          4074,
          4664,
          1302,
          217,
          828,
          1089,
          34496,
          85,
          1595797,
          23,
          276002,
          50835,
          13973,
          4845,
          11250,
          9993,
          24536,
          22191,
          338,
          341043,
          92608,
          1165,
          765,
          1923,
          5908,
          31515,
          166081,
          151022,
          9993,
          2223,
          526,
          1382480,
          9815,
          1493,
          324,
          34496,
          59705,
          276002,
          24645,
          1506,
          1762,
          1577385,
          46563,
          1512,
          299480,
          4575,
          3224,
          761,
          7268,
          207,
          9594,
          70,
          34882,
          863,
          270712,
          1930,
          50489,
          20478,
          307,
          1363,
          1532,
          1789,
          20328,
          149,
          5451,
          1312922,
          479994,
          42817,
          1946,
          105549,
          75903,
          198,
          214518,
          1643,
          378909,
          1143,
          32891,
          258,
          817312,
          75830,
          1412,
          6006,
          207,
          144160,
          478,
          1689,
          1517,
          1517,
          291,
          276896,
          489,
          2408,
          267,
          725,
          4159,
          344,
          937,
          5875,
          28739,
          805,
          176,
          7646,
          35705,
          522,
          647,
          105549,
          3285,
          59744,
          27020,
          1360,
          1293,
          122111,
          52,
          328,
          139,
          633,
          3202,
          19054,
          1970,
          4056,
          4508,
          1643,
          493806,
          3807,
          198,
          1506,
          21125,
          186140,
          21134,
          1970,
          95035,
          509,
          686,
          743,
          19685,
          2054,
          1684,
          13717,
          673342,
          69793,
          50835,
          47211,
          1490,
          571,
          87124,
          215,
          5161,
          1666,
          233717,
          863,
          79613,
          828,
          1263321,
          28425,
          4653,
          344,
          1263321,
          743,
          10717,
          1263321,
          1689,
          1075,
          46,
          2836,
          823,
          922,
          7646,
          467,
          139650,
          242,
          137067,
          324,
          427,
          116001,
          973849,
          427,
          355,
          2395,
          695,
          759,
          1019,
          19408,
          372,
          732,
          467,
          95,
          2206,
          178,
          99,
          134056,
          19685,
          5512,
          760,
          1261,
          1617,
          1847,
          2456,
          8830,
          5875,
          11256,
          741,
          633,
          139650,
          754,
          1442,
          34882,
          1019,
          551,
          1263321,
          222785,
          70,
          165,
          516,
          1563,
          743,
          1461,
          973849,
          804,
          1536,
          51427,
          242,
          9679,
          112,
          255,
          46,
          551,
          143,
          391389,
          19090,
          73,
          95035,
          5989,
          3458,
          313,
          7297,
          2211,
          970,
          608,
          324,
          3684,
          1526206,
          13717,
          1126,
          1241364,
          1595797,
          2092,
          71335,
          320420,
          376,
          4290,
          186140,
          551,
          460,
          302,
          2395,
          5875,
          1943,
          757530,
          1517,
          344,
          2457,
          471,
          532,
          346,
          123,
          888,
          489,
          1810,
          509,
          34496,
          241,
          1075,
          8019,
          20328,
          61,
          545147,
          35371,
          16183,
          1423,
          1565,
          522,
          18128,
          1892,
          4367,
          4845,
          11256,
          1617,
          1725,
          828,
          1126,
          1195,
          4090,
          2607,
          489,
          229,
          310,
          3805,
          1979,
          92294,
          5875,
          94014,
          477,
          94014,
          71335,
          3202,
          888,
          1925,
          1126,
          6469,
          459921,
          9165,
          1680,
          71485,
          4533,
          2526,
          123373,
          19408,
          4074,
          52,
          3807,
          6006,
          1770,
          46,
          1789,
          753116,
          71335,
          7692,
          33917,
          186140,
          1583,
          5875,
          6951,
          4081,
          100,
          42384,
          52,
          1760,
          450,
          2906700,
          2206,
          276002,
          765,
          832,
          142,
          341,
          46944,
          3495,
          532,
          1165,
          6006,
          413574,
          736284,
          337,
          722,
          4474,
          10295,
          1146,
          308,
          836,
          106,
          24645,
          3263,
          1643,
          526,
          331,
          2456,
          2971,
          1574,
          1979,
          92106,
          55581,
          184,
          118,
          1847,
          1745,
          4074,
          5875,
          1892,
          1382480,
          45303,
          1423,
          123,
          927396,
          163415,
          1979,
          1126,
          186140,
          1261,
          5548,
          13835,
          237282,
          3224,
          1132,
          459921,
          230,
          2089,
          1490,
          1595797,
          601723,
          224256,
          5621,
          1126,
          3104,
          128715,
          597,
          695,
          3996,
          94325,
          828,
          4542,
          4090,
          836,
          4090,
          136,
          1190,
          759,
          391389,
          673342,
          4424,
          63,
          111,
          5457,
          3776,
          76383,
          47249,
          331,
          1563,
          19090,
          823,
          551,
          270712,
          4878,
          4354,
          190,
          864,
          1190,
          1523,
          4474,
          238602,
          1656,
          172817,
          24840,
          3508,
          2258,
          687276,
          46563,
          372,
          158701,
          18459,
          571,
          828,
          49,
          3766,
          2644,
          1423,
          5791,
          100,
          13602,
          263,
          255,
          2401,
          242,
          45303,
          1532,
          722,
          186140,
          885,
          1186,
          165,
          1745,
          2368,
          1512,
          43,
          409656,
          3807,
          1363,
          1770,
          23,
          36784,
          3202,
          606,
          5875,
          466,
          736284,
          532,
          5719,
          1022298,
          863,
          140,
          6006,
          190,
          31394,
          34882,
          218,
          1923,
          5354,
          34882,
          16305,
          25459,
          217,
          419,
          22305,
          5895,
          1504,
          1617,
          3104,
          5196,
          522,
          47772,
          32891,
          276896,
          1735,
          104396,
          11432,
          124967,
          4726,
          2971,
          381459,
          186140,
          92608,
          1453,
          258,
          2211,
          15269,
          2807,
          15647,
          217,
          3228,
          1312,
          1263321,
          198,
          3255,
          1847,
          759,
          2317,
          2856,
          276896,
          804,
          5895,
          2328,
          7646,
          5901,
          409656,
          11250,
          632,
          1461,
          1190,
          4172,
          4653,
          110,
          76383,
          20478,
          470,
          1324,
          105638,
          1196,
          765,
          1196,
          1412,
          2060,
          134056,
          475,
          54767,
          186140,
          106,
          2092,
          308,
          6581,
          77,
          49,
          37,
          2526,
          128354,
          3263,
          106,
          77,
          50835,
          73,
          493806,
          519,
          695,
          1426,
          1490,
          67082,
          18128,
          1923,
          5875,
          276,
          737,
          5895,
          2368,
          20328,
          718,
          11751,
          158701,
          5211,
          26551,
          95,
          3495,
          673342,
          34882,
          190178,
          9034,
          1654,
          346,
          84106,
          509,
          4056,
          1261,
          295,
          4593,
          19685,
          640470,
          824,
          9815,
          233060,
          6284,
          12335,
          4913,
          224256,
          2148,
          84861,
          1606,
          1324,
          3805,
          1490,
          242,
          1324,
          2135,
          1166,
          733,
          139,
          3279,
          276896,
          2456,
          71335,
          1675,
          5895,
          1241364,
          75903,
          50835,
          224256,
          1666,
          194500,
          717255,
          3104,
          276,
          376,
          1089,
          1684,
          581,
          118,
          237282,
          686,
          1923,
          888,
          498,
          50835,
          3451,
          5875,
          2135,
          277,
          1892,
          910148,
          1810,
          242,
          1909,
          5341,
          836,
          2518,
          51,
          24645,
          4533,
          5760,
          270712,
          1019,
          207,
          134056,
          269,
          1517,
          5161,
          33804,
          46563,
          178,
          18408,
          741,
          4664,
          337,
          140,
          2870,
          2036,
          409656,
          104396,
          5950,
          475,
          471,
          551,
          338,
          74,
          381459,
          1686,
          18128,
          267,
          647,
          15623,
          1126,
          471,
          1089,
          1526206,
          976,
          4653,
          3688,
          564,
          1126,
          722,
          1523,
          42384,
          744,
          2211,
          478,
          1645,
          378909,
          2523,
          24536,
          9034,
          320420,
          3688,
          1532,
          864,
          3508,
          46,
          888,
          239,
          1363,
          4589,
          5760,
          419,
          673342,
          4542,
          828,
          2328,
          6120,
          166081,
          571,
          1490,
          1595797,
          1102,
          1075,
          1261,
          1595797,
          927396,
          878,
          1126,
          828,
          105638,
          43102,
          397,
          350,
          6018,
          74,
          1412,
          59705,
          74,
          1654,
          467,
          1446,
          765,
          6284,
          407,
          2328,
          270712,
          341,
          153,
          50835,
          7420,
          9679,
          899,
          76,
          1939,
          190249,
          888,
          5666,
          1423,
          564,
          48194,
          606,
          92106,
          27971,
          186140,
          798,
          100,
          5662,
          2644,
          5196,
          43,
          7155,
          450,
          13835,
          5666,
          1583,
          47,
          4593,
          1132,
          10076,
          31394,
          19090,
          22930,
          11751,
          1261,
          17867,
          972,
          16183,
          124967,
          341043,
          970,
          7163,
          270712,
          1274,
          71335,
          1312922,
          27020,
          277,
          11256,
          190178,
          5927,
          1504,
          230,
          45100,
          964,
          190178,
          759,
          21134,
          964,
          237282,
          6006,
          341,
          1271,
          530,
          647,
          1595797,
          804,
          111,
          33804,
          1810,
          4074,
          6120,
          267,
          34882,
          381459,
          267,
          832,
          2872,
          51,
          299480,
          1810,
          407,
          34882,
          54767,
          5778,
          673342,
          286,
          100,
          206,
          191096,
          776,
          2644,
          1252,
          2518,
          1810,
          140,
          606,
          6120,
          7155,
          310,
          7646,
          825,
          800,
          43,
          23,
          27971,
          136,
          737,
          241,
          4172,
          46,
          2526,
          1645,
          370,
          53,
          972,
          69793,
          1745,
          4074,
          1680,
          718,
          969,
          54767,
          823,
          241,
          1493,
          5726,
          321490,
          1577385,
          128715,
          18408,
          3688,
          4653,
          2566,
          35371,
          1530,
          910148,
          3223,
          718,
          1453,
          370,
          343,
          836,
          4512,
          14783,
          42384,
          18128,
          128,
          757530,
          3994,
          718,
          571,
          52126,
          76383,
          238602,
          489,
          973849,
          732,
          1383,
          238602,
          3279,
          43,
          911,
          67082,
          137067,
          52126,
          2870,
          355,
          1970,
          2501,
          321490,
          2644,
          13061,
          59744,
          198,
          1686,
          1442,
          6025,
          207,
          564,
          1512,
          564,
          3224,
          6469,
          2054,
          59744,
          912,
          471,
          1383,
          1312,
          3684,
          391389,
          800,
          836,
          642,
          67082,
          8097,
          5875,
          5216,
          19685,
          1288,
          86954,
          84106,
          18128,
          71485,
          391389,
          27020,
          1132,
          134056,
          27971,
          4729,
          3684,
          1166,
          2089,
          899,
          1645,
          276002,
          4354,
          92106,
          2368,
          2401,
          255,
          5438,
          5666,
          258,
          1831,
          124967,
          5895,
          589,
          695,
          18128,
          4913,
          1271,
          1526206,
          276002,
          341043,
          1038,
          222785,
          6469,
          4354,
          32891,
          172817,
          21902,
          2092,
          2054,
          299480,
          276002,
          878,
          84106,
          2471,
          2383912,
          122111,
          1446,
          2870,
          73,
          308,
          1766,
          2290,
          1689,
          277,
          1654,
          17867,
          1760,
          1810,
          42817,
          493,
          3699,
          217,
          7297,
          470,
          4533,
          5662,
          116001,
          18760,
          718,
          107941,
          895,
          467,
          5760,
          1892,
          32891,
          31394,
          94325,
          2786,
          1089,
          917,
          630,
          3876,
          61,
          686,
          11250,
          3451,
          2135,
          14871,
          85,
          1178,
          2906700,
          94014,
          743,
          230,
          2786,
          50489,
          100,
          242,
          606,
          207,
          346,
          1426,
          2906700,
          923,
          1523,
          1847,
          6120,
          470,
          191096,
          190178,
          3766,
          2523,
          493,
          757530,
          718,
          1725,
          899,
          530,
          333497,
          35371,
          641,
          443,
          2856,
          520,
          3807,
          3430,
          526,
          1324,
          759,
          1970,
          2807,
          5875,
          7297,
          3508,
          47,
          324,
          589,
          1850,
          5621,
          9165,
          571,
          26120,
          545147,
          111,
          1791,
          571,
          1656,
          595,
          343,
          824,
          399,
          597,
          864,
          302,
          20478,
          18760,
          5901,
          2121,
          192,
          4074,
          69,
          648,
          276002,
          2807,
          1360,
          34496,
          595,
          1132,
          518429,
          1810,
          4090,
          241,
          601723,
          136895,
          10076,
          2206,
          15269,
          94014,
          1288,
          23,
          129,
          1263321,
          123,
          320420,
          516,
          633,
          1789,
          21125,
          177,
          222785,
          247,
          1263321,
          922,
          1019,
          43,
          2435,
          805,
          1804,
          917,
          1617,
          255,
          134056,
          1352,
          191096,
          798,
          207,
          320420,
          23045,
          27971,
          2443,
          48194,
          69,
          124967,
          863,
          133,
          4049,
          18408,
          397,
          564,
          1472,
          6713,
          77,
          687276,
          263,
          67082,
          346,
          118,
          79613,
          804,
          1850,
          71335,
          18408,
          337,
          376,
          27020,
          133,
          22305,
          1643,
          673342,
          1617,
          647,
          2121,
          478,
          493806,
          34882,
          1089,
          606,
          74,
          24840,
          725,
          9772,
          128,
          307,
          321,
          3066,
          158701,
          478,
          1571,
          192,
          743,
          1075,
          77,
          630,
          601723,
          12747,
          1383,
          308,
          2906700,
          4993,
          470,
          27020,
          74,
          885,
          1847,
          5621,
          489,
          795,
          1453,
          151022,
          628,
          23727,
          828,
          1472,
          4508,
          22305,
          320,
          247,
          1532,
          71335,
          568,
          1363,
          718,
          2211,
          2971,
          328,
          4074,
          3430,
          2097,
          1850,
          2258,
          217,
          276896,
          4074,
          346,
          11256,
          9506,
          1760,
          493806,
          260,
          321,
          2303,
          640470,
          1263321,
          213,
          137067,
          343,
          1019,
          489,
          85,
          4575,
          2471,
          564,
          1680,
          1324,
          31394,
          31515,
          71485,
          9993,
          1574,
          498,
          3833,
          1735,
          22305,
          1532,
          158701,
          3224,
          46944,
          91,
          964,
          230,
          17867,
          4198,
          595,
          522,
          48194,
          680,
          370,
          6120,
          269,
          349,
          885,
          10076,
          310,
          5621,
          302,
          276002,
          3833,
          695,
          337,
          10295,
          5726,
          1679,
          11751,
          163415,
          73,
          1241364,
          413574,
          427,
          110,
          9594,
          302,
          2906700,
          2317,
          22191,
          4198,
          267,
          42619,
          626,
          43102,
          338,
          653,
          5719,
          804,
          2097,
          743,
          42817,
          2208,
          1140,
          23727,
          7646,
          85,
          177,
          1892,
          4575,
          350,
          4729,
          601723,
          269,
          6841,
          6508,
          207,
          471,
          106,
          87124,
          614,
          46563,
          11432,
          1789,
          5662,
          3032,
          2206,
          1302,
          276896,
          1925,
          823,
          765,
          5760,
          2317,
          409656,
          17867,
          645,
          3224,
          77,
          1725,
          509,
          1131,
          828,
          139,
          54185,
          344,
          3862,
          718,
          4354,
          2408,
          641349,
          19090,
          177,
          23,
          3776,
          6713,
          139650,
          20328,
          470,
          4677,
          12486,
          1363,
          470,
          2526,
          687276,
          1749,
          817312,
          34496,
          6703,
          1414,
          27971,
          471,
          1126,
          24840,
          718,
          84106,
          118,
          7420,
          606,
          4542,
          1850,
          47,
          4512,
          4993,
          479994,
          466,
          2644,
          3996,
          4575,
          1063,
          1631,
          2376,
          71463,
          7297,
          54185,
          9772,
          899,
          736284,
          238602,
          7565,
          2807,
          601723,
          42817,
          464,
          1686,
          32891,
          4542,
          1228,
          1760,
          9034,
          151785,
          37,
          589,
          276896,
          744,
          513,
          343,
          145,
          3495,
          198,
          595,
          2526,
          11250,
          1252,
          76383,
          972,
          633,
          7297,
          5791,
          2691,
          771,
          761,
          601723,
          4913,
          443,
          2408,
          346,
          765,
          47772,
          167,
          1080,
          344,
          2368,
          12335,
          92608,
          757530,
          1202,
          520,
          551,
          77,
          237282,
          5548,
          239,
          137,
          95015,
          139,
          3876,
          302,
          5927,
          725,
          1493,
          4993,
          565,
          771,
          2211,
          71485,
          381459,
          376,
          741,
          9784,
          1749,
          2036,
          276896,
          6951,
          22305,
          275,
          165556,
          156391,
          520,
          970,
          1595797,
          1979,
          192805,
          34496,
          13717,
          7155,
          92106,
          4533,
          230,
          4895,
          355,
          275,
          43,
          743,
          1563,
          145,
          551,
          3807,
          99,
          530,
          1847,
          6018,
          1841,
          2211,
          31394,
          165556,
          970,
          4049,
          888,
          564,
          276896,
          493806,
          86954,
          626,
          513,
          1532,
          165,
          2054,
          2644,
          23,
          18408,
          1735,
          2691,
          1420,
          22305,
          1966,
          1766,
          91,
          3032,
          647,
          1426,
          1412,
          1847,
          530,
          2906700,
          4471,
          630,
          885,
          551,
          516,
          35439,
          22191,
          94014,
          6025,
          1858,
          214703,
          7297,
          3833,
          1324,
          151815,
          30770,
          5791,
          895,
          1666,
          153,
          341043,
          59744,
          269,
          151022,
          464,
          95015,
          489,
          895,
          47772,
          10076,
          4895,
          14871,
          836,
          376,
          302,
          732,
          565,
          2148,
          224256,
          184,
          6284,
          267,
          48194,
          18408,
          1595797,
          1178,
          71463,
          71485,
          1412,
          35439,
          2223,
          5791,
          459921,
          11432,
          1617,
          3495,
          320420,
          565,
          5895,
          413574,
          35439,
          84106,
          632,
          914,
          564,
          324,
          836,
          1126,
          3263,
          1423,
          1532,
          28739,
          91,
          22191,
          295,
          47249,
          184,
          878,
          27971,
          27971,
          106,
          4542,
          795,
          639,
          77,
          878,
          832,
          973849,
          6703,
          229,
          190178,
          1078,
          16183,
          238602,
          47249,
          7155,
          37,
          1791,
          34496,
          270712,
          823,
          922,
          1304,
          2097,
          238602,
          23727,
          194500,
          190178,
          9587,
          22191,
          1841,
          2135,
          1675,
          18408,
          13983,
          1228,
          743,
          725,
          1324,
          277,
          2518,
          214518,
          911,
          828,
          276896,
          397,
          321490,
          3032,
          100,
          52126,
          5621,
          493806,
          11751,
          2799,
          124967,
          14783,
          2504700,
          1925,
          43102,
          104,
          970,
          798,
          2036,
          4677,
          104,
          467,
          85,
          1302,
          206,
          673342,
          341,
          1966,
          4845,
          1925,
          19090,
          4993,
          207410,
          276002,
          16163,
          673342,
          1178,
          725,
          99,
          21902,
          3032,
          248,
          76,
          118,
          31515,
          513,
          471,
          239,
          19408,
          5548,
          71335,
          328,
          632,
          104,
          67082,
          4653,
          1102,
          4895,
          1504,
          927396,
          5908,
          8097,
          378909,
          118,
          1293,
          61,
          928,
          5903,
          79008,
          378909,
          4367,
          647,
          254282,
          21635,
          828,
          23727,
          1228,
          4603,
          22305,
          1988,
          1302,
          9521,
          5760,
          6508,
          13717,
          43,
          4575,
          910148,
          1909,
          1126,
          124967,
          94014,
          142,
          1352,
          14871,
          1022298,
          498,
          888,
          5451,
          224256,
          673342,
          341,
          1263321,
          526,
          99,
          1617,
          77,
          1512,
          635,
          1089,
          1831,
          409656,
          5760,
          328,
          1645,
          391389,
          2097,
          631,
          568,
          2870,
          1909,
          878,
          46,
          475,
          75830,
          1089,
          18408,
          1312,
          7268,
          5726,
          1100,
          836,
          1360,
          632,
          2328,
          381459,
          606,
          737,
          140,
          71335,
          69,
          3202,
          19685,
          1080,
          1382480,
          2135,
          878,
          633,
          143,
          1563,
          2290,
          111,
          276002,
          1383,
          46,
          7268,
          470,
          192805,
          324,
          9815,
          5196,
          3495,
          69793,
          2303,
          836,
          1909,
          6581,
          736284,
          2368,
          2443,
          128715,
          25459,
          134056,
          2258,
          493,
          680,
          718,
          21902,
          42384,
          532,
          7430,
          51,
          67082,
          3487,
          3487,
          1131,
          258,
          753116,
          28425,
          1970,
          686,
          3279,
          9679,
          241,
          5577,
          86954,
          899,
          27020,
          1523,
          24840,
          1089,
          2870,
          355,
          1196,
          895,
          45303,
          165,
          2223,
          270712,
          3495,
          5548,
          269,
          1274,
          566,
          378909,
          1749,
          1324,
          18182,
          1988,
          45303,
          1312922,
          27020,
          2368,
          1506,
          21437,
          218,
          7155,
          965,
          1725,
          391389,
          2518,
          828,
          5927,
          1126,
          207410,
          1577385,
          478,
          254282,
          922,
          1139,
          498,
          5621,
          7430,
          151785,
          673342,
          2906700,
          5662,
          46563,
          5760,
          320420,
          320,
          1643,
          51427,
          1923,
          1686,
          1523,
          757530,
          43,
          3430,
          238602,
          4512,
          376,
          7268,
          1847,
          222785,
          207,
          737,
          589,
          33804,
          4354,
          1312922,
          525713,
          372,
          3202,
          85,
          6284,
          640470,
          581,
          1201,
          478,
          722,
          133,
          606,
          10295,
          2016,
          4993,
          1979,
          267,
          1645,
          520,
          21902,
          493806,
          1196,
          590,
          19685,
          52126,
          6581,
          2443,
          397,
          6469,
          759,
          338,
          26120,
          2304,
          140,
          33917,
          1988,
          34153,
          761,
          733,
          229,
          276002,
          3688,
          4074,
          736284,
          6120,
          67082,
          341,
          177,
          25459,
          878,
          313,
          2060,
          35439,
          47249,
          5507,
          4729,
          93193,
          50835,
          407,
          3862,
          16183,
          123,
          381459,
          608,
          1382480,
          95,
          1078,
          9993,
          878,
          1517,
          12335,
          76383,
          2435,
          1195,
          427,
          2148,
          75903,
          145,
          5778,
          626,
          207,
          741,
          4081,
          478,
          134056,
          516,
          1661,
          2518,
          1892,
          343,
          153,
          1789,
          42817,
          1745,
          1178,
          564,
          222,
          47772,
          1132,
          551,
          409656,
          258,
          1186,
          31515,
          4729,
          695,
          743,
          237282,
          1666,
          2395,
          1201,
          28425,
          84106,
          8007,
          77,
          21134,
          895,
          1656,
          5875,
          759,
          722,
          2078,
          87124,
          1789,
          6841,
          912,
          37,
          337,
          2395,
          9496,
          10295,
          888,
          8830,
          2906700,
          1831,
          233717,
          823,
          489,
          2456,
          3202,
          328,
          99,
          8874,
          741,
          123373,
          149,
          2135,
          565,
          914,
          602,
          2317,
          1988,
          3279,
          1363,
          4575,
          107941,
          370,
          695,
          11253,
          1165,
          4081,
          123,
          1412,
          222785,
          4729,
          1312,
          50835,
          27829,
          717255,
          79613,
          4367,
          237282,
          5196,
          15426,
          258,
          2142,
          635,
          276002,
          914,
          242,
          2906700,
          21902,
          50489,
          96942,
          167,
          2376,
          823,
          471,
          1504,
          888,
          1909,
          1946,
          13835,
          630,
          885,
          105638,
          895,
          1453,
          4512,
          4542,
          333497,
          489,
          2435,
          413574,
          673342,
          475,
          271,
          798,
          320420,
          3066,
          632,
          328,
          673342,
          1241364,
          6713,
          298,
          1606,
          1606,
          95,
          7155,
          15269,
          5791,
          6581,
          165,
          2263,
          1925,
          12349,
          1261,
          68211,
          4512,
          18182,
          885,
          1241364,
          348,
          1089,
          1925,
          276896,
          71463,
          177,
          917,
          59744,
          2202,
          84106,
          47249,
          206,
          8874,
          1312922,
          11751,
          1789,
          2395,
          50835,
          626,
          3451,
          333497,
          9993,
          639,
          18182,
          241,
          2501,
          6703,
          198,
          460,
          5354,
          45100,
          5161,
          6006,
          165,
          14742,
          22305,
          722,
          128715,
          4729,
          878,
          910148,
          687276,
          186140,
          1923,
          1804,
          4424,
          28278,
          100,
          344,
          163415,
          759,
          832,
          4056,
          1645,
          914,
          9521,
          2303,
          680,
          606,
          224256,
          3104,
          5341,
          639,
          5211,
          4575,
          4074,
          595,
          5895,
          626,
          4575,
          841711,
          229,
          136,
          463,
          45303,
          10256,
          13602,
          528,
          911,
          1140,
          1228,
          467,
          4680,
          2036,
          3688,
          378909,
          595,
          5507,
          5341,
          910148,
          1426,
          301,
          459921,
          1201,
          5760,
          45100,
          686,
          145,
          3766,
          4729,
          355,
          459921,
          71463,
          214703,
          824,
          16183,
          46,
          21134,
          337,
          21902,
          2456,
          27020,
          13717,
          5895,
          9034,
          22305,
          645,
          1923,
          1925,
          99,
          136,
          824,
          1536,
          378909,
          1368,
          328,
          1453,
          732,
          1563,
          5927,
          239,
          504,
          85,
          1490,
          9587,
          2395,
          4074,
          626,
          24536,
          395,
          4653,
          3766,
          765,
          1749,
          5512,
          153,
          1804,
          320420,
          2906700,
          71335,
          34882,
          47249,
          267,
          5621,
          1979,
          190178,
          608,
          1810,
          823,
          2456,
          337,
          493,
          53,
          263,
          4512,
          73,
          4005,
          233717,
          341043,
          1577385,
          3395,
          269,
          111,
          18182,
          254282,
          267,
          3684,
          84106,
          493,
          1420,
          137,
          1453,
          4542,
          5196,
          2368,
          2856,
          2206,
          207410,
          5577,
          9679,
          328,
          50835,
          1666,
          105549,
          18128,
          13061,
          238602,
          111,
          878,
          680,
          186140,
          230,
          254282,
          2856,
          205,
          3119,
          2691,
          302,
          3402,
          3104,
          2971,
          47772,
          413574,
          35371,
          823,
          1675,
          2368,
          341,
          19685,
          54767,
          1606,
          1363,
          640470,
          4726,
          1312922,
          177,
          1312,
          3684,
          13973,
          1271,
          192,
          1228,
          1443,
          3066,
          686,
          2504700,
          2408,
          94014,
          151022,
          99,
          69,
          1563,
          18182,
          269,
          27829,
          276896,
          1143,
          741,
          1190,
          4603,
          3996,
          1745,
          4726,
          2607,
          3395,
          21902,
          9034,
          2435,
          532,
          673342,
          1512,
          172817,
          863,
          5901,
          2135,
          213,
          50835,
          28425,
          71485,
          1063,
          4726,
          504,
          910148,
          2328,
          7646,
          2457,
          2401,
          73,
          2526,
          177,
          4726,
          1334,
          8097,
          2054,
          2258,
          123373,
          302,
          2523,
          1261,
          69,
          601723,
          190,
          42384,
          1075,
          571,
          1791,
          9993,
          861,
          2906700,
          28739,
          6469,
          733,
          2566,
          17047,
          194500,
          144160,
          1423,
          4726,
          71463,
          2786,
          823,
          128715,
          248858,
          8333,
          1725,
          116001,
          328,
          2202,
          207410,
          470,
          190249,
          2504700,
          695,
          5666,
          3776,
          94014,
          85,
          198,
          1526206,
          372,
          378909,
          5161,
          350,
          899,
          409656,
          137067,
          5161,
          454,
          647,
          14783,
          3684,
          2135,
          5354,
          214703,
          96942,
          8007,
          6629,
          217,
          172817,
          493806,
          3994,
          4290,
          459921,
          248858,
          198,
          1686,
          13973,
          765,
          4542,
          5548,
          258,
          237282,
          4074,
          107941,
          35299,
          7646,
          77,
          69,
          4878,
          276002,
          34153,
          320,
          343,
          2691,
          4542,
          427,
          4198,
          12335,
          601723,
          2368,
          105549,
          46563,
          100,
          4575,
          1261,
          1442,
          2836,
          1923,
          493,
          475,
          79008,
          782,
          8874,
          59744,
          99,
          18408,
          71335,
          1735,
          5438,
          241,
          922,
          255,
          741,
          69793,
          2206,
          2526,
          328,
          84106,
          100,
          258,
          3224,
          18128,
          863,
          2317,
          151815,
          4895,
          1923,
          5216,
          4090,
          19685,
          35371,
          34496,
          237282,
          5989,
          19090,
          328,
          1909,
          1490,
          1490,
          77,
          2906700,
          3096,
          5512,
          308,
          7268,
          4726,
          753116,
          198,
          46944,
          229,
          2471,
          632,
          71485,
          343,
          1263321,
          341043,
          1412,
          1178,
          1680,
          276,
          19408,
          370,
          530,
          1766,
          8097,
          1847,
          378909,
          46563,
          177,
          30770,
          222785,
          198,
          14871,
          111,
          9679,
          2054,
          50489,
          2376,
          663,
          78968,
          2158,
          504,
          2872,
          128354,
          3085,
          718,
          5577,
          4005,
          163415,
          3104,
          105549,
          911,
          1178,
          922,
          2060,
          2258,
          217,
          158701,
          632,
          20478,
          53,
          509,
          140,
          16163,
          5354,
          4367,
          626,
          31394,
          1368,
          1789,
          1909,
          92043,
          10076,
          54767,
          1131,
          1480,
          71485,
          2383912,
          341,
          205,
          184,
          4680,
          24645,
          48194,
          1078,
          2304,
          19054,
          2906700,
          1679,
          1075,
          190,
          1078,
          2368,
          2836,
          22305,
          4993,
          1302,
          184,
          5196,
          10256,
          1461,
          1166,
          217,
          19408,
          1760,
          5621,
          116001,
          1126,
          53,
          92337,
          73,
          7297,
          137,
          34153,
          4005,
          1661,
          9506,
          122111,
          937,
          2258,
          207,
          46944,
          105638,
          427,
          4664,
          477,
          269,
          7646,
          1512,
          2607,
          23,
          341,
          5927,
          99,
          1512,
          5657,
          13717,
          932,
          6469,
          270712,
          479994,
          1288,
          571,
          564,
          149,
          8333,
          67858,
          34153,
          836,
          3730,
          21134,
          134056,
          36438,
          49,
          1312,
          1506,
          2456,
          27829,
          5760,
          1312922,
          258,
          632,
          6581,
          6713,
          215,
          50489,
          863,
          525713,
          1645,
          602,
          12349,
          299480,
          466,
          1577385,
          241,
          372,
          630,
          298,
          344,
          8874,
          320420,
          291,
          324,
          1019,
          241,
          142,
          1571,
          5621,
          23805,
          142,
          895,
          94325,
          91,
          61,
          158701,
          1686,
          1312922,
          34882,
          111,
          471,
          93193,
          5196,
          460,
          378909,
          96942,
          509,
          1595797,
          1363,
          1595797,
          498,
          4573,
          5927,
          1595797,
          878,
          1766,
          2395,
          92608,
          1186,
          3766,
          743,
          1770,
          911,
          276896,
          298,
          5548,
          298,
          5950,
          914,
          1850,
          519,
          632,
          15647,
          54287,
          9993,
          888,
          328,
          91,
          140,
          680,
          509,
          27829,
          1166,
          230,
          1126,
          320420,
          686,
          626,
          761,
          258,
          3395,
          2906700,
          641349,
          1666,
          1228,
          1923,
          409656,
          3451,
          1631,
          190178,
          34496,
          3451,
          23045,
          349,
          606,
          736284,
          595,
          450,
          3688,
          1628,
          42619,
          258,
          224256,
          459921,
          346,
          105549,
          2121,
          302,
          13835,
          6841,
          372,
          124967,
          1078,
          964,
          156391,
          863,
          34153,
          270712,
          1334,
          47772,
          972,
          25459,
          321,
          3996,
          8019,
          6713,
          1766,
          1100,
          2856,
          1241364,
          804,
          5341,
          565,
          606,
          295,
          260,
          47249,
          6508,
          69793,
          123,
          59744,
          805,
          765,
          1523,
          477,
          365,
          54287,
          128354,
          49,
          4090,
          18408,
          1143,
          653,
          1022298,
          471,
          2566,
          302,
          18128,
          2317,
          407,
          571,
          151022,
          13061,
          31394,
          370,
          1453,
          910148,
          217,
          581,
          1075,
          1312922,
          19054,
          341,
          166081,
          7420,
          7163,
          2518,
          67082,
          28739,
          128,
          341043,
          765,
          630,
          14783,
          78968,
          31394,
          239,
          34882,
          2328,
          1909,
          540,
          899,
          5512,
          1261,
          23727,
          111,
          463,
          4512,
          9512,
          28425,
          263,
          626,
          5577,
          5950,
          4354,
          76383,
          168,
          1841,
          13717,
          743,
          13835,
          1725,
          123373,
          207,
          10717,
          14871,
          1363,
          5341,
          144160,
          5512,
          15647,
          2661,
          1312922,
          647,
          128715,
          409656,
          836,
          241,
          718,
          2054,
          466,
          1271,
          54287,
          10295,
          4729,
          7155,
          1228,
          749635,
          337,
          1423,
          21134,
          88735,
          260,
          118,
          475,
          168,
          4049,
          5619,
          1735,
          10717,
          1360,
          1363,
          1930,
          337,
          1789,
          9815,
          640470,
          258,
          2307,
          504,
          409656,
          4354,
          2258,
          2523,
          238602,
          475,
          192805,
          276002,
          186140,
          932,
          923,
          38912,
          2148,
          972,
          519,
          71463,
          247,
          151815,
          308,
          9594,
          2016,
          95,
          5548,
          92294,
          3096,
          516,
          313,
          2304,
          34882,
          2304,
          68211,
          36784,
          2395,
          1190,
          267,
          30770,
          76,
          391389,
          166081,
          7297,
          1970,
          1363,
          2054,
          343,
          18408,
          87124,
          19054,
          1847,
          260,
          73,
          134056,
          343,
          4090,
          1532,
          84106,
          937,
          1595797,
          10076,
          606,
          85,
          10717,
          111,
          765,
          6581,
          1022298,
          1536,
          1263321,
          2078,
          1312,
          389246,
          391389,
          1766,
          2328,
          471,
          22930,
          328,
          1383,
          4090,
          493806,
          3255,
          1858,
          1892,
          346,
          241,
          6284,
          258,
          21902,
          224256,
          71335,
          923,
          413574,
          76383,
          1606,
          885,
          260,
          4074,
          271,
          647,
          21902,
          1571,
          895,
          1426,
          28739,
          1526206,
          34496,
          6006,
          341,
          32891,
          1126,
          207,
          722,
          2870,
          13061,
          757530,
          540,
          590,
          186140,
          395,
          186140,
          8333,
          540,
          1595797,
          932,
          6951,
          263,
          910148,
          1897,
          5507,
          21902,
          36438,
          2206,
          19685,
          158701,
          1304,
          7430,
          4056,
          276,
          5895,
          46563,
          4729,
          3224,
          973849,
          1847,
          1446,
          2661,
          606,
          1201,
          320420,
          8019,
          5719,
          5341,
          4154,
          564,
          5621,
          1766,
          4878,
          471,
          18128,
          478,
          1766,
          198,
          782,
          104,
          73,
          9993,
          136,
          836,
          3688,
          13602,
          798,
          6284,
          242,
          19054,
          34882,
          5950,
          3096,
          4664,
          653,
          217,
          2036,
          2135,
          765,
          5989,
          1166,
          3688,
          1760,
          11432,
          6703,
          737,
          31515,
          79613,
          641349,
          489,
          28739,
          9993,
          2376,
          27971,
          276896,
          2307,
          5848,
          3289,
          589,
          134056,
          49,
          626,
          50835,
          17867,
          3032,
          1946,
          67082,
          1178,
          3224,
          4474,
          137,
          333497,
          1628,
          1132,
          782,
          725,
          4471,
          215,
          21902,
          1656,
          795,
          55345,
          11250,
          1577385,
          47772,
          348,
          13061,
          525713,
          2202,
          2036,
          18408,
          932,
          156391,
          3688,
          17867,
          116001,
          168,
          7646,
          413574,
          2290,
          1656,
          206,
          5666,
          642,
          1312,
          8874,
          2471,
          645,
          43,
          4138,
          3487,
          760,
          571,
          321490,
          47249,
          47249,
          1102,
          782,
          2443,
          229,
          71335,
          477,
          6469,
          337,
          123373,
          8874,
          177,
          47249,
          606,
          817312,
          5619,
          198,
          4575,
          341,
          171170,
          35371,
          2518,
          478,
          914,
          3228,
          3996,
          5354,
          427,
          190178,
          258,
          9679,
          79613,
          633,
          914,
          163415,
          2504700,
          11250,
          4575,
          3279,
          477,
          602,
          1645,
          717255,
          76383,
          530,
          333497,
          344,
          1420,
          151022,
          1453,
          653,
          765,
          95,
          128715,
          680,
          7646,
          760,
          1749,
          78968,
          46944,
          85,
          1766,
          48194,
          722,
          20328,
          214703,
          525713,
          269,
          3104,
          237282,
          1132,
          258,
          1126,
          1831,
          3876,
          2290,
          54287,
          911,
          4542,
          70,
          1970,
          7268,
          4474,
          378909,
          276002,
          467,
          626,
          1758,
          1146,
          895,
          2328,
          137067,
          94014,
          805,
          2036,
          3807,
          1412,
          269,
          324,
          914,
          419,
          186140,
          67082,
          1089,
          4913,
          1946,
          1352,
          732,
          823,
          2202,
          1186,
          1745,
          737,
          35439,
          4198,
          149,
          2807,
          61,
          310,
          5760,
          1536,
          1312,
          532,
          504,
          467,
          1595797,
          4049,
          409656,
          76383,
          217,
          239,
          4074,
          186140,
          1140,
          516,
          267,
          632,
          1909,
          263,
          1423,
          1271,
          376,
          836,
          192,
          564,
          1166,
          1423,
          910148,
          1643,
          192805,
          725,
          36438,
          463,
          1595797,
          2408,
          34882,
          149,
          239,
          498,
          1140,
          255,
          7297,
          104396,
          19054,
          21902,
          910148,
          75903,
          54287,
          116001,
          970,
          5760,
          1178,
          606,
          4074,
          17867,
          1324,
          1252,
          331,
          1414,
          680,
          1725,
          207410,
          3458,
          1526206,
          2644,
          28425,
          111,
          3032,
          3279,
          59744,
          2054,
          5666,
          2078,
          1190,
          973849,
          632,
          1453,
          1780,
          52126,
          1909,
          2376,
          2971,
          760,
          626,
          11256,
          3289,
          3833,
          632,
          4090,
          31394,
          1261,
          4056,
          1423,
          4074,
          4367,
          606,
          6703,
          2121,
          165556,
          3224,
          1453,
          2661,
          134056,
          1526206,
          192,
          16305,
          181438,
          568,
          2135,
          1414,
          1507,
          47249,
          99,
          166081,
          5548,
          471,
          1201,
          32891,
          215,
          1126,
          198,
          2148,
          12349,
          28739,
          237282,
          2906700,
          67082,
          4533,
          2836,
          214703,
          2518,
          760,
          743,
          118,
          601723,
          911,
          11256,
          579,
          378909,
          149,
          136,
          895,
          419,
          313,
          207410,
          46563,
          1140,
          3862,
          1925,
          1504,
          76383,
          1897,
          1312922,
          137,
          116155,
          177,
          53,
          7692,
          151815,
          724,
          34153,
          2383912,
          54767,
          25459,
          198,
          663,
          26551,
          1078,
          1810,
          16183,
          1196,
          606,
          754,
          2916,
          184,
          1532,
          3263,
          21134,
          310,
          825,
          1762,
          1271,
          32891,
          328,
          3223,
          741,
          463,
          4424,
          276,
          3996,
          4090,
          571,
          128,
          1679,
          75830,
          142,
          73,
          7297,
          13422,
          276002,
          633,
          258,
          241,
          525713,
          16183,
          32891,
          3766,
          970,
          144160,
          1302,
          2376,
          1195,
          116001,
          749635,
          128715,
          6951,
          165556,
          1423,
          571,
          110,
          2456,
          5901,
          601723,
          5354,
          381459,
          8830,
          7297,
          1196,
          895,
          2523,
          28278,
          76,
          489,
          1504,
          78968,
          348,
          36784,
          1288,
          190249,
          76383,
          4306,
          10076,
          6629,
          128,
          725,
          19090,
          163415,
          17047,
          695,
          5989,
          276896,
          13717,
          10076,
          18408,
          3996,
          1126,
          19408,
          493806,
          1190,
          1382480,
          4542,
          571,
          5901,
          3343,
          910148,
          381459,
          28425,
          2376,
          86954,
          642,
          83,
          5901,
          24536,
          3688,
          35439,
          129,
          229,
          1190,
          348,
          467,
          31394,
          7692,
          4533,
          765,
          20328,
          475,
          67858,
          2258,
          964,
          313,
          811,
          1523,
          11751,
          23727,
          2906700,
          122111,
          1063,
          3996,
          6713,
          145,
          1166,
          328,
          238602,
          79008,
          1252,
          241,
          759,
          722,
          1523,
          695,
          2856,
          522,
          1241364,
          427,
          18128,
          2644,
          328,
          606,
          276896,
          718,
          116001,
          1453,
          214703,
          372,
          630,
          6006,
          369,
          743,
          192,
          71485,
          1512,
          5438,
          3805,
          725,
          525713,
          1132,
          276896,
          965,
          5760,
          1360,
          3224,
          1190,
          1923,
          1334,
          10076,
          1263321,
          606,
          1970,
          914,
          1089,
          1858,
          1478,
          10076,
          3684,
          1892,
          372,
          2836,
          551,
          224256,
          601723,
          1261,
          26551,
          27971,
          198,
          551,
          71485,
          1019,
          771,
          128715,
          973849,
          3279,
          45100,
          673342,
          346,
          1271,
          1019,
          1966,
          69,
          1512,
          67082,
          2906700,
          823,
          241,
          247,
          4653,
          190178,
          4172,
          5791,
          4474,
          11751,
          71463,
          128,
          3395,
          6120,
          1970,
          116155,
          1166,
          1760,
          1480,
          4056,
          4778,
          343,
          61,
          5161,
          7155,
          85,
          341,
          190178,
          116001,
          2644,
          3776,
          6469,
          4005,
          128715,
          341,
          5875,
          1762,
          1939,
          47249,
          2807,
          825,
          928,
          1089,
          467,
          648,
          504,
          346,
          341,
          23,
          680,
          828,
          22191,
          337,
          348,
          31515,
          20328,
          1140,
          1306,
          509,
          158701,
          1201,
          828,
          95035,
          686,
          258,
          606,
          2395,
          2211,
          333497,
          1139,
          1532,
          847,
          177,
          630,
          23727,
          516,
          19054,
          2566,
          168,
          218,
          3255,
          1766,
          100,
          725,
          328,
          9993,
          207410,
          19090,
          1178,
          626,
          6713,
          1022298,
          172817,
          5211,
          635,
          28425,
          2211,
          5901,
          782,
          1595797,
          19685,
          1453,
          3862,
          564,
          3451,
          2457,
          337,
          589,
          184,
          1140,
          885,
          165556,
          145,
          116001,
          1263321,
          3224,
          4508,
          2607,
          823,
          20478,
          4512,
          4090,
          269,
          647,
          9506,
          5875,
          4993,
          4845,
          6120,
          320420,
          1131,
          258,
          1140,
          864,
          6434,
          749635,
          27971,
          6703,
          1675,
          6703,
          733,
          1565,
          165,
          22305,
          1970,
          828,
          3508,
          4729,
          732,
          1302,
          520,
          34882,
          237282,
          4913,
          10717,
          1532,
          1760,
          35299,
          47249,
          27829,
          912,
          687276,
          2307,
          324,
          46944,
          71463,
          190178,
          105549,
          16183,
          1725,
          1643,
          95035,
          14871,
          1051,
          899,
          15426,
          343,
          2290,
          1442,
          87124,
          1892,
          7297,
          31515,
          233060,
          608,
          1382480,
          213,
          302,
          7155,
          344,
          7646,
          76383,
          5354,
          741,
          5211,
          67082,
          136895,
          863,
          47249,
          1131,
          378909,
          520,
          18760,
          2870,
          1178,
          1766,
          1700,
          3228,
          92337,
          5989,
          635,
          92043,
          1628,
          4913,
          79613,
          2211,
          321,
          1420,
          1523,
          111,
          10717,
          12335,
          237282,
          10076,
          1804,
          28739,
          2971,
          477,
          2916,
          1131,
          241,
          680,
          532,
          5903,
          2395,
          466,
          337,
          641349,
          1684,
          308,
          614,
          30770,
          271,
          635,
          71485,
          8333,
          192,
          92043,
          19054,
          269,
          4159,
          1087,
          4056,
          2523,
          54287,
          105638,
          1645,
          32891,
          85,
          5903,
          1261,
          2518,
          1512,
          1263321,
          178,
          489,
          218,
          92985,
          914,
          798,
          530,
          467,
          765,
          1312,
          1988,
          198,
          4542,
          5341,
          1360,
          3684,
          1645,
          4913,
          12486,
          224256,
          260,
          369,
          1745,
          571,
          224256,
          633,
          498,
          12335,
          302,
          3395,
          595,
          224256,
          18182,
          3343,
          214703,
          9051,
          123373,
          3395,
          4074,
          4049,
          297,
          136,
          1143,
          21437,
          276002,
          145,
          566,
          1966,
          1126,
          1897,
          912,
          1166,
          1536,
          5760,
          20478,
          10717,
          151815,
          302,
          3684,
          372,
          5875,
          5211,
          46,
          7155,
          218,
          3279,
          601723,
          765,
          214703,
          4542,
          1412,
          6951,
          79613,
          1725,
          21134,
          5512,
          95015,
          71485,
          571,
          498,
          5161,
          1804,
          6581,
          2504700,
          4913,
          1228,
          3699,
          129,
          2523,
          2836,
          1324,
          134056,
          4573,
          61,
          276896,
          632,
          1791,
          1507,
          2906700,
          124967,
          2836,
          337,
          71485,
          1102,
          545147,
          969,
          1186,
          2870,
          217,
          910148,
          10717,
          2906700,
          2691,
          77,
          87124,
          2644,
          630,
          4720,
          258,
          100,
          1089,
          686,
          137067,
          134056,
          427,
          1595797,
          757530,
          2263,
          9496,
          52126,
          34153,
          466,
          218,
          5548,
          1892,
          106,
          545147,
          516,
          1263321,
          224256,
          1643,
          237282,
          2523,
          1423,
          759,
          828,
          43,
          1831,
          84106,
          9772,
          20328,
          2456,
          5895,
          1139,
          1461,
          7297,
          2142,
          271,
          3451,
          502,
          5760,
          4424,
          2054,
          518429,
          79613,
          972,
          158701,
          3766,
          12335,
          203571,
          95,
          741,
          365,
          190178,
          320,
          888,
          1725,
          1770,
          391389,
          205,
          899,
          771,
          365,
          17867,
          5621,
          19054,
          1766,
          16163,
          341043,
          198,
          917,
          3833,
          177,
          14228,
          639,
          186140,
          22305,
          86954,
          11751,
          270712,
          92043,
          123373,
          169,
          4575,
          2376,
          5211,
          1507,
          464,
          1631,
          307,
          8097,
          1453,
          163415,
          105549,
          2807,
          1143,
          84106,
          34496,
          177,
          1139,
          5908,
          1383,
          258,
          341,
          653,
          502,
          1810,
          1517,
          95,
          743,
          640470,
          1514,
          632,
          267,
          255,
          254,
          1126,
          1271,
          22305,
          824,
          1461,
          5895,
          2092,
          107941,
          4726,
          520,
          2097,
          23,
          172247,
          71335,
          4653,
          52126,
          1201,
          112,
          633,
          258,
          2258,
          3255,
          2872,
          128715,
          1758,
          3289,
          333497,
          5989,
          307,
          4729,
          136,
          186140,
          673342,
          2526,
          215,
          163415,
          88735,
          2054,
          1383,
          743,
          5989,
          760,
          663,
          1195,
          27020,
          6120,
          28739,
          222785,
          239,
          3395,
          673342,
          18128,
          528,
          765,
          1480,
          595,
          247,
          207410,
          61,
          1523,
          2401,
          1675,
          3766,
          21125,
          642,
          2971,
          912,
          3289,
          13973,
          1758,
          48194,
          116001,
          1383,
          36784,
          878,
          737,
          477,
          9594,
          5619,
          51427,
          2158,
          759,
          1631,
          1810,
          1504,
          811,
          1078,
          13835,
          302,
          4367,
          50835,
          104396,
          1383,
          530,
          765,
          1263321,
          276896,
          122111,
          2501,
          645,
          2368,
          2135,
          2258,
          1190,
          71335,
          3285,
          190178,
          1666,
          509,
          341,
          888,
          564,
          1382480,
          1490,
          3508,
          1526206,
          217,
          85,
          4533,
          2148,
          94014,
          18408,
          828,
          5354,
          1102,
          260,
          1749,
          291,
          530,
          1201,
          427,
          2208,
          602,
          885,
          267,
          804,
          1762,
          214703,
          5908,
          478,
          571,
          365,
          55581,
          1807,
          5457,
          493806,
          92985,
          302,
          1684,
          2836,
          1595797,
          1526206,
          1443,
          237282,
          260,
          37,
          34882,
          349,
          4198,
          1478,
          3224,
          2274,
          320,
          606,
          601723,
          5657,
          54767,
          1078,
          92608,
          632,
          172817,
          3104,
          565,
          184,
          972,
          2456,
          1202,
          9815,
          937,
          320420,
          181438,
          749635,
          581,
          378909,
          551,
          640470,
          1850,
          255,
          2501,
          95035,
          663,
          1179,
          16305,
          1725,
          647,
          5791,
          5908,
          15269,
          1412,
          163415,
          1312922,
          2135,
          1530,
          18182,
          2328,
          186140,
          722,
          6508,
          489,
          95,
          8874,
          365,
          1532,
          69,
          60,
          1352,
          479994,
          1196,
          1312,
          2691,
          1679,
          969,
          653,
          460,
          467,
          1946,
          2501,
          7987,
          895,
          2872,
          7163,
          4474,
          349,
          937,
          1352,
          1126,
          1897,
          276896,
          27971,
          969,
          2691,
          69793,
          3508,
          15647,
          1261,
          241,
          1810,
          9772,
          8512,
          321,
          313,
          136,
          471,
          1925,
          863,
          564,
          84106,
          263,
          9993,
          828,
          631,
          229,
          710,
          2317,
          149,
          349,
          606,
          1382480,
          2121,
          1617,
          427,
          7268,
          27020,
          218,
          1186,
          3430,
          2408,
          1512,
          21134,
          1656,
          343,
          269,
          836,
          5760,
          878,
          427,
          12335,
          218,
          255,
          71335,
          760,
          2526,
          1288,
          1126,
          1766,
          60,
          1749,
          6951,
          3807,
          124967,
          1680,
          8007,
          5161,
          128715,
          94325,
          230,
          895,
          878,
          2807,
          5895,
          149,
          144160,
          139,
          53,
          4074,
          2607,
          1762,
          2471,
          409656,
          964,
          413574,
          1293,
          84106,
          11256,
          3032,
          186140,
          184,
          911,
          233717,
          1312922,
          276896,
          828,
          1523,
          2870,
          653,
          1490,
          94014,
          4074,
          1190,
          69,
          128354,
          841711,
          94014,
          151785,
          912,
          7155,
          3994,
          1472,
          1131,
          1909,
          36784,
          475,
          498,
          1645,
          86954,
          2644,
          42817,
          895,
          504,
          1089,
          5791,
          737,
          602,
          2408,
          2089,
          140,
          8874,
          1762,
          224256,
          116001,
          166081,
          532,
          237282,
          3224,
          25459,
          5196,
          4677,
          149,
          3766,
          23,
          5875,
          841711,
          341,
          17047,
          1304,
          1745,
          47772,
          163415,
          34496,
          686,
          1700,
          14228,
          513,
          2456,
          71463,
          68211,
          17867,
          2607,
          217,
          118,
          5621,
          341043,
          9565,
          564,
          277,
          722,
          3202,
          4090,
          1302,
          46944,
          409656,
          5196,
          2916,
          922,
          1140,
          606,
          6629,
          1302,
          46944,
          1446,
          399,
          3402,
          602,
          331,
          100,
          270712,
          4056,
          7297,
          34882,
          4090,
          1943,
          123,
          1241364,
          181438,
          717255,
          1312922,
          13602,
          133,
          269,
          1789,
          343,
          88735,
          614,
          2435,
          134056,
          95015,
          270712,
          331,
          254282,
          213,
          1423,
          13973,
          213,
          4726,
          3228,
          7430,
          1909,
          765,
          171170,
          1970,
          5895,
          741,
          4367,
          972,
          1749,
          743,
          2443,
          350,
          1078,
          1766,
          31515,
          520,
          391389,
          302,
          7430,
          365,
          16183,
          69,
          3688,
          3119,
          4573,
          743,
          75903,
          910148,
          6469,
          124967,
          1453,
          286,
          1274,
          241,
          1241364,
          1078,
          2607,
          5341,
          8830,
          914,
          2566,
          1595797,
          276002,
          28278,
          3402,
          116001,
          105638,
          467,
          2523,
          847,
          1661,
          302,
          1446,
          391389,
          190178,
          45100,
          765,
          581,
          5875,
          1841,
          863,
          6018,
          568,
          1725,
          1324,
          7163,
          1645,
          595,
          46563,
          1426,
          1178,
          165,
          184,
          502,
          2607,
          13973,
          2870,
          17867,
          267,
          516,
          205,
          69,
          5354,
          459921,
          725,
          27971,
          5657,
          3224,
          28425,
          1228,
          973849,
          190178,
          2368,
          77,
          1679,
          2379,
          18128,
          123373,
          46563,
          10076,
          1583,
          13422,
          126,
          2856,
          7430,
          2644,
          3688,
          5666,
          346,
          1595797,
          1131,
          5666,
          10295,
          13717,
          759,
          520,
          885,
          1102,
          276002,
          23,
          2208,
          207,
          5903,
          2906700,
          475,
          3430,
          2607,
          1858,
          504,
          1979,
          21902,
          276,
          1762,
          1102,
          463,
          2523,
          59744,
          54287,
          19685,
          23727,
          27971,
          270712,
          9594,
          52,
          1271,
          198,
          74,
          3202,
          27971,
          1512,
          190,
          69,
          1810,
          899,
          1504,
          28278,
          2368,
          828,
          42619,
          1807,
          20478,
          1363,
          928,
          116001,
          43102,
          18408,
          5451,
          391389,
          203571,
          8874,
          4056,
          2368,
          5512,
          4726,
          4533,
          3451,
          2607,
          2376,
          20478,
          427,
          1080,
          32891,
          1274,
          899,
          1102,
          13835,
          134056,
          964,
          2566,
          1288,
          28278,
          270712,
          128,
          50489,
          463,
          4508,
          771,
          355,
          12747,
          144160,
          590,
          11250,
          32891,
          1645,
          136895,
          5760,
          1770,
          69,
          25459,
          140,
          47249,
          238602,
          145,
          238602,
          3688,
          2328,
          8874,
          5875,
          1132,
          606,
          722,
          4081,
          2328,
          1178,
          2206,
          71485,
          18182,
          632,
          23045,
          597,
          186140,
          2786,
          4471,
          1512,
          32891,
          205,
          78968,
          51,
          137067,
          1512,
          270712,
          5662,
          6284,
          313,
          14228,
          31515,
          6629,
          1022298,
          5548,
          4895,
          43,
          16183,
          21437,
          13717,
          128354,
          5548,
          124967,
          206,
          54767,
          3402,
          18128,
          1324,
          276,
          1504,
          9496,
          606,
          8874,
          12349,
          163415,
          75903,
          5548,
          11256,
          190178,
          341,
          139650,
          647,
          348,
          1126,
          1770,
          2092,
          129,
          1679,
          190178,
          2644,
          4677,
          1146,
          5438,
          1504,
          1201,
          413574,
          73,
          31515,
          673342,
          743,
          3289,
          15269,
          92608,
          571,
          20478,
          744,
          28739,
          1666,
          1196,
          1063,
          1312922,
          11256,
          4354,
          1423,
          341043,
          9587,
          9772,
          5875,
          5621,
          1126,
          165556,
          2290,
          9784,
          129,
          1804,
          601723,
          413574,
          241,
          77,
          36438,
          498,
          1312922,
          391389,
          123,
          34153,
          761,
          1780,
          1190,
          1426,
          4172,
          3289,
          564,
          413574,
          823,
          269,
          3451,
          237282,
          1075,
          4603,
          269,
          5161,
          15647,
          24840,
          32891,
          489,
          95,
          105638,
          1504,
          4729,
          302,
          565,
          1453,
          6469,
          475,
          1507,
          35371,
          722,
          1841,
          3833,
          545147,
          733,
          606,
          5161,
          21125,
          35439,
          7420,
          100,
          105638,
          895,
          2526,
          1504,
          49,
          964,
          1661,
          1196,
          15623,
          151785,
          1595797,
          519,
          55345,
          632,
          2870,
          2872,
          11250,
          46944,
          337,
          24840,
          409656,
          899,
          13717,
          84106,
          1654,
          207,
          1565,
          1595797,
          828,
          13973,
          71485,
          9815,
          5901,
          4542,
          1988,
          275,
          540,
          52126,
          31394,
          267,
          137067,
          1523,
          7430,
          3066,
          1850,
          8874,
          5778,
          2148,
          105638,
          601723,
          331,
          341043,
          26551,
          19685,
          737,
          223,
          2290,
          276002,
          9815,
          5507,
          218,
          168,
          1383,
          92043,
          475,
          71335,
          630,
          1666,
          888,
          11250,
          258,
          11256,
          176,
          27829,
          50835,
          207410,
          551,
          1847,
          895,
          1858,
          27971,
          302,
          172817,
          270712,
          177,
          3807,
          832,
          75830,
          477,
          241,
          532,
          1690,
          1241364,
          11250,
          878,
          1461,
          248,
          52,
          1302,
          313,
          46,
          47772,
          911,
          9772,
          1426,
          128354,
          5161,
          99,
          2211,
          519,
          217,
          2872,
          1700,
          21437,
          1312922,
          128715,
          1523,
          647,
          641,
          1766,
          218,
          795,
          1178,
          722,
          224256,
          1526206,
          328,
          5760,
          241,
          551,
          308,
          1490,
          4474,
          927396,
          255,
          343,
          5354,
          346,
          493,
          328,
          2328,
          1063,
          823,
          3996,
          9815,
          14871,
          1288,
          878,
          42384,
          1804,
          1443,
          1143,
          1925,
          13422,
          5666,
          3104,
          3224,
          272134,
          973849,
          5927,
          608,
          47249,
          24536,
          95,
          7155,
          6581,
          76,
          2060,
          4508,
          4533,
          749635,
          4049,
          8830,
          100,
          1841,
          1925,
          10076,
          2376,
          100,
          391389,
          50835,
          759,
          23,
          133,
          5211,
          324,
          79008,
          571,
          1700,
          9565,
          391389,
          3688,
          409656,
          1324,
          635,
          5577,
          32891,
          927396,
          153,
          1132,
          78968,
          2036,
          911,
          218,
          1312922,
          11250,
          79008,
          34153,
          2523,
          30770,
          7268,
          1661,
          2906700,
          1196,
          5666,
          7155,
          1526206,
          207,
          18760,
          1178,
          3805,
          15623,
          645,
          5989,
          584,
          3684,
          116155,
          229,
          27971,
          43,
          53,
          498,
          724,
          3343,
          2258,
          1847,
          1645,
          466,
          753116,
          608,
          7268,
          9165,
          2786,
          20328,
          1595797,
          55345,
          5895,
          1442,
          564,
          1312922,
          263,
          1312922,
          1675,
          765,
          165,
          1631,
          67082,
          733,
          602,
          4172,
          1493,
          2471,
          190,
          11432,
          1190,
          5927,
          3430,
          110,
          824,
          302,
          128715,
          260,
          1512,
          190178,
          914,
          68211,
          5760,
          333497,
          22305,
          1749,
          60,
          19685,
          1038,
          3224,
          237282,
          2054,
          640470,
          207410,
          126,
          1312922,
          2644,
          6006,
          5875,
          5875,
          14075,
          241,
          736284,
          5548,
          8097,
          1892,
          3285,
          321,
          823,
          2501,
          885,
          11253,
          19090,
          13422,
          3807,
          471,
          1102,
          177,
          118,
          1178,
          6508,
          413574,
          19054,
          68211,
          2401,
          5457,
          25459,
          181438,
          753116,
          369,
          911,
          470,
          3032,
          725,
          20328,
          83,
          1847,
          5875,
          1656,
          2836,
          2906700,
          2054,
          5548,
          6841,
          4074,
          172247,
          1089,
          836,
          759,
          4680,
          2661,
          2395,
          7297,
          1725,
          551,
          123373,
          18128,
          79613,
          471,
          2135,
          4015,
          530,
          53,
          1446,
          74,
          71485,
          1645,
          1684,
          3202,
          3833,
          1858,
          5791,
          743,
          459921,
          71335,
          2435,
          1684,
          103927,
          409656,
          1261,
          606,
          54287,
          46,
          149,
          532,
          110,
          5901,
          765,
          23727,
          54185,
          2376,
          217,
          1478,
          5903,
          276002,
          67082,
          1526206,
          1923,
          2661,
          18128,
          4913,
          4508,
          1143,
          467,
          5662,
          13973,
          5512,
          192805,
          192,
          1263321,
          1126,
          11250,
          504,
          4993,
          1420,
          6841,
          172817,
          297,
          673342,
          5621,
          800,
          45303,
          307,
          61,
          7268,
          475,
          6951,
          1656,
          140,
          1100,
          27971,
          1196,
          218,
          14228,
          18408,
          24536,
          28425,
          4653,
          571,
          1923,
          498,
          100,
          21125,
          46944,
          2307,
          1423,
          349,
          471,
          895,
          1847,
          68211,
          376,
          489,
          10717,
          47211,
          2872,
          6120,
          153,
          1766,
          595,
          140,
          137,
          53,
          291,
          258,
          1643,
          13973,
          409656,
          241,
          30770,
          686,
          7268,
          1970,
          15426,
          2906700,
          123,
          71485,
          69,
          917,
          2836,
          2856,
          76383,
          23,
          601723,
          19408,
          969,
          964,
          107941,
          1760,
          2290,
          19054,
          341043,
          331,
          7163,
          9772,
          4056,
          1762,
          513,
          9815,
          4508,
          47249,
          5211,
          84106,
          2304,
          1019,
          258,
          324,
          69793,
          467,
          4729,
          478,
          1201,
          863,
          1656,
          1574,
          1595797,
          631,
          4895,
          129,
          1228,
          5875,
          1179,
          2202,
          123,
          350,
          43,
          105549,
          5621,
          3807,
          31515,
          67082,
          509,
          19408,
          341043,
          565,
          33917,
          2786,
          129,
          3451,
          10076,
          276,
          1478,
          3395,
          1383,
          2872,
          32891,
          2078,
          48194,
          34882,
          7646,
          7565,
          22930,
          602,
          73,
          76,
          828,
          1970,
          247,
          4729,
          18182,
          269,
          55581,
          213,
          52,
          3032,
          5657,
          2870,
          828,
          824,
          932,
          153,
          5507,
          198,
          99,
          6469,
          341043,
          635,
          595,
          222785,
          1063,
          1312922,
          2504700,
          2870,
          6284,
          54185,
          3451,
          771,
          381459,
          2317,
          1810,
          568,
          10076,
          2661,
          1195,
          1263321,
          77,
          103927,
          3289,
          92294,
          31970,
          5875,
          59744,
          4542,
          1749,
          2368,
          5895,
          70,
          471,
          2368,
          238602,
          1897,
          31515,
          76383,
          7297,
          1645,
          3451,
          606,
          341043,
          1412,
          1426,
          9051,
          36438,
          530,
          932,
          2870,
          11256,
          23805,
          911,
          489,
          222785,
          86954,
          1426,
          205,
          24840,
          4575,
          743,
          1758,
          5354,
          687276,
          4542,
          6025,
          233717,
          16183,
          191096,
          254282,
          3032,
          4367,
          2395,
          2148,
          7987,
          4354,
          7646,
          271,
          5196,
          928,
          140,
          70,
          5908,
          516,
          3862,
          190178,
          248858,
          1302,
          260,
          13973,
          190178,
          2223,
          864,
          378909,
          99,
          6284,
          88735,
          3807,
          1490,
          795,
          190178,
          17047,
          10717,
          11256,
          4542,
          635,
          258,
          1512,
          7163,
          1530,
          5161,
          863,
          6469,
          269,
          9034,
          378909,
          7155,
          42619,
          1504,
          568,
          601723,
          50835,
          105549,
          177,
          2304,
          6508,
          5648,
          1504,
          595,
          3833,
          606,
          21902,
          224256,
          137067,
          1766,
          526,
          1075,
          965,
          1791,
          4895,
          1165,
          1970,
          2290,
          1196,
          1850,
          307,
          1271,
          805,
          841711,
          1643,
          11432,
          1312922,
          15623,
          346,
          5507,
          20478,
          7646,
          10256,
          8007,
          1923,
          1909,
          42817,
          242,
          13973,
          759,
          23,
          73,
          144160,
          144160,
          5196,
          911,
          1140,
          2870,
          71335,
          128,
          9815,
          241,
          18182,
          88735,
          6284,
          1988,
          564,
          1186,
          105549,
          1382480,
          4424,
          26551,
          632,
          1288,
          824,
          14783,
          2395,
          1446,
          4729,
          498,
          2258,
          467,
          184,
          6120,
          207,
          2523,
          241,
          269,
          1517,
          760,
          378909,
          1271,
          50835,
          233717,
          516,
          564,
          899,
          4367,
          8874,
          1536,
          1645,
          475,
          12335,
          3085,
          1051,
          1195,
          565,
          4015,
          606,
          21437,
          92106,
          1312922,
          5451,
          11256,
          4993,
          105638,
          737,
          516,
          3766,
          653,
          4090,
          5719,
          753116,
          1228,
          413574,
          346,
          136,
          795,
          602,
          165556,
          4542,
          1132,
          254282,
          413574,
          741,
          804,
          1202,
          1810,
          25459,
          564,
          1022298,
          178,
          10295,
          267,
          190178,
          4653,
          899,
          899,
          11751,
          355,
          4726,
          1190,
          30770,
          4138,
          626,
          2036,
          116001,
          68211,
          782,
          177,
          910148,
          255,
          337,
          722,
          229,
          43,
          9993,
          47,
          1312922,
          910148,
          1312922,
          467,
          69,
          35371,
          564,
          13983,
          3451,
          7163,
          263,
          129,
          504,
          18760,
          1725,
          2916,
          1461,
          888,
          106,
          899,
          568,
          725,
          1966,
          191096,
          4542,
          198,
          1970,
          1078,
          741,
          350,
          33804,
          477,
          47772,
          7987,
          5512,
          9165,
          409656,
          163415,
          928,
          6951,
          3776,
          1533,
          3766,
          149,
          50489,
          172247,
          5161,
          50489,
          1312922,
          13973,
          32891,
          601723,
          35705,
          493806,
          1523,
          899,
          4056,
          972,
          260,
          2307,
          1791,
          969,
          1684,
          1139,
          922,
          198,
          504,
          1195,
          47249,
          68211,
          276896,
          1946,
          24536,
          61,
          642,
          4090,
          1645,
          122111,
          5507,
          973849,
          295,
          836,
          134056,
          1504,
          3224,
          3805,
          6469,
          5196,
          532,
          1102,
          828,
          470,
          139,
          238602,
          3343,
          217,
          2906700,
          46944,
          1165,
          590,
          69,
          9506,
          36784,
          5989,
          1645,
          93193,
          489,
          151022,
          2328,
          1810,
          11250,
          2036,
          1533,
          186140,
          5548,
          50489,
          28739,
          3684,
          92043,
          1078,
          1132,
          4512,
          27020,
          124967,
          1312922,
          4198,
          753116,
          51,
          2121,
          1643,
          50835,
          158701,
          87124,
          878,
          355,
          1186,
          3202,
          54185,
          589,
          13973,
          4653,
          464,
          54287,
          4090,
          321490,
          581,
          302,
          1766,
          1850,
          17867,
          1078,
          198,
          3402,
          14228,
          888,
          743,
          8333,
          1382480,
          1504,
          736284,
          71463,
          5760,
          1725,
          13835,
          328,
          811,
          192,
          5341,
          71335,
          124967,
          79613,
          255,
          1970,
          32891,
          267,
          5791,
          1745,
          2504700,
          1725,
          581,
          144160,
          2607,
          1146,
          741,
          722,
          9815,
          467,
          54287,
          51,
          95,
          140,
          85,
          291,
          932,
          1241364,
          298,
          571,
          106,
          11250,
          717255,
          242,
          1493,
          248858,
          1847,
          230,
          313,
          32891,
          2456,
          194500,
          75830,
          1089,
          6120,
          365,
          11250,
          11256,
          736284,
          3487,
          5354,
          391389,
          1595797,
          4090,
          7268,
          736284,
          3224,
          1631,
          1228,
          25459,
          34496,
          757530,
          5577,
          606,
          743,
          1274,
          1507,
          110,
          471,
          214518,
          1988,
          964,
          1312922,
          32891,
          190,
          158701,
          3766,
          5341,
          54767,
          798,
          6120,
          841711,
          4677,
          238602,
          4172,
          136,
          1089,
          413574,
          87124,
          753116,
          2317,
          2916,
          6460,
          48194,
          32891,
          13061,
          110,
          95,
          518429,
          2135,
          910148,
          5161,
          459921,
          21902,
          2328,
          1810,
          139,
          626,
          3508,
          477,
          1478,
          427,
          1453,
          532,
          811,
          864,
          910148,
          1946,
          128715,
          409656,
          248,
          1684,
          6006,
          964,
          530,
          2121,
          128715,
          3684,
          107941,
          21134,
          1970,
          237282,
          1666,
          647,
          7155,
          493806,
          224256,
          167,
          5657,
          2303,
          725,
          2526,
          2906700,
          13973,
          1925,
          192,
          149,
          7268,
          2290,
          163415,
          2906700,
          190,
          198,
          5760,
          1758,
          163415,
          1700,
          63,
          1770,
          128,
          99,
          413574,
          8007,
          642,
          2317,
          214703,
          52126,
          3807,
          222,
          275,
          2307,
          1271,
          144160,
          409656,
          2054,
          1139,
          1196,
          198,
          134056,
          564,
          11432,
          628,
          18128,
          7987,
          5438,
          79613,
          128,
          828,
          21902,
          564,
          753116,
          757530,
          9051,
          165,
          9815,
          1139,
          1312922,
          258,
          970,
          1472,
          139650,
          927396,
          1897,
          1606,
          2807,
          242,
          932,
          3224,
          863,
          213,
          207,
          754,
          19054,
          79613,
          1643,
          207,
          4653,
          3451,
          1186,
          631,
          895,
          355,
          6469,
          50835,
          1831,
          3066,
          5901,
          824,
          151022,
          242,
          10076,
          798,
          276,
          885,
          229,
          863,
          17047,
          310,
          3119,
          1274,
          43,
          275,
          687276,
          149,
          111,
          640470,
          744,
          1762,
          2379,
          43102,
          2135,
          741,
          895,
          258,
          970,
          165556,
          47249,
          324,
          105549,
          13835,
          7420,
          21125,
          3684,
          564,
          1312922,
          397,
          2317,
          8269,
          653,
          5760,
          687276,
          917,
          313,
          640470,
          1186,
          630,
          1606,
          365,
          5196,
          743,
          1804,
          1420,
          271,
          276896,
          68211,
          1749,
          136,
          241,
          99,
          973849,
          166081,
          741,
          391389,
          4542,
          85,
          7163,
          2036,
          2566,
          258,
          4573,
          1507,
          744,
          443,
          771,
          1019,
          1684,
          2376,
          270712,
          4542,
          836,
          6841,
          53,
          1831,
          1051,
          4172,
          302,
          105638,
          3395,
          13061,
          69793,
          2456,
          1382480,
          601723,
          3451,
          198,
          19685,
          1770,
          1725,
          1760,
          207410,
          17867,
          645,
          129,
          20328,
          24536,
          343,
          76383,
          124967,
          899,
          1360,
          565,
          1022298,
          71463,
          749635,
          16183,
          1656,
          19090,
          241,
          136895,
          76,
          77,
          2148,
          471,
          571,
          4542,
          5211,
          1526206,
          128715,
          16305,
          16163,
          123,
          3279,
          6951,
          5507,
          673342,
          2526,
          509,
          1146,
          192,
          3862,
          94014,
          217,
          2644,
          17047,
          602,
          77,
          230,
          5161,
          69,
          1791,
          743,
          17867,
          83,
          10256,
          107941,
          50489,
          1075,
          112,
          307,
          24840,
          3805,
          3766,
          2148,
          759,
          878,
          1946,
          370,
          2786,
          277,
          276002,
          471,
          1725,
          397,
          8874,
          4575,
          391389,
          757530,
          743,
          27020,
          647,
          30770,
          230,
          51,
          648,
          1274,
          454,
          1426,
          760,
          6120,
          134056,
          238602,
          16183,
          1970,
          673342,
          124967,
          602,
          2135,
          525713,
          602,
          2526,
          184,
          34496,
          71485,
          71485,
          759,
          606,
          218,
          50489,
          3343,
          1507,
          1791,
          106,
          94325,
          635,
          1089,
          2054,
          13422,
          376,
          1897,
          3279,
          1271,
          15647,
          863,
          6469,
          84106,
          648,
          3224,
          760,
          3202,
          760,
          229,
          14742,
          9679,
          863,
          1382480,
          207,
          92043,
          2836,
          165556,
          502,
          140,
          725,
          6951,
          1526206,
          1263321,
          2290,
          13835,
          2786,
          53,
          757530,
          276002,
          17867,
          372,
          248858,
          5895,
          171170,
          4542,
          86954,
          198,
          1131,
          5507,
          320420,
          1679,
          233717,
          4015,
          302,
          13061,
          104396,
          165,
          176,
          6508,
          19054,
          124967,
          5989,
          100,
          3263,
          6284,
          1302,
          1022298,
          4198,
          95,
          11250,
          2906700,
          2307,
          27020,
          16183,
          269,
          5354,
          4778,
          27971,
          86954,
          409656,
          242,
          70,
          3224,
          606,
          1675,
          595,
          18182,
          5989,
          413574,
          911,
          15647,
          28425,
          276002,
          328,
          5989,
          633,
          2607,
          1312922,
          3805,
          24840,
          343,
          1312922,
          272134,
          1512,
          5341,
          337,
          1312922,
          93193,
          965,
          12349,
          3263,
          111,
          2092,
          1022298,
          965,
          9165,
          20478,
          493806,
          248,
          519,
          5211,
          46944,
          459921,
          190178,
          1897,
          54185,
          832,
          6951,
          2016,
          2158,
          37,
          2158,
          33917,
          17867,
          349,
          328,
          13602,
          1363,
          1654,
          927396,
          1423,
          4575,
          1019,
          1789,
          177,
          276896,
          22305,
          1725,
          3289,
          1970,
          741,
          51,
          1533,
          1131,
          493,
          5908,
          2368,
          2471,
          4074,
          1725,
          2376,
          49,
          46944,
          94014,
          3104,
          5161,
          1507,
          99,
          52126,
          116001,
          316665,
          1312922,
          7268,
          28739,
          207410,
          190,
          276,
          4074,
          3451,
          3104,
          519,
          276,
          307,
          2523,
          10717,
          1892,
          277,
          3684,
          71335,
          207,
          151785,
          1075,
          680,
          1139,
          14742,
          7297,
          568,
          3495,
          5161,
          134056,
          7420,
          42384,
          43,
          14783,
          825,
          630,
          565,
          269,
          320,
          1302,
          137,
          551,
          341043,
          136,
          94325,
          343,
          27971,
          217,
          516,
          26551,
          33804,
          2142,
          218,
          2304,
          23,
          5908,
          395,
          217,
          71335,
          2211,
          13422,
          922,
          1925,
          1241364,
          3395,
          2290,
          55345,
          111,
          9815,
          710,
          2457,
          267,
          247,
          2526,
          24645,
          376,
          54767,
          263,
          1666,
          2644,
          297,
          307,
          765,
          5901,
          31394,
          337,
          1420,
          3776,
          2644,
          4512,
          914,
          328,
          71485,
          642,
          140,
          1442,
          116155,
          302,
          19090,
          4653,
          2142,
          7565,
          450,
          4533,
          23727,
          4542,
          2872,
          28425,
          4005,
          95035,
          824,
          134056,
          5875,
          2206,
          4729,
          36438,
          5451,
          48194,
          743,
          606,
          673342,
          3430,
          258,
          2856,
          1190,
          124967,
          932,
          21134,
          2376,
          47249,
          1087,
          1228,
          5875,
          42817,
          3032,
          47249,
          5512,
          1304,
          1490,
          248858,
          30770,
          4474,
          2870,
          165556,
          349,
          1363,
          1334,
          1324,
          645,
          14871,
          134056,
          53,
          4677,
          3833,
          470,
          3766,
          54185,
          5354,
          135332,
          4778,
          38912,
          35705,
          217,
          213,
          223,
          24536,
          21902,
          630,
          1075,
          3085,
          2097,
          76383,
          190178,
          2395,
          156391,
          551,
          1288,
          21902,
          4074,
          37,
          2092,
          21902,
          299480,
          165556,
          1443,
          467,
          1523,
          46944,
          100,
          95035,
          736284,
          1850,
          3495,
          1126,
          46563,
          2607,
          7297,
          50489,
          3032,
          1661,
          50489,
          47772,
          269,
          1577385,
          12335,
          4198,
          1850,
          922,
          33917,
          5662,
          2470,
          313,
          1725,
          3032,
          20328,
          7646,
          927396,
          92043,
          19054,
          1526206,
          63,
          43,
          2906700,
          1312922,
          13422,
          111,
          571,
          92106,
          5901,
          526,
          3766,
          409656,
          14783,
          13835,
          3876,
          601723,
          47249,
          3343,
          969,
          1186,
          1684,
          811,
          2290,
          3495,
          186140,
          2016,
          590,
          1087,
          1261,
          4677,
          3996,
          1131,
          17867,
          16305,
          1923,
          2870,
          3688,
          590,
          493806,
          3279,
          71485,
          260,
          540,
          275,
          19685,
          186140,
          172817,
          184,
          190178,
          2148,
          765,
          4354,
          4729,
          1526206,
          341,
          153,
          87124,
          475,
          1412,
          2401,
          1201,
          1195,
          899,
          2317,
          269,
          4575,
          321,
          828,
          1186,
          1631,
          2258,
          2526,
          5760,
          270712,
          2328,
          139650,
          4354,
          269,
          67082,
          823,
          760,
          269,
          11751,
          628,
          1089,
          1533,
          1087,
          1490,
          1261,
          276,
          397,
          286,
          545147,
          10076,
          4154,
          30770,
          2906700,
          55581,
          213,
          191096,
          3224,
          128,
          1745,
          111,
          2036,
          645,
          2290,
          927396,
          33804,
          31394,
          19054,
          237282,
          24840,
          5719,
          2971,
          76,
          42817,
          841711,
          2263,
          5354,
          4729,
          1293,
          27971,
          92043,
          2916,
          1858,
          2158,
          639,
          156391,
          79613,
          6460,
          1925,
          71463,
          1443,
          1126,
          2054,
          54287,
          1288,
          123,
          260,
          277,
          3402,
          224256,
          504,
          973849,
          1382480,
          11751,
          1988,
          1195,
          324,
          46563,
          176,
          581,
          1178,
          3096,
          27971,
          1063,
          1507,
          1143,
          811,
          258,
          140,
          1120,
          464,
          165556,
          136,
          223,
          168,
          71335,
          172817,
          6951,
          1654,
          686,
          832,
          2142,
          17867,
          1263321,
          467,
          551,
          1841,
          9594,
          123373,
          526,
          10256,
          1654,
          568,
          1252,
          498,
          828,
          2135,
          9565,
          470,
          595,
          663,
          50489,
          247,
          222785,
          137067,
          5989,
          413574,
          143,
          743,
          95,
          376,
          1312922,
          630,
          571,
          1970,
          1760,
          9815,
          42619,
          28739,
          633,
          190178,
          333497,
          19090,
          969,
          128354,
          653,
          642,
          1383,
          836,
          30770,
          1679,
          765,
          139650,
          338,
          85,
          413574,
          450,
          2504700,
          1382480,
          60,
          1132,
          5791,
          3862,
          579,
          2566,
          824,
          76383,
          85,
          128715,
          3766,
          1617,
          1988,
          601723,
          276,
          632,
          14742,
          2317,
          271,
          128715,
          21902,
          1274,
          391389,
          878,
          2303,
          641349,
          139,
          241,
          1146,
          91,
          823,
          824,
          151785,
          1617,
          6629,
          5732,
          798,
          911,
          823,
          1645,
          186140,
          4056,
          1195,
          2870,
          269,
          55345,
          13835,
          518429,
          1507,
          3688,
          1201,
          970,
          2518,
          302,
          9565,
          6841,
          1195,
          545147,
          139,
          151815,
          571,
          399,
          307,
          128354,
          1831,
          46,
          10256,
          4575,
          5161,
          46944,
          551,
          1789,
          1102,
          302,
          568,
          895,
          601723,
          111,
          92985,
          973849,
          4056,
          1628,
          222785,
          87124,
          4573,
          7268,
          77,
          302,
          3279,
          277,
          248,
          92985,
          242,
          3458,
          59744,
          331,
          153,
          269,
          471,
          12486,
          3495,
          5950,
          55581,
          1186,
          71463,
          1766,
          836,
          614,
          800,
          478,
          626,
          1789,
          95035,
          321490,
          307,
          2054,
          811,
          94014,
          2786,
          2504700,
          112,
          642,
          48194,
          718,
          1583,
          2395,
          3862,
          1766,
          313,
          4367,
          10076,
          413574,
          1645,
          1595797,
          632,
          2691,
          718,
          5161,
          863,
          798,
          149,
          1831,
          811,
          52126,
          1645,
          1382480,
          1196,
          36784,
          372,
          144160,
          6951,
          16183,
          12335,
          7163,
          18408,
          1666,
          134056,
          4512,
          1526206,
          1382480,
          1382480,
          5760,
          1532,
          2304,
          3224,
          571,
          167,
          4729,
          1506,
          165,
          479994,
          320,
          2501,
          1762,
          3223,
          241,
          75830,
          13422,
          2906700,
          178,
          2376,
          3402,
          140,
          47249,
          9679,
          964,
          21437,
          9594,
          59705,
          172247,
          248,
          84106,
          31515,
          111,
          413574,
          1382480,
          184,
          37,
          3343,
          248858,
          116155,
          3119,
          642,
          13973,
          43102,
          1324,
          151022,
          579,
          836,
          5927,
          3487,
          5778,
          153,
          516,
          93193,
          1252,
          1595797,
          297,
          365,
          795,
          3402,
          21125,
          172247,
          365,
          31394,
          5760,
          5438,
          5732,
          489,
          2607,
          1760,
          123,
          136,
          1490,
          1536,
          477,
          6841,
          1352,
          21902,
          1126,
          19054,
          19054,
          1446,
          3430,
          450,
          104,
          23727,
          1178,
          1261,
          3766,
          564,
          1970,
          1263321,
          198,
          2457,
          43102,
          4367,
          653,
          9993,
          5548,
          2872,
          370,
          540,
          1523,
          54287,
          2906700,
          67858,
          899,
          2376,
          21902,
          43,
          69,
          3430,
          13717,
          680,
          203571,
          1288,
          2223,
          50489,
          3224,
          1165,
          1089,
          5895,
          238602,
          163415,
          606,
          1749,
          2274,
          222,
          178,
          9784,
          9594,
          134056,
          5196,
          224256,
          4161,
          71335,
          471,
          6469,
          94325,
          214703,
          1514,
          1196,
          5908,
          271,
          732,
          276896,
          168,
          6469,
          237282,
          87124,
          1423,
          331,
          1312,
          626,
          1507,
          77,
          922,
          3805,
          192805,
          3451,
          165556,
          4726,
          13835,
          771,
          4726,
          1063,
          2607,
          218,
          798,
          645,
          5726,
          21134,
          687276,
          242,
          105549,
          1504,
          2328,
          754,
          116155,
          140,
          7163,
          7646,
          3862,
          165556,
          167,
          1617,
          7297,
          565,
          11432,
          2906700,
          237282,
          5507,
          1383,
          1120,
          71335,
          71485,
          3684,
          5875,
          673342,
          2290,
          498,
          1382480,
          1139,
          2456,
          163415,
          2148,
          344,
          5512,
          1140,
          932,
          969,
          277,
          753116,
          1089,
          565,
          190178,
          341,
          158701,
          2661,
          31515,
          158701,
          3032,
          241,
          5760,
          1526206,
          52126,
          3996,
          749635,
          344,
          5621,
          1063,
          969,
          817312,
          1461,
          832,
          1472,
          1563,
          26551,
          8269,
          2148,
          4081,
          969,
          218,
          267,
          1201,
          237282,
          757530,
          1577385,
          13973,
          2518,
          632,
          2395,
          1228,
          134056,
          847,
          2856,
          1368,
          1382480,
          372,
          2872,
          3766,
          1131,
          8874,
          328,
          606,
          92106,
          5895,
          1577385,
          166081,
          9594,
          25459,
          1493,
          128,
          372,
          6841,
          19685,
          2078,
          2290,
          6434,
          23045,
          5875,
          1263321,
          9679,
          725,
          16183,
          4575,
          28739,
          69793,
          276002,
          717255,
          1686,
          5621,
          67082,
          1923,
          19685,
          242,
          77,
          3688,
          277,
          20328,
          24536,
          1643,
          128,
          910148,
          1507,
          3699,
          2607,
          13973,
          372,
          190249,
          695,
          2054,
          718,
          1526206,
          1970,
          1892,
          1979,
          2607,
          307,
          224256,
          144160,
          645,
          1749,
          5875,
          9594,
          391389,
          489,
          84106,
          1766,
          2089,
          1762,
          214703,
          1293,
          1382480,
          47211,
          230,
          19408,
          11751,
          450,
          1196,
          5621,
          23727,
          51427,
          391389,
          1461,
          391389,
          1312922,
          4367,
          248,
          1131,
          1789,
          341043,
          470,
          55581,
          1858,
          910148,
          722,
          1089,
          964,
          964,
          1766,
          413574,
          722,
          276002,
          895,
          1312922,
          579,
          2290,
          1970,
          4677,
          198,
          1563,
          20478,
          6951,
          467,
          1909,
          87124,
          2691,
          68211,
          9034,
          2644,
          2872,
          46,
          158701,
          18182,
          350,
          214703,
          139650,
          1523,
          67082,
          888,
          4573,
          632,
          1517,
          12486,
          3289,
          895,
          626,
          5161,
          1563,
          19685,
          5901,
          116001,
          48194,
          2906700,
          1850,
          338,
          94014,
          2661,
          1523,
          749635,
          302,
          2566,
          509,
          1745,
          12335,
          922,
          163415,
          36784,
          13422,
          761,
          2036,
          3224,
          18128,
          1577385,
          741,
          237282,
          571,
          927396,
          718,
          140,
          639,
          190,
          172247,
          43,
          1363,
          1810,
          1261,
          139,
          824,
          272,
          5548,
          190178,
          1725,
          47772,
          741,
          95,
          372,
          331,
          4172,
          1791,
          258,
          718,
          1504,
          346,
          836,
          1506,
          1186,
          1831,
          4603,
          11253,
          9815,
          680,
          20478,
          9772,
          376,
          1196,
          932,
          1684,
          641349,
          53,
          10076,
          741,
          1312,
          241,
          888,
          545147,
          241,
          1288,
          34153,
          3104,
          1760,
          324,
          1166,
          24645,
          7163,
          606,
          520,
          21902,
          1126,
          79613,
          10256,
          1228,
          214518,
          493,
          5621,
          50489,
          1749,
          178,
          828,
          15426,
          725,
          2870,
          1595797,
          1383,
          255,
          17867,
          571,
          4354,
          116001,
          969,
          50489,
          128715,
          601723,
          28739,
          571,
          1847,
          13973,
          471,
          737,
          158701,
          1302,
          92294,
          198,
          145,
          5161,
          22191,
          910148,
          4720,
          1195,
          911,
          69,
          172817,
          464,
          6025,
          1312922,
          1847,
          1324,
          12349,
          3104,
          743,
          4074,
          641349,
          190178,
          3343,
          3766,
          31515,
          116155,
          5512,
          5848,
          6460,
          641349,
          1789,
          186140,
          1228,
          87124,
          255,
          10717,
          11751,
          3223,
          564,
          276,
          765,
          6469,
          1643,
          372,
          59744,
          267,
          5619,
          397,
          28739,
          277,
          964,
          804,
          632,
          391389,
          4895,
          50835,
          1302,
          46,
          85,
          753116,
          878,
          60,
          5512,
          1661,
          378909,
          3104,
          5791,
          129,
          545147,
          343,
          640470,
          7646,
          48194,
          642,
          13835,
          67082,
          3684,
          1126,
          333497,
          93193,
          1565,
          149,
          2135,
          571,
          590,
          5211,
          123373,
          192,
          475,
          372,
          1271,
          922,
          105549,
          2504700,
          291,
          16183,
          129,
          725,
          1263321,
          372,
          1850,
          4049,
          606,
          54185,
          1293,
          34882,
          139,
          1383,
          5719,
          6951,
          92043,
          545147,
          270712,
          1261,
          34882,
          140,
          9165,
          267,
          134056,
          2121,
          4878,
          28739,
          759,
          126,
          1312922,
          976,
          640470,
          381459,
          286,
          198,
          237282,
          1063,
          269,
          5211,
          217,
          2054,
          233717,
          207,
          1571,
          260,
          489,
          932,
          137,
          6841,
          737,
          5875,
          878,
          2092,
          22930,
          759,
          163415,
          2258,
          214518,
          782,
          2223,
          804,
          3104,
          100,
          36784,
          46944,
          104,
          71485,
          4720,
          653,
          6951,
          1897,
          126,
          5927,
          743,
          757530,
          8512,
          3699,
          614,
          4677,
          836,
          741,
          2856,
          2916,
          224256,
          177,
          804,
          427,
          1745,
          5196,
          13602,
          7155,
          2368,
          1645,
          2435,
          6841,
          878,
          5657,
          2443,
          18408,
          1563,
          67082,
          137,
          640470,
          129,
          110,
          1532,
          13717,
          118,
          1930,
          564,
          1804,
          459921,
          350,
          4005,
          471,
          1679,
          391389,
          471,
          85,
          2054,
          1139,
          4729,
          2691,
          42384,
          45303,
          1078,
          128354,
          4729,
          21902,
          1241364,
          5895,
          1423,
          2456,
          1643,
          272134,
          3402,
          20478,
          15269,
          2304,
          105549,
          823,
          4878,
          13717,
          648,
          5927,
          1789,
          1970,
          346,
          341,
          137,
          229,
          6841,
          3032,
          1645,
          51,
          969,
          78968,
          760,
          3096,
          413574,
          1565,
          1897,
          95,
          343,
          349,
          1925,
          11432,
          811,
          647,
          564,
          50835,
          759,
          6581,
          215,
          1789,
          391389,
          493806,
          520,
          2786,
          217,
          313,
          4354,
          911,
          276896,
          86954,
          95015,
          59744,
          276896,
          18408,
          5196,
          85,
          2135,
          914,
          2906700,
          5457,
          1165,
          381459,
          4090,
          178,
          71335,
          3688,
          7692,
          8019,
          1563,
          1051,
          584,
          31394,
          328,
          34496,
          1536,
          247,
          7430,
          1196,
          1178,
          11253,
          1766,
          242,
          372,
          6841,
          817312,
          741,
          1263321,
          123,
          2036,
          1165,
          1770,
          5196,
          165,
          1758,
          595,
          4081,
          4542,
          348,
          4138,
          1766,
          206,
          7646,
          2691,
          1512,
          321490,
          133,
          348,
          9512,
          5196,
          2566,
          9594,
          11256,
          158701,
          4471,
          589,
          59705,
          302,
          3343,
          20328,
          566,
          20478,
          965,
          217,
          4878,
          2456,
          107941,
          1478,
          1841,
          198,
          172817,
          1760,
          3279,
          3776,
          1563,
          14742,
          85,
          76383,
          1789,
          1022298,
          1196,
          134056,
          149,
          1506,
          647,
          914,
          464,
          1690,
          479994,
          355,
          823,
          606,
          263,
          795,
          3805,
          1595797,
          343,
          100,
          888,
          4913,
          1789,
          7430,
          1675,
          1749,
          2661,
          7297,
          3684,
          24840,
          1970,
          123373,
          67082,
          20478,
          190178,
          3766,
          471,
          43,
          1735,
          15269,
          269,
          4056,
          79008,
          5662,
          1565,
          533,
          2856,
          878,
          92985,
          18128,
          149,
          2036,
          242,
          601723,
          49,
          1970,
          1745,
          2607,
          19090,
          248858,
          14871,
          260,
          7163,
          213,
          85,
          1100,
          365,
          2457,
          158701,
          595,
          76383,
          4056,
          190178,
          158701,
          5726,
          765,
          9679,
          9521,
          18408,
          2501,
          413574,
          4424,
          145,
          1684,
          13983,
          186140,
          2836,
          795,
          1274,
          6006,
          328,
          1420,
          34153,
          648,
          105549,
          11250,
          743,
          18408,
          1654,
          2060,
          19685,
          4913,
          2971,
          31515,
          5621,
          28425,
          54185,
          1946,
          116001,
          1700,
          137067,
          192805,
          6703,
          7987,
          67082,
          145,
          571,
          106,
          3263,
          248858,
          320420,
          107941,
          1493,
          19090,
          3833,
          4056,
          4664,
          1725,
          836,
          28739,
          782,
          106,
          5908,
          186140,
          847,
          2916,
          86954,
          19054,
          471,
          136,
          1850,
          2401,
          47249,
          21125,
          69,
          2471,
          75830,
          207410,
          177,
          1760,
          370,
          1195,
          1507,
          1293,
          6951,
          13983,
          9051,
          1666,
          1274,
          9815,
          540,
          140,
          1263321,
          1563,
          2971,
          4090,
          242,
          1892,
          1446,
          324,
          95,
          2470,
          397,
          22305,
          5354,
          142,
          54767,
          861,
          18128,
          18408,
          365,
          2121,
          45303,
          136,
          631,
          1261,
          104,
          165556,
          759,
          123,
          397,
          378909,
          9815,
          217,
          136,
          207,
          1749,
          5211,
          276896,
          4603,
          3255,
          86954,
          1661,
          1631,
          1423,
          1643,
          22305,
          1363,
          27971,
          95,
          23,
          1334,
          2307,
          9051,
          9993,
          1423,
          1766,
          276002,
          836,
          467,
          1412,
          2435,
          9506,
          571,
          213,
          12349,
          477,
          1530,
          1689,
          166081,
          584,
          344,
          177,
          1263321,
          215,
          725,
          467,
          18182,
          2307,
          3766,
          608,
          1745,
          530,
          46,
          33917,
          4367,
          28739,
          5657,
          614,
          4198,
          96942,
          248,
          337,
          804,
          320420,
          241,
          46,
          4913,
          223,
          348,
          466,
          1512,
          15647,
          2376,
          241,
          5732,
          1100,
          5196,
          1847,
          1334,
          5927,
          471,
          1051,
          2456,
          2408,
          2304,
          532,
          1595797,
          5760,
          1442,
          84106,
          84861,
          167,
          409656,
          128,
          520,
          2135,
          238602,
          2526,
          4172,
          5211,
          4056,
          736284,
          47249,
          551,
          71463,
          139,
          878,
          1789,
          470,
          532,
          77,
          158701,
          99,
          84861,
          84106,
          3487,
          2504700,
          718,
          606,
          4653,
          52126,
          1201,
          4653,
          118,
          4074,
          1461,
          151785,
          2807,
          493806,
          331,
          1368,
          6469,
          302,
          272134,
          1514,
          136,
          765,
          5512,
          272134,
          1645,
          1762,
          30770,
          21902,
          5657,
          54287,
          34882,
          1453,
          18182,
          21635,
          832,
          136895,
          733,
          75830,
          165556,
          47772,
          1645,
          77,
          2290,
          1745,
          28278,
          276002,
          2872,
          2135,
          158701,
          895,
          1312922,
          568,
          378909,
          5791,
          516,
          25459,
          5341,
          59744,
          18128,
          5161,
          378909,
          271,
          6508,
          124967,
          571,
          50489,
          568,
          4720,
          5451,
          1131,
          606,
          1078,
          213,
          67082,
          648,
          2872,
          1563,
          341043,
          1680,
          31394,
          828,
          34496,
          28739,
          128354,
          885,
          21125,
          79008,
          291,
          76383,
          21437,
          1892,
          7646,
          205,
          54287,
          10295,
          1472,
          504,
          475,
          5662,
          3805,
          2799,
          27971,
          1420,
          31515,
          1758,
          298,
          1201,
          46,
          632,
          192805,
          606,
          2644,
          19090,
          13422,
          4575,
          1631,
          333497,
          355,
          23727,
          158701,
          4081,
          4729,
          6284,
          10256,
          21125,
          1126,
          1577385,
          276,
          1480,
          771,
          1271,
          878,
          1791,
          310,
          47772,
          34153,
          1126,
          277,
          972,
          51427,
          6025,
          824,
          7268,
          3807,
          1263321,
          970,
          825,
          1595797,
          471,
          71463,
          2054,
          811,
          642,
          118,
          31394,
          493806,
          163415,
          825,
          2135,
          94014,
          12335,
          11250,
          5895,
          4056,
          67082,
          5901,
          5760,
          493,
          885,
          760,
          143,
          4680,
          526,
          3104,
          973849,
          489,
          3833,
          1302,
          2317,
          1666,
          6006,
          248,
          545147,
          1412,
          34882,
          1577385,
          2092,
          144160,
          223,
          190178,
          10256,
          1804,
          74,
          21437,
          217,
          1804,
          7430,
          5662,
          964,
          391389,
          1490,
          239,
          14228,
          267,
          753116,
          34882,
          151022,
          673342,
          149,
          757530,
          1078,
          1684,
          3395,
          722,
          4508,
          1526206,
          10076,
          205,
          2097,
          1645,
          571,
          12335,
          21902,
          970,
          1661,
          828,
          4138,
          217,
          471,
          509,
          1078,
          888,
          11253,
          922,
          71485,
          1595797,
          47211,
          1506,
          2135,
          134056,
          328,
          1423,
          87124,
          45100,
          1507,
          94325,
          2807,
          1735,
          3776,
          427,
          922,
          372,
          1631,
          21134,
          5548,
          320,
          5778,
          46944,
          13835,
          976,
          341043,
          269,
          16183,
          606,
          9784,
          564,
          46,
          165,
          6120,
          69793,
          878,
          324,
          2691,
          648,
          6006,
          194500,
          341043,
          12747,
          895,
          34153,
          2661,
          19054,
          1583,
          5507,
          895,
          15623,
          1051,
          836,
          14871,
          1312,
          1196,
          564,
          21134,
          190178,
          1631,
          128715,
          1595797,
          743,
          105549,
          46,
          647,
          4056,
          1970,
          46944,
          9594,
          107941,
          316665,
          1789,
          9679,
          1166,
          2121,
          910148,
          165556,
          7297,
          888,
          4161,
          71335,
          2078,
          1442,
          372,
          3085,
          3279,
          18128,
          10076,
          8007,
          6284,
          1063,
          1645,
          4575,
          895,
          5875,
          1426,
          1810,
          4913,
          153,
          50489,
          2036,
          2376,
          804,
          254282,
          55581,
          743,
          1078,
          1643,
          5512,
          1196,
          1324,
          158701,
          1700,
          9772,
          1536,
          320420,
          34882,
          2121,
          2456,
          23,
          7155,
          3223,
          914,
          369,
          1847,
          4056,
          471,
          7155,
          736284,
          2661,
          493806,
          3451,
          895,
          276002,
          1946,
          2661,
          4895,
          3263,
          5548,
          2368,
          545147,
          3202,
          14228,
          565,
          2504700,
          106,
          811,
          3032,
          397,
          601723,
          217,
          6284,
          737,
          3343,
          224256,
          3202,
          1089,
          151815,
          606,
          15623,
          498,
          1804,
          606,
          2395,
          4074,
          2870,
          471,
          7155,
          1089,
          69,
          3202,
          7163,
          626,
          1758,
          313,
          31515,
          413574,
          965,
          7565,
          1725,
          321,
          1847,
          2258,
          4015,
          46563,
          1363,
          241,
          55345,
          93193,
          23045,
          1202,
          1140,
          1565,
          54287,
          61,
          355,
          1302,
          94325,
          1382480,
          128715,
          1526206,
          33804,
          248,
          18760,
          20328,
          475,
          4290,
          2401,
          571,
          237282,
          151022,
          493806,
          1139,
          6284,
          134056,
          2836,
          10076,
          54185,
          744,
          8512,
          759,
          4542,
          9034,
          1022298,
          365,
          973849,
          128354,
          1228,
          3343,
          19408,
          298,
          1679,
          145,
          3202,
          2644,
          5457,
          1762,
          564,
          54767,
          238602,
          34882,
          25459,
          1423,
          239,
          581,
          564,
          237282,
          248,
          1131,
          4575,
          324,
          18128,
          504,
          92985,
          50489,
          7565,
          46563,
          5438,
          215,
          123373,
          2644,
          1645,
          241,
          258,
          15647,
          2870,
          970,
          5507,
          391389,
          1606,
          19054,
          3699,
          391389,
          137,
          4729,
          2379,
          6841,
          123,
          348,
          59705,
          27020,
          1493,
          454,
          19090,
          267,
          1414,
          519,
          466,
          172817,
          545147,
          571,
          4542,
          74,
          1925,
          1312922,
          1263321,
          1261,
          9679,
          343,
          973849,
          2870,
          8512,
          35371,
          1190,
          263,
          75830,
          31394,
          2807,
          725,
          1201,
          718,
          1131,
          140,
          71463,
          4198,
          927396,
          645,
          7646,
          1423,
          6006,
          28425,
          6581,
          18760,
          2526,
          4074,
          10076,
          2304,
          6434,
          50835,
          1423,
          2644,
          2471,
          1526206,
          1847,
          757530,
          1735,
          4878,
          88735,
          2457,
          1478,
          2518,
          6841,
          78968,
          116001,
          565,
          1831,
          1850,
          3224,
          1022298,
          540,
          1312922,
          76383,
          9565,
          4090,
          1022298,
          76383,
          1595797,
          743,
          973849,
          2518,
          4726,
          1178,
          71463,
          4913,
          1078,
          1166,
          1810,
          54287,
          20328,
          471,
          207,
          3402,
          5903,
          1675,
          92043,
          1749,
          34153,
          2395,
          18408,
          21902,
          33804,
          3343,
          459921,
          24536,
          1841,
          269,
          5927,
          3032,
          2376,
          4664,
          590,
          525713,
          3096,
          1595797,
          571,
          106,
          3730,
          863,
          8019,
          489,
          5875,
          217,
          1166,
          6284,
          1442,
          736284,
          151815,
          606,
          27971,
          255,
          2148,
          324,
          128715,
          31515,
          9587,
          3876,
          13717,
          163415,
          136,
          765,
          136,
          631,
          69,
          606,
          144160,
          1523,
          673342,
          137,
          1925,
          140,
          1628,
          33804,
          1645,
          3224,
          937,
          47772,
          370,
          4090,
          391389,
          63,
          878,
          165,
          198,
          355,
          6951,
          324,
          86954,
          192,
          741,
          470,
          71463,
          7163,
          28739,
          4354,
          341,
          737,
          1368,
          298,
          27829,
          50489,
          105549,
          21125,
          328,
          1758,
          1684,
          2799,
          2208,
          1645,
          381459,
          2971,
          1574,
          970,
          111,
          1131,
          413574,
          45303,
          680,
          68211,
          1075,
          5989,
          2307,
          254,
          5903,
          782,
          1312,
          1383,
          4913,
          970,
          3730,
          641349,
          13717,
          19054,
          30770,
          7268,
          1075,
          20478,
          641349,
          1930,
          46,
          92294,
          1679,
          128354,
          836,
          14228,
          782,
          828,
          341043,
          276,
          48194,
          5875,
          1979,
          1523,
          6951,
          1442,
          144160,
          2078,
          158701,
          2471,
          1261,
          4074,
          4074,
          632,
          602,
          198,
          601723,
          475,
          36784,
          973849,
          1514,
          1443,
          32891,
          1807,
          2870,
          1943,
          8512,
          1858,
          5211,
          811,
          895,
          765,
          2836,
          158701,
          1532,
          1186,
          269,
          17047,
          190178,
          1675,
          7268,
          2202,
          144160,
          673342,
          4172,
          88735,
          571,
          459921,
          31394,
          17867,
          1472,
          213,
          1087,
          1789,
          7155,
          2870,
          177,
          177,
          4090,
          1126,
          522,
          168,
          397,
          118,
          3766,
          69,
          1780,
          23727,
          302,
          4993,
          237282,
          2906700,
          331,
          3766,
          302,
          673342,
          565,
          5875,
          1146,
          192,
          509,
          50489,
          923,
          2395,
          760,
          118,
          1533,
          53,
          1749,
          7155,
          302,
          181438,
          1679,
          2408,
          1533,
          3343,
          19090,
          5778,
          99,
          5512,
          1075,
          663,
          3255,
          753116,
          4664,
          5760,
          263,
          4653,
          737,
          129,
          2383912,
          10076,
          526,
          9587,
          17867,
          1595797,
          128715,
          172817,
          498,
          1190,
          1190,
          184,
          206,
          1925,
          267,
          413574,
          9565,
          1645,
          1324,
          134056,
          823,
          4138,
          8874,
          6713,
          545147,
          2303,
          3224,
          736284,
          142,
          532,
          923,
          76383,
          722,
          581,
          276002,
          116001,
          1892,
          269,
          595,
          635,
          7430,
          4575,
          6018,
          1858,
          140,
          94014,
          337,
          493806,
          836,
          489,
          1075,
          30770,
          1302,
          695,
          75903,
          346,
          1810,
          467,
          969,
          1925,
          409656,
          1453,
          493806,
          321,
          828,
          4677,
          2290,
          718,
          725,
          1139,
          50835,
          100,
          213,
          3279,
          836,
          88735,
          3402,
          27971,
          861,
          207,
          927396,
          5778,
          1195,
          1679,
          338,
          71335,
          2456,
          320420,
          297,
          509,
          3862,
          2906700,
          10256,
          27971,
          2408,
          2408,
          471,
          864,
          320420,
          509,
          171170,
          4573,
          222785,
          2518,
          100,
          1442,
          301,
          3807,
          3996,
          5211,
          4653,
          241,
          493,
          395,
          198,
          6006,
          545147,
          5161,
          331,
          17867,
          1140,
          153,
          2092,
          1252,
          25459,
          45303,
          74,
          753116,
          2836,
          17867,
          172817,
          2121,
          149,
          22305,
          217,
          391389,
          5662,
          85,
          242,
          18128,
          328,
          8874,
          4198,
          128715,
          1383,
          27020,
          1126,
          4533,
          18760,
          3066,
          9496,
          2206,
          337,
          42384,
          3766,
          2148,
          641,
          17867,
          760,
          4533,
          172817,
          12486,
          516,
          140,
          1725,
          254282,
          5989,
          828,
          765,
          743,
          178,
          3876,
          46563,
          16163,
          3684,
          1523,
          836,
          2504700,
          5161,
          1930,
          47772,
          4573,
          3495,
          54767,
          917,
          743,
          18182,
          320,
          2661,
          270712,
          3279,
          19054,
          743,
          128354,
          69793,
          1195,
          129,
          1078,
          15647,
          32891,
          24645,
          1536,
          722,
          1923,
          633,
          633,
          2054,
          4664,
          759,
          116001,
          301,
          1679,
          427,
          1679,
          214703,
          477,
          1368,
          528,
          177,
          297,
          2471,
          743,
          46944,
          31394,
          1735,
          8333,
          34882,
          3263,
          710,
          824,
          31515,
          27971,
          206,
          2906700,
          6120,
          3224,
          12335,
          530,
          9815,
          397,
          1791,
          564,
          2523,
          493,
          581,
          1324,
          217,
          6469,
          46,
          5901,
          1453,
          1666,
          13061,
          606,
          1228,
          324,
          590,
          71463,
          5341,
          28739,
          7565,
          467,
          241,
          2135,
          1493,
          836,
          35371,
          276002,
          14871,
          172817,
          24645,
          1909,
          3430,
          191096,
          277,
          2395,
          1360,
          545147,
          528,
          27971,
          1850,
          172817,
          34496,
          1523,
          673342,
          258,
          59744,
          9594,
          18459,
          140,
          129,
          1190,
          1196,
          136895,
          7163,
          55581,
          1654,
          144160,
          177,
          46563,
          271,
          48194,
          96942,
          20328,
          7155,
          5989,
          86954,
          964,
          471,
          22305,
          176,
          5950,
          328,
          2290,
          828,
          2807,
          77,
          1143,
          3699,
          376,
          914,
          1019,
          1831,
          222,
          11256,
          4677,
          760,
          1490,
          36438,
          2471,
          99,
          116155,
          970,
          673342,
          186140,
          1363,
          136,
          606,
          2526,
          5621,
          2328,
          795,
          69,
          34882,
          365,
          1334,
          238602,
          391389,
          2401,
          1979,
          5438,
          54287,
          93193,
          743,
          217,
          2501,
          922,
          34882,
          3458,
          36438,
          100,
          378909,
          1480,
          1143,
          13422,
          70,
          3451,
          126,
          965,
          2856,
          5908,
          5657,
          823,
          4081,
          1453,
          6006,
          1645,
          1252,
          124967,
          34496,
          847,
          759,
          45100,
          4090,
          94014,
          8333,
          888,
          128354,
          18760,
          46,
          86954,
          765,
          836,
          27020,
          725,
          673342,
          238602,
          3458,
          123373,
          7646,
          1595797,
          513,
          2408,
          1420,
          9815,
          71335,
          30770,
          530,
          21635,
          5657,
          139,
          134056,
          26120,
          5457,
          13973,
          1228,
          642,
          233717,
          21134,
          1178,
          824,
          878,
          4138,
          2523,
          2317,
          2307,
          736284,
          2206,
          3684,
          71485,
          6120,
          1643,
          50835,
          6434,
          92294,
          530,
          207,
          9587,
          123,
          184,
          3833,
          206,
          4913,
          105549,
          397,
          3279,
          30770,
          463,
          106,
          841711,
          1897,
          9496,
          308,
          753116,
          4677,
          198,
          2036,
          1461,
          1423,
          254282,
          2036,
          5662,
          123,
          2607,
          2368,
          6120,
          475,
          9815,
          103927,
          15269,
          606,
          639,
          85,
          1617,
          2518,
          695,
          27020,
          413574,
          18128,
          477,
          1725,
          502,
          13983,
          910148,
          43102,
          545147,
          194500,
          498,
          1261,
          30770,
          2526,
          2870,
          631,
          42384,
          172817,
          5507,
          370,
          1312922,
          1190,
          759,
          5621,
          5901,
          94014,
          2906700,
          1656,
          337,
          76,
          1304,
          241,
          589,
          79613,
          463,
          1166,
          5901,
          22930,
          207410,
          3066,
          1631,
          79008,
          190178,
          888,
          885,
          5548,
          888,
          1228,
          42619,
          1274,
          450,
          1645,
          149,
          2872,
          1263321,
          190178,
          836,
          178,
          530,
          1186,
          272,
          470,
          20478,
          450,
          5875,
          43,
          34496,
          568,
          4081,
          493806,
          105638,
          272,
          1139,
          3343,
          632,
          128,
          144160,
          3202,
          641349,
          1131,
          1412,
          1679,
          24840,
          34153,
          45303,
          1810,
          3776,
          9815,
          895,
          595,
          1202,
          74,
          1523,
          46,
          1382480,
          1140,
          276002,
          9993,
          725,
          77,
          647,
          910148,
          5662,
          230,
          2856,
          1382480,
          165556,
          718,
          186140,
          50835,
          1383,
          687276,
          3996,
          5211,
          91,
          372,
          1766,
          35439,
          409656,
          4653,
          79613,
          1680,
          237282,
          564,
          5908,
          2408,
          4471,
          1126,
          741,
          172817,
          1195,
          1645,
          24536,
          53,
          328,
          565,
          1139,
          1293,
          2158,
          917,
          124967,
          21902,
          3279,
          276002,
          4542,
          35371,
          718,
          5760,
          143,
          337,
          1577385,
          1312922,
          450,
          7646,
          7268,
          85,
          1490,
          104,
          1228,
          217,
          43,
          1506,
          5895,
          9679,
          3684,
          23,
          4895,
          134056,
          899,
          75903,
          1261,
          782,
          399,
          4081,
          205,
          760,
          6951,
          1132,
          565,
          1202,
          2661,
          477,
          1178,
          743,
          759,
          7163,
          1179,
          6120,
          1631,
          271,
          863,
          320420,
          341043,
          35371,
          50835,
          321490,
          14871,
          28425,
          186140,
          333497,
          4993,
          741,
          4993,
          99,
          4680,
          191096,
          297,
          1252,
          207410,
          52126,
          970,
          1925,
          24645,
          2206,
          389246,
          5726,
          192805,
          863,
          467,
          8874,
          35371,
          2395,
          823,
          1423,
          1051,
          4474,
          1360,
          741,
          4056,
          5895,
          2518,
          350,
          9506,
          123,
          1512,
          60,
          20478,
          551,
          248858,
          4081,
          320420,
          1426,
          1126,
          533,
          163415,
          190178,
          2786,
          27020,
          2906700,
          177,
          46563,
          4074,
          77,
          2807,
          606,
          378909,
          1412,
          46563,
          271,
          602,
          460,
          878,
          247,
          3688,
          5875,
          106,
          1075,
          522,
          69793,
          7155,
          19408,
          12747,
          1745,
          1523,
          4474,
          1324,
          2258,
          673342,
          269,
          107941,
          3343,
          8007,
          137067,
          2906700,
          320,
          1195,
          3688,
          5512,
          743,
          177,
          4508,
          2456,
          50489,
          45100,
          551,
          1643,
          937,
          663,
          3255,
          409656,
          313,
          1228,
          25459,
          2504700,
          3066,
          825,
          2148,
          2836,
          1892,
          5196,
          276002,
          346,
          1426,
          27971,
          151815,
          471,
          1979,
          1804,
          35439,
          3224,
          1186,
          3996,
          186140,
          4913,
          158701,
          3119,
          217,
          71485,
          34496,
          922,
          52126,
          4653,
          1423,
          1178,
          910148,
          4993,
          1571,
          5211,
          1791,
          841711,
          1595797,
          23,
          470,
          2856,
          348,
          725,
          1360,
          20478,
          450,
          348,
          9679,
          136,
          927396,
          1312,
          149,
          836,
          1841,
          6120,
          888,
          798,
          71485,
          140,
          6469,
          69793,
          20478,
          1847,
          1850,
          477,
          2916,
          1075,
          163415,
          13422,
          1595797,
          54185,
          1261,
          9496,
          106,
          2504700,
          4653,
          151022,
          595,
          5621,
          1166,
          2443,
          1892,
          653,
          68211,
          2317,
          67082,
          343,
          136895,
          229,
          59705,
          1595797,
          51,
          92608,
          1261,
          316665,
          19408,
          413574,
          276896,
          233060,
          526,
          17867,
          761,
          4424,
          910148,
          1442,
          276896,
          2135,
          328,
          1179,
          32891,
          4993,
          8830,
          9512,
          606,
          680,
          8830,
          804,
          391389,
          1412,
          71335,
          34153,
          4664,
          4533,
          606,
          732,
          753116,
          564,
          28739,
          520,
          4653,
          1132,
          847,
          321,
          277,
          1689,
          1383,
          828,
          2290,
          5989,
          601723,
          9496,
          276002,
          1261,
          3224,
          134056,
          673342,
          4653,
          1675,
          69,
          5548,
          51,
          181438,
          2786,
          10076,
          1577385,
          26551,
          79008,
          2870,
          475,
          248,
          5548,
          372,
          3263,
          4664,
          310,
          4005,
          21902,
          828,
          878,
          479994,
          519,
          5196,
          1631,
          2872,
          3343,
          165,
          255,
          1970,
          105638,
          46,
          4664,
          6951,
          337,
          3684,
          372,
          5927,
          722,
          94325,
          4913,
          50835,
          673342,
          759,
          9496,
          276,
          1201,
          782,
          1382480,
          5989,
          297,
          128,
          4533,
          1228,
          566,
          110,
          9594,
          2916,
          2328,
          276002,
          36784,
          1507,
          19054,
          223,
          540,
          1190,
          270712,
          530,
          710,
          20478,
          2518,
          912,
          1923,
          3224,
          271,
          36784,
          207410,
          1925,
          378909,
          1654,
          413574,
          2208,
          6006,
          1196,
          1970,
          260,
          28739,
          1656,
          123,
          1263321,
          177,
          2202,
          1506,
          71335,
          471,
          1423,
          111,
          972,
          965,
          355,
          2054,
          832,
          137,
          471,
          1383,
          28425,
          71463,
          3032,
          229,
          17867,
          69793,
          2408,
          1760,
          3684,
          20478,
          2401,
          2518,
          911,
          626,
          19408,
          571,
          1766,
          7268,
          733,
          4081,
          203571,
          77,
          198,
          2526,
          213,
          3289,
          331,
          969,
          203571,
          13061,
          207410,
          50835,
          4508,
          105638,
          471,
          628,
          3202,
          3224,
          409656,
          2307,
          1643,
          1780,
          1526206,
          35439,
          1606,
          18182,
          1946,
          3104,
          10256,
          24536,
          94014,
          1213,
          18408,
          1523,
          1453,
          566,
          348,
          20478,
          43102,
          761,
          28278,
          2644,
          2518,
          242,
          823,
          5621,
          320,
          2906700,
          687276,
          263,
          513,
          46,
          1126,
          888,
          104396,
          12747,
          136,
          1762,
          128354,
          614,
          260,
          263,
          6120,
          21134,
          4290,
          13973,
          1274,
          1628,
          23,
          1139,
          165556,
          350,
          2135,
          1943,
          3289,
          502,
          2206,
          571,
          749635,
          2856,
          92106,
          1789,
          42817,
          100,
          137067,
          5657,
          5507,
          237282,
          71485,
          910148,
          9772,
          181438,
          5621,
          19408,
          270712,
          241,
          2607,
          413574,
          75830,
          1132,
          718,
          1423,
          128715,
          190178,
          2135,
          1700,
          595,
          48194,
          1532,
          1892,
          4913,
          551,
          372,
          2328,
          59744,
          277,
          28739,
          3224,
          1139,
          42384,
          343,
          3730,
          11751,
          427,
          1850,
          137,
          1831,
          564,
          308,
          1196,
          172817,
          230,
          1789,
          1360,
          79613,
          899,
          3451,
          69,
          606,
          3343,
          3119,
          45303,
          832,
          502,
          1261,
          3119,
          1271,
          1131,
          71485,
          129,
          3224,
          737,
          42384,
          4074,
          298,
          276896,
          52,
          1595797,
          135332,
          1140,
          1423,
          207,
          2135,
          2395,
          1892,
          2078,
          863,
          241,
          53,
          1423,
          4367,
          1577385,
          976,
          1758,
          341043,
          110,
          1363,
          695,
          242,
          331,
          168,
          68211,
          21902,
          20328,
          520,
          10256,
          7163,
          493806,
          1312922,
          222,
          18128,
          1789,
          47249,
          20328,
          1102,
          4198,
          5196,
          69,
          663,
          158701,
          94325,
          67858,
          1383,
          1804,
          1132,
          817312,
          4056,
          8830,
          23,
          10717,
          760,
          1563,
          478,
          381459,
          6841,
          5895,
          37,
          1423,
          276002,
          642,
          104,
          337,
          20328,
          722,
          139,
          5507,
          1420,
          17047,
          19090,
          47772,
          233717,
          601723,
          2526,
          33917,
          3255,
          100,
          2906700,
          470,
          1909,
          4575,
          861,
          741,
          13835,
          1617,
          42817,
          333497,
          172817,
          263,
          116001,
          970,
          128,
          5950,
          11256,
          241,
          34882,
          320420,
          470,
          172817,
          540,
          1263321,
          2443,
          111,
          3343,
          1925,
          1166,
          595,
          1909,
          3096,
          378909,
          4729,
          828,
          1970,
          911,
          5895,
          6469,
          964,
          489,
          276002,
          467,
          450,
          54185,
          2836,
          254,
          804,
          4542,
          1909,
          470,
          20328,
          7987,
          1312,
          972,
          50835,
          69,
          260,
          341,
          13717,
          76383,
          2368,
          321,
          1526206,
          910148,
          687276,
          21134,
          165556,
          687276,
          48194,
          277,
          2054,
          1490,
          4306,
          1661,
          6120,
          31515,
          5507,
          1383,
          88735,
          9512,
          4367,
          34153,
          4172,
          13061,
          9815,
          302,
          2906700,
          520,
          16183,
          1689,
          277,
          32891,
          1523,
          2906700,
          1446,
          222,
          2836,
          1770,
          123373,
          4895,
          841711,
          595,
          46563,
          471,
          258,
          1504,
          413574,
          2135,
          798,
          2092,
          163415,
          545147,
          237282,
          47249,
          2401,
          43,
          516,
          4015,
          1617,
          744,
          3487,
          565,
          2872,
          2518,
          1930,
          520,
          190178,
          237282,
          343,
          459921,
          1523,
          3032,
          1897,
          50489,
          1324,
          372,
          19408,
          589,
          105549,
          6469,
          3508,
          427,
          5875,
          1766,
          7155,
          1383,
          320420,
          163415,
          3730,
          804,
          270712,
          2872,
          1442,
          1532,
          1363,
          54287,
          741,
          3279,
          6841,
          295,
          8269,
          43102,
          91,
          1051,
          1352,
          6508,
          633,
          1526206,
          3451,
          6951,
          35371,
          1966,
          96942,
          540,
          395,
          6581,
          241,
          533,
          4154,
          9496,
          914,
          19054,
          493806,
          3684,
          3684,
          1523,
          260,
          1312,
          10076,
          270712,
          2368,
          71335,
          749635,
          633,
          111,
          5760,
          94014,
          128354,
          12747,
          19408,
          3688,
          24536,
          50835,
          10295,
          1526206,
          969,
          1606,
          718,
          21437,
          647,
          888,
          647,
          255,
          31394,
          372,
          1831,
          124967,
          477,
          2607,
          7297,
          4471,
          18182,
          6284,
          1312922,
          331,
          5908,
          43102,
          4542,
          409656,
          1526206,
          737,
          213,
          18408,
          177,
          1022298,
          1766,
          105549,
          1762,
          9772,
          85,
          1263321,
          5161,
          1383,
          302,
          5848,
          31970,
          34153,
          653,
          6469,
          1383,
          248,
          824,
          111,
          186140,
          9815,
          776,
          973849,
          307,
          19408,
          5507,
          899,
          5648,
          70,
          177,
          1178,
          1925,
          686,
          2807,
          48194,
          2607,
          16183,
          817312,
          20478,
          932,
          832,
          4729,
          680,
          5161,
          899,
          35439,
          51,
          31394,
          3688,
          1196,
          1312922,
          263,
          2092,
          1892,
          5927,
          4090,
          964,
          192805,
          4653,
          277,
          192,
          1930,
          33804,
          630,
          104,
          1075,
          899,
          8874,
          4729,
          5903,
          163415,
          190,
          1897,
          450,
          828,
          673342,
          124967,
          50489,
          9512,
          4575,
          9506,
          5354,
          9679,
          1645,
          321,
          378909,
          1228,
          35705,
          54767,
          165556,
          641349,
          1684,
          5621,
          320420,
          2395,
          795,
          207410,
          927396,
          2916,
          718,
          74,
          53,
          365,
          1725,
          6841,
          1725,
          832,
          214703,
          2471,
          1075,
          76,
          107941,
          35371,
          331,
          95,
          71463,
          79008,
          680,
          258,
          8874,
          3066,
          540,
          378909,
          647,
          5927,
          5760,
          1850,
          355,
          4533,
          1443,
          1923,
          50835,
          1925,
          158701,
          5760,
          606,
          6006,
          331,
          27971,
          1423,
          3862,
          493,
          116001,
          4306,
          647,
          1201,
          34882,
          6508,
          19090,
          224256,
          254,
          2504700,
          5875,
          2036,
          4664,
          27971,
          5901,
          184,
          2971,
          771,
          116155,
          2206,
          369,
          717255,
          19090,
          34153,
          686,
          2456,
          3807,
          471,
          2443,
          27829,
          923,
          571,
          18182,
          134056,
          46563,
          74,
          4533,
          104396,
          530,
          217,
          2457,
          237282,
          1478,
          123,
          828,
          4367,
          1453,
          964,
          92985,
          5901,
          158701,
          15426,
          1789,
          116155,
          331,
          878,
          24840,
          1645,
          888,
          725,
          427,
          1661,
          1493,
          145,
          1700,
          190,
          2856,
          7155,
          184,
          1979,
          19054,
          1577385,
          687276,
          805,
          241,
          59744,
          864,
          254,
          54287,
          67082,
          581,
          8512,
          4778,
          2135,
          737,
          2376,
          207410,
          238602,
          75830,
          1080,
          530,
          31394,
          1760,
          15426,
          53,
          2872,
          111,
          35371,
          5950,
          630,
          140,
          2435,
          21902,
          23805,
          1563,
          3495,
          9594,
          673342,
          71463,
          823,
          551,
          2836,
          77,
          9772,
          7987,
          10717,
          718,
          167,
          6284,
          128715,
          1766,
          4653,
          7155,
          4726,
          49,
          21902,
          5908,
          45100,
          885,
          116001,
          863,
          4005,
          139,
          376,
          198,
          2054,
          1507,
          1789,
          206,
          630,
          1131,
          23,
          88735,
          67082,
          286,
          964,
          863,
          111,
          92608,
          308,
          233717,
          1858,
          5211,
          6713,
          205,
          68211,
          1689,
          17867,
          260,
          75903,
          647,
          116001,
          509,
          1762,
          5989,
          79613,
          7155,
          178,
          1930,
          545147,
          165556,
          1512,
          3805,
          828,
          254282,
          302,
          105549,
          255,
          165556,
          223,
          2456,
          2471,
          687276,
          149,
          5161,
          3688,
          413574,
          824,
          94014,
          134056,
          23045,
          307,
          258,
          1334,
          350,
          640470,
          378909,
          1617,
          239,
          1213,
          409656,
          3224,
          518429,
          6713,
          3766,
          2376,
          2376,
          7646,
          46563,
          30770,
          12747,
          22305,
          320,
          136,
          1078,
          32891,
          1368,
          782,
          105638,
          1423,
          1758,
          7163,
          459921,
          5161,
          2208,
          3833,
          1022298,
          207,
          519,
          46563,
          601723,
          3202,
          973849,
          1791,
          276896,
          242,
          1334,
          16163,
          263,
          1383,
          198,
          111,
          49,
          355,
          2121,
          3688,
          344,
          5341,
          111,
          355,
          1925,
          222785,
          1791,
          133,
          11256,
          1617,
          725,
          832,
          6951,
          795,
          10076,
          84106,
          45303,
          136,
          725,
          463,
          59705,
          93193,
          633,
          139,
          5161,
          965,
          15269,
          74,
          1089,
          4533,
          346,
          1577385,
          718,
          14075,
          217,
          1766,
          54767,
          198,
          2148,
          16163,
          103927,
          104396,
          828,
          28739,
          640470,
          2303,
          1675,
          2036,
          71335,
          6841,
          26120,
          28425,
          3688,
          6629,
          343,
          2518,
          1507,
          35439,
          184,
          54287,
          95,
          647,
          338,
          59744,
          6508,
          722,
          260,
          8512,
          3776,
          1334,
          4993,
          493806,
          1970,
          3395,
          1126,
          1228,
          760,
          28278,
          1583,
          324,
          136,
          133,
          1656,
          206,
          35371,
          337,
          7420,
          1504,
          263,
          1745,
          71335,
          45303,
          3032,
          760,
          695,
          761,
          271,
          4512,
          606,
          1228,
          743,
          291,
          95,
          502,
          54185,
          864,
          888,
          3430,
          260,
          198,
          571,
          7297,
          313,
          1661,
          291,
          42619,
          35371,
          395,
          16163,
          3104,
          885,
          1970,
          878,
          1019,
          237282,
          1523,
          299480,
          35439,
          34882,
          973849,
          493806,
          1725,
          10076,
          1631,
          8019,
          2504700,
          55345,
          1725,
          110,
          1263321,
          5507,
          4573,
          1512,
          4895,
          11250,
          733,
          498,
          84106,
          269,
          1132,
          5791,
          76,
          4664,
          313,
          1412,
          2054,
          1443,
          1745,
          4729,
          276002,
          83,
          2395,
          198,
          1363,
          229,
          321,
          60,
          922,
          1324,
          568,
          3688,
          1909,
          695,
          450,
          343,
          76383,
          76,
          798,
          1643,
          516,
          344,
          105549,
          1426,
          2870,
          2092,
          214703,
          184,
          2435,
          1126,
          75903,
          190178,
          321,
          8830,
          1923,
          1925,
          5901,
          71335,
          198,
          186140,
          111,
          21902,
          343,
          7430,
          5507,
          743,
          214518,
          878,
          1166,
          1789,
          328,
          888,
          4664,
          545147,
          6841,
          595,
          61,
          6006,
          6469,
          1271,
          2054,
          54185,
          1228,
          1923,
          972,
          1075,
          28278,
          1263321,
          3279,
          3833,
          50835,
          3684,
          7163,
          10076,
          137067,
          3263,
          1426,
          1745,
          564,
          247,
          863,
          1453,
          237282,
          1063,
          5895,
          297,
          156391,
          470,
          1789,
          116001,
          12335,
          34153,
          6120,
          344,
          92337,
          6629,
          223,
          2376,
          3096,
          757530,
          1186,
          3508,
          118,
          1595797,
          51,
          107941,
          1563,
          4354,
          522,
          2060,
          3996,
          105638,
          2304,
          2376,
          4573,
          564,
          911,
          3104,
          47249,
          899,
          5438,
          1126,
          3730,
          3994,
          1892,
          136,
          744,
          55345,
          186140,
          3202,
          381459,
          8830,
          1480,
          606,
          128354,
          1595797,
          1241364,
          571,
          1126,
          776,
          24536,
          343,
          105549,
          9815,
          1120,
          346,
          85,
          31394,
          77,
          34153,
          192,
          321490,
          17867,
          128715,
          2121,
          136895,
          4542,
          45100,
          242,
          270712,
          888,
          99,
          601723,
          85,
          1565,
          105638,
          365,
          158701,
          722,
          341043,
          140,
          320420,
          571,
          14871,
          248,
          427,
          35371,
          242,
          970,
          365,
          2376,
          4074,
          817312,
          823,
          823,
          34153,
          641,
          87124,
          888,
          165556,
          1201,
          409656,
          475,
          230,
          291,
          5354,
          172817,
          1186,
          324,
          242,
          1789,
          297,
          1643,
          213,
          718,
          532,
          910148,
          11751,
          86954,
          5791,
          741,
          241,
          271,
          757530,
          24536,
          937,
          346,
          4161,
          1078,
          1789,
          413574,
          6508,
          137,
          1595797,
          640470,
          1745,
          470,
          1228,
          248858,
          55581,
          1512,
          2691,
          237282,
          93193,
          76383,
          1583,
          632,
          2799,
          825,
          3766,
          271,
          13717,
          1841,
          1745,
          269,
          832,
          258,
          276002,
          47772,
          743,
          4512,
          1897,
          7692,
          2470,
          595,
          1190,
          9034,
          3862,
          1595797,
          207,
          9594,
          5354,
          229,
          67082,
          258,
          3508,
          732,
          5875,
          7646,
          391389,
          1617,
          276,
          207410,
          3202,
          145,
          105549,
          7420,
          910148,
          1847,
          828,
          167,
          163415,
          217,
          33917,
          1126,
          2504700,
          409656,
          493,
          31970,
          1970,
          1725,
          2379,
          3684,
          76383,
          258,
          1324,
          1312922,
          5196,
          4159,
          3730,
          76383,
          4074,
          1453,
          828,
          516,
          6951,
          4172,
          391389,
          20478,
          191096,
          8333,
          1228,
          248858,
          224256,
          647,
          184,
          19090,
          23727,
          4664,
          24840,
          270712,
          54185,
          1970,
          4542,
          186140,
          4729,
          3766,
          1271,
          190178,
          4354,
          1758,
          75830,
          50835,
          198,
          5341,
          328,
          2036,
          313,
          263,
          302,
          50835,
          2644,
          76,
          1504,
          5621,
          4720,
          471,
          12486,
          178,
          17867,
          192805,
          3430,
          105638,
          88735,
          645,
          230,
          60,
          2518,
          18182,
          2211,
          3996,
          828,
          18408,
          139650,
          695,
          3766,
          32891,
          530,
          2317,
          31515,
          3343,
          337,
          71485,
          69,
          5648,
          190178,
          128715,
          824,
          568,
          206,
          191096,
          95035,
          2016,
          151022,
          1420,
          3699,
          1490,
          478,
          207,
          1506,
          128354,
          1847,
          55581,
          888,
          828,
          1324,
          1897,
          564,
          5901,
          2526,
          3395,
          725,
          3994,
          409656,
          105638,
          6581,
          1766,
          1700,
          5791,
          509,
          1523,
          1841,
          163415,
          129,
          973849,
          910148,
          140,
          2036,
          413574,
          1126,
          370,
          1075,
          970,
          134056,
          158701,
          568,
          87124,
          5903,
          233717,
          1143,
          333497,
          350,
          498,
          241,
          1847,
          11250,
          7163,
          2836,
          21134,
          95,
          493806,
          1523,
          13602,
          8019,
          1363,
          782,
          1228,
          165556,
          149,
          1517,
          276896,
          722,
          47772,
          1274,
          1126,
          1412,
          969,
          27971,
          1847,
          744,
          51,
          169,
          530,
          5161,
          271,
          817312,
          5211,
          129,
          92043,
          2054,
          269,
          105549,
          28739,
          3289,
          1312922,
          1979,
          3066,
          1858,
          1690,
          50835,
          653,
          4573,
          337,
          653,
          25459,
          302,
          530,
          343,
          3688,
          3223,
          76,
          6469,
          2526,
          9993,
          1526206,
          254,
          307,
          1725,
          5848,
          1679,
          344,
          2836,
          571,
          4653,
          1252,
          168,
          7155,
          914,
          2317,
          3508,
          1102,
          413574,
          198,
          2206,
          258,
          69793,
          4074,
          95035,
          2148,
          1758,
          1195,
          13717,
          198,
          7987,
          320,
          337,
          928,
          3688,
          1312,
          2435,
          800,
          5507,
          1132,
          18408,
          133,
          123,
          970,
          45100,
          302,
          1606,
          861,
          601723,
          140,
          20328,
          824,
          4138,
          1858,
          1453,
          1617,
          1661,
          475,
          3119,
          663,
          6841,
          84106,
          1565,
          1302,
          1271,
          184,
          737,
          10076,
          222785,
          198,
          5354,
          2317,
          71485,
          5875,
          2307,
          76,
          3395,
          718,
          1689,
          2906700,
          43,
          151022,
          1446,
          73,
          137,
          922,
          355,
          3032,
          2206,
          895,
          885,
          467,
          6629,
          78968,
          2872,
          1858,
          17867,
          5211,
          341043,
          85,
          10076,
          5760,
          2328,
          2456,
          467,
          129,
          19090,
          2786,
          6460,
          632,
          297,
          4993,
          972,
          177,
          15647,
          5621,
          9594,
          828,
          94014,
          1274,
          3202,
          4589,
          172817,
          260,
          105549,
          581,
          1453,
          1186,
          5908,
          795,
          213,
          69793,
          407,
          19685,
          1312922,
          7155,
          99,
          564,
          32891,
          3119,
          77,
          645,
          5848,
          1749,
          1271,
          4512,
          73,
          328,
          6713,
          191096,
          477,
          595,
          519,
          1583,
          93193,
          937,
          2906700,
          6629,
          321490,
          470,
          5875,
          532,
          33804,
          46563,
          741,
          8830,
          94014,
          970,
          1443,
          533,
          128,
          493,
          42817,
          795,
          20478,
          463,
          99,
          1507,
          1595797,
          11432,
          2607,
          3096,
          1595797,
          337,
          1423,
          46,
          11751,
          3684,
          7646,
          123,
          1382480,
          28739,
          2526,
          741,
          626,
          914,
          13422,
          2290,
          1102,
          836,
          824,
          6006,
          922,
          760,
          6951,
          223,
          341043,
          158701,
          302,
          47249,
          46,
          687276,
          1762,
          104396,
          18128,
          42619,
          1478,
          516,
          186140,
          2078,
          190178,
          328,
          2317,
          2317,
          186140,
          73,
          12335,
          2435,
          4512,
          2148,
          581,
          686,
          105638,
          276,
          1442,
          1146,
          1656,
          477,
          2971,
          5875,
          2290,
          4664,
          19054,
          11253,
          35705,
          365,
          4074,
          378909,
          4015,
          241,
          9772,
          1241364,
          14783,
          932,
          28278,
          8333,
          4573,
          76383,
          1970,
          1383,
          77,
          42817,
          73,
          1645,
          2401,
          2121,
          606,
          3255,
          530,
          12486,
          42817,
          1363,
          2307,
          247,
          7155,
          498,
          2518,
          276896,
          2258,
          564,
          1288,
          87124,
          217,
          35705,
          277,
          100,
          1089,
          104396,
          722,
          895,
          124967,
          3096,
          52,
          10295,
          964,
          5908,
          1770,
          3289,
          1595797,
          4049,
          467,
          32891,
          493806,
          46944,
          1897,
          12747,
          1196,
          4680,
          4653,
          255,
          504,
          516,
          13835,
          192,
          307,
          606,
          1383,
          34882,
          1563,
          1745,
          1507,
          3202,
          2317,
          1925,
          23727,
          1970,
          343,
          31515,
          3766,
          69,
          413574,
          1946,
          1766,
          1526206,
          151785,
          520,
          1791,
          71485,
          6581,
          3996,
          4845,
          67858,
          158701,
          1312922,
          324,
          71335,
          2290,
          5760,
          2258,
          470,
          2872,
          895,
          207410,
          105549,
          525713,
          263,
          20328,
          34496,
          3876,
          1178,
          824,
          224256,
          647,
          4474,
          601723,
          5341,
          647,
          525713,
          5548,
          76,
          172817,
          1617,
          5621,
          77,
          732,
          341,
          85,
          88735,
          914,
          248,
          46563,
          2290,
          271,
          1241364,
          92985,
          343,
          520,
          471,
          1420,
          765,
          725,
          391389,
          105638,
          19054,
          6841,
          5196,
          18408,
          1363,
          397,
          5548,
          242,
          15426,
          43102,
          207410,
          3807,
          158701,
          370,
          922,
          85,
          13717,
          241,
          224256,
          43,
          1946,
          5512,
          7565,
          520,
          137,
          4653,
          1689,
          50835,
          776,
          725,
          1970,
          95035,
          2906700,
          5875,
          1858,
          477,
          606,
          502,
          126,
          2443,
          760,
          3495,
          21902,
          1228,
          2456,
          42817,
          2971,
          2471,
          9512,
          222,
          7155,
          2142,
          1241364,
          13973,
          2526,
          489,
          100,
          47772,
          1574,
          5760,
          217,
          4474,
          2856,
          6951,
          34882,
          156391,
          743,
          10717,
          581,
          1426,
          2135,
          1606,
          824,
          450,
          459921,
          1382480,
          530,
          22930,
          165,
          18128,
          863,
          2644,
          237282,
          346,
          626,
          277,
          2148,
          34153,
          3279,
          7155,
          863,
          192805,
          1080,
          4049,
          21125,
          2135,
          12486,
          824,
          725,
          369,
          642,
          2661,
          85,
          743,
          94325,
          76383,
          139650,
          276896,
          632,
          5621,
          910148,
          99,
          43102,
          4726,
          2290,
          2443,
          365,
          3032,
          128715,
          743,
          1645,
          31970,
          5196,
          17867,
          190178,
          7155,
          737,
          76383,
          4056,
          2607,
          687276,
          687276,
          1102,
          9679,
          899,
          4508,
          32891,
          9506,
          198,
          717255,
          94014,
          1252,
          9784,
          4367,
          1132,
          11256,
          47249,
          836,
          1504,
          27971,
          143,
          1766,
          275,
          321,
          1453,
          53,
          4573,
          2566,
          24645,
          4172,
          2457,
          186140,
          198,
          1758,
          2304,
          277,
          348,
          10076,
          1523,
          75903,
          2148,
          16163,
          55345,
          310,
          42619,
          5908,
          2036,
          137,
          271,
          1563,
          21902,
          633,
          970,
          1302,
          1656,
          2135,
          140,
          22930,
          1504,
          218,
          46944,
          54185,
          427,
          222785,
          21134,
          348,
          1263321,
          1988,
          4056,
          34153,
          233717,
          489,
          21437,
          10717,
          1909,
          1909,
          92043,
          626,
          4878,
          136,
          32891,
          912,
          477,
          7163,
          3862,
          878,
          372,
          213,
          31394,
          269,
          1758,
          77,
          419,
          22930,
          5211,
          23045,
          341,
          104396,
          255,
          84861,
          2408,
          1271,
          795,
          217,
          687276,
          241,
          1643,
          4878,
          680,
          104396,
          128,
          71485,
          686,
          2383912,
          50835,
          6951,
          75903,
          136,
          1766,
          10717,
          36784,
          2206,
          1102,
          5621,
          823,
          1810,
          2607,
          8333,
          571,
          137,
          24840,
          166081,
          77,
          217,
          2135,
          1850,
          470,
          478,
          34496,
          21125,
          269,
          343,
          14783,
          69793,
          3684,
          551,
          34496,
          4720,
          53,
          459921,
          1453,
          54185,
          632,
          198,
          124967,
          1514,
          31515,
          85,
          136,
          864,
          1423,
          3862,
          519,
          470,
          4512,
          276002,
          551,
          4677,
          1897,
          648,
          4778,
          4729,
          35371,
          910148,
          450,
          427,
          267,
          532,
          3228,
          5927,
          23,
          15623,
          2208,
          1312,
          13835,
          718,
          2456,
          1523,
          836,
          21635,
          5901,
          158701,
          276002,
          75830,
          4653,
          5791,
          165556,
          3684,
          2121,
          4542,
          5211,
          1312922,
          2121,
          260,
          349,
          4474,
          1363,
          502,
          149,
          3223,
          263,
          1252,
          3876,
          477,
          1078,
          31515,
          2376,
          3224,
          927396,
          3833,
          3766,
          4845,
          12335,
          320420,
          5908,
          20328,
          3032,
          346,
          6841,
          765,
          3224,
          7565,
          241,
          1360,
          4573,
          87124,
          1102,
          910148,
          260,
          520,
          118,
          1533,
          172817,
          21902,
          3402,
          28425,
          1679,
          51,
          1643,
          24840,
          1412,
          888,
          54287,
          230,
          217,
          2307,
          824,
          2872,
          1789,
          134056,
          13973,
          757530,
          4575,
          1631,
          972,
          2368,
          1517,
          863,
          2135,
          1512,
          910148,
          2092,
          2435,
          71335,
          192,
          804,
          632,
          128354,
          1324,
          55581,
          641349,
          42384,
          54287,
          10295,
          626,
          640470,
          516,
          391389,
          2376,
          372,
          7646,
          105638,
          630,
          1186,
          1453,
          28739,
          107941,
          92985,
          970,
          579,
          5507,
          4542,
          94014,
          270712,
          19054,
          76383,
          7646,
          639,
          12335,
          84106,
          30770,
          107941,
          31515,
          7268,
          828,
          11751,
          5760,
          136,
          2092,
          1523,
          1643,
          85,
          5341,
          67082,
          1478,
          2307,
          341043,
          248,
          20328,
          3699,
          498,
          275,
          1577385,
          722,
          1089,
          213,
          191096,
          16183,
          2607,
          169,
          828,
          1228,
          606,
          223,
          269,
          912,
          14228,
          92106,
          7692,
          99,
          4474,
          165556,
          128715,
          1423,
          17047,
          190178,
          4993,
          158701,
          828,
          1426,
          5848,
          172817,
          1178,
          1274,
          151022,
          1532,
          1563,
          6018,
          308,
          192,
          87124,
          307,
          13973,
          5666,
          213,
          1078,
          1780,
          3104,
          229,
          331,
          759,
          2290,
          1022298,
          116001,
          737,
          1261,
          71463,
          299480,
          2526,
          477,
          551,
          4090,
          258,
          3688,
          7565,
          914,
          355,
          1324,
          5161,
          22305,
          207,
          376,
          1461,
          4367,
          11751,
          922,
          1241364,
          5196,
          471,
          3994,
          140,
          100,
          2523,
          77,
          7987,
          376,
          3688,
          5548,
          1089,
          6581,
          2566,
          804,
          166081,
          92043,
          969,
          116155,
          165556,
          477,
          198,
          632,
          9815,
          1925,
          1892,
          128354,
          103927,
          5927,
          124967,
          6469,
          4005,
          105549,
          229,
          1271,
          50489,
          427,
          571,
          77,
          27971,
          229,
          1166,
          970,
          722,
          302,
          263,
          1595797,
          105638,
          302,
          589,
          532,
          970,
          1312,
          471,
          46,
          1382480,
          1075,
          376,
          31394,
          741,
          186140,
          391389,
          24840,
          647,
          633,
          2691,
          1089,
          116155,
          54287,
          1360,
          7297,
          1146,
          828,
          178,
          5621,
          648,
          1595797,
          895,
          21134,
          888,
          2206,
          333497,
          1970,
          5621,
          1850,
          263,
          52126,
          888,
          1089,
          20328,
          341043,
          459921,
          42384,
          136,
          128715,
          5196,
          21902,
          21902,
          1132,
          7268,
          42619,
          34153,
          165556,
          5848,
          23805,
          4913,
          1022298,
          2328,
          795,
          134056,
          1312922,
          22305,
          718,
          450,
          1745,
          213,
          341043,
          2456,
          509,
          532,
          76,
          269,
          5875,
          276002,
          5196,
          99,
          277,
          1420,
          895,
          1288,
          741,
          1909,
          2526,
          331,
          71463,
          630,
          74,
          34496,
          1352,
          2691,
          5196,
          3289,
          241,
          13422,
          5196,
          10076,
          686,
          71485,
          2092,
          4542,
          186140,
          370,
          1507,
          35299,
          1725,
          1412,
          3766,
          899,
          2142,
          1850,
          910148,
          489,
          343,
          6951,
          817312,
          663,
          1363,
          2206,
          1595797,
          601723,
          4680,
          633,
          4542,
          46944,
          165,
          2383912,
          7155,
          111,
          217,
          1517,
          22930,
          1595797,
          864,
          1201,
          6703,
          471,
          5927,
          1512,
          276002,
          5161,
          5760,
          14871,
          2303,
          4138,
          2471,
          467,
          4542,
          99,
          1324,
          156391,
          349,
          276896,
          222,
          2916,
          673342,
          2691,
          224256,
          498,
          206,
          153,
          333497,
          5901,
          50489,
          1241364,
          847,
          224256,
          1274,
          520,
          47772,
          7155,
          207,
          1850,
          341,
          217,
          241,
          663,
          5895,
          1523,
          4895,
          105549,
          3343,
          1126,
          454,
          606,
          128354,
          192,
          2872,
          76383,
          1368,
          5875,
          1988,
          1504,
          2906700,
          1412,
          9679,
          805,
          3688,
          11256,
          680,
          22930,
          741,
          165556,
          530,
          14871,
          2471,
          34882,
          1686,
          276896,
          172817,
          3289,
          337,
          1791,
          1577385,
          805,
          27829,
          757530,
          238602,
          2526,
          341043,
          116001,
          333497,
          68211,
          1966,
          20328,
          30770,
          4993,
          5875,
          2504700,
          5341,
          1979,
          737,
          27971,
          626,
          744,
          1453,
          564,
          5621,
          1892,
          139,
          1426,
          5196,
          3285,
          28739,
          277,
          33804,
          34153,
          823,
          3994,
          46,
          5875,
          78968,
          241,
          128715,
          165,
          92608,
          134056,
          172247,
          743,
          5577,
          757530,
          14783,
          5778,
          1363,
          4542,
          427,
          5908,
          828,
          471,
          217,
          8874,
          1831,
          104396,
          23805,
          914,
          1131,
          910148,
          222,
          1019,
          337,
          158701,
          2078,
          107941,
          4056,
          94014,
          67082,
          355,
          151022,
          222785,
          1858,
          222785,
          4593,
          1939,
          151815,
          1897,
          6581,
          1760,
          5732,
          2016,
          6951,
          1426,
          2456,
          6629,
          30770,
          1196,
          3223,
          545147,
          1532,
          1334,
          489,
          118,
          761,
          3684,
          1766,
          687276,
          43,
          84106,
          45100,
          4198,
          765,
          2501,
          5791,
          725,
          247,
          1126,
          1666,
          59705,
          2274,
          184,
          1102,
          2435,
          4512,
          1766,
          1078,
          376,
          3279,
          493,
          78968,
          841711,
          1749,
          365,
          15647,
          67082,
          1288,
          17867,
          2799,
          126,
          910148,
          26551,
          895,
          912,
          5577,
          55581,
          95035,
          2328,
          30770,
          4074,
          30770,
          1970,
          124967,
          9587,
          606,
          10076,
          178,
          4533,
          641349,
          5507,
          1923,
          18408,
          4161,
          20328,
          1654,
          828,
          1943,
          10295,
          5848,
          31515,
          519,
          2661,
          828,
          1789,
          192805,
          639,
          2304,
          86954,
          1087,
          92985,
          1847,
          76,
          45303,
          93193,
          276002,
          1583,
          3776,
          1563,
          1700,
          247,
          67082,
          4542,
          863,
          298,
          18182,
          276896,
          922,
          258,
          50835,
          2526,
          248,
          320420,
          741,
          338,
          1126,
          798,
          191096,
          776,
          165556,
          2202,
          242,
          5512,
          128715,
          111,
          25459,
          467,
          3343,
          27020,
          372,
          885,
          1423,
          143,
          63,
          3224,
          632,
          5211,
          269,
          4573,
          520,
          2016,
          4198,
          10256,
          1979,
          579,
          743,
          4354,
          1075,
          25459,
          91,
          140,
          68211,
          5903,
          1412,
          1804,
          1446,
          1383,
          217,
          95,
          1261,
          504,
          192805,
          718,
          1970,
          804,
          186140,
          145,
          6018,
          1749,
          163415,
          467,
          2836,
          5760,
          137,
          42817,
          969,
          4367,
          128715,
          10295,
          910148,
          1749,
          626,
          633,
          1228,
          2872,
          145,
          4993,
          3833,
          1312922,
          565,
          686,
          470,
          99,
          166081,
          1363,
          976,
          24840,
          14871,
          9496,
          4680,
          151785,
          67082,
          50489,
          899,
          3776,
          346,
          914,
          899,
          144160,
          467,
          71335,
          372,
          321,
          601723,
          320420,
          409656,
          346,
          1577385,
          313,
          34153,
          338,
          6025,
          5719,
          7155,
          864,
          258,
          8019,
          3807,
          156391,
          8830,
          4056,
          9993,
          5719,
          172817,
          16163,
          969,
          241,
          3223,
          632,
          128354,
          1334,
          269,
          59705,
          10295,
          207410,
          3688,
          4680,
          238602,
          516,
          3684,
          1051,
          3202,
          1461,
          1368,
          725,
          601723,
          35439,
          1925,
          863,
          263,
          191096,
          836,
          466,
          1312922,
          71335,
          7163,
          5666,
          28739,
          1334,
          1201,
          2644,
          736284,
          238602,
          3684,
          16183,
          123373,
          378909,
          355,
          176,
          5666,
          27020,
          571,
          51,
          970,
          2501,
          31515,
          579,
          5512,
          6006,
          6469,
          910148,
          5216,
          224256,
          972,
          184,
          118,
          25459,
          258,
          710,
          597,
          564,
          771,
          206,
          804,
          53,
          5512,
          145,
          19408,
          2223,
          21134,
          184,
          1841,
          10295,
          346,
          2661,
          2036,
          5161,
          2906700,
          42619,
          632,
          21125,
          1979,
          1577385,
          107941,
          824,
          3104,
          1804,
          269,
          276002,
          4154,
          13835,
          540,
          2368,
          2092,
          178,
          493,
          1656,
          1766,
          3996,
          19685,
          922,
          626,
          2971,
          95035,
          9034,
          186140,
          328,
          270712,
          1420,
          4474,
          116001,
          1760,
          409656,
          34882,
          736284,
          73,
          77,
          12747,
          4512,
          5726,
          8512,
          3104,
          9815,
          297,
          60,
          9679,
          782,
          470,
          2258,
          190178,
          878,
          885,
          93193,
          133,
          5989,
          2408,
          217,
          137,
          516,
          836,
          93193,
          346,
          61,
          828,
          192,
          530,
          1102,
          276002,
          645,
          24536,
          6951,
          1126,
          21635,
          48194,
          50835,
          2263,
          248858,
          1442,
          21635,
          26120,
          526,
          828,
          3289,
          520,
          1383,
          3833,
          571,
          13835,
          1909,
          782,
          601723,
          828,
          308,
          215,
          1526206,
          641,
          1725,
          1360,
          1892,
          116155,
          2807,
          15647,
          6120,
          35371,
          46563,
          71463,
          601723,
          2457,
          732,
          1195,
          54767,
          22930,
          5875,
          177,
          5666,
          166081,
          2206,
          20478,
          2317,
          50489,
          239,
          413574,
          7268,
          1261,
          4653,
          267,
          1504,
          71335,
          239,
          10256,
          1334,
          12486,
          276896,
          2379,
          932,
          1126,
          2916,
          1909,
          836,
          7646,
          7430,
          2135,
          1565,
          34496,
          13061,
          5895,
          46,
          737,
          1577385,
          19408,
          4474,
          8512,
          2036,
          42817,
          2376,
          140,
          509,
          1363,
          5196,
          540,
          579,
          493806,
          52,
          13602,
          1923,
          2135,
          1166,
          186140,
          95,
          129,
          922,
          207,
          269,
          2566,
          99,
          9815,
          2290,
          110,
          1892,
          1745,
          21125,
          1725,
          272,
          1523,
          832,
          1261,
          922,
          22930,
          1363,
          824,
          372,
          1892,
          825,
          530,
          4542,
          2304,
          191096,
          3202,
          128,
          1228,
          2036,
          37,
          409656,
          14871,
          645,
          50835,
          836,
          2307,
          46,
          771,
          2607,
          18760,
          389246,
          4015,
          229,
          3833,
          9815,
          4367,
          1725,
          106,
          1577385,
          3688,
          601723,
          381459,
          1666,
          2383912,
          759,
          741,
          76,
          7163,
          1078,
          888,
          969,
          13973,
          9815,
          2872,
          2263,
          96942,
          75830,
          107941,
          295,
          301,
          565,
          233717,
          7155,
          27971,
          804,
          4090,
          1263321,
          811,
          376,
          2376,
          4074,
          76,
          475,
          6951,
          647,
          69,
          6434,
          645,
          139,
          18128,
          276896,
          43,
          6629,
          2566,
          760,
          43102,
          1382480,
          45303,
          1443,
          258,
          1654,
          184,
          17047,
          372,
          95035,
          732,
          215,
          741,
          493806,
          1186,
          2504700,
          218,
          365,
          124967,
          6629,
          276896,
          341,
          1426,
          348,
          230,
          85,
          26551,
          4074,
          1789,
          13835,
          76,
          1038,
          914,
          3776,
          47772,
          1201,
          28739,
          478,
          6508,
          477,
          77,
          972,
          106,
          167,
          910148,
          606,
          1766,
          466,
          136895,
          32891,
          1512,
          50489,
          4015,
          21134,
          4090,
          8097,
          4729,
          128715,
          922,
          5666,
          1791,
          96942,
          7646,
          333497,
          54185,
          564,
          378909,
          1766,
          878,
          5512,
          214703,
          5719,
          1512,
          686,
          450,
          5662,
          18128,
          145,
          1892,
          4575,
          673342,
          1423,
          1166,
          2060,
          207,
          1565,
          5908,
          48194,
          5662,
          5666,
          217,
          722,
          1461,
          2121,
          516,
          566,
          153,
          409656,
          30770,
          673342,
          84106,
          2121,
          13602,
          22930,
          376,
          1490,
          36438,
          516,
          376,
          602,
          471,
          454,
          166081,
          1725,
          229,
          269,
          3285,
          1909,
          1789,
          1680,
          722,
          3996,
          737,
          321490,
          1271,
          2872,
          878,
          301,
          2501,
          218,
          5875,
          733,
          53,
          76383,
          391389,
          3876,
          3807,
          68211,
          166081,
          2328,
          1512,
          20328,
          1312,
          568,
          222785,
          241,
          1241364,
          10295,
          798,
          20478,
          753116,
          23727,
          680,
          823,
          5161,
          276896,
          4726,
          4993,
          4161,
          71335,
          372,
          914,
          1970,
          828,
          498,
          23,
          269,
          4993,
          1051,
          4198,
          346,
          21134,
          5895,
          184,
          46563,
          254282,
          717255,
          2097,
          471,
          258,
          258,
          1382480,
          128715,
          6581,
          1666,
          365,
          269,
          5662,
          3202,
          149,
          25459,
          3833,
          1766,
          3730,
          1789,
          77,
          18408,
          54767,
          8333,
          5666,
          1770,
          343,
          532,
          68211,
          1196,
          863,
          647,
          4354,
          1166,
          1946,
          832,
          4056,
          85,
          34496,
          1075,
          2379,
          725,
          350,
          104396,
          116001,
          167,
          9594,
          277,
          391389,
          606,
          2395,
          270712,
          4664,
          331,
          297,
          589,
          198,
          2836,
          1970,
          3096,
          12335,
          1271,
          302,
          2036,
          1810,
          1420,
          76383,
          741,
          87124,
          59744,
          2401,
          34153,
          3495,
          100,
          7297,
          34153,
          341,
          1312,
          1666,
          341,
          804,
          502,
          107941,
          298,
          493806,
          910148,
          1679,
          2317,
          1563,
          67858,
          1577385,
          2504700,
          267,
          42619,
          298,
          466,
          67082,
          15623,
          2395,
          581,
          376,
          1423,
          1228,
          45303,
          128,
          2607,
          169,
          54287,
          237282,
          378909,
          863,
          77,
          409656,
          1383,
          389246,
          6951,
          1930,
          3688,
          79613,
          1563,
          7268,
          168,
          2691,
          2644,
          450,
          302,
          4081,
          184,
          10295,
          2328,
          156391,
          123,
          4074,
          10717,
          85,
          863,
          1178,
          463,
          32891,
          191096,
          581,
          2208,
          1735,
          47249,
          123,
          6841,
          276896,
          601723,
          4575,
          171170,
          8097,
          673342,
          1684,
          18408,
          1414,
          33804,
          19054,
          75830,
          18182,
          79613,
          79008,
          1514,
          409656,
          171170,
          471,
          136,
          35371,
          2307,
          13835,
          590,
          878,
          3096,
          1261,
          540,
          3395,
          663,
          632,
          1186,
          7268,
          3996,
          470,
          18182,
          642,
          1446,
          207,
          640470,
          2121,
          116001,
          129,
          5196,
          1939,
          48194,
          124967,
          158701,
          571,
          136895,
          3684,
          545147,
          277,
          522,
          16305,
          1645,
          6841,
          76383,
          6284,
          509,
          475,
          206,
          795,
          94325,
          922,
          525713,
          545147,
          129,
          263,
          4542,
          602,
          626,
          12747,
          1019,
          1758,
          192,
          2263,
          331,
          15269,
          17867,
          369,
          320,
          1735,
          9565,
          1022298,
          203571,
          2526,
          5341,
          2054,
          21134,
          545147,
          7155,
          4573,
          532,
          99,
          67082,
          1063,
          316665,
          13061,
          30770,
          1312922,
          5507,
          1532,
          409656,
          1810,
          136,
          1312,
          2836,
          269,
          530,
          92985,
          2470,
          470,
          5875,
          540,
          88735,
          526,
          128,
          12486,
          1571,
          75830,
          1312922,
          1126,
          3766,
          313,
          95,
          74,
          8007,
          1186,
          165556,
          3224,
          276002,
          493806,
          4306,
          7420,
          4090,
          969,
          1195,
          344,
          276896,
          321490,
          969,
          1523,
          355,
          365,
          1675,
          313,
          526,
          346,
          5895,
          177,
          5732,
          823,
          7646,
          1563,
          71335,
          48194,
          51,
          899,
          28278,
          2856,
          1725,
          136,
          213,
          276002,
          2135,
          110,
          626,
          1334,
          95,
          238602,
          79613,
          733,
          238602,
          1526206,
          640470,
          1383,
          165,
          36438,
          687276,
          6951,
          21902,
          2870,
          736284,
          242,
          695,
          964,
          828,
          5848,
          922,
          409656,
          153,
          34153,
          519,
          4512,
          1412,
          1512,
          165556,
          1412,
          6581,
          104,
          4542,
          271,
          271,
          1089,
          722,
          32891,
          2148,
          4508,
          1263321,
          1089,
          1423,
          213,
          71335,
          140,
          76,
          1804,
          2501,
          645,
          13973,
          104396,
          1789,
          606,
          4845,
          9496,
          737,
          680,
          276896,
          15269,
          589,
          11432,
          320420,
          504,
          1631,
          50489,
          551,
          932,
          1293,
          6951,
          639,
          247,
          19685,
          3202,
          663,
          518429,
          71335,
          459921,
          1606,
          673342,
          2836,
          269,
          370,
          513,
          7646,
          1420,
          233717,
          841711,
          129,
          21902,
          973849,
          2036,
          93193,
          302,
          1312922,
          167,
          765,
          184,
          34882,
          642,
          168,
          836,
          18408,
          69,
          765,
          1686,
          151785,
          34882,
          69,
          5507,
          6120,
          1507,
          144160,
          343,
          24840,
          270712,
          186140,
          471,
          5760,
          3996,
          5760,
          140,
          14871,
          1530,
          2457,
          1442,
          413574,
          1302,
          2872,
          1288,
          4533,
          1140,
          222,
          4720,
          1288,
          2401,
          22191,
          1850,
          54287,
          732,
          248,
          302,
          743,
          10076,
          427,
          1841,
          1946,
          5927,
          3996,
          178,
          2258,
          31394,
          46563,
          1493,
          1512,
          3996,
          320420,
          365,
          6006,
          17867,
          5211,
          6018,
          365,
          151785,
          910148,
          1241364,
          254282,
          2328,
          291,
          84106,
          1383,
          63,
          320420,
          11432,
          743,
          320,
          718,
          3508,
          376,
          5161,
          286,
          1656,
          937,
          516,
          9679,
          602,
          106,
          1271,
          46563,
          4306,
          267,
          6006,
          10295,
          4575,
          7565,
          248858,
          2408,
          156391,
          20478,
          186140,
          25459,
          970,
          973849,
          54287,
          4542,
          1263321,
          10076,
          13602,
          9512,
          2202,
          2206,
          823,
          647,
          151815,
          1179,
          69793,
          1595797,
          100,
          771,
          94014,
          198,
          3430,
          1241364,
          222,
          60,
          717255,
          313,
          3255,
          137,
          6120,
          2872,
          4993,
          1442,
          4575,
          1063,
          181438,
          2135,
          1939,
          5341,
          4895,
          6284,
          4993,
          136,
          5778,
          167,
          378909,
          3430,
          5875,
          213,
          1312922,
          254282,
          7297,
          2202,
          1804,
          134056,
          922,
          489,
          4198,
          76,
          4161,
          3776,
          1472,
          1263321,
          1675,
          190249,
          94325,
          911,
          922,
          1925,
          52126,
          1312922,
          2307,
          4993,
          30770,
          695,
          2607,
          5451,
          922,
          5950,
          18128,
          1022298,
          5619,
          6120,
          37,
          4729,
          238602,
          391389,
          608,
          466,
          118,
          1263321,
          2304,
          18128,
          48194,
          478,
          1762,
          341,
          370,
          910148,
          1382480,
          67082,
          139,
          277,
          1334,
          1078,
          92294,
          5760,
          1461,
          230,
          1453,
          5196,
          4056,
          630,
          14871,
          4664,
          349,
          3104,
          111,
          2148,
          571,
          1360,
          205,
          4573,
          22305,
          33917,
          477,
          8874,
          3224,
          489,
          2518,
          1970,
          34153,
          47211,
          74,
          26551,
          687276,
          832,
          205,
          695,
          5648,
          1700,
          1312922,
          1749,
          2836,
          1988,
          911,
          328,
          427,
          477,
          1617,
          5621,
          1312,
          2304,
          409656,
          341043,
          78968,
          743,
          74,
          397,
          33917,
          6120,
          21125,
          2089,
          571,
          69793,
          186140,
          2456,
          337,
          389246,
          4074,
          470,
          20478,
          1925,
          47211,
          2328,
          765,
          35371,
          1810,
          241,
          192,
          2870,
          5666,
          4508,
          92608,
          389246,
          5161,
          1565,
          516,
          307,
          118,
          18182,
          18182,
          466,
          5621,
          1420,
          1675,
          1850,
          372,
          1363,
          1758,
          76,
          2607,
          1190,
          20478,
          836,
          263,
          376,
          502,
          1789,
          19090,
          190,
          1383,
          1988,
          4542,
          242,
          76,
          123373,
          45100,
          17867,
          71485,
          19685,
          888,
          1261,
          2456,
          1363,
          14871,
          255,
          5875,
          128354,
          365,
          59744,
          16183,
          10076,
          94325,
          828,
          149,
          811,
          70,
          606,
          1241364,
          140,
          601723,
          509,
          2328,
          4913,
          885,
          2644,
          104396,
          230,
          34882,
          2078,
          1131,
          92106,
          13422,
          7155,
          42817,
          333497,
          3776,
          369,
          427,
          328,
          46944,
          5451,
          23727,
          241,
          2304,
          1645,
          1426,
          190178,
          19685,
          1241364,
          1766,
          798,
          372,
          970,
          28739,
          6460,
          6703,
          1789,
          27020,
          1178,
          313,
          1490,
          207410,
          71485,
          4138,
          1725,
          9496,
          2258,
          163415,
          166081,
          9993,
          123373,
          12335,
          276002,
          4677,
          9772,
          217,
          6629,
          4090,
          3289,
          5341,
          1126,
          687276,
          1577385,
          73,
          2872,
          1595797,
          198,
          5726,
          186140,
          218,
          606,
          1051,
          178,
          1930,
          1493,
          308,
          817312,
          198,
          13717,
          111,
          104396,
          969,
          16305,
          372,
          4677,
          4778,
          9772,
          736284,
          1382480,
          4680,
          1645,
          1617,
          1100,
          5895,
          1383,
          349,
          601723,
          4664,
          530,
          105549,
          1631,
          2786,
          7268,
          128354,
          1789,
          759,
          5457,
          836,
          626,
          1453,
          532,
          69,
          100,
          1063,
          4575,
          1645,
          1631,
          602,
          255,
          3395,
          5875,
          1478,
          149,
          2408,
          137067,
          2206,
          7155,
          824,
          272,
          519,
          222,
          3032,
          450,
          765,
          145,
          8333,
          54287,
          2504700,
          92337,
          1970,
          1533,
          545147,
          295,
          641,
          722,
          271,
          606,
          3279,
          753116,
          76383,
          4138,
          207,
          198,
          639,
          99,
          4424,
          178,
          238602,
          6841,
          4138,
          2518,
          4664,
          229,
          602,
          10717,
          571,
          1789,
          2206,
          759,
          2607,
          123,
          2401,
          478,
          27020,
          1022298,
          895,
          78968,
          302,
          346,
          35371,
          6469,
          409656,
          2518,
          73,
          1360,
          5354,
          79008,
          321,
          1442,
          46944,
          545147,
          1304,
          214518,
          19685,
          15647,
          4677,
          355,
          50835,
          1679,
          571,
          899,
          118,
          409656,
          277,
          805,
          736284,
          134056,
          1512,
          31515,
          190178,
          18459,
          3833,
          5161,
          9496,
          5666,
          1909,
          4878,
          166081,
          3430,
          337,
          192805,
          1302,
          7646,
          190178,
          316665,
          5927,
          100,
          4589,
          34882,
          9993,
          927396,
          34882,
          1324,
          128,
          635,
          1946,
          3776,
          2054,
          25459,
          1143,
          324,
          67082,
          5507,
          498,
          911,
          5927,
          4090,
          153,
          128715,
          520,
          276002,
          324,
          67858,
          71485,
          1532,
          3430,
          413574,
          1689,
          165,
          3996,
          19090,
          2307,
          3202,
          10295,
          673342,
          4664,
          1892,
          6460,
          328,
          272,
          2054,
          14871,
          11256,
          129,
          2872,
          21902,
          213,
          46,
          564,
          914,
          2691,
          1132,
          450,
          2121,
          145,
          413574,
          43,
          1493,
          1288,
          4895,
          1523,
          565,
          1689,
          647,
          2290,
          9034,
          477,
          34882,
          7268,
          378909,
          2435,
          2307,
          4049,
          28278,
          92985,
          2258,
          13717,
          2872,
          27020,
          54767,
          6006,
          518429,
          4878,
          302,
          606,
          1617,
          3279,
          92294,
          1661,
          320,
          722,
          2376,
          2836,
          2872,
          824,
          1526206,
          3684,
          1532,
          207,
          1583,
          32891,
          1725,
          540,
          128,
          6018,
          2504700,
          817312,
          1645,
          186140,
          5989,
          2870,
          11250,
          2307,
          972,
          2054,
          71463,
          1526206,
          229,
          6841,
          4198,
          564,
          1241364,
          32891,
          3807,
          241,
          248858,
          568,
          61,
          5719,
          471,
          743,
          3223,
          3699,
          341,
          111,
          51,
          276896,
          343,
          104396,
          248,
          413574,
          1271,
          166081,
          61,
          11751,
          136,
          6508,
          1577385,
          1892,
          5657,
          1263321,
          470,
          263,
          3224,
          2566,
          1988,
          1909,
          8874,
          118,
          239,
          4913,
          350,
          128,
          248858,
          129,
          1766,
          35371,
          19408,
          5662,
          2376,
          9772,
          2526,
          2870,
          2223,
          30770,
          7268,
          5216,
          1789,
          95035,
          5211,
          1186,
          1841,
          136,
          7155,
          1645,
          565,
          478,
          128354,
          2135,
          34496,
          104396,
          14871,
          760,
          2135,
          2644,
          76,
          4878,
          372,
          1075,
          186140,
          165,
          1423,
          35439,
          6120,
          601723,
          92985,
          349,
          1858,
          964,
          1909,
          3776,
          1617,
          46944,
          1078,
          13973,
          4680,
          4913,
          118,
          927396,
          47249,
          1089,
          207410,
          320420,
          1725,
          3032,
          760,
          95,
          3119,
          3104,
          878,
          1241364,
          349,
          606,
          206,
          254,
          22305,
          9051,
          2290,
          381459,
          84106,
          804,
          1506,
          3833,
          254,
          21134,
          6951,
          198,
          795,
          2456,
          1089,
          13717,
          144160,
          885,
          1858,
          153,
          6284,
          1089,
          5895,
          581,
          2872,
          36784,
          1749,
          4354,
          1810,
          1804,
          123373,
          5875,
          2135,
          54767,
          128354,
          42817,
          3833,
          4533,
          836,
          1302,
          520,
          91,
          2307,
          136895,
          320420,
          564,
          21902,
          2870,
          568,
          54767,
          239,
          568,
          498,
          686,
          601723,
          144160,
          156391,
          92608,
          269,
          911,
          1791,
          2328,
          207,
          1571,
          151785,
          2786,
          2906700,
          1263321,
          1841,
          1789,
          272,
          286,
          2395,
          4198,
          18182,
          743,
          409656,
          7163,
          277,
          914,
          626,
          4895,
          2054,
          21125,
          6841,
          15426,
          85,
          237282,
          248,
          647,
          4653,
          95,
          973849,
          19685,
          372,
          3766,
          2872,
          653,
          320420,
          241,
          1414,
          299480,
          12335,
          647,
          722,
          333497,
          1858,
          31394,
          673342,
          269,
          95015,
          630,
          823,
          2836,
          1420,
          5848,
          564,
          2408,
          24840,
          128,
          10717,
          92608,
          519,
          2263,
          198,
          17047,
          217,
          35371,
          237282,
          270712,
          308,
          45100,
          565,
          1563,
          798,
          1263321,
          526,
          215,
          3395,
          399,
          343,
          5619,
          104396,
          19054,
          765,
          1312922,
          69793,
          3766,
          2408,
          22191,
          1019,
          13983,
          642,
          77,
          242,
          165556,
          1680,
          841711,
          2607,
          76383,
          11751,
          2379,
          1420,
          19090,
          5778,
          2408,
          2328,
          737,
          71463,
          397,
          614,
          899,
          5577,
          640470,
          321,
          4512,
          525713,
          302,
          970,
          3833,
          551,
          639,
          3395,
          32891,
          2504700,
          1526206,
          218,
          464,
          33804,
          1791,
          1504,
          218,
          59744,
          1139,
          1179,
          308,
          110,
          467,
          571,
          736284,
          105549,
          545147,
          105638,
          184,
          3684,
          144160,
          2661,
          1423,
          1577385,
          1512,
          137,
          230,
          214518,
          759,
          4474,
          106,
          203571,
          470,
          9594,
          1312922,
          1051,
          5950,
          48194,
          3495,
          145,
          564,
          1760,
          321,
          761,
          5989,
          263,
          2092,
          1414,
          151815,
          1858,
          1631,
          1202,
          589,
          4726,
          27020,
          9496,
          413574,
          23,
          10256,
          1789,
          215,
          23805,
          172247,
          4056,
          1089,
          302,
          3684,
          54767,
          1274,
          647,
          128,
          3104,
          93193,
          635,
          1595797,
          6508,
          8512,
          1274,
          42384,
          1617,
          186140,
          16183,
          272,
          13717,
          817312,
          3805,
          3776,
          504,
          128,
          6581,
          192,
          177,
          198,
          1897,
          825,
          606,
          18128,
          71485,
          171170,
          24840,
          1970,
          5875,
          1102,
          13835,
          139,
          475,
          47249,
          1970,
          5354,
          1526206,
          595,
          391389,
          7692,
          1686,
          95,
          310,
          17867,
          8830,
          36784,
          1022298,
          397,
          50835,
          238602,
          1789,
          464,
          7987,
          85,
          18408,
          167,
          48194,
          1507,
          1241364,
          46,
          23727,
          5732,
          6508,
          389246,
          1190,
          217,
          239,
          725,
          53,
          4354,
          513,
          7646,
          71485,
          606,
          11256,
          224256,
          6713,
          96942,
          214703,
          571,
          910148,
          365,
          15426,
          2456,
          320420,
          2607,
          313,
          1930,
          163415,
          736284,
          47772,
          378909,
          123373,
          31515,
          687276,
          5211,
          4367,
          6284,
          3508,
          75830,
          11250,
          5895,
          7163,
          798,
          4845,
          4913,
          21902,
          736284,
          836,
          3684,
          601723,
          73,
          526,
          2501,
          3279,
          13717,
          71463,
          498,
          502,
          2208,
          1412,
          741,
          341,
          863,
          222785,
          602,
          7565,
          46,
          2036,
          50835,
          1631,
          760,
          6629,
          207410,
          3104,
          247,
          6713,
          1506,
          18128,
          248,
          5791,
          2121,
          9165,
          76,
          128,
          1595797,
          6581,
          7268,
          128,
          5791,
          760,
          927396,
          725,
          459921,
          8007,
          647,
          43,
          1850,
          970,
          2206,
          378909,
          106,
          1512,
          5161,
          42817,
          741,
          70,
          9772,
          51,
          1675,
          640470,
          1533,
          1583,
          5875,
          828,
          85,
          149,
          2206,
          6006,
          42817,
          2263,
          69,
          149,
          84106,
          504,
          104396,
          1631,
          1507,
          71485,
          1446,
          15269,
          5507,
          9679,
          5619,
          3032,
          16305,
          177,
          864,
          1909,
          203571,
          743,
          269,
          18182,
          1810,
          4367,
          213,
          888,
          35299,
          2158,
          355,
          1565,
          116001,
          545147,
          1383,
          2504700,
          3279,
          1201,
          67082,
          320,
          828,
          759,
          52126,
          1758,
          2644,
          479994,
          1661,
          5161,
          771,
          565,
          140,
          92043,
          1461,
          749635,
          1131,
          753116,
          5791,
          565,
          78968,
          606,
          6508,
          341043,
          811,
          641,
          9496,
          6469,
          1643,
          17047,
          5161,
          722,
          1302,
          134056,
          313,
          71463,
          1426,
          53,
          885,
          1780,
          24536,
          151815,
          194500,
          144160,
          9165,
          847,
          5908,
          1288,
          1213,
          1847,
          1274,
          267,
          568,
          18128,
          5512,
          1679,
          6120,
          828,
          19054,
          4049,
          4512,
          2906700,
          760,
          95015,
          7268,
          134056,
          126,
          263,
          1725,
          2148,
          7297,
          286,
          99,
          7297,
          4074,
          976,
          973849,
          14871,
          1078,
          346,
          530,
          1523,
          5791,
          2307,
          376,
          760,
          26551,
          533,
          1939,
          1490,
          641349,
          914,
          14742,
          346,
          1517,
          5341,
          21125,
          320,
          14742,
          1831,
          895,
          1312922,
          1526206,
          331,
          46,
          2054,
          1080,
          1841,
          1089,
          376,
          153,
          151785,
          21902,
          1324,
          31515,
          59705,
          1472,
          1563,
          1512,
          1514,
          1675,
          16305,
          1312922,
          34153,
          2036,
          168,
          4172,
          3996,
          51,
          2456,
          2457,
          94014,
          923,
          3085,
          4575,
          76,
          128354,
          5989,
          4512,
          1312922,
          14871,
          743,
          824,
          34153,
          504,
          606,
          5354,
          190,
          105638,
          6469,
          248,
          4993,
          126,
          206,
          1675,
          5778,
          1577385,
          964,
          5989,
          21902,
          571,
          737,
          34153,
          224256,
          828,
          5457,
          9815,
          744,
          301,
          19408,
          725,
          224256,
          1504,
          3807,
          1780,
          498,
          568,
          45303,
          1019,
          5196,
          302,
          4575,
          163415,
          46,
          1725,
          31515,
          832,
          493,
          3766,
          5732,
          263,
          1766,
          6018,
          5791,
          630,
          255,
          1631,
          964,
          2307,
          15426,
          167,
          5908,
          321490,
          1263321,
          186140,
          381459,
          628,
          149,
          413574,
          1426,
          823,
          4533,
          136,
          1690,
          525713,
          6581,
          798,
          6120,
          1360,
          1178,
          35439,
          207410,
          3224,
          107941,
          87124,
          1595797,
          673342,
          128715,
          3066,
          341,
          2121,
          1970,
          4593,
          530,
          46,
          3766,
          27020,
          4508,
          5196,
          24536,
          124967,
          31394,
          1382480,
          8830,
          2906700,
          895,
          13835,
          475,
          2504700,
          5950,
          4074,
          71485,
          5875,
          3032,
          297,
          6951,
          75903,
          2607,
          741,
          493806,
          1791,
          595,
          178,
          673342,
          1617,
          7987,
          338,
          1643,
          34882,
          630,
          1490,
          6460,
          35439,
          6951,
          973849,
          1532,
          73,
          2457,
          321,
          11256,
          722,
          153,
          2906700,
          528,
          76383,
          172817,
          564,
          1745,
          3699,
          589,
          641,
          3684,
          2036,
          1577385,
          14871,
          21902,
          4005,
          2504700,
          1656,
          30770,
          2274,
          899,
          606,
          95,
          24645,
          1271,
          1252,
          1271,
          248,
          1178,
          276002,
          725,
          6460,
          21134,
          2121,
          77,
          836,
          207410,
          207,
          1075,
          324,
          1132,
          1143,
          2906700,
          84106,
          5760,
          50835,
          2158,
          1089,
          84106,
          888,
          263,
          77,
          493806,
          321,
          32891,
          2504700,
          74,
          46563,
          1263321,
          1051,
          20328,
          54287,
          502,
          177,
          2518,
          32891,
          237282,
          798,
          519,
          4778,
          84106,
          267,
          4677,
          151785,
          2457,
          1228,
          7646,
          3255,
          52126,
          3430,
          190178,
          263,
          186140,
          276002,
          1749,
          111,
          144160,
          9594,
          10717,
          16163,
          17047,
          6581,
          271,
          493806,
          263,
          299480,
          647,
          1228,
          110,
          321490,
          601723,
          247,
          123,
          49,
          2328,
          4056,
          2870,
          1271,
          1363,
          19408,
          912,
          46563,
          601723,
          626,
          346,
          320,
          571,
          190178,
          151815,
          2856,
          92294,
          238602,
          178,
          105638,
          1504,
          61,
          84106,
          4575,
          1841,
          14228,
          1423,
          19054,
          1892,
          804,
          166081,
          1679,
          895,
          6120,
          1363,
          79613,
          177,
          14742,
          3289,
          36438,
          99,
          54767,
          2906700,
          28739,
          5341,
          95035,
          1271,
          606,
          626,
          69,
          5908,
          100,
          116155,
          3996,
          5760,
          470,
          276002,
          269,
          2523,
          725,
          136,
          54287,
          1228,
          341043,
          46,
          134056,
          92043,
          248,
          129,
          1196,
          3688,
          1228,
          1909,
          5760,
          190178,
          1810,
          75830,
          69,
          302,
          686,
          6508,
          198,
          1789,
          824,
          922,
          2379,
          5211,
          163415,
          478,
          118,
          85,
          3104,
          2401,
          31394,
          331,
          630,
          5657,
          3289,
          601723,
          247,
          1532,
          1414,
          149,
          7692,
          753116,
          836,
          565,
          6469,
          3766,
          737,
          42619,
          276002,
          341,
          3862,
          7692,
          4542,
          54287,
          1925,
          7297,
          836,
          21134,
          3508,
          137067,
          3508,
          34153,
          35299,
          969,
          27971,
          1831,
          4573,
          1166,
          5927,
          3395,
          2408,
          136,
          198,
          32891,
          1970,
          3776,
          811,
          2054,
          5901,
          1423,
          5908,
          5354,
          2307,
          4603,
          741,
          1360,
          92608,
          129,
          641,
          1228,
          2206,
          5507,
          258,
          18408,
          4653,
          59744,
          163415,
          640470,
          3876,
          9594,
          8830,
          1617,
          3766,
          271,
          143,
          7692,
          1271,
          7646,
          302,
          471,
          922,
          717255,
          1988,
          530,
          5512,
          20328,
          9165,
          847,
          105549,
          344,
          584,
          341,
          190178,
          242,
          92294,
          3996,
          571,
          571,
          198,
          69793,
          5875,
          15623,
          349,
          104,
          5989,
          55581,
          2304,
          602,
          241,
          2054,
          2872,
          413574,
          477,
          493806,
          606,
          207410,
          540,
          43102,
          743,
          3202,
          21125,
          409656,
          910148,
          1166,
          321,
          824,
          568,
          105638,
          1186,
          111,
          76383,
          533,
          4512,
          137,
          427,
          1686,
          123,
          276,
          4542,
          165556,
          95,
          18128,
          551,
          928,
          75830,
          36438,
          307,
          3223,
          6120,
          1228,
          824,
          899,
          92337,
          736284,
          328,
          645,
          2206,
          2501,
          2523,
          663,
          22305,
          932,
          589,
          3032,
          1382480,
          18128,
          864,
          4664,
          4664,
          1423,
          346,
          316665,
          493806,
          532,
          6284,
          7268,
          76383,
          471,
          172817,
          269,
          71335,
          178,
          759,
          34882,
          1758,
          2870,
          1675,
          1595797,
          1504,
          1850,
          895,
          4878,
          50489,
          1261,
          540,
          93193,
          9521,
          540,
          4074,
          84861,
          3862,
          10717,
          1132,
          241,
          242,
          9815,
          647,
          12335,
          156391,
          79008,
          87124,
          14228,
          10076,
          1617,
          6469,
          2135,
          566,
          718,
          1943,
          242,
          397,
          2376,
          2906700,
          217,
          341,
          1352,
          2223,
          71463,
          2258,
          49,
          104,
          149,
          9993,
          8830,
          192805,
          43,
          509,
          242,
          9587,
          186140,
          6581,
          964,
          3104,
          2092,
          59744,
          19054,
          1943,
          584,
          1126,
          4720,
          736284,
          522,
          628,
          149,
          409656,
          1970,
          2092,
          1126,
          1201,
          14228,
          463,
          277,
          2121,
          1312922,
          30770,
          5760,
          54767,
          331,
          2607,
          413574,
          1334,
          1383,
          75830,
          13602,
          3202,
          743,
          493806,
          27020,
          320420,
          24840,
          1263321,
          970,
          302,
          743,
          413574,
          128715,
          2401,
          2872,
          640470,
          18760,
          3833,
          2263,
          35371,
          21134,
          192,
          2807,
          419,
          2016,
          9496,
          369,
          551,
          13835,
          2054,
          1472,
          4720,
          19685,
          350,
          2443,
          276896,
          59705,
          4542,
          502,
          23045,
          213,
          11432,
          192805,
          1089,
          86954,
          1523,
          302,
          3289,
          1574,
          509,
          4913,
          52,
          333497,
          5354,
          2470,
          2504700,
          9587,
          370,
          642,
          78968,
          743,
          489,
          717255,
          4677,
          12335,
          24536,
          239,
          1252,
          1075,
          927396,
          6629,
          1758,
          214518,
          4653,
          530,
          7155,
          1988,
          3119,
          695,
          321490,
          899,
          1791,
          964,
          1526206,
          1675,
          817312,
          99,
          2526,
          308,
          5895,
          35705,
          2872,
          606,
          1631,
          1563,
          19685,
          4474,
          92043,
          3104,
          1595797,
          568,
          11250,
          238602,
          824,
          194500,
          932,
          21902,
          581,
          94325,
          3279,
          19408,
          37,
          595,
          53,
          1725,
          1493,
          51427,
          272134,
          24645,
          551,
          823,
          338,
          1631,
          15647,
          910148,
          602,
          1126,
          77,
          1643,
          346,
          1126,
          2607,
          1749,
          1909,
          2395,
          99,
          1645,
          1261,
          215,
          144160,
          2317,
          606,
          4474,
          3279,
          163415,
          5908,
          1196,
          186140,
          1131,
          144160,
          229,
          4090,
          914,
          680,
          782,
          4533,
          233717,
          3699,
          513,
          123,
          601723,
          74,
          759,
          139,
          1383,
          99,
          2258,
          43102,
          2206,
          1051,
          6006,
          118,
          2661,
          2258,
          1780,
          1749,
          230,
          178,
          3805,
          630,
          302,
          3279,
          8007,
          1643,
          4533,
          1446,
          55581,
          222,
          3202,
          178,
          413574,
          25459,
          4056,
          3766,
          3119,
          4878,
          3833,
          331,
          93193,
          21902,
          95035,
          4074,
          757530,
          1577385,
          1363,
          413574,
          1766,
          172817,
          2368,
          1352,
          861,
          7155,
          23,
          4729,
          19090,
          1766,
          140,
          427,
          686,
          1228,
          1038,
          242,
          23045,
          4367,
          653,
          1595797,
          233717,
          4720,
          743,
          5791,
          27020,
          5903,
          151022,
          9496,
          1804,
          217,
          805,
          230,
          85,
          825,
          338,
          33804,
          2644,
          2054,
          100,
          2856,
          55345,
          973849,
          828,
          741,
          144160,
          530,
          6469,
          1019,
          19090,
          1423,
          686,
          85,
          1490,
          1847,
          53,
          2317,
          13602,
          5791,
          107941,
          1656,
          21134,
          2036,
          687276,
          260,
          1126,
          1201,
          302,
          2078,
          15647,
          399,
          21902,
          687276,
          395,
          123,
          571,
          31394,
          489,
          4845,
          4729,
          630,
          1274,
          73,
          331,
          7268,
          142,
          640470,
          20478,
          238602,
          54767,
          647,
          467,
          1446,
          11256,
          1179,
          571,
          6469,
          1312922,
          35439,
          2401,
          7155,
          12349,
          237282,
          1850,
          1666,
          571,
          105638,
          3255,
          1022298,
          365,
          1532,
          2526,
          23805,
          761,
          1507,
          5901,
          1126,
          1563,
          817312,
          5507,
          50835,
          4664,
          1263321,
          302,
          276,
          20478,
          224256,
          972,
          1536,
          378909,
          2376,
          376,
          77,
          628,
          1423,
          123373,
          1690,
          9815,
          270712,
          910148,
          467,
          608,
          1532,
          54287,
          1789,
          77,
          532,
          52126,
          1271,
          69,
          355,
          760,
          1131,
          1271,
          3776,
          606,
          22191,
          313,
          732,
          3032,
          7646,
          5666,
          15269,
          1789,
          1850,
          165556,
          493806,
          54287,
          391389,
          2206,
          18408,
          3684,
          48194,
          6841,
          21437,
          100,
          3833,
          928,
          3833,
          153,
          149,
          378909,
          258,
          3684,
          1946,
          519,
          5211,
          725,
          308,
          1517,
          530,
          217,
          1970,
          1745,
          302,
          1271,
          782,
          22305,
          3279,
          817312,
          1490,
          12486,
          460,
          149,
          190178,
          50835,
          19685,
          14871,
          191096,
          42619,
          34496,
          2661,
          2501,
          165556,
          67082,
          321,
          218,
          217,
          2872,
          1523,
          2408,
          467,
          328,
          2206,
          9165,
          1504,
          1493,
          836,
          626,
          35299,
          5354,
          128354,
          1791,
          24645,
          2872,
          1051,
          5791,
          1725,
          1263321,
          17867,
          1363,
          1631,
          2501,
          3688,
          54767,
          172817,
          2870,
          9679,
          6006,
          911,
          3395,
          2148,
          1228,
          269,
          42384,
          2457,
          528,
          6713,
          3996,
          1506,
          341043,
          397,
          13973,
          914,
          299480,
          1453,
          836,
          213,
          16305,
          337,
          14871,
          1804,
          229,
          2263,
          94325,
          53,
          1420,
          597,
          4306,
          11751,
          31394,
          18128,
          46563,
          42384,
          341,
          4575,
          2135,
          71335,
          7268,
          4090,
          2290,
          2089,
          1478,
          2148,
          4056,
          165,
          5875,
          743,
          12335,
          276002,
          1453,
          43102,
          191096,
          4878,
          686,
          2408,
          8007,
          5908,
          19685,
          17867,
          165,
          346,
          910148,
          532,
          923,
          95035,
          4090,
          969,
          178,
          77,
          69793,
          12486,
          328,
          1102,
          8830,
          128715,
          139,
          969,
          105549,
          2916,
          1766,
          308,
          1143,
          78968,
          35299,
          489,
          78968,
          10295,
          5989,
          1679,
          321490,
          34153,
          3096,
          137,
          765,
          381459,
          191096,
          4512,
          9496,
          241,
          94325,
          4677,
          1228,
          276,
          106,
          5507,
          3279,
          4575,
          528,
          1140,
          23805,
          1617,
          601723,
          2661,
          5216,
          564,
          194500,
          27971,
          55581,
          1143,
          6951,
          11250,
          192805,
          70,
          1414,
          21902,
          302,
          825,
          47249,
          70,
          8097,
          2661,
          206,
          3096,
          4593,
          15269,
          95015,
          168,
          1102,
          331,
          910148,
          1274,
          737,
          1810,
          77,
          241,
          1745,
          888,
          1334,
          9587,
          73,
          6469,
          31394,
          1453,
          18128,
          194500,
          736284,
          1517,
          1847,
          92608,
          13422,
          1530,
          5732,
          140,
          21125,
          741,
          1293,
          376,
          10076,
          92043,
          1925,
          21125,
          11432,
          695,
          69,
          964,
          641,
          21902,
          18128,
          6460,
          26551,
          3279,
          601723,
          413574,
          551,
          828,
          545147,
          4159,
          757530,
          910148,
          5908,
          21902,
          1186,
          78968,
          1075,
          4575,
          630,
          140,
          4172,
          653,
          1139,
          863,
          9993,
          1847,
          475,
          158701,
          54185,
          32891,
          1490,
          35439,
          13717,
          2906700,
          86954,
          1131,
          5901,
          1988,
          626,
          76,
          4198,
          217,
          1745,
          1680,
          67858,
          313,
          217,
          263,
          276896,
          21902,
          530,
          2906700,
          530,
          1789,
          532,
          493,
          1461,
          1841,
          302,
          601723,
          5438,
          3688,
          248,
          33917,
          718,
          310,
          33917,
          48194,
          207410,
          2836,
          841711,
          276896,
          344,
          3688,
          149,
          760,
          1979,
          1745,
          680,
          6841,
          1078,
          21902,
          307,
          885,
          320420,
          15426,
          1312922,
          31515,
          686,
          2691,
          5778,
          1423,
          2036,
          217,
          35439,
          22305,
          2836,
          1078,
          743,
          25459,
          348,
          14742,
          633,
          36438,
          172247,
          1383,
          47772,
          1679,
          233717,
          1684,
          642,
          92294,
          165556,
          1770,
          27020,
          343,
          46,
          737,
          88735,
          17867,
          743,
          878,
          286,
          2471,
          105638,
          269,
          341,
          2644,
          878,
          5341,
          1760,
          732,
          2518,
          409656,
          158701,
          1363,
          248858,
          520,
          47772,
          15426,
          1504,
          2376,
          427,
          1186,
          863,
          765,
          27020,
          471,
          16183,
          2526,
          551,
          67082,
          18408,
          391389,
          478,
          832,
          782,
          248858,
          1241364,
          530,
          17867,
          1595797,
          337,
          798,
          54287,
          601723,
          19685,
          964,
          1565,
          341,
          498,
          350,
          2121,
          4354,
          1766,
          27020,
          3805,
          4726,
          1146,
          26551,
          8512,
          241,
          36784,
          606,
          207,
          95035,
          1201,
          1925,
          2807,
          5621,
          254282,
          2526,
          1700,
          71485,
          31394,
          128,
          23727,
          2211,
          798,
          111,
          372,
          7646,
          5507,
          4878,
          477,
          4161,
          626,
          7155,
          5507,
          270712,
          2916,
          466,
          19054,
          20478,
          260,
          493,
          2304,
          23,
          129,
          344,
          1762,
          1126,
          1684,
          5548,
          95035,
          1126,
          1446,
          6006,
          1780,
          166081,
          140,
          3224,
          5196,
          910148,
          83,
          1735,
          722,
          26551,
          229,
          1523,
          2408,
          14742,
          470,
          626,
          1363,
          6629,
          242,
          74,
          1766,
          184,
          1288,
          1536,
          67082,
          7155,
          3495,
          2457,
          239,
          551,
          1831,
          606,
          222,
          3255,
          470,
          5848,
          1131,
          3279,
          864,
          35439,
          2202,
          22930,
          1831,
          52126,
          71463,
          207410,
          4575,
          23727,
          595,
          3766,
          1089,
          1925,
          67082,
          3451,
          50489,
          1909,
          805,
          1363,
          1324,
          213,
          190249,
          1293,
          163415,
          2158,
          2401,
          128,
          206,
          134056,
          95035,
          198,
          606,
          1078,
          1201,
          753116,
          242,
          190,
          47249,
          632,
          972,
          800,
          823,
          914,
          67082,
          207,
          4589,
          1132,
          2607,
          1324,
          53,
          1190,
          568,
          1228,
          3096,
          1532,
          2906700,
          1139,
          471,
          79613,
          5657,
          370,
          3699,
          95,
          7430,
          136,
          6713,
          248,
          828,
          190178,
          798,
          602,
          346,
          2317,
          54767,
          43,
          92043,
          35439,
          79613,
          19408,
          1196,
          741,
          13973,
          1526206,
          718,
          1654,
          525713,
          158701,
          16183,
          4720,
          504,
          3224,
          3104,
          504,
          140,
          16183,
          198,
          321,
          27971,
          2054,
          100,
          14228,
          214703,
          597,
          895,
          571,
          641,
          46,
          7155,
          105549,
          3224,
          60,
          1201,
          2307,
          59744,
          2870,
          2368,
          504,
          1780,
          970,
          3104,
          606,
          124967,
          3343,
          409656,
          19408,
          601723,
          761,
          74,
          106,
          61,
          6508,
          55581,
          413574,
          2916,
          6284,
          7163,
          1132,
          1190,
          2328,
          1302,
          5354,
          50489,
          106,
          1847,
          5621,
          165556,
          13061,
          95015,
          192805,
          92106,
          795,
          885,
          4533,
          1679,
          55345,
          1075,
          38912,
          686,
          20328,
          759,
          1583,
          372,
          222785,
          3032,
          1909,
          686,
          5211,
          1583,
          1274,
          1453,
          3279,
          320420,
          6469,
          9512,
          42817,
          566,
          2456,
          2457,
          10076,
          2376,
          551,
          31515,
          9679,
          137067,
          24536,
          1190,
          493806,
          1089,
          198,
          9993,
          589,
          54287,
          4542,
          341043,
          3343,
          2566,
          95015,
          928,
          1909,
          2644,
          54185,
          771,
          5895,
          407,
          4090,
          2408,
          1412,
          717255,
          79008,
          509,
          67082,
          73,
          2202,
          725,
          24536,
          970,
          27020,
          207,
          18760,
          765,
          4090,
          18408,
          85,
          1526206,
          20328,
          95,
          526,
          6951,
          467,
          2317,
          427,
          1595797,
          5438,
          1196,
          516,
          16183,
          9993,
          1140,
          35705,
          85,
          566,
          454,
          2471,
          10717,
          878,
          1725,
          1271,
          5732,
          761,
          47772,
          310,
          19685,
          76383,
          381459,
          1595797,
          341043,
          46563,
          1261,
          301,
          267,
          3085,
          12486,
          1970,
          823,
          922,
          1490,
          1131,
          970,
          2206,
          128,
          276002,
          12335,
          76383,
          7420,
          2097,
          828,
          1228,
          10295,
          343,
          601723,
          899,
          9594,
          2408,
          1075,
          1939,
          68211,
          1847,
          888,
          1288,
          1507,
          308,
          337,
          222785,
          116001,
          645,
          581,
          3402,
          9587,
          630,
          1078,
          2054,
          1507,
          911,
          75903,
          922,
          2395,
          53,
          13835,
          302,
          3684,
          2916,
          639,
          1261,
          4593,
          3032,
          111,
          606,
          795,
          2317,
          1075,
          1909,
          2457,
          545147,
          2607,
          630,
          1643,
          19054,
          116001,
          642,
          116001,
          530,
          51,
          413574,
          35705,
          602,
          595,
          233060,
          69,
          493806,
          258,
          2807,
          969,
          8269,
          149,
          1925,
          10076,
          409656,
          520,
          1261,
          18128,
          35439,
          324,
          2148,
          302,
          648,
          230,
          5903,
          59744,
          1075,
          165556,
          43,
          20478,
          1766,
          4056,
          743,
          1312922,
          653,
          137067,
          1970,
          22305,
          391389,
          4074,
          191096,
          13835,
          2443,
          166081,
          2443,
          247,
          19408,
          847,
          10256,
          76383,
          4081,
          1241364,
          4575,
          1132,
          590,
          1679,
          759,
          1363,
          32891,
          413574,
          1312922,
          413574,
          4424,
          13717,
          13422,
          1725,
          54767,
          217,
          32891,
          1831,
          1241364,
          1263321,
          1312922,
          1038,
          45303,
          348,
          171170,
          3833,
          5927,
          3202,
          5903,
          5760,
          31394,
          207410,
          116155,
          13422,
          973849,
          310,
          6508,
          3996,
          2328,
          601723,
          4993,
          140,
          626,
          168,
          914,
          87124,
          1523,
          381459,
          206,
          1725,
          100,
          937,
          1892,
          928,
          9506,
          3289,
          198,
          14871,
          1302,
          254282,
          1766,
          6703,
          263,
          3119,
          1228,
          124967,
          1526206,
          10076,
          71485,
          84106,
          69,
          1563,
          718,
          31515,
          4729,
          3202,
          749635,
          1382480,
          4993,
          5662,
          21134,
          32891,
          12335,
          50489,
          3263,
          1263321,
          95015,
          4913,
          24536,
          464,
          19408,
          1324,
          606,
          1789,
          190,
          1324,
          1645,
          4081,
          2135,
          725,
          502,
          34882,
          7646,
          18408,
          2435,
          214703,
          15647,
          459921,
          1654,
          324,
          355,
          4090,
          2504700,
          6284,
          5512,
          602,
          1847,
          878,
          5760,
          2456,
          217,
          34882,
          1312922,
          19685,
          77,
          36784,
          277,
          70,
          1523,
          13602,
          302,
          798,
          2135,
          2303,
          60,
          1606,
          270712,
          5903,
          470,
          45100,
          885,
          1533,
          23727,
          1654,
          4138,
          836,
          46944,
          5621,
          107941,
          2368,
          165,
          85,
          320,
          137067,
          771,
          11256,
          206,
          241,
          13422,
          1493,
          1645,
          4090,
          5791,
          1526206,
          237282,
          205,
          519,
          43102,
          3688,
          172817,
          4056,
          1140,
          589,
          463,
          836,
          922,
          277,
          54287,
          6460,
          2054,
          680,
          8512,
          13422,
          15426,
          11751,
          1533,
          1766,
          597,
          186140,
          4913,
          526,
          25459,
          4573,
          140,
          498,
          291,
          765,
          645,
          18760,
          191096,
          4508,
          297,
          53,
          5354,
          1810,
          722,
          276002,
          2870,
          10076,
          2408,
          466,
          4895,
          22305,
          270712,
          5648,
          932,
          5666,
          3263,
          551,
          128,
          93193,
          7268,
          911,
          338,
          759,
          1166,
          93193,
          139650,
          3085,
          276002,
          3224,
          2456,
          1979,
          54185,
          333497,
          4664,
          28739,
          71463,
          1443,
          17867,
          2471,
          248,
          22930,
          1368,
          28278,
          118,
          3096,
          471,
          48194,
          2456,
          47249,
          5875,
          1684,
          1063,
          376,
          217,
          1988,
          4575,
          337,
          2328,
          31394,
          3202,
          75830,
          186140,
          725,
          106,
          1563,
          1526206,
          1643,
          910148,
          571,
          1461,
          1645,
          313,
          5908,
          765,
          270712,
          2471,
          2401,
          24645,
          149,
          107941,
          23,
          732,
          20328,
          346,
          4664,
          571,
          878,
          76,
          60,
          165,
          376,
          136,
          1426,
          1563,
          163415,
          94325,
          4729,
          95,
          5927,
          18182,
          753116,
          6120,
          1263321,
          1139,
          140,
          3085,
          69,
          741,
          1078,
          269,
          248858,
          2135,
          3807,
          653,
          863,
          365,
          1288,
          4354,
          2258,
          71463,
          581,
          23805,
          409656,
          2435,
          823,
          75830,
          1166,
          1507,
          493806,
          910148,
          5908,
          595,
          2644,
          1132,
          1426,
          372,
          2607,
          1666,
          79008,
          528,
          218,
          77,
          8830,
          4172,
          84861,
          192805,
          6006,
          1493,
          46563,
          6469,
          795,
          914,
          498,
          1271,
          4090,
          142,
          7268,
          60,
          743,
          4573,
          263,
          3430,
          1595797,
          13602,
          1131,
          1892,
          22305,
          348,
          55581,
          1988,
          136,
          191096,
          27971,
          1363,
          1420,
          276002,
          1293,
          92043,
          663,
          4198,
          276896,
          19408,
          1979,
          8874,
          320420,
          1368,
          647,
          13602,
          761,
          370,
          5989,
          1810,
          135332,
          3395,
          267,
          15426,
          1075,
          910148,
          34882,
          28278,
          1382480,
          163415,
          370,
          8874,
          381459,
          743,
          1195,
          5619,
          1312922,
          346,
          76383,
          8830,
          190178,
          3833,
          878,
          2456,
          1988,
          328,
          680,
          828,
          397,
          1631,
          86954,
          3395,
          3805,
          35371,
          68211,
          140,
          5848,
          34882,
          4664,
          1143,
          1850,
          276,
          207,
          276896,
          765,
          1089,
          1791,
          7155,
          13717,
          1606,
          1453,
          5211,
          3766,
          673342,
          1293,
          69,
          1324,
          2121,
          46563,
          94014,
          1312922,
          36438,
          2607,
          19054,
          4512,
          1228,
          2208,
          1847,
          1923,
          11751,
          79613,
          2501,
          190178,
          3688,
          267,
          276896,
          1178,
          471,
          3996,
          1453,
          2395,
          124967,
          1493,
          1261,
          1656,
          19685,
          1178,
          137,
          4589,
          176,
          3684,
          46944,
          376,
          1263321,
          399,
          1595797,
          276896,
          1087,
          3224,
          3807,
          2060,
          74,
          1196,
          5619,
          2807,
          5901,
          167,
          136,
          355,
          16183,
          214518,
          687276,
          136895,
          5895,
          248,
          743,
          8874,
          116155,
          60,
          526,
          21134,
          36784,
          1139,
          725,
          466,
          5196,
          372,
          1202,
          16183,
          2906700,
          8874,
          528,
          519,
          47772,
          2644,
          1847,
          346,
          498,
          76,
          1841,
          1595797,
          653,
          301,
          1089,
          17867,
          6951,
          477,
          1165,
          1643,
          258,
          5989,
          2158,
          94014,
          286,
          14871,
          15426,
          1261,
          6006,
          320,
          134056,
          1762,
          1080,
          910148,
          1789,
          291,
          9815,
          776,
          75830,
          1536,
          863,
          647,
          341,
          9165,
          59744,
          94014,
          3684,
          48194,
          172817,
          128,
          140,
          4138,
          94014,
          1725,
          1666,
          427,
          93193,
          19054,
          145,
          1324,
          198,
          2376,
          1051,
          233717,
          606,
          301,
          163415,
          9772,
          229,
          123373,
          337,
          10295,
          149,
          1563,
          3279,
          1645,
          1680,
          247,
          1577385,
          888,
          92043,
          1523,
          4154,
          1293,
          3096,
          5760,
          4198,
          86954,
          105549,
          2307,
          1186,
          1526206,
          601723,
          10076,
          914,
          1312922,
          1453,
          343,
          302,
          4474,
          30770,
          298,
          478,
          338,
          1925,
          92106,
          970,
          118,
          2148,
          85,
          861,
          736284,
          922,
          302,
          584,
          17867,
          32891,
          5760,
          1526206,
          1526206,
          186140,
          595,
          269,
          71335,
          139,
          565,
          2870,
          218,
          1334,
          76,
          276002,
          128,
          2092,
          149,
          104396,
          69793,
          13422,
          16163,
          307,
          84106,
          328,
          4895,
          105638,
          86954,
          23,
          4090,
          337,
          67082,
          1089,
          1178,
          3032,
          1577385,
          31515,
          776,
          1970,
          20478,
          1324,
          489,
          2303,
          263,
          1571,
          123,
          1143,
          606,
          190178,
          545147,
          3807,
          27971,
          4575,
          1563,
          725,
          95015,
          67082,
          606,
          14228,
          92608,
          413574,
          308,
          242,
          3032,
          964,
          381459,
          328,
          73,
          5666,
          8830,
          24536,
          76,
          3833,
          136,
          378909,
          5666,
          123,
          1789,
          198,
          970,
          192805,
          861,
          1312,
          37,
          4878,
          2290,
          4993,
          94325,
          1131,
          153,
          645,
          123,
          1966,
          5908,
          22191,
          765,
          4508,
          863,
          239,
          378909,
          1892,
          28739,
          2054,
          242,
          31394,
          1132,
          34153,
          376,
          2526,
          2786,
          1512,
          391389,
          828,
          2121,
          7297,
          579,
          4172,
          73,
          1087,
          11751,
          3289,
          77,
          888,
          2208,
          341043,
          18760,
          192,
          10717,
          7163,
          832,
          1909,
          1760,
          6284,
          1442,
          50835,
          239,
          509,
          1288,
          95015,
          19090,
          378909,
          54287,
          271,
          4090,
          2223,
          477,
          172817,
          4720,
          16183,
          9496,
          207,
          2408,
          178,
          532,
          459921,
          1363,
          13835,
          718,
          1078,
          12747,
          1666,
          1261,
          3104,
          344,
          1382480,
          1195,
          258,
          16163,
          407,
          759,
          1645,
          3430,
          35299,
          1126,
          805,
          1368,
          15269,
          71485,
          4474,
          2435,
          1617,
          590,
          321,
          333497,
          11256,
          33804,
          76,
          828,
          370,
          2872,
          2121,
          1654,
          230,
          28739,
          13422,
          10076,
          263,
          53,
          4680,
          286,
          276896,
          238602,
          1700,
          194500,
          910148,
          277,
          1202,
          753116,
          5161,
          2872,
          295,
          5895,
          9772,
          4729,
          5512,
          269,
          95035,
          25459,
          1661,
          2148,
          4049,
          14871,
          1533,
          2906700,
          1078,
          2135,
          1022298,
          3776,
          378909,
          34496,
          6469,
          2274,
          2135,
          1261,
          1850,
          1617,
          207,
          1102,
          3395,
          277,
          104,
          1019,
          1196,
          532,
          69,
          95015,
          19685,
          641,
          824,
          589,
          237282,
          6006,
          1143,
          5161,
          1684,
          13835,
          272134,
          1595797,
          2121,
          3699,
          372,
          1382480,
          13717,
          1526206,
          23,
          19090,
          18760,
          23045,
          165,
          910148,
          1078,
          1423,
          26120,
          776,
          5662,
          123,
          302,
          493806,
          241,
          477,
          46,
          4474,
          932,
          2036,
          92608,
          1412,
          614,
          302,
          3202,
          4090,
          248858,
          475,
          878,
          16163,
          888,
          111,
          74,
          1241364,
          2060,
          2471,
          142,
          1126,
          2148,
          2036,
          104,
          365,
          5848,
          1126,
          757530,
          4589,
          50489,
          365,
          24645,
          4005,
          346,
          20328,
          13422,
          2518,
          35371,
          895,
          2328,
          5778,
          75903,
          1263321,
          395,
          372,
          168,
          7268,
          1201,
          43,
          24536,
          540,
          4074,
          6120,
          3032,
          1631,
          2135,
          6713,
          540,
          190178,
          128715,
          17047,
          1666,
          4542,
          551,
          8830,
          77,
          27971,
          493,
          1312,
          2607,
          467,
          1288,
          718,
          1679,
          823,
          128715,
          4895,
          1533,
          237282,
          269,
          970,
          13717,
          95,
          92608,
          8007,
          14742,
          2401,
          760,
          3684,
          128715,
          10295,
          4154,
          34882,
          2304,
          937,
          118,
          718,
          545147,
          1923,
          2456,
          3430,
          1383,
          207,
          969,
          1631,
          6508,
          7155,
          16183,
          1140,
          17867,
          3032,
          241,
          2142,
          579,
          1680,
          1789,
          653,
          68211,
          2644,
          4778,
          343,
          6508,
          1412,
          419,
          26551,
          69,
          927396,
          23045,
          378909,
          51,
          128354,
          78968,
          1979,
          1679,
          149,
          21902,
          54185,
          4056,
          972,
          158701,
          372,
          1271,
          1766,
          3996,
          1143,
          277,
          5927,
          2856,
          2457,
          6284,
          932,
          26120,
          133,
          2097,
          5901,
          198,
          341,
          129,
          60,
          52126,
          3776,
          190178,
          20328,
          333497,
          498,
          964,
          1563,
          10256,
          863,
          13835,
          4677,
          1725,
          95035,
          19054,
          2971,
          27020,
          271,
          165556,
          176,
          3805,
          1606,
          19054,
          1925,
          7646,
          6460,
          1140,
          1075,
          969,
          471,
          238602,
          397,
          2054,
          100,
          1271,
          4575,
          540,
          443,
          1190,
          899,
          795,
          15426,
          513,
          6006,
          6581,
          530,
          27829,
          540,
          92106,
          733,
          6434,
          13422,
          5196,
          19408,
          9594,
          9679,
          1841,
          6629,
          136,
          3032,
          381459,
          2644,
          104396,
          247,
          863,
          3807,
          50835,
          639,
          320420,
          2872,
          237282,
          602,
          2607,
          11751,
          710,
          116001,
          475,
          163415,
          324,
          95015,
          128,
          341,
          2307,
          632,
          1382480,
          17047,
          5507,
          13835,
          885,
          192,
          584,
          9594,
          1565,
          5662,
          626,
          50489,
          466,
          450,
          321,
          5791,
          5577,
          1087,
          151815,
          6508,
          1423,
          467,
          163415,
          111,
          69,
          242,
          4074,
          32891,
          5161,
          1970,
          328,
          1186,
          1383,
          156391,
          52126,
          1412,
          4993,
          965,
          241,
          1312922,
          1426,
          105638,
          258,
          1201,
          190,
          3807,
          6713,
          5548,
          13422,
          92608,
          5895,
          571,
          1446,
          1263321,
          166081,
          43,
          828,
          757530,
          35299,
          1684,
          413574,
          59705,
          372,
          151785,
          1089,
          198,
          186140,
          9587,
          581,
          493,
          1178,
          378909,
          717255,
          633,
          38912,
          20478,
          540,
          2856,
          54185,
          46563,
          1532,
          11256,
          606,
          4573,
          47772,
          176,
          45100,
          1089,
          54287,
          824,
          10076,
          168,
          95015,
          1745,
          4512,
          686,
          2097,
          35705,
          31515,
          13835,
          123373,
          381459,
          17867,
          242,
          84106,
          976,
          269,
          4512,
          1490,
          1847,
          372,
          205,
          722,
          1302,
          4090,
          2304,
          198,
          198,
          355,
          970,
          1684,
          20478,
          53,
          307,
          60,
          1760,
          525713,
          1523,
          1423,
          35439,
          717255,
          899,
          217,
          172817,
          828,
          4172,
          498,
          1306,
          198,
          2376,
          1970,
          331,
          564,
          18128,
          85,
          241,
          43102,
          19685,
          1762,
          2148,
          35371,
          53,
          241,
          9993,
          571,
          177,
          4542,
          1201,
          255,
          16183,
          276002,
          10256,
          828,
          149,
          151815,
          1791,
          1190,
          1442,
          76,
          203571,
          6951,
          190,
          378909,
          1186,
          1760,
          99,
          106,
          759,
          1038,
          759,
          45100,
          229,
          145,
          602,
          337,
          338,
          1512,
          9815,
          13061,
          673342,
          1680,
          1442,
          107941,
          19090,
          564,
          3487,
          4074,
          43,
          13717,
          1139,
          1412,
          238602,
          1923,
          1312922,
          18408,
          1304,
          7155,
          1617,
          1312922,
          124967,
          21902,
          493806,
          1412,
          823,
          1302,
          443,
          1178,
          1241364,
          836,
          111,
          69,
          19054,
          224256,
          602,
          9993,
          190178,
          191096,
          1643,
          191096,
          2836,
          4172,
          4677,
          149,
          191096,
          165,
          795,
          5927,
          100,
          105638,
          502,
          13422,
          6469,
          3395,
          123,
          14075,
          166081,
          4198,
          4354,
          2518,
          76383,
          2607,
          1126,
          6284,
          5908,
          310,
          754,
          28278,
          1022298,
          75903,
          397,
          798,
          75830,
          1909,
          271,
          1228,
          4993,
          2401,
          30770,
          824,
          6006,
          276002,
          540,
          254282,
          71463,
          1766,
          1526206,
          207,
          509,
          207410,
          2307,
          6951,
          9784,
          1038,
          493,
          7268,
          1461,
          1725,
          757530,
          270712,
          3807,
          459921,
          1679,
          47249,
          276002,
          413574,
          20478,
          1126,
          190178,
          267,
          1680,
          73,
          376,
          21134,
          464,
          206,
          1312922,
          782,
          1063,
          647,
          1847,
          4090,
          198,
          601723,
          134056,
          324,
          106,
          805,
          237282,
          1312922,
          911,
          6434,
          1228,
          94325,
          337,
          1166,
          276002,
          899,
          927396,
          1490,
          23,
          186140,
          69,
          5848,
          269,
          489,
          79008,
          6841,
          48194,
          99,
          749635,
          13973,
          885,
          92337,
          601723,
          3495,
          1536,
          116155,
          1504,
          467,
          4993,
          3688,
          30770,
          910148,
          564,
          128,
          3255,
          1195,
          761,
          165,
          737,
          1228,
          4677,
          18408,
          4306,
          22305,
          96942,
          467,
          3202,
          4074,
          3032,
          2263,
          4575,
          1831,
          276,
          7420,
          217,
          1725,
          1368,
          5621,
          217,
          100,
          77,
          1312922,
          67082,
          1089,
          551,
          50835,
          2258,
          1841,
          331,
          1725,
          6120,
          686,
          237282,
          2054,
          1858,
          267,
          528,
          1131,
          5760,
          3766,
          1512,
          46563,
          123,
          10717,
          341,
          21134,
          1423,
          190249,
          313,
          459921,
          376,
          4845,
          92985,
          910148,
          718,
          1051,
          233717,
          1804,
          1196,
          229,
          54767,
          1606,
          673342,
          5196,
          35299,
          313,
          804,
          1850,
          2202,
          4664,
          743,
          9594,
          15426,
          158701,
          34882,
          14783,
          673342,
          1038,
          1595797,
          242,
          1504,
          54287,
          13717,
          45100,
          276002,
          16183,
          99,
          7646,
          589,
          1166,
          7268,
          24840,
          5216,
          736284,
          824,
          5619,
          1139,
          1970,
          4895,
          2092,
          3833,
          5848,
          51,
          5848,
          5161,
          116001,
          18128,
          50489,
          69,
          413574,
          579,
          11250,
          1131,
          5908,
          28278,
          6120,
          19054,
          1261,
          1512,
          7646,
          389246,
          969,
          450,
          151815,
          149,
          459921,
          2836,
          686,
          4726,
          4367,
          13717,
          601723,
          2135,
          1132,
          1512,
          2807,
          23,
          149,
          460,
          601723,
          1645,
          540,
          1143,
          824,
          1656,
          145,
          460,
          1166,
          7646,
          2290,
          307,
          1563,
          1195,
          12335,
          4090,
          2456,
          53,
          343,
          2258,
          165,
          626,
          1078,
          118,
          23045,
          601723,
          50835,
          970,
          30770,
          198,
          1078,
          471,
          4993,
          1970,
          1102,
          2142,
          18128,
          1420,
          878,
          137,
          1645,
          1446,
          2607,
          35371,
          4913,
          1925,
          19090,
          502,
          19408,
          69,
          123373,
          1684,
          1360,
          2368,
          100,
          2258,
          1271,
          489,
          409656,
          1288,
          122111,
          2906700,
          276002,
          28425,
          71335,
          9594,
          237282,
          54767,
          5354,
          722,
          5895,
          2135,
          85,
          5760,
          450,
          3104,
          1271,
          1946,
          540,
          467,
          525713,
          32891,
          137067,
          9772,
          331,
          230,
          50489,
          516,
          224256,
          46,
          50489,
          504,
          50835,
          34882,
          3395,
          50835,
          331,
          1166,
          1831,
          798,
          94014,
          489,
          760,
          85,
          1368,
          47249,
          530,
          1453,
          3119,
          4354,
          1139,
          346,
          2526,
          1423,
          475,
          92294,
          34153,
          1423,
          1412,
          45303,
          99,
          3699,
          260,
          6469,
          4081,
          467,
          5791,
          4913,
          798,
          4090,
          17047,
          15647,
          67082,
          79613,
          18182,
          13602,
          2368,
          1745,
          27971,
          608,
          3776,
          36438,
          760,
          4878,
          2290,
          899,
          663,
          123373,
          99,
          320420,
          75903,
          973849,
          969,
          4993,
          27020,
          695,
          1363,
          24645,
          795,
          1271,
          1970,
          341043,
          12335,
          2092,
          5196,
          276896,
          419,
          2097,
          27020,
          14075,
          17047,
          163415,
          467,
          413574,
          640470,
          798,
          31394,
          5875,
          1382480,
          18182,
          21134,
          1302,
          5619,
          2376,
          4471,
          2872,
          299480,
          804,
          595,
          2906700,
          606,
          824,
          77,
          153,
          4845,
          1490,
          123373,
          24840,
          348,
          21134,
          184,
          84861,
          391389,
          5901,
          761,
          5895,
          2328,
          3684,
          7646,
          504,
          2872,
          1120,
          95,
          7297,
          51,
          263,
          205,
          337,
          331,
          3688,
          2471,
          2906700,
          5211,
          4533,
          86954,
          551,
          69,
          1228,
          7646,
          2856,
          1807,
          301,
          1804,
          2304,
          190249,
          3224,
          9594,
          3807,
          67082,
          1523,
          94014,
          163415,
          302,
          372,
          3487,
          2807,
          1478,
          165556,
          2566,
          722,
          337,
          14783,
          1100,
          271,
          3876,
          743,
          1966,
          31394,
          276,
          4049,
          14075,
          5726,
          914,
          137,
          450,
          3495,
          139650,
          6951,
          78968,
          9815,
          736284,
          910148,
          2644,
          376,
          67082,
          190178,
          163415,
          15623,
          530,
          2395,
          635,
          95035,
          1925,
          969,
          863,
          641349,
          493,
          761,
          38912,
          5908,
          5927,
          454,
          2258,
          7268,
          910148,
          36784,
          43102,
          123373,
          43102,
          241,
          1443,
          1139,
          5778,
          502,
          1675,
          5507,
          124967,
          207410,
          241,
          206,
          1766,
          520,
          190178,
          238602,
          765,
          128715,
          1383,
          320420,
          112,
          328,
          88735,
          9993,
          1166,
          409656,
          229,
          804,
          1080,
          648,
          1022298,
          4726,
          2504700,
          1478,
          22305,
          409656,
          1263321,
          1577385,
          95,
          1766,
          172817,
          1643,
          3688,
          911,
          540,
          21437,
          1100,
          4074,
          35299,
          93193,
          2092,
          878,
          2036,
          149,
          964,
          5354,
          328,
          2456,
          136,
          11256,
          5341,
          545147,
          27829,
          158701,
          5577,
          2401,
          528,
          272134,
          3807,
          2036,
          1684,
          5196,
          1324,
          5341,
          1453,
          123373,
          3279,
          19685,
          6581,
          5548,
          61,
          5648,
          1745,
          4512,
          1507,
          105549,
          84106,
          71335,
          972,
          2121,
          105549,
          46563,
          343,
          23,
          248858,
          861,
          8007,
          4056,
          302,
          17867,
          348,
          1293,
          1089,
          626,
          3096,
          269,
          22930,
          4074,
          530,
          2208,
          277,
          4354,
          3343,
          641349,
          566,
          3451,
          53,
          5895,
          13717,
          3495,
          47772,
          341043,
          1645,
          59744,
          4424,
          270712,
          798,
          116155,
          3119,
          395,
          7163,
          1186,
          782,
          92608,
          1526206,
          15269,
          92608,
          190178,
          1847,
          466,
          2526,
          10076,
          1831,
          277,
          238602,
          107941,
          21134,
          5989,
          2148,
          1847,
          1442,
          4056,
          2518,
          163415,
          13835,
          321,
          369,
          19054,
          2872,
          105638,
          2208,
          1789,
          320420,
          276896,
          581,
          9594,
          2121,
          753116,
          1850,
          301,
          759,
          741,
          1195,
          3202,
          1363,
          91,
          489,
          24536,
          642,
          276002,
          145,
          841711,
          4895,
          3032,
          1190,
          77,
          302,
          601723,
          1190,
          206,
          13602,
          1382480,
          4090,
          13422,
          757530,
          647,
          937,
          313,
          79613,
          20478,
          4471,
          23,
          1022298,
          1382480,
          964,
          70,
          4198,
          87124,
          800,
          214703,
          1645,
          54287,
          6841,
          3862,
          722,
          14871,
          11256,
          124967,
          25459,
          35299,
          2501,
          5161,
          2016,
          299480,
          1126,
          2307,
          104,
          972,
          673342,
          13422,
          4172,
          1166,
          493806,
          1892,
          5161,
          5548,
          736284,
          2456,
          191096,
          477,
          16305,
          71335,
          23,
          27020,
          2258,
          111,
          172817,
          45100,
          77,
          1789,
          8512,
          5354,
          1126,
          450,
          50489,
          5662,
          3807,
          166081,
          5875,
          2148,
          118,
          18128,
          191096,
          7155,
          467,
          123373,
          136,
          46944,
          145,
          18182,
          888,
          1725,
          3066,
          2518,
          36438,
          1453,
          7268,
          5196,
          36438,
          2661,
          110,
          1453,
          2872,
          34153,
          71335,
          805,
          3684,
          77,
          1190,
          27020,
          1526206,
          2401,
          478,
          71485,
          15269,
          2501,
          341,
          1789,
          614,
          2856,
          2566,
          2148,
          3776,
          12335,
          5507,
          1263321,
          71335,
          2906700,
          1228,
          224256,
          276896,
          321,
          248,
          759,
          286,
          54767,
          77,
          198,
          9034,
          128715,
          5341,
          71335,
          1263321,
          717255,
          12486,
          722,
          6006,
          800,
          1261,
          680,
          31970,
          59744,
          3451,
          5341,
          36784,
          1810,
          5726,
          736284,
          741,
          248858,
          1789,
          489,
          581,
          832,
          3119,
          2501,
          128,
          1324,
          3263,
          687276,
          976,
          2408,
          18459,
          519,
          5161,
          1263321,
          1909,
          395,
          269,
          2661,
          50489,
          1536,
          207410,
          1263321,
          601723,
          238602,
          35299,
          1791,
          18182,
          47249,
          310,
          965,
          1312,
          1126,
          1080,
          4878,
          163415,
          24645,
          165556,
          630,
          3202,
          910148,
          1789,
          2317,
          1684,
          5989,
          525713,
          4074,
          1186,
          917,
          647,
          1178,
          7268,
          5903,
          3684,
          687276,
          631,
          5507,
          320420,
          3876,
          320420,
          128,
          969,
          2148,
          647,
          238602,
          3451,
          1178,
          2304,
          4090,
          502,
          3085,
          3684,
          836,
          2661,
          964,
          8019,
          224256,
          9993,
          224256,
          92106,
          91,
          27971,
          2607,
          2290,
          1089,
          1532,
          836,
          260,
          242,
          3508,
          2208,
          73,
          3119,
          269,
          13061,
          5903,
          4056,
          1791,
          1847,
          67082,
          11432,
          13061,
          5895,
          1453,
          409656,
          1146,
          817312,
          828,
          743,
          1725,
          6284,
          911,
          111,
          602,
          92337,
          1565,
          2121,
          92608,
          217,
          350,
          1241364,
          1988,
          6284,
          28739,
          1643,
          1807,
          498,
          459921,
          4542,
          276002,
          2443,
          186140,
          1140,
          2054,
          272,
          165556,
          680,
          795,
          112,
          328,
          3994,
          153,
          1804,
          51427,
          1166,
          741,
          16183,
          673342,
          186140,
          45303,
          286,
          276896,
          1019,
          3202,
          1261,
          2263,
          5507,
          6629,
          477,
          932,
          568,
          218,
          1532,
          324,
          7163,
          47249,
          2504700,
          798,
          8512,
          4512,
          3458,
          2523,
          28425,
          9165,
          139,
          3495,
          2135,
          606,
          899,
          46944,
          3996,
          128,
          3395,
          217,
          2092,
          5875,
          3766,
          11250,
          242,
          695,
          313,
          9815,
          9679,
          77,
          736284,
          1686,
          140,
          23727,
          1841,
          1526206,
          3289,
          478,
          1789,
          32891,
          7155,
          5161,
          743,
          176,
          260,
          8019,
          230,
          1312922,
          378909,
          2054,
          5512,
          2036,
          1078,
          1745,
          2401,
          1686,
          1789,
          927396,
          1679,
          75830,
          888,
          761,
          241,
          128715,
          922,
          602,
          601723,
          129,
          50835,
          136,
          8007,
          134056,
          378909,
          2456,
          308,
          87124,
          589,
          520,
          341,
          55581,
          5341,
          1126,
          2906700,
          1749,
          1312922,
          321,
          5778,
          13061,
          2906700,
          316665,
          151815,
          229,
          241,
          1263321,
          1617,
          129,
          606,
          397,
          134056,
          217,
          20478,
          885,
          14871,
          2307,
          99,
          3451,
          1689,
          1689,
          1758,
          376,
          1334,
          53,
          3684,
          28739,
          4778,
          343,
          2906700,
          1261,
          526,
          1725,
          1288,
          224256,
          105549,
          3688,
          233717,
          1132,
          471,
          74,
          276896,
          85,
          134056,
          888,
          198,
          1195,
          3684,
          190249,
          878,
          346,
          1228,
          107941,
          911,
          42817,
          590,
          836,
          134056,
          5196,
          45303,
          771,
          1532,
          16183,
          760,
          1979,
          413574,
          1195,
          230,
          1426,
          475,
          61,
          2078,
          6581,
          4354,
          178,
          19054,
          1126,
          20478,
          276,
          1841,
          33917,
          59744,
          427,
          1847,
          15426,
          18128,
          2906700,
          743,
          1574,
          863,
          79613,
          8269,
          32891,
          74,
          695,
          969,
          489,
          911,
          413574,
          1472,
          298,
          23727,
          1263321,
          1126,
          2304,
          1132,
          1606,
          964,
          298,
          1645,
          3255,
          35371,
          2317,
          5989,
          1804,
          7268,
          759,
          76,
          4138,
          307,
          498,
          516,
          2304,
          192,
          272134,
          198,
          73,
          20478,
          1656,
          737,
          2856,
          2916,
          1420,
          1847,
          242,
          54287,
          1661,
          722,
          571,
          7268,
          1312922,
          1412,
          606,
          1089,
          42619,
          2443,
          8019,
          9034,
          313,
          736284,
          836,
          277,
          22930,
          973849,
          653,
          34153,
          4575,
          248858,
          34496,
          737,
          47249,
          35439,
          6581,
          333497,
          910148,
          1532,
          718,
          1735,
          695,
          118,
          269,
          407,
          6508,
          10295,
          242,
          10076,
          1312922,
          832,
          5211,
          471,
          12486,
          969,
          5161,
          36438,
          4015,
          3451,
          1970,
          1078,
          217,
          10076,
          2526,
          46563,
          6006,
          1909,
          1595797,
          71463,
          19685,
          46,
          151022,
          47772,
          3228,
          95035,
          1089,
          31394,
          2401,
          459921,
          1577385,
          5341,
          757530,
          8830,
          6469,
          741,
          2786,
          673342,
          2856,
          1804,
          2092,
          2906700,
          3263,
          532,
          9165,
          258,
          5354,
          105549,
          5950,
          399,
          413574,
          1383,
          1577385,
          111,
          92106,
          75830,
          1841,
          3430,
          1643,
          263,
          1063,
          13973,
          4913,
          134056,
          4573,
          12486,
          67082,
          2906700,
          54287,
          2376,
          343,
          804,
          1745,
          1312,
          1261,
          128715,
          1766,
          46,
          198,
          1725,
          349,
          910148,
          647,
          7155,
          5548,
          5726,
          105549,
          8269,
          3495,
          192805,
          71335,
          20328,
          1595797,
          4354,
          8874,
          395,
          237282,
          1571,
          85,
          23,
          427,
          11250,
          1186,
          3119,
          2691,
          1078,
          248858,
          1979,
          349,
          9506,
          158701,
          50835,
          722,
          817312,
          75830,
          328,
          695,
          3688,
          973849,
          551,
          695,
          3699,
          149,
          198,
          2971,
          932,
          1143,
          153,
          642,
          140,
          18408,
          1132,
          626,
          13422,
          6951,
          4198,
          1304,
          18128,
          6284,
          641349,
          914,
          863,
          493806,
          545147,
          4354,
          3119,
          589,
          1617,
          11256,
          17867,
          85,
          224256,
          42817,
          1178,
          3699,
          1312,
          1038,
          224256,
          313,
          1675,
          190,
          19090,
          4424,
          419,
          310,
          1791,
          413574,
          71335,
          540,
          1831,
          4056,
          736284,
          105549,
          608,
          530,
          4778,
          2916,
          1120,
          2691,
          798,
          3495,
          5666,
          1201,
          7268,
          9051,
          737,
          7297,
          1606,
          5895,
          46563,
          136,
          4005,
          1363,
          2870,
          1423,
          5666,
          2456,
          92985,
          776,
          6025,
          741,
          8512,
          5621,
          12335,
          741,
          31394,
          606,
          1606,
          381459,
          105638,
          5760,
          378909,
          111,
          864,
          753116,
          1645,
          632,
          17867,
          45100,
          1383,
          969,
          10717,
          51,
          13973,
          276,
          18408,
          4198,
          13422,
          213,
          238602,
          1324,
          2290,
          1504,
          35439,
          124967,
          1324,
          2368,
          1946,
          74,
          2526,
          36438,
          614,
          169,
          1565,
          5657,
          899,
          1645,
          454,
          397,
          370,
          105549,
          4729,
          1847,
          3430,
          2523,
          378909,
          110,
          2016,
          1946,
          4074,
          630,
          6120,
          1745,
          1909,
          1423,
          489,
          156391,
          21125,
          320420,
          722,
          1766,
          1666,
          964,
          631,
          973849,
          5908,
          6434,
          2799,
          502,
          493806,
          247,
          635,
          320420,
          53,
          1126,
          165,
          136895,
          17867,
          1195,
          298,
          863,
          149,
          5354,
          922,
          92985,
          564,
          47772,
          477,
          16163,
          2135,
          19408,
          828,
          190178,
          832,
          3766,
          5903,
          328,
          71485,
          149,
          1139,
          743,
          7155,
          5875,
          463,
          194500,
          6951,
          10076,
          165556,
          25459,
          46,
          1126,
          10295,
          20328,
          24840,
          1841,
          1577385,
          14228,
          6703,
          2691,
          2906700,
          1201,
          128,
          7163,
          2906700,
          564,
          260,
          1700,
          28739,
          1288,
          1453,
          1504,
          1831,
          1363,
          391389,
          23805,
          8830,
          7565,
          3285,
          6713,
          1532,
          841711,
          1140,
          27020,
          2457,
          75830,
          470,
          343,
          140,
          1791,
          17867,
          84861,
          276002,
          3833,
          4895,
          1360,
          663,
          640470,
          47,
          47249,
          1490,
          15647,
          4729,
          1789,
          6018,
          5657,
          765,
          910148,
          899,
          271,
          409656,
          263,
          186140,
          5726,
          1679,
          639,
          7268,
          2523,
          54185,
          5760,
          28739,
          3451,
          310,
          4172,
          2304,
          2383912,
          565,
          341,
          761,
          105638,
          328,
          19054,
          3395,
          381459,
          19090,
          525713,
          1274,
          139,
          1178,
          6951,
          466,
          910148,
          308,
          3996,
          324,
          78968,
          93193,
          11256,
          3766,
          2274,
          47211,
          308,
          1666,
          969,
          104396,
          1120,
          11751,
          239,
          673342,
          1645,
          2317,
          1453,
          14783,
          2870,
          184,
          129,
          140,
          6841,
          51,
          86954,
          5196,
          571,
          16163,
          717255,
          19408,
          14075,
          1461,
          12335,
          191096,
          50835,
          11751,
          4512,
          3862,
          1442,
          5196,
          467,
          19408,
          1595797,
          372,
          27971,
          71485,
          6006,
          6951,
          602,
          836,
          18408,
          67082,
          1654,
          184,
          2471,
          3807,
          5950,
          516,
          79613,
          324,
          6120,
          3096,
          6713,
          1858,
          15269,
          99,
          828,
          1526206,
          1789,
          222,
          111,
          863,
          1102,
          270712,
          626,
          2435,
          23727,
          19408,
          647,
          128715,
          255,
          5791,
          1925,
          1923,
          6508,
          320420,
          136,
          733,
          2916,
          1791,
          2916,
          343,
          1563,
          2036,
          1988,
          291,
          239,
          1190,
          99,
          601723,
          5760,
          760,
          635,
          341043,
          22930,
          14075,
          4573,
          1493,
          760,
          17867,
          4512,
          163415,
          2368,
          2135,
          22930,
          1923,
          9594,
          308,
          27020,
          5438,
          2135,
          647,
          9772,
          470,
          4895,
          754,
          2016,
          381459,
          4474,
          83,
          1532,
          79008,
          653,
          21134,
          1461,
          95015,
          6460,
          2223,
          509,
          635,
          817312,
          129,
          409656,
          2202,
          2971,
          895,
          267,
          52126,
          27020,
          3508,
          965,
          5457,
          275,
          1312,
          307,
          4090,
          13717,
          6581,
          1645,
          7297,
          34153,
          3032,
          1022298,
          1453,
          530,
          5621,
          828,
          1684,
          88735,
          1512,
          75830,
          3996,
          51427,
          6951,
          1758,
          8830,
          471,
          14228,
          914,
          4542,
          46563,
          1324,
          717255,
          15647,
          1506,
          969,
          230,
          92985,
          276,
          158701,
          192,
          1312922,
          1063,
          24536,
          2368,
          1909,
          1493,
          2148,
          343,
          49,
          18182,
          42384,
          5950,
          743,
          1606,
          7987,
          100,
          27971,
          224256,
          1383,
          21125,
          516,
          5507,
          3224,
          749635,
          5548,
          1526206,
          271,
          275,
          3776,
          186140,
          1363,
          177,
          46563,
          78968,
          477,
          1725,
          741,
          409656,
          836,
          2263,
          14075,
          540,
          5903,
          3224,
          3684,
          450,
          4367,
          104396,
          165556,
          71485,
          1847,
          1228,
          1523,
          540,
          2661,
          602,
          217,
          9565,
          1443,
          836,
          1312922,
          1617,
          1288,
          151022,
          84861,
          6460,
          145,
          270712,
          110,
          1841,
          1412,
          145,
          2456,
          1490,
          498,
          3224,
          1810,
          1461,
          3833,
          673342,
          749635,
          16183,
          823,
          2202,
          7155,
          136,
          1078,
          75830,
          75830,
          8333,
          247,
          1533,
          254,
          372,
          3688,
          1504,
          6006,
          1606,
          263,
          4172,
          18408,
          3688,
          341043,
          23,
          50835,
          409656,
          105549,
          1760,
          1684,
          470,
          372,
          1186,
          269,
          1810,
          798,
          10295,
          3096,
          635,
          1595797,
          86954,
          1850,
          27971,
          14228,
          471,
          1426,
          632,
          6284,
          320,
          1595797,
          1132,
          238602,
          321490,
          811,
          1186,
          478,
          6951,
          53,
          372,
          316665,
          1850,
          233060,
          73,
          1195,
          263,
          13061,
          69,
          3119,
          19408,
          27971,
          1140,
          836,
          337,
          6120,
          2644,
          5548,
          151815,
          464,
          77,
          198,
          107941,
          2607,
          2471,
          754,
          348,
          964,
          9679,
          1804,
          725,
          1617,
          1770,
          14075,
          454,
          153,
          206,
          172817,
          1195,
          116001,
          2906700,
          7646,
          5211,
          276896,
          970,
          718,
          92608,
          1690,
          1979,
          177,
          344,
          3066,
          378909,
          911,
          28739,
          348,
          4198,
          1595797,
          5507,
          695,
          1770,
          520,
          140,
          5196,
          1196,
          369,
          346,
          59705,
          1312922,
          478,
          4471,
          248858,
          229,
          1679,
          139,
          34153,
          43,
          725,
          95035,
          571,
          1324,
          648,
          5548,
          6018,
          116001,
          1506,
          805,
          341043,
          302,
          11256,
          3833,
          166081,
          166081,
          207,
          79008,
          1261,
          493806,
          207,
          94325,
          9815,
          34882,
          2368,
          1571,
          338,
          718,
          16163,
          1228,
          540,
          568,
          349,
          13422,
          927396,
          7430,
          77,
          172817,
          518429,
          640470,
          885,
          9051,
          749635,
          34882,
          478,
          166081,
          60,
          276002,
          5161,
          343,
          6469,
          464,
          3699,
          2328,
          27971,
          1102,
          551,
          84106,
          370,
          1190,
          722,
          1766,
          1666,
          177,
          771,
          223,
          333497,
          5577,
          269,
          493806,
          516,
          3085,
          493806,
          297,
          1132,
          3688,
          2317,
          28739,
          6469,
          467,
          878,
          4306,
          337,
          4778,
          269,
          663,
          31394,
          2303,
          5161,
          493,
          1139,
          269,
          54287,
          606,
          28425,
          47211,
          59744,
          601723,
          502,
          165,
          124967,
          6703,
          4993,
          489,
          516,
          13835,
          92106,
          14228,
          3395,
          2807,
          910148,
          105549,
          241,
          1228,
          1970,
          4895,
          718,
          1089,
          276896,
          493806,
          695,
          2501,
          271,
          11250,
          4512,
          145,
          7155,
          1925,
          177,
          910148,
          631,
          6469,
          139650,
          27971,
          74,
          55581,
          5211,
          626,
          310,
          248858,
          6469,
          30770,
          571,
          1139,
          16183,
          324,
          34153,
          20478,
          308,
          470,
          28425,
          888,
          2092,
          165,
          1925,
          372,
          1643,
          84106,
          32891,
          241,
          54287,
          50835,
          23045,
          54767,
          165556,
          1504,
          123373,
          1686,
          509,
          165,
          9594,
          1022298,
          1595797,
          606,
          443,
          23045,
          5354,
          17867,
          888,
          5196,
          2504700,
          105549,
          291,
          824,
          493806,
          248,
          18408,
          2607,
          140,
          647,
          2016,
          695,
          128715,
          1643,
          2807,
          10076,
          35371,
          1850,
          50835,
          928,
          1745,
          4015,
          1606,
          5211,
          85,
          888,
          255,
          1126,
          186140,
          45303,
          4198,
          23727,
          6434,
          489,
          1051,
          19685,
          91,
          645,
          463,
          238602,
          269,
          9772,
          409656,
          272,
          736284,
          95035,
          32891,
          4677,
          581,
          203571,
          1302,
          2906700,
          35371,
          602,
          133,
          95035,
          1126,
          190178,
          376,
          1595797,
          37,
          6581,
          77,
          972,
          2971,
          302,
          1087,
          218,
          1196,
          1368,
          55581,
          2566,
          2206,
          123373,
          519,
          67082,
          4589,
          5507,
          95,
          20328,
          7297,
          5577,
          100,
          71485,
          2906700,
          2148,
          1190,
          308,
          1749,
          648,
          1302,
          190178,
          158701,
          927396,
          31394,
          198,
          61,
          493806,
          1139,
          6841,
          33917,
          45303,
          1595797,
          28739,
          3430,
          3807,
          895,
          2443,
          2379,
          1022298,
          34496,
          1078,
          158701,
          269,
          765,
          269,
          123,
          15647,
          564,
          28425,
          6469,
          1850,
          718,
          94014,
          26551,
          1420,
          467,
          9565,
          2142,
          45100,
          4474,
          914,
          828,
          1178,
          1617,
          1661,
          642,
          95,
          601723,
          2518,
          3862,
          15269,
          1196,
          1263321,
          4878,
          79613,
          4172,
          24840,
          224256,
          566,
          647,
          2607,
          1490,
          509,
          6951,
          757530,
          1923,
          77,
          67082,
          128,
          94014,
          338,
          5950,
          276002,
          2208,
          817312,
          73,
          722,
          736284,
          504,
          642,
          4056,
          1892,
          606,
          647,
          313,
          54185,
          276896,
          6006,
          2274,
          1263321,
          301,
          140,
          34882,
          5196,
          3279,
          863,
          823,
          2471,
          32891,
          673342,
          53,
          1679,
          545147,
          937,
          5662,
          832,
          6951,
          1577385,
          6841,
          116001,
          1228,
          13973,
          5438,
          217,
          6284,
          1228,
          695,
          5726,
          20478,
          973849,
          5726,
          24840,
          85,
          6284,
          5196,
          4056,
          207410,
          7155,
          502,
          321490,
          12335,
          928,
          151785,
          116155,
          2368,
          4726,
          35439,
          888,
          14742,
          186140,
          2376,
          1725,
          8830,
          42619,
          313,
          463,
          5648,
          3119,
          2206,
          203571,
          6581,
          3032,
          5512,
          4677,
          136,
          771,
          581,
          1684,
          2786,
          1312,
          71335,
          516,
          823,
          53,
          471,
          3343,
          191096,
          260,
          1263321,
          2303,
          2135,
          2566,
          471,
          1526206,
          970,
          126,
          1196,
          2368,
          263,
          151022,
          142,
          255,
          526,
          647,
          2135,
          795,
          94014,
          737,
          1166,
          1078,
          2870,
          241,
          14228,
          1507,
          11751,
          313,
          1563,
          1089,
          6006,
          169,
          2501,
          16183,
          391389,
          757530,
          320420,
          67082,
          6469,
          46563,
          737,
          76383,
          1038,
          6951,
          8333,
          2870,
          922,
          1504,
          2317,
          118,
          124967,
          75830,
          190178,
          2148,
          9521,
          2457,
          1363,
          1089,
          186140,
          3996,
          34882,
          1038,
          1241364,
          5950,
          2607,
          450,
          21902,
          7646,
          3451,
          106,
          355,
          1583,
          13602,
          14742,
          128,
          3996,
          19090,
          11256,
          85,
          213,
          1595797,
          2290,
          1925,
          1131,
          4172,
          551,
          811,
          1675,
          9772,
          222,
          502,
          276002,
          341043,
          53,
          1051,
          92985,
          4090,
          241,
          248,
          69,
          1970,
          2607,
          5577,
          4074,
          238602,
          140,
          2644,
          1383,
          5512,
          137,
          1595797,
          107941,
          267,
          725,
          914,
          258,
          4512,
          85,
          1412,
          1324,
          965,
          54287,
          3495,
          91,
          7268,
          824,
          2836,
          2121,
          1595797,
          722,
          369,
          6508,
          817312,
          67082,
          1306,
          516,
          1306,
          46563,
          9587,
          71485,
          129,
          895,
          77,
          2471,
          54287,
          8512,
          1132,
          2036,
          530,
          2906700,
          9815,
          237282,
          31394,
          1131,
          324,
          79613,
          1523,
          307,
          320420,
          969,
          413574,
          87124,
          1504,
          343,
          30770,
          1178,
          192,
          2518,
          165556,
          817312,
          59705,
          206,
          1689,
          467,
          1565,
          910148,
          328,
          899,
          61,
          477,
          47,
          19054,
          73,
          648,
          233717,
          1166,
          6120,
          4878,
          1490,
          53,
          606,
          737,
          343,
          1352,
          737,
          224256,
          2607,
          32891,
          218,
          14871,
          35439,
          407,
          19685,
          191096,
          6841,
          530,
          28739,
          103927,
          1324,
          641,
          134056,
          7987,
          14742,
          2202,
          104396,
          2089,
          14871,
          2290,
          3279,
          14228,
          34882,
          911,
          124967,
          5732,
          1196,
          22305,
          34496,
          717255,
          888,
          2836,
          5512,
          7268,
          1526206,
          71485,
          128354,
          2836,
          4090,
          71335,
          680,
          1675,
          2379,
          2303,
          167,
          344,
          1075,
          258,
          1595797,
          1263321,
          800,
          163415,
          761,
          2092,
          863,
          973849,
          2304,
          95015,
          45303,
          533,
          5548,
          128354,
          15269,
          28278,
          635,
          3458,
          30770,
          16183,
          463,
          75903,
          124967,
          86954,
          973849,
          4172,
          198,
          9512,
          776,
          4508,
          475,
          1089,
          224256,
          509,
          254282,
          647,
          1810,
          1577385,
          86954,
          337,
          123373,
          28739,
          5438,
          1480,
          628,
          1126,
          1019,
          207,
          349,
          1412,
          50489,
          331,
          2206,
          78968,
          1970,
          21134,
          1480,
          509,
          297,
          1312922,
          381459,
          885,
          9587,
          59705,
          35299,
          124967,
          192,
          2097,
          4729,
          8269,
          34153,
          218,
          85,
          3289,
          1892,
          168,
          5778,
          718,
          8007,
          2206,
          17867,
          43102,
          5438,
          5895,
          6025,
          71335,
          112,
          50489,
          1446,
          2206,
          35705,
          6581,
          5662,
          248858,
          7692,
          1228,
          19408,
          1526206,
          21134,
          1271,
          145,
          10076,
          3263,
          222785,
          337,
          1595797,
          532,
          595,
          181438,
          1312922,
          346,
          50835,
          16305,
          1766,
          67082,
          21902,
          513,
          3451,
          215,
          2401,
          34882,
          1789,
          21902,
          7155,
          3224,
          343,
          2368,
          52126,
          191096,
          28739,
          4081,
          1080,
          20478,
          4090,
          722,
          5903,
          3805,
          1312922,
          642,
          106,
          972,
          680,
          608,
          128715,
          5621,
          911,
          128715,
          34496,
          343,
          753116,
          397,
          6841,
          165556,
          2456,
          320420,
          135332,
          3224,
          1512,
          1762,
          321,
          213,
          3224,
          632,
          717255,
          9815,
          163415,
          313,
          23045,
          1412,
          30770,
          965,
          1334,
          568,
          2644,
          1382480,
          5760,
          276002,
          2054,
          145,
          85,
          32891,
          129,
          4575,
          76,
          3508,
          69,
          3285,
          2501,
          165,
          5791,
          6841,
          321,
          17867,
          632,
          1507,
          4573,
          343,
          4056,
          178,
          7155,
          532,
          95,
          276896,
          116001,
          6018,
          1946,
          1228,
          230,
          5666,
          2376,
          9512,
          258,
          2016,
          346,
          732,
          520,
          372,
          310,
          12335,
          24536,
          192,
          744,
          32891,
          1263321,
          55345,
          20328,
          647,
          686,
          1526206,
          1749,
          45303,
          214518,
          25459,
          4878,
          4161,
          14742,
          47211,
          129,
          1760,
          186140,
          2836,
          192,
          686,
          804,
          123,
          166081,
          331,
          1661,
          198,
          255,
          34882,
          61,
          2092,
          776,
          230,
          504,
          27971,
          2456,
          3451,
          680,
          743,
          551,
          337,
          267,
          5577,
          3684,
          673342,
          8830,
          192805,
          2471,
          1643,
          895,
          343,
          757530,
          2408,
          1423,
          32891,
          5950,
          45303,
          118,
          69,
          134056,
          1263321,
          765,
          471,
          134056,
          31394,
          9594,
          1847,
          139650,
          67082,
          1654,
          18408,
          45303,
          1689,
          9815,
          7646,
          2644,
          1735,
          2607,
          18408,
          69,
          34882,
          1252,
          11253,
          3263,
          2456,
          177,
          970,
          1102,
          26551,
          21437,
          2504700,
          530,
          1271,
          516,
          601723,
          241,
          1190,
          95035,
          1140,
          248,
          687276,
          28278,
          7163,
          1412,
          606,
          673342,
          878,
          6841,
          782,
          811,
          207,
          1383,
          2376,
          2368,
          478,
          1271,
          343,
          419,
          85,
          79613,
          467,
          776,
          459921,
          47772,
          832,
          33917,
          1760,
          1263321,
          333497,
          471,
          1577385,
          61,
          241,
          1645,
          350,
          2368,
          3688,
          1791,
          177,
          302,
          1725,
          910148,
          35371,
          1423,
          413574,
          528,
          178,
          5457,
          2206,
          165,
          568,
          258,
          18182,
          4542,
          190249,
          2148,
          136895,
          504,
          4508,
          19054,
          61,
          1749,
          6120,
          2368,
          717255,
          7268,
          2501,
          76383,
          16305,
          798,
          94325,
          1228,
          824,
          1334,
          16183,
          186140,
          139,
          4005,
          7163,
          7430,
          1412,
          1690,
          823,
          1791,
          2206,
          46,
          722,
          5760,
          191096,
          3104,
          1190,
          14871,
          129,
          12349,
          1565,
          122111,
          87124,
          1645,
          765,
          328,
          13422,
          391389,
          4508,
          1847,
          4726,
          20478,
          2786,
          230,
          4895,
          5778,
          13973,
          1360,
          459921,
          4845,
          493,
          308,
          47772,
          4049,
          20328,
          571,
          530,
          263,
          1201,
          3684,
          128715,
          8874,
          2317,
          1970,
          276,
          55581,
          2807,
          502,
          2661,
          1414,
          46,
          498,
          6841,
          2526,
          9506,
          128,
          140,
          928,
          123373,
          149,
          67858,
          34153,
          2054,
          1288,
          1789,
          346,
          760,
          320,
          686,
          595,
          11432,
          1606,
          333497,
          6581,
          832,
          18760,
          2121,
          6629,
          498,
          51427,
          3807,
          795,
          736284,
          276002,
          5719,
          804,
          2916,
          1807,
          1749,
          3730,
          84106,
          736284,
          3224,
          239,
          753116,
          5895,
          137,
          237282,
          341043,
          1274,
          2290,
          2208,
          2856,
          836,
          7646,
          21134,
          237282,
          464,
          2135,
          163415,
          5901,
          828,
          1666,
          76383,
          11256,
          1923,
          6703,
          166081,
          43,
          124967,
          4726,
          4015,
          836,
          4090,
          69,
          463,
          413574,
          475,
          337,
          4726,
          2916,
          16163,
          595,
          207410,
          198,
          633,
          5577,
          207,
          2135,
          922,
          2644,
          3343,
          470,
          725,
          348,
          4653,
          111,
          255,
          5341,
          1383,
          647,
          391389,
          4680,
          1970,
          847,
          42384,
          589,
          2526,
          743,
          489,
          5621,
          5512,
          1414,
          3766,
          1190,
          198,
          71463,
          532,
          61,
          16183,
          4049,
          35299,
          276896,
          932,
          24840,
          530,
          310,
          4664,
          242,
          91,
          1360,
          21437,
          7430,
          140,
          24840,
          1656,
          1274,
          19090,
          811,
          1770,
          7565,
          1892,
          9496,
          136,
          190178,
          4993,
          9993,
          372,
          35439,
          207410,
          55581,
          1841,
          3263,
          493806,
          172817,
          276,
          2036,
          1791,
          653,
          6120,
          84861,
          471,
          344,
          190,
          184,
          14871,
          190249,
          7692,
          1847,
          687276,
          190,
          3688,
          498,
          165556,
          3688,
          4074,
          551,
          50489,
          4542,
          2379,
          1423,
          95035,
          5778,
          86954,
          7692,
          832,
          1201,
          626,
          28425,
          20478,
          158701,
          341043,
          4729,
          128354,
          31394,
          595,
          73,
          1139,
          1139,
          5161,
          18182,
          3688,
          1583,
          270712,
          123373,
          344,
          63,
          3202,
          1165,
          341,
          1595797,
          413574,
          53,
          7268,
          1847,
          4290,
          635,
          350,
          633,
          2054,
          343,
          27971,
          14228,
          346,
          1186,
          276002,
          2054,
          922,
          3730,
          68211,
          21902,
          295,
          238602,
          61,
          233717,
          69,
          1897,
          1271,
          5989,
          9815,
          213,
          520,
          4726,
          528,
          310,
          255,
          341043,
          222785,
          14871,
          355,
          1897,
          1847,
          1201,
          5666,
          206,
          1684,
          2870,
          50835,
          478,
          71335,
          736284,
          4198,
          241,
          328,
          26551,
          6006,
          77,
          320420,
          1892,
          166081,
          467,
          12747,
          270712,
          331,
          736284,
          19090,
          276896,
          2523,
          254282,
          123,
          647,
          606,
          1352,
          2290,
          1190,
          6120,
          13717,
          84106,
          118,
          19685,
          532,
          1606,
          137,
          2971,
          2661,
          520,
          1288,
          2395,
          190178,
          248858,
          333497,
          4056,
          1523,
          149,
          144160,
          1423,
          1523,
          3487,
          6469,
          3996,
          601723,
          10256,
          1038,
          321490,
          798,
          122111,
          168,
          532,
          2135,
          928,
          19685,
          1770,
          51427,
          158701,
          4677,
          28278,
          2856,
          378909,
          1791,
          31394,
          107941,
          725,
          343,
          8007,
          3395,
          2054,
          1675,
          4074,
          2408,
          927396,
          923,
          647,
          1140,
          927396,
          1166,
          206,
          2395,
          1789,
          5211,
          760,
          8512,
          1675,
          94325,
          67082,
          2408,
          1897,
          1178,
          1574,
          4575,
          648,
          378909,
          190178,
          1063,
          36784,
          229,
          4593,
          1970,
          343,
          258,
          1749,
          1446,
          1089,
          717255,
          782,
          1766,
          18182,
          1271,
          328,
          14228,
          522,
          2526,
          2906700,
          74,
          477,
          105549,
          365,
          241,
          1132,
          124967,
          1213,
          2317,
          4726,
          7163,
          6025,
          1446,
          4508,
          198,
          2872,
          135332,
          741,
          166081,
          1595797,
          1490,
          5778,
          1507,
          67858,
          633,
          478,
          134056,
          470,
          6120,
          18182,
          46563,
          13061,
          551,
          308,
          9679,
          1810,
          10256,
          782,
          324,
          35299,
          9594,
          7646,
          653,
          338,
          18408,
          1850,
          717255,
          207410,
          4508,
          77,
          1360,
          77,
          1766,
          8512,
          1595797,
          34496,
          203571,
          1312,
          26551,
          158701,
          163415,
          46563,
          1126,
          1063,
          320420,
          1970,
          1789,
          4726,
          1970,
          1132,
          922,
          13983,
          31515,
          5778,
          153,
          509,
          5196,
          8007,
          1274,
          1472,
          54287,
          124967,
          454,
          215,
          76383,
          1988,
          19408,
          2786,
          4575,
          4056,
          1645,
          324,
          13602,
          2504700,
          686,
          4653,
          1563,
          16183,
          1789,
          308,
          54767,
          77,
          2135,
          478,
          149,
          4653,
          230,
          186140,
          1858,
          4575,
          800,
          628,
          8874,
          910148,
          1512,
          151815,
          895,
          878,
          2054,
          13717,
          165,
          172817,
          5548,
          9051,
          2092,
          1909,
          1139,
          5196,
          8874,
          1302,
          743,
          1654,
          43,
          50835,
          9993,
          1063,
          54287,
          166081,
          1606,
          5161,
          1075,
          540,
          4138,
          526,
          27020,
          328,
          1725,
          328,
          836,
          1684,
          2135,
          10256,
          6284,
          17867,
          3066,
          18128,
          6120,
          2135,
          1506,
          1089,
          324,
          46944,
          307,
          648,
          1263321,
          341043,
          3996,
          1645,
          1645,
          471,
          973849,
          320,
          21125,
          564,
          1038,
          69,
          2368,
          96942,
          79008,
          4354,
          276,
          970,
          30770,
          5548,
          237282,
          79613,
          1517,
          3402,
          1766,
          1946,
          1530,
          370,
          5666,
          124967,
          759,
          1631,
          718,
          2870,
          964,
          217,
          5619,
          76383,
          1804,
          136,
          3833,
          5908,
          1645,
          1263321,
          530,
          1725,
          2304,
          1858,
          9594,
          67858,
          1426,
          680,
          4474,
          4138,
          372,
          1749,
          6284,
          110,
          565,
          14871,
          372,
          23,
          725,
          3996,
          3487,
          18128,
          736284,
          741,
          2307,
          1089,
          589,
          50835,
          413574,
          198,
          267,
          7297,
          186140,
          5950,
          106,
          76,
          606,
          2395,
          1563,
          276002,
          970,
          9815,
          459921,
          568,
          1526206,
          171170,
          1514,
          11256,
          1312922,
          5512,
          47249,
          1758,
          823,
          6018,
          606,
          4680,
          19408,
          46944,
          7268,
          601723,
          493806,
          1606,
          9784,
          124967,
          533,
          24645,
          4542,
          87124,
          1288,
          9772,
          7297,
          743,
          1312922,
          34153,
          606,
          467,
          207,
          149,
          6841,
          1139,
          1312922,
          5760,
          26120,
          350,
          601723,
          320,
          3263,
          28278,
          878,
          798,
          1186,
          2504700,
          206,
          341,
          295,
          3085,
          564,
          3833,
          4878,
          55581,
          106,
          4575,
          5950,
          5512,
          5438,
          3807,
          71485,
          6284,
          7268,
          31515,
          744,
          24840,
          20478,
          34153,
          1312922,
          276896,
          824,
          1526206,
          509,
          31394,
          608,
          878,
          190178,
          139,
          2148,
          19685,
          258,
          116155,
          12335,
          2607,
          3684,
          525713,
          14871,
          5621,
          606,
          24536,
          32891,
          269,
          84106,
          765,
          595,
          313,
          307,
          75903,
          3289,
          1201,
          43,
          238602,
          718,
          42384,
          4726,
          4589,
          4913,
          1383,
          12335,
          737,
          3688,
          9565,
          19408,
          1261,
          502,
          237282,
          77,
          144160,
          391389,
          1051,
          1526206,
          191096,
          48194,
          695,
          972,
          1324,
          1089,
          1988,
          237282,
          4138,
          18408,
          2443,
          13061,
          824,
          5621,
          680,
          1925,
          4533,
          186140,
          7646,
          190178,
          590,
          753116,
          21134,
          1897,
          19090,
          1140,
          214518,
          964,
          9594,
          184,
          1789,
          565,
          4198,
          551,
          2135,
          8097,
          1252,
          95035,
          302,
          2691,
          1745,
          107941,
          46944,
          320,
          754,
          2097,
          1453,
          69,
          36784,
          1383,
          269,
          5211,
          409656,
          218,
          2383912,
          3104,
          7646,
          1241364,
          2906700,
          21134,
          1022298,
          365,
          3402,
          95,
          753116,
          5760,
          589,
          5666,
          899,
          597,
          1804,
          21134,
          69,
          126,
          71335,
          7430,
          1271,
          6284,
          3699,
          34496,
          2135,
          26120,
          3224,
          1186,
          4474,
          2471,
          11250,
          178,
          1725,
          519,
          35371,
          247,
          4726,
          128,
          2691,
          1178,
          3430,
          1577385,
          1690,
          6841,
          1241364,
          207410,
          365,
          1261,
          4729,
          140,
          3223,
          2208,
          69793,
          320,
          76,
          1523,
          3395,
          1789,
          4172,
          632,
          498,
          888,
          76383,
          6951,
          836,
          2078,
          2258,
          744,
          13717,
          571,
          4573,
          43,
          230,
          21134,
          4878,
          753116,
          528,
          46563,
          5512,
          640470,
          123373,
          2856,
          237282,
          230,
          328,
          3833,
          215,
          888,
          43102,
          1679,
          5438,
          1577385,
          1684,
          116001,
          3495,
          69,
          3688,
          99,
          1583,
          525713,
          1645,
          725,
          11751,
          899,
          722,
          1241364,
          564,
          4056,
          1420,
          277,
          94325,
          1423,
          5619,
          128715,
          11253,
          271,
          5760,
          4895,
          836,
          1930,
          295,
          3279,
          1512,
          6713,
          31515,
          1288,
          276002,
          1686,
          241,
          3766,
          341043,
          722,
          241,
          722,
          1078,
          165,
          241,
          466,
          545147,
          129,
          34496,
          21134,
          258,
          4845,
          2121,
          5548,
          632,
          863,
          12486,
          128354,
          372,
          1102,
          18128,
          224256,
          413574,
          743,
          459921,
          601723,
          272,
          331,
          6460,
          836,
          1847,
          134056,
          328,
          1190,
          5760,
          525713,
          516,
          663,
          493,
          242,
          1970,
          1139,
          5895,
          454,
          372,
          3833,
          498,
          23727,
          744,
          20328,
          145,
          4533,
          1526206,
          5354,
          276002,
          1324,
          248858,
          50835,
          640470,
          2408,
          47249,
          33917,
          1850,
          369,
          5895,
          4081,
          725,
          23,
          601723,
          1631,
          895,
          4533,
          165,
          241,
          34882,
          92985,
          1770,
          27971,
          686,
          35439,
          2135,
          4512,
          443,
          28739,
          2786,
          166081,
          34496,
          1577385,
          34153,
          137,
          914,
          118,
          1512,
          601723,
          53,
          1847,
          21902,
          520,
          2906700,
          168,
          4878,
          6006,
          471,
          84861,
          673342,
          1577385,
          759,
          324,
          35439,
          276896,
          389246,
          1943,
          338,
          165556,
          1087,
          663,
          163415,
          1507,
          467,
          1412,
          2471,
          8874,
          239,
          76383,
          632,
          565,
          172817,
          31394,
          27020,
          9565,
          1595797,
          653,
          172817,
          11256,
          1261,
          1186,
          84861,
          1631,
          1078,
          5760,
          341043,
          333497,
          192,
          4677,
          247,
          1202,
          1288,
          861,
          346,
          2089,
          3395,
          1504,
          1841,
          1617,
          530,
          1831,
          1831,
          2872,
          328,
          6006,
          13973,
          581,
          1690,
          1261,
          571,
          3228,
          7297,
          277,
          680,
          107941,
          1196,
          864,
          878,
          761,
          2368,
          759,
          320420,
          1507,
          1063,
          932,
          11432,
          1577385,
          1780,
          467,
          34882,
          49,
          964,
          4172,
          1850,
          166081,
          75903,
          836,
          1725,
          4533,
          520,
          1979,
          1789,
          601723,
          6469,
          601723,
          151815,
          18459,
          467,
          276,
          238602,
          338,
          7646,
          1841,
          1472,
          105638,
          1126,
          123373,
          11751,
          4913,
          4508,
          864,
          1526206,
          83,
          1368,
          2607,
          136,
          4508,
          964,
          355,
          1022298,
          9587,
          5621,
          79008,
          631,
          910148,
          1760,
          328,
          341,
          1019,
          87124,
          1261,
          54287,
          30770,
          15426,
          630,
          254,
          239,
          316665,
          5512,
          7430,
          1312,
          222,
          3495,
          1760,
          6713,
          2368,
          632,
          11751,
          5507,
          46,
          642,
          6703,
          413574,
          1132,
          71463,
          1443,
          1126,
          22191,
          2906700,
          1923,
          4354,
          4508,
          518429,
          1383,
          2526,
          389246,
          2054,
          26551,
          2089,
          11250,
          525713,
          8830,
          59744,
          67858,
          1140,
          5901,
          343,
          1766,
          2089,
          2504700,
          4049,
          1312,
          6006,
          2872,
          4138,
          54185,
          76383,
          184,
          348,
          35439,
          4090,
          258,
          7646,
          1334,
          2501,
          214518,
          198,
          4677,
          1288,
          14783,
          832,
          1617,
          5341,
          76383,
          50835,
          1563,
          1102,
          99,
          1517,
          4603,
          864,
          31515,
          1686,
          6434,
          753116,
          9815,
          1478,
          635,
          28739,
          1766,
          84106,
          478,
          1131,
          186140,
          4575,
          5548,
          765,
          11256,
          1617,
          5760,
          4664,
          2470,
          732,
          3996,
          77,
          1443,
          370,
          9679,
          1628,
          749635,
          237282,
          878,
          18408,
          1526206,
          477,
          1766,
          218,
          3766,
          1383,
          717255,
          14228,
          9815,
          1196,
          331,
          3395,
          10076,
          3688,
          85,
          378909,
          817312,
          376,
          1666,
          107941,
          338,
          899,
          92985,
          765,
          13422,
          765,
          9815,
          2408,
          91,
          1892,
          3263,
          3066,
          1196,
          2872,
          5341,
          55581,
          105549,
          817312,
          471,
          310,
          158701,
          595,
          1423,
          5354,
          1075,
          568,
          6841,
          3807,
          7155,
          9512,
          878,
          110,
          16183,
          922,
          910148,
          1312922,
          1334,
          639,
          2206,
          12349,
          85,
          1679,
          4726,
          568,
          2644,
          1334,
          237282,
          190178,
          828,
          26551,
          3684,
          1858,
          2328,
          825,
          1595797,
          239,
          71463,
          467,
          3833,
          1577385,
          3343,
          84106,
          581,
          11432,
          128715,
          291,
          49,
          1526206,
          3279,
          346,
          1523,
          2870,
          14871,
          190178,
          1892,
          1970,
          16305,
          247,
          70,
          7163,
          18182,
          1970,
          823,
          1530,
          105549,
          972,
          1583,
          134056,
          10295,
          899,
          313,
          46563,
          94325,
          144160,
          321490,
          4726,
          564,
          1271,
          5657,
          628,
          5507,
          106,
          190249,
          630,
          84861,
          140,
          18408,
          5726,
          3430,
          1312922,
          459921,
          73,
          1293,
          248858,
          601723,
          137,
          2799,
          313,
          297,
          5719,
          1263321,
          35371,
          2317,
          3495,
          518429,
          3224,
          320,
          5621,
          2836,
          1382480,
          2504700,
          564,
          724,
          811,
          77,
          4653,
          14871,
          2644,
          1766,
          2443,
          4726,
          18182,
          341043,
          2856,
          1228,
          45303,
          14871,
          165,
          105638,
          198,
          15426,
          3224,
          626,
          71485,
          83,
          333497,
          241,
          923,
          2401,
          466,
          365,
          18128,
          811,
          34496,
          123373,
          3451,
          2644,
          1132,
          49,
          149,
          1606,
          186140,
          736284,
          76,
          502,
          11250,
          1700,
          6703,
          9784,
          1679,
          30770,
          46,
          2856,
          32891,
          832,
          1241364,
          4726,
          1791,
          2408,
          606,
          3684,
          653,
          1909,
          123,
          32891,
          969,
          1078,
          564,
          24840,
          1213,
          23727,
          2368,
          1526206,
          5662,
          680,
          18128,
          302,
          3395,
          888,
          7155,
          1909,
          151022,
          355,
          1493,
          571,
          19685,
          11256,
          277,
          1080,
          139650,
          270712,
          687276,
          104396,
          4512,
          3224,
          214703,
          331,
          2906700,
          5875,
          3876,
          680,
          1165,
          1563,
          509,
          1423,
          477,
          1420,
          2036,
          7430,
          1443,
          568,
          1102,
          1766,
          260,
          110,
          1512,
          687276,
          3202,
          1334,
          4056,
          134056,
          172817,
          46,
          276002,
          4593,
          272134,
          1423,
          165556,
          2148,
          1645,
          1577385,
          2290,
          16183,
          765,
          4575,
          467,
          722,
          21134,
          478,
          11256,
          9587,
          302,
          18760,
          346,
          1970,
          1131,
          910148,
          224256,
          1261,
          2328,
          22305,
          1293,
          1063,
          972,
          464,
          2376,
          427,
          836,
          321,
          1686,
          137067,
          22305,
          18408,
          224256,
          213,
          1472,
          24840,
          1324,
          5760,
          1490,
          23,
          710,
          165556,
          31515,
          49,
          54287,
          3085,
          4508,
          2607,
          6006,
          194500,
          1288,
          964,
          477,
          213,
          413574,
          67082,
          31515,
          17047,
          47249,
          1988,
          23,
          11256,
          2501,
          18182,
          95,
          15623,
          134056,
          46944,
          348,
          28739,
          324,
          973849,
          5512,
          3862,
          1228,
          641349,
          135332,
          19685,
          328,
          53,
          3119,
          1420,
          94325,
          5438,
          899,
          222,
          1480,
          1606,
          104,
          545147,
          2376,
          899,
          158701,
          355,
          765,
          9815,
          104396,
          628,
          2661,
          71485,
          313,
          269,
          11250,
          1970,
          899,
          1517,
          5507,
          1241364,
          493,
          1063,
          489,
          1426,
          1780,
          18182,
          1533,
          776,
          1684,
          320,
          33917,
          222785,
          124967,
          2906700,
          20328,
          11751,
          123373,
          254282,
          647,
          6120,
          1453,
          1263321,
          2142,
          1766,
          372,
          760,
          13602,
          178,
          144160,
          743,
          137,
          516,
          2368,
          969,
          571,
          320420,
          247,
          128354,
          43102,
          4993,
          105549,
          263,
          475,
          217,
          79613,
          493806,
          67082,
          471,
          61,
          137,
          1271,
          595,
          2328,
          237282,
          3996,
          2368,
          1689,
          5621,
          50489,
          84106,
          606,
          1925,
          471,
          238602,
          3202,
          7268,
          1563,
          722,
          1312922,
          297,
          79008,
          105549,
          1946,
          2135,
          2457,
          1606,
          911,
          3776,
          104,
          6841,
          471,
          6713,
          23045,
          1533,
          172817,
          1412,
          5719,
          502,
          14742,
          7692,
          27971,
          732,
          733,
          4090,
          3289,
          166081,
          14871,
          710,
          151785,
          178,
          3730,
          899,
          4993,
          1645,
          2786,
          7565,
          725,
          21902,
          5438,
          184,
          55581,
          333497,
          3996,
          1302,
          50489,
          4081,
          1684,
          1075,
          291,
          1810,
          34882,
          1850,
          1051,
          5161,
          1686,
          9512,
          91,
          2054,
          2408,
          718,
          1536,
          96942,
          1261,
          3688,
          99,
          192,
          1988,
          378909,
          372,
          9496,
          32891,
          2274,
          1841,
          78968,
          166081,
          3096,
          136,
          1847,
          124967,
          1383,
          17047,
          321,
          21902,
          137,
          565,
          4575,
          32891,
          595,
          2368,
          2443,
          695,
          1979,
          376,
          1892,
          7155,
          1132,
          2092,
          725,
          241,
          2526,
          910148,
          43102,
          269,
          1988,
          9565,
          5875,
          163415,
          888,
          297,
          878,
          653,
          20328,
          20328,
          16305,
          516,
          302,
          1480,
          105549,
          214703,
          123,
          493,
          1700,
          2408,
          4172,
          28739,
          1022298,
          2644,
          632,
          254282,
          2872,
          509,
          832,
          2870,
          1758,
          6713,
          564,
          1360,
          1892,
          3104,
          53,
          13717,
          1789,
          5895,
          106,
          2518,
          337,
          52126,
          9165,
          641349,
          229,
          71463,
          695,
          1382480,
          836,
          1897,
          5548,
          269,
          9772,
          276002,
          1263321,
          2258,
          733,
          4074,
          9679,
          134056,
          10076,
          1563,
          53,
          795,
          1443,
          242,
          128715,
          207,
          1312922,
          1617,
          1383,
          11256,
          427,
          2566,
          602,
          2470,
          1970,
          238602,
          5577,
          31394,
          413574,
          749635,
          1324,
          525713,
          601723,
          233717,
          149,
          17867,
          1063,
          5666,
          1443,
          238602,
          1352,
          111,
          128354,
          4729,
          100,
          158701,
          4354,
          571,
          888,
          20478,
          581,
          343,
          126,
          471,
          2304,
          467,
          533,
          1382480,
          30770,
          92043,
          2089,
          6006,
          1414,
          1271,
          110,
          343,
          1087,
          4090,
          2304,
          128,
          128715,
          92985,
          6951,
          1923,
          1686,
          4726,
          2501,
          3996,
          4542,
          16163,
          3279,
          203571,
          391389,
          914,
          13602,
          140,
          509,
          378909,
          128715,
          4424,
          22930,
          2202,
          61,
          722,
          5451,
          13422,
          1089,
          218,
          737,
          1412,
          4575,
          9512,
          8874,
          3263,
          24840,
          2395,
          1089,
          2206,
          69,
          595,
          222785,
          1089,
          9521,
          3279,
          1970,
          427,
          6508,
          2142,
          601723,
          1909,
          17047,
          134056,
          7297,
          277,
          3402,
          528,
          1725,
          2518,
          673342,
          761,
          4653,
          15647,
          47772,
          3096,
          18128,
          9496,
          571,
          3688,
          328,
          2097,
          475,
          836,
          722,
          642,
          753116,
          254,
          1288,
          46563,
          378909,
          19685,
          928,
          277,
          1517,
          1178,
          13835,
          122111,
          1102,
          156391,
          1979,
          6629,
          864,
          21635,
          302,
          69793,
          10256,
          31515,
          69,
          3343,
          565,
          5507,
          5341,
          258,
          4074,
          9565,
          581,
          372,
          663,
          1360,
          4542,
          1565,
          493806,
          519,
          310,
          1478,
          6841,
          55581,
          275,
          1595797,
          565,
          601723,
          67858,
          92106,
          1675,
          6703,
          589,
          27020,
          5196,
          3996,
          910148,
          11250,
          1201,
          21902,
          2368,
          92608,
          9594,
          167,
          1423,
          31970,
          2408,
          1666,
          4720,
          686,
          136,
          12486,
          9496,
          1312,
          248858,
          104396,
          976,
          6120,
          3263,
          1472,
          7155,
          1666,
          144160,
          519,
          1760,
          1461,
          15269,
          6469,
          630,
          15426,
          207410,
          1446,
          168,
          28278,
          1583,
          3202,
          645,
          67082,
          2471,
          54287,
          595,
          2607,
          242,
          564,
          927396,
          34882,
          15269,
          24536,
          470,
          3766,
          2408,
          606,
          45100,
          759,
          540,
          36784,
          804,
          3104,
          2036,
          1507,
          320420,
          5662,
          2870,
          5621,
          3224,
          242,
          143,
          13061,
          2470,
          970,
          1241364,
          218,
          320420,
          54287,
          509,
          1312,
          35371,
          3495,
          2872,
          520,
          241,
          2290,
          885,
          973849,
          7646,
          46,
          9993,
          270712,
          1766,
          3495,
          571,
          134056,
          104396,
          34882,
          106,
          1075,
          369,
          13602,
          5548,
          969,
          137067,
          4575,
          1087,
          237282,
          7163,
          124967,
          606,
          198,
          136,
          9772,
          922,
          2471,
          5619,
          3996,
          3684,
          2401,
          2504700,
          736284,
          5341,
          207,
          215,
          3805,
          355,
          1075,
          1288,
          2148,
          1186,
          3289,
          76383,
          165556,
          165556,
          761,
          489,
          7430,
          836,
          267,
          372,
          346,
          7268,
          509,
          5895,
          910148,
          8830,
          1925,
          633,
          513,
          1126,
          1132,
          4198,
          9679,
          4653,
          124967,
          331,
          3699,
          12335,
          969,
          937,
          1643,
          35371,
          92608,
          1190,
          2870,
          267,
          24840,
          71463,
          1423,
          1126,
          1102,
          4081,
          139,
          165556,
          836,
          680,
          606,
          743,
          28739,
          191096,
          1847,
          27971,
          12335,
          647,
          1324,
          1725,
          1643,
          864,
          20478,
          35439,
          60,
          475,
          206,
          493,
          895,
          276896,
          1645,
          9034,
          5619,
          237282,
          1892,
          172817,
          5619,
          530,
          37,
          2786,
          248,
          92985,
          972,
          5512,
          828,
          2304,
          1745,
          190178,
          2274,
          2304,
          6120,
          753116,
          5512,
          5848,
          470,
          78968,
          5908,
          1019,
          22930,
          1443,
          2208,
          1675,
          4161,
          269,
          564,
          84106,
          165,
          9784,
          1595797,
          741,
          6006,
          2856,
          28739,
          14871,
          6841,
          198,
          149,
          153,
          355,
          1312922,
          478,
          118,
          2401,
          50835,
          271,
          32891,
          295,
          2607,
          23727,
          4729,
          105638,
          673342,
          4005,
          2395,
          50835,
          4575,
          8097,
          92294,
          321,
          2471,
          34496,
          673342,
          34882,
          540,
          237282,
          50835,
          153,
          4138,
          606,
          43,
          7155,
          192,
          969,
          55345,
          270712,
          630,
          104396,
          1766,
          1758,
          42619,
          2906700,
          759,
          725,
          233717,
          2456,
          13973,
          28278,
          5341,
          5507,
          139650,
          1689,
          466,
          124967,
          149,
          911,
          30770,
          19090,
          2457,
          1595797,
          2304,
          519,
          184,
          153,
          2408,
          93193,
          1654,
          47249,
          186140,
          12335,
          2304,
          4913,
          5512,
          2368,
          3096,
          3833,
          1970,
          5211,
          427,
          1166,
          564,
          1075,
          3996,
          321490,
          7155,
          841711,
          76383,
          19685,
          242,
          24536,
          1745,
          695,
          1679,
          320420,
          31515,
          1446,
          207410,
          753116,
          2523,
          372,
          136,
          9772,
          2307,
          1680,
          34496,
          11256,
          895,
          8269,
          49,
          34496,
          1804,
          2368,
          2870,
          213,
          4090,
          467,
          571,
          4015,
          43102,
          276896,
          71463,
          2501,
          158701,
          3343,
          597,
          9496,
          516,
          1577385,
          932,
          519,
          84106,
          302,
          601723,
          632,
          343,
          828,
          229,
          464,
          4878,
          45303,
          18408,
          1139,
          76383,
          320420,
          3458,
          10256,
          4424,
          2274,
          128,
          899,
          42384,
          271,
          381459,
          2906700,
          4056,
          743,
          46563,
          343,
          5726,
          20478,
          1770,
          917,
          2501,
          937,
          17867,
          31394,
          606,
          28739,
          2872,
          3684,
          3223,
          606,
          3032,
          28425,
          18128,
          5548,
          75903,
          1241364,
          1201,
          238602,
          1288,
          804,
          46944,
          601723,
          450,
          409656,
          928,
          218,
          20478,
          5216,
          14228,
          4081,
          14075,
          207410,
          10717,
          124967,
          149,
          1979,
          4172,
          4424,
          1909,
          34496,
          349,
          106,
          144160,
          970,
          20328,
          84106,
          163415,
          46944,
          1132,
          1943,
          1178,
          4542,
          409656,
          1735,
          718,
          1022298,
          1131,
          37,
          1504,
          166081,
          2258,
          67858,
          2208,
          1288,
          1051,
          53,
          695,
          134056,
          5760,
          863,
          6006,
          6120,
          16163,
          1666,
          841711,
          2501,
          3430,
          35705,
          9034,
          1970,
          26551,
          5341,
          224256,
          1675,
          673342,
          1909,
          100,
          6469,
          1288,
          836,
          760,
          1426,
          1202,
          1089,
          5950,
          1195,
          14228,
          1271,
          520,
          302,
          1288,
          133,
          1190,
          1178,
          34153,
          1190,
          260,
          12335,
          321,
          565,
          4049,
          475,
          75830,
          36438,
          5901,
          54185,
          14783,
          28739,
          308,
          19408,
          3766,
          254,
          28425,
          47249,
          1382480,
          163415,
          5196,
          1190,
          276002,
          42619,
          1078,
          260,
          13061,
          255,
          5908,
          1970,
          1195,
          493806,
          595,
          24536,
          79613,
          1412,
          3289,
          1946,
          2807,
          917,
          10256,
          5196,
          271,
          2518,
          1847,
          5457,
          1804,
          321490,
          2408,
          5903,
          372,
          99,
          71463,
          5512,
          77,
          1146,
          1368,
          239,
          54287,
          391389,
          224256,
          26551,
          722,
          3032,
          606,
          21902,
          95035,
          7268,
          87124,
          597,
          1078,
          38912,
          7565,
          105549,
          1312922,
          1126,
          910148,
          276,
          26551,
          744,
          19054,
          3395,
          3395,
          1382480,
          450,
          1858,
          4778,
          1749,
          301,
          5760,
          397,
          267,
          263,
          1804,
          3343,
          1126,
          2054,
          237282,
          11432,
          3096,
          341,
          207,
          106,
          34882,
          1680,
          75903,
          1087,
          631,
          1078,
          513,
          520,
          5341,
          1858,
          1446,
          2916,
          589,
          307,
          917,
          276896,
          3807,
          597,
          2054,
          4367,
          571,
          87124,
          88735,
          15426,
          53,
          1930,
          811,
          1078,
          1654,
          526,
          17047,
          3776,
          320,
          5908,
          269,
          589,
          914,
          765,
          4895,
          123,
          54767,
          922,
          3996,
          2456,
          4573,
          53,
          928,
          6581,
          782,
          1684,
          7297,
          355,
          134056,
          165556,
          4074,
          69,
          1078,
          230,
          4354,
          804,
          5621,
          36784,
          3395,
          1661,
          137,
          1577385,
          118,
          863,
          910148,
          53,
          5512,
          1132,
          2523,
          475,
          2644,
          2916,
          5927,
          2971,
          5438,
          241,
          7420,
          328,
          136,
          1126,
          4049,
          5901,
          1126,
          7297,
          106,
          1526206,
          1946,
          31970,
          725,
          18408,
          4680,
          1288,
          1791,
          111,
          2661,
          1909,
          5927,
          5548,
          478,
          427,
          1563,
          970,
          911,
          1514,
          1804,
          2504700,
          32891,
          61,
          4172,
          22191,
          239,
          3430,
          639,
          4508,
          77,
          1563,
          1523,
          1536,
          1426,
          910148,
          241,
          50489,
          5895,
          6120,
          3833,
          110,
          1195,
          20478,
          2526,
          4090,
          545147,
          518429,
          1201,
          1423,
          673342,
          178,
          291,
          631,
          313,
          1577385,
          12747,
          3862,
          12747,
          1241364,
          167,
          22305,
          4845,
          2644,
          450,
          206,
          136,
          3279,
          427,
          272134,
          6951,
          467,
          104,
          307,
          2691,
          79008,
          18408,
          184,
          736284,
          1078,
          4074,
          190178,
          1312922,
          128,
          16183,
          1892,
          4081,
          1631,
          370,
          1382480,
          49,
          217,
          7646,
          34496,
          32891,
          5196,
          5760,
          8512,
          2786,
          1178,
          34882,
          2036,
          276002,
          2691,
          4726,
          413574,
          96942,
          10256,
          1443,
          2661,
          1089,
          163415,
          5621,
          31515,
          2258,
          9496,
          349,
          1178,
          2290,
          1480,
          680,
          95035,
          276896,
          91,
          427,
          61,
          923,
          1075,
          2379,
          409656,
          579,
          18128,
          276002,
          341043,
          2523,
          2135,
          14871,
          757530,
          254,
          341,
          969,
          248,
          7646,
          2518,
          3223,
          5760,
          372,
          207410,
          565,
          2443,
          725,
          3451,
          753116,
          165556,
          2518,
          1302,
          12747,
          5512,
          224256,
          1745,
          736284,
          343,
          372,
          5662,
          804,
          520,
          54767,
          4878,
          78968,
          1186,
          427,
          241,
          21902,
          606,
          302,
          270712,
          71335,
          2504700,
          2786,
          5507,
          59705,
          207410,
          3862,
          7268,
          5778,
          4913,
          35705,
          18128,
          1661,
          94014,
          343,
          1923,
          18182,
          3032,
          6120,
          743,
          1132,
          2872,
          3684,
          4512,
          2644,
          765,
          140,
          6951,
          3289,
          84106,
          272134,
          105638,
          116155,
          3224,
          144160,
          9784,
          5507,
          632,
          565,
          2328,
          6841,
          18760,
          28739,
          4993,
          530,
          3807,
          19054,
          743,
          140,
          5760,
          489,
          8333,
          10256,
          22305,
          1306,
          1140,
          3032,
          136895,
          35371,
          467,
          2307,
          6469,
          736284,
          471,
          276896,
          116001,
          118,
          106,
          8269,
          206,
          42817,
          6841,
          4677,
          43,
          1078,
          4474,
          1892,
          3833,
          718,
          192805,
          1363,
          105549,
          75830,
          337,
          51,
          4049,
          899,
          99,
          36438,
          5927,
          1595797,
          84106,
          1595797,
          589,
          4533,
          22305,
          4074,
          1749,
          1363,
          526,
          1126,
          46944,
          888,
          1979,
          47249,
          137,
          1312,
          84106,
          1263321,
          258,
          16183,
          7692,
          95035,
          1533,
          4993,
          1923,
          341,
          647,
          832,
          2456,
          46563,
          1201,
          105638,
          526,
          258,
          2121,
          566,
          376,
          5662,
          765,
          46563,
          51427,
          1241364,
          2607,
          28739,
          1078,
          153,
          2303,
          1453,
          475,
          110,
          493,
          34153,
          970,
          372,
          3066,
          836,
          321,
          46563,
          17867,
          5732,
          489,
          376,
          391389,
          520,
          2092,
          633,
          1360,
          191096,
          2870,
          1100,
          178,
          8830,
          1574,
          207,
          2206,
          5895,
          795,
          301,
          2401,
          3228,
          263,
          899,
          84861,
          3776,
          722,
          1689,
          190249,
          9679,
          207410,
          5341,
          13422,
          2376,
          4056,
          1758,
          427,
          307,
          969,
          116001,
          9496,
          1780,
          771,
          673342,
          1689,
          23727,
          1656,
          4074,
          269,
          5341,
          191096,
          475,
          69793,
          3119,
          2290,
          3285,
          128354,
          1532,
          158701,
          551,
          198,
          3487,
          687276,
          899,
          153,
          321490,
          2307,
          276896,
          1089,
          1126,
          828,
          333497,
          167,
          37,
          241,
          828,
          248,
          37,
          467,
          397,
          4542,
          48194,
          718,
          9815,
          139,
          520,
          276002,
          7155,
          1847,
          4198,
          205,
          291,
          54185,
          4512,
          6508,
          34496,
          12335,
          270712,
          46563,
          753116,
          3994,
          932,
          346,
          3766,
          2328,
          1196,
          888,
          3104,
          1583,
          878,
          186140,
          7155,
          372,
          37,
          648,
          427,
          1780,
          5927,
          8874,
          3833,
          1414,
          1261,
          1383,
          811,
          43102,
          1577385,
          166081,
          2135,
          2097,
          61,
          969,
          645,
          1453,
          1791,
          12335,
          2274,
          30770,
          163415,
          3684,
          5760,
          530,
          151815,
          1988,
          11432,
          1166,
          2607,
          1930,
          291,
          7155,
          2607,
          3766,
          54287,
          105549,
          178,
          460,
          1897,
          291,
          324,
          4090,
          1606,
          1453,
          5211,
          1080,
          648,
          43102,
          832,
          1179,
          6581,
          5778,
          42384,
          760,
          28739,
          836,
          1382480,
          5895,
          2317,
          15426,
          1680,
          20478,
          140,
          331,
          1022298,
          3684,
          2054,
          606,
          633,
          320,
          1423,
          73,
          540,
          932,
          6120,
          1909,
          35371,
          1228,
          344,
          498,
          69,
          1766,
          2304,
          230,
          601723,
          111,
          4677,
          310,
          13973,
          6434,
          85,
          242,
          1661,
          477,
          1943,
          20478,
          841711,
          20328,
          378909,
          3430,
          348,
          470,
          1700,
          28739,
          601723,
          737,
          276,
          158701,
          1645,
          4542,
          331,
          1196,
          11256,
          861,
          277,
          321,
          106,
          1126,
          2691,
          757530,
          4354,
          6434,
          295,
          3776,
          1446,
          96942,
          18182,
          302,
          5354,
          276896,
          1132,
          628,
          8874,
          1675,
          2368,
          1420,
          1368,
          2799,
          5778,
          23727,
          1241364,
          4664,
          2691,
          1143,
          324,
          647,
          571,
          397,
          124967,
          2274,
          1143,
          172817,
          1725,
          571,
          163415,
          647,
          84106,
          1606,
          1645,
          12486,
          3495,
          964,
          1263321,
          331,
          116001,
          9815,
          1749,
          824,
          28425,
          346,
          2443,
          695,
          2408,
          3805,
          76,
          85,
          343,
          270712,
          24645,
          2518,
          1523,
          190178,
          99,
          817312,
          2807,
          372,
          63,
          878,
          899,
          198,
          5895,
          2836,
          177,
          2906700,
          687276,
          297,
          1791,
          2518,
          923,
          100,
          5901,
          1675,
          1382480,
          2456,
          595,
          1493,
          192,
          12335,
          5895,
          3776,
          6841,
          123373,
          5875,
          4159,
          271,
          343,
          502,
          321,
          2121,
          18128,
          153,
          628,
          863,
          1368,
          2906700,
          213,
          1749,
          6951,
          1831,
          190178,
          276,
          3807,
          2456,
          1166,
          5619,
          5989,
          798,
          6120,
          564,
          647,
          5760,
          5927,
          478,
          207410,
          2807,
          46,
          59744,
          16183,
          695,
          4729,
          176,
          76,
          1745,
          71463,
          530,
          590,
          2607,
          5196,
          741,
          1442,
          471,
          1749,
          1850,
          2036,
          75830,
          2906700,
          30770,
          753116,
          1563,
          33804,
          836,
          687276,
          190,
          139,
          2368,
          4589,
          498,
          2304,
          217,
          54287,
          1810,
          5341,
          14742,
          493,
          450,
          1654,
          4878,
          518429,
          46,
          76383,
          4056,
          932,
          129,
          258,
          5196,
          105638,
          6120,
          782,
          878,
          2148,
          736284,
          47249,
          502,
          207410,
          190178,
          1446,
          467,
          241,
          1725,
          1383,
          7646,
          137067,
          171170,
          13973,
          1288,
          365,
          5895,
          1526206,
          743,
          23,
          178,
          3688,
          413574,
          1312922,
          804,
          4542,
          1165,
          5989,
          365,
          520,
          478,
          1075,
          4653,
          10717,
          626,
          841711,
          1423,
          6703,
          1241364,
          413574,
          2644,
          10256,
          186140,
          59705,
          1766,
          571,
          6581,
          71485,
          1897,
          2016,
          163415,
          270712,
          28278,
          817312,
          238602,
          123,
          6713,
          2661,
          973849,
          302,
          2856,
          46,
          254282,
          269,
          140,
          153,
          749635,
          632,
          9496,
          878,
          601723,
          85,
          4049,
          13602,
          1631,
          346,
          1241364,
          94014,
          52126,
          43,
          3776,
          761,
          248,
          6713,
          84861,
          1745,
          75830,
          217,
          13973,
          1574,
          18182,
          471,
          530,
          307,
          397,
          3255,
          741,
          2906700,
          3684,
          7987,
          2471,
          92043,
          4575,
          459921,
          1791,
          263,
          198,
          928,
          1749,
          1126,
          105638,
          2836,
          35705,
          7420,
          589,
          47249,
          46944,
          1526206,
          33917,
          804,
          190,
          3684,
          3104,
          1749,
          4056,
          564,
          165,
          673342,
          100,
          741,
          151785,
          811,
          1841,
          1334,
          4354,
          337,
          1925,
          1595797,
          254282,
          2303,
          46944,
          743,
          6469,
          973849,
          378909,
          595,
          1643,
          4575,
          757530,
          198,
          1831,
          341043,
          6284,
          413574,
          673342,
          1643,
          47249,
          663,
          635,
          3395,
          2263,
          2504700,
          2290,
          67082,
          2092,
          365,
          1645,
          50489,
          776,
          27829,
          71485,
          7420,
          4081,
          878,
          3104,
          27971,
          1190,
          4090,
          49,
          76,
          378909,
          1293,
          464,
          263,
          1656,
          1324,
          321490,
          647,
          2916,
          1263321,
          71463,
          3096,
          34153,
          1517,
          76,
          55581,
          1228,
          144160,
          52126,
          5901,
          18760,
          2504700,
          1725,
          532,
          1966,
          376,
          1617,
          4845,
          467,
          626,
          1631,
          595,
          1565,
          914,
          645,
          673342,
          1383,
          75830,
          320,
          153,
          186140,
          20328,
          571,
          118,
          258,
          663,
          1063,
          589,
          92337,
          144160,
          46944,
          6581,
          241,
          324,
          5760,
          3508,
          6581,
          1925,
          5512,
          564,
          1038,
          878,
          1512,
          2408,
          760,
          95,
          2906700,
          5507,
          68211,
          153,
          207410,
          49,
          2526,
          899,
          341,
          718,
          19090,
          4074,
          6951,
          205,
          4074,
          1512,
          1078,
          722,
          1120,
          540,
          895,
          3487,
          737,
          140,
          732,
          5619,
          2408,
          4729,
          55581,
          46,
          928,
          5657,
          564,
          135332,
          4720,
          4512,
          129,
          92608,
          144160,
          76383,
          3495,
          1850,
          878,
          1293,
          1453,
          272,
          31515,
          1847,
          1675,
          836,
          1420,
          5161,
          172817,
          1051,
          5895,
          824,
          1645,
          2856,
          3032,
          8333,
          564,
          3255,
          276002,
          213,
          571,
          863,
          641,
          35371,
          16183,
          1312922,
          32891,
          15647,
          798,
          7297,
          4533,
          1532,
          914,
          2408,
          753116,
          2303,
          11432,
          27971,
          1504,
          776,
          18182,
          128,
          13973,
          190178,
          47249,
          149,
          5901,
          3451,
          10295,
          1749,
          1166,
          116155,
          3343,
          2401,
          922,
          516,
          47772,
          899,
          100,
          50489,
          207,
          1574,
          1360,
          1666,
          18408,
          863,
          13717,
          69,
          271,
          1420,
          1312,
          1368,
          3688,
          1656,
          139,
          84106,
          922,
          3805,
          1196,
          1606,
          151785,
          18128,
          381459,
          823,
          46,
          2135,
          176,
          1302,
          1789,
          1789,
          1493,
          597,
          5354,
          1089,
          725,
          43102,
          1988,
          184,
          10717,
          11256,
          640470,
          95,
          128,
          31394,
          6120,
          4664,
          922,
          1087,
          128715,
          110,
          2457,
          9512,
          502,
          1725,
          571,
          2258,
          95015,
          824,
          34882,
          75903,
          5875,
          46,
          1383,
          3224,
          1274,
          343,
          190178,
          341,
          1831,
          3343,
          5875,
          395,
          74,
          1595797,
          270712,
          30770,
          35705,
          969,
          75830,
          331,
          3688,
          171170,
          2401,
          1446,
          165556,
          165,
          647,
          571,
          10076,
          1490,
          324,
          4878,
          13835,
          1139,
          601723,
          502,
          467,
          13973,
          4090,
          34882,
          1252,
          2504700,
          321490,
          136,
          1334,
          45100,
          86954,
          1493,
          5895,
          37,
          5548,
          2870,
          2307,
          3776,
          128,
          493806,
          1631,
          123,
          92608,
          269,
          579,
          1132,
          158701,
          194500,
          343,
          34153,
          17867,
          3833,
          2644,
          2092,
          5457,
          568,
          2906700,
          27971,
          215,
          1426,
          899,
          467,
          1334,
          71485,
          1583,
          19408,
          910148,
          11250,
          757530,
          686,
          640470,
          1201,
          3684,
          5895,
          2526,
          5211,
          2470,
          24536,
          7297,
          1201,
          1760,
          1360,
          378909,
          645,
          1970,
          71335,
          7163,
          376,
          355,
          43,
          1523,
          832,
          2258,
          1166,
          895,
          194500,
          4589,
          18128,
          3104,
          2906700,
          1324,
          3807,
          276002,
          7430,
          7646,
          190178,
          111,
          595,
          10076,
          47772,
          3684,
          176,
          5666,
          1363,
          1352,
          5760,
          2054,
          54185,
          32891,
          237282,
          50489,
          158701,
          54287,
          493806,
          7268,
          1446,
          76,
          1943,
          1645,
          45100,
          1078,
          8512,
          5507,
          3066,
          145,
          191096,
          757530,
          83,
          828,
          19685,
          409656,
          1360,
          765,
          1810,
          88735,
          1725,
          21635,
          1334,
          55581,
          841711,
          381459,
          9496,
          36438,
          1312922,
          324,
          743,
          2060,
          4172,
          673342,
          71485,
          34153,
          19408,
          1666,
          467,
          3096,
          409656,
          74,
          26551,
          743,
          69793,
          2456,
          355,
          1087,
          2906700,
          71485,
          13717,
          804,
          42817,
          1892,
          1126,
          427,
          77,
          741,
          471,
          54767,
          1897,
          645,
          15269,
          28739,
          124967,
          12335,
          34496,
          13983,
          1850,
          165,
          4512,
          5438,
          237282,
          970,
          2290,
          1271,
          35439,
          129,
          1789,
          4471,
          5196,
          165556,
          95,
          116001,
          9594,
          737,
          564,
          238602,
          301,
          4306,
          1087,
          149,
          35299,
          2443,
          5648,
          75830,
          7646,
          20328,
          19054,
          1656,
          22305,
          20478,
          1166,
          1165,
          1263321,
          757530,
          1201,
          21902,
          6284,
          258,
          139650,
          190178,
          1684,
          9815,
          321490,
          5341,
          1312922,
          1565,
          158701,
          6581,
          3684,
          1426,
          10256,
          1271,
          1643,
          1970,
          238602,
          156391,
          255,
          18128,
          346,
          1526206,
          565,
          267,
          2786,
          165,
          4354,
          467,
          1051,
          133,
          888,
          13422,
          55581,
          106,
          4653,
          460,
          1979,
          324,
          107941,
          67082,
          128,
          571,
          2443,
          136,
          14783,
          3487,
          1126,
          194500,
          85,
          1453,
          4138,
          12747,
          54287,
          217,
          223,
          4913,
          176,
          737,
          21125,
          464,
          192805,
          139650,
          391389,
          976,
          68211,
          6713,
          1472,
          1126,
          1478,
          647,
          224256,
          1139,
          85,
          67082,
          186140,
          23,
          1970,
          753116,
          475,
          241,
          1979,
          341043,
          31394,
          590,
          9679,
          6841,
          269,
          3805,
          136,
          397,
          1490,
          346,
          1789,
          3994,
          34496,
          475,
          1766,
          722,
          139,
          2607,
          28739,
          725,
          238602,
          18128,
          471,
          94014,
          1791,
          1645,
          12335,
          7297,
          298,
          477,
          50489,
          19408,
          20328,
          106,
          15647,
          24645,
          15623,
          2054,
          190178,
          1102,
          518429,
          2456,
          475,
          595,
          6951,
          632,
          1766,
          207,
          139,
          1577385,
          3766,
          3224,
          895,
          2274,
          1228,
          1139,
          2691,
          1443,
          302,
          21902,
          13835,
          419,
          218,
          186140,
          47249,
          753116,
          5666,
          54287,
          42619,
          46944,
          4575,
          493806,
          1126,
          301,
          5161,
          1595797,
          34153,
          3066,
          545147,
          1132,
          93193,
          45303,
          2401,
          27020,
          1383,
          18182,
          4542,
          116001,
          272,
          7155,
          85,
          1563,
          532,
          376,
          4575,
          2566,
          302,
          116001,
          927396,
          2916,
          1631,
          1762,
          27020,
          169,
          2526,
          5927,
          1766,
          134056,
          35705,
          100,
          27829,
          3119,
          75830,
          13973,
          324,
          165556,
          27971,
          630,
          910148,
          4056,
          3451,
          30770,
          43,
          3684,
          717255,
          910148,
          450,
          7268,
          313,
          167,
          832,
          76,
          217,
          14783,
          1923,
          8333,
          540,
          525713,
          341043,
          9165,
          341,
          238602,
          2644,
          530,
          68211,
          1847,
          1689,
          1324,
          5354,
          584,
          9587,
          1383,
          1166,
          2290,
          53,
          910148,
          1675,
          5778,
          71335,
          4542,
          5161,
          190178,
          118,
          932,
          1909,
          14742,
          5901,
          467,
          151785,
          53,
          87124,
          1766,
          1143,
          601723,
          3224,
          50835,
          15426,
          35439,
          647,
          93193,
          3202,
          23,
          1363,
          267,
          413574,
          99,
          825,
          124967,
          47,
          54185,
          11250,
          92043,
          744,
          760,
          3807,
          2523,
          271,
          26551,
          129,
          5216,
          13717,
          9815,
          111,
          1312,
          75903,
          124967,
          32891,
          973849,
          5341,
          297,
          77,
          26120,
          2303,
          32891,
          198,
          92294,
          4542,
          166081,
          2317,
          238602,
          1760,
          2456,
          3202,
          475,
          765,
          43,
          163415,
          4895,
          530,
          640470,
          128354,
          753116,
          31394,
          1446,
          525713,
          7155,
          2457,
          1261,
          10295,
          964,
          1770,
          571,
          1606,
          4878,
          27971,
          123,
          270712,
          1363,
          28739,
          258,
          128354,
          1442,
          504,
          100,
          18408,
          105549,
          2501,
          19685,
          134056,
          564,
          2290,
          21902,
          584,
          741,
          1302,
          686,
          2807,
          878,
          2307,
          847,
          513,
          1324,
          2906700,
          3224,
          4090,
          564,
          9815,
          222,
          1923,
          190,
          291,
          52126,
          1666,
          686,
          23,
          2135,
          52126,
          1595797,
          4090,
          59744,
          31394,
          151022,
          2142,
          1312922,
          47772,
          276896,
          34496,
          4172,
          4575,
          3279,
          1446,
          964,
          595,
          165,
          641,
          26551,
          21125,
          223,
          795,
          190,
          32891,
          470,
          302,
          391389,
          139650,
          641,
          11256,
          14871,
          427,
          1675,
          349,
          4895,
          241,
          470,
          198,
          753116,
          19685,
          267,
          5791,
          7646,
          5778,
          75830,
          489,
          471,
          2121,
          45100,
          725,
          565,
          566,
          346,
          7297,
          71485,
          45303,
          308,
          397,
          277,
          378909,
          3289,
          1595797,
          2971,
          167,
          76383,
          78968,
          493806,
          22930,
          242,
          43,
          910148,
          60,
          105549,
          7646,
          229,
          100,
          126,
          4680,
          3224,
          9587,
          4664,
          106,
          910148,
          1526206,
          6951,
          397,
          107941,
          526,
          8874,
          1412,
          307,
          10295,
          5648,
          4729,
          2121,
          922,
          4198,
          1302,
          18128,
          324,
          1831,
          4074,
          9815,
          19685,
          28425,
          3495,
          5507,
          2328,
          7155,
          910148,
          1228,
          21635,
          3202,
          1178,
          10256,
          632,
          530,
          38912,
          3688,
          1526206,
          20478,
          2566,
          269,
          338,
          184,
          1051,
          1063,
          2395,
          260,
          321,
          645,
          151022,
          2290,
          104396,
          218,
          566,
          4729,
          134056,
          145,
          7297,
          123,
          1368,
          190178,
          276002,
          276896,
          5354,
          4367,
          104396,
          35371,
          2644,
          1078,
          372,
          1512,
          172817,
          564,
          378909,
          1536,
          31515,
          344,
          218,
          1493,
          263,
          381459,
          365,
          9565,
          5662,
          24536,
          92043,
          178,
          320,
          78968,
          5927,
          911,
          4913,
          50835,
          43102,
          8874,
          2501,
          1363,
          397,
          910148,
          7155,
          606,
          564,
          391389,
          4074,
          36438,
          530,
          25459,
          551,
          295,
          52126,
          7268,
          269,
          158701,
          633,
          337,
          1512,
          3996,
          1363,
          3343,
          589,
          1526206,
          144160,
          28425,
          178,
          2971,
          17867,
          463,
          4913,
          241,
          3451,
          77,
          1791,
          2368,
          94014,
          1078,
          1563,
          1766,
          2836,
          333497,
          804,
          3224,
          54287,
          1139,
          4542,
          4056,
          470,
          1312922,
          489,
          571,
          9165,
          7268,
          811,
          215,
          105638,
          116001,
          1178,
          31394,
          1810,
          1165,
          6951,
          718,
          328,
          757530,
          6018,
          922,
          8512,
          8874,
          804,
          653,
          5341,
          771,
          912,
          4172,
          7646,
          20478,
          2786,
          2395,
          2526,
          92337,
          493806,
          2258,
          395,
          3224,
          1412,
          38912,
          230,
          1661,
          149,
          85,
          237282,
          1126,
          1684,
          2304,
          277,
          47249,
          344,
          92106,
          11751,
          551,
          927396,
          31515,
          5507,
          5927,
          255,
          2317,
          69793,
          5989,
          166081,
          1196,
          3289,
          6120,
          104,
          7268,
          136895,
          86954,
          5196,
          5791,
          459921,
          1414,
          7163,
          71463,
          22305,
          467,
          2304,
          14228,
          4138,
          741,
          2135,
          106,
          1261,
          970,
          254282,
          6508,
          1131,
          153,
          795,
          172817,
          92106,
          647,
          94014,
          238602,
          686,
          105549,
          2526,
          2566,
          2202,
          2211,
          1274,
          16183,
          757530,
          532,
          229,
          1766,
          6120,
          94014,
          4512,
          2383912,
          198,
          4172,
          19090,
          2290,
          166081,
          4603,
          504,
          1252,
          2661,
          914,
          124967,
          4198,
          76383,
          7430,
          270712,
          7155,
          145,
          76,
          269,
          206,
          54287,
          923,
          4049,
          3402,
          99,
          1252,
          19054,
          765,
          207,
          564,
          1645,
          341,
          7565,
          1892,
          43102,
          346,
          4081,
          1512,
          520,
          571,
          54287,
          5512,
          1080,
          1970,
          5341,
          2206,
          31515,
          241,
          1288,
          184,
          1679,
          19054,
          973849,
          92106,
          2395,
          1382480,
          105638,
          18459,
          1930,
          248,
          922,
          1766,
          3263,
          20478,
          3688,
          736284,
          1762,
          302,
          4575,
          5548,
          595,
          1700,
          128354,
          743,
          4542,
          34496,
          922,
          771,
          1897,
          10295,
          8333,
          276,
          198,
          2290,
          344,
          27020,
          733,
          140,
          69,
          172817,
          5354,
          190178,
          214518,
          1190,
          51,
          475,
          1923,
          1507,
          54767,
          3202,
          863,
          17867,
          2317,
          10295,
          286,
          1897,
          1423,
          2870,
          1426,
          3508,
          272,
          328,
          5778,
          695,
          922,
          1274,
          1858,
          5895,
          149,
          13422,
          376,
          1022298,
          18182,
          191096,
          6629,
          2518,
          52,
          1423,
          35439,
          1680,
          111,
          15426,
          502,
          27829,
          1789,
          13422,
          84106,
          63,
          6120,
          13602,
          275,
          86954,
          1241364,
          3684,
          20328,
          1897,
          88735,
          1643,
          470,
          589,
          888,
          1791,
          37,
          372,
          478,
          1791,
          413574,
          6581,
          376,
          85,
          2523,
          1760,
          753116,
          4575,
          378909,
          686,
          70,
          7163,
          1791,
          602,
          118,
          94014,
          530,
          717255,
          463,
          105638,
          1807,
          568,
          9506,
          36784,
          5901,
          895,
          1019,
          824,
          3119,
          286,
          9784,
          230,
          344,
          34882,
          8830,
          1132,
          184,
          24645,
          3285,
          653,
          5901,
          186140,
          123,
          1979,
          828,
          1078,
          6713,
          927396,
          8512,
          2036,
          2906700,
          471,
          1523,
          341043,
          1512,
          6018,
          606,
          630,
          686,
          817312,
          7155,
          2135,
          3684,
          1302,
          4074,
          1749,
          313,
          344,
          2258,
          20328,
          832,
          5848,
          680,
          647,
          76383,
          3508,
          134056,
          725,
          248858,
          2971,
          1312922,
          7430,
          76,
          2471,
          4074,
          19408,
          267,
          470,
          2135,
          565,
          765,
          1684,
          26551,
          1089,
          299480,
          338,
          54767,
          914,
          3766,
          2661,
          1412,
          2036,
          4726,
          601723,
          632,
          51427,
          242,
          8097,
          177,
          4090,
          11432,
          1426,
          51,
          27971,
          6469,
          99,
          172817,
          71463,
          276896,
          13061,
          5161,
          9496,
          23805,
          653,
          2471,
          24840,
          308,
          86954,
          166081,
          6006,
          177,
          725,
          343,
          1446,
          1022298,
          2872,
          1022298,
          2523,
          316665,
          3458,
          1368,
          518429,
          42384,
          964,
          1523,
          153,
          320420,
          21134,
          3688,
          1606,
          653,
          99,
          663,
          641349,
          8333,
          630,
          4512,
          478,
          753116,
          743,
          1420,
          241,
          20478,
          94325,
          222785,
          124967,
          2408,
          1925,
          9594,
          61,
          686,
          917,
          695,
          4913,
          1841,
          5438,
          5354,
          1523,
          1523,
          16183,
          2526,
          165556,
          2395,
          710,
          2526,
          5908,
          2906700,
          167,
          267,
          3688,
          4895,
          888,
          365,
          888,
          166081,
          77,
          242,
          248858,
          4575,
          338,
          5507,
          255,
          270712,
          16305,
          128715,
          224256,
          1804,
          5507,
          198,
          99,
          3343,
          533,
          6713,
          1749,
          1271,
          513,
          1312922,
          7268,
          254282,
          172817,
          1645,
          1766,
          1263321,
          166081,
          301,
          4542,
          5760,
          8512,
          2661,
          5666,
          5211,
          73,
          3684,
          333497,
          3688,
          172817,
          71485,
          3430,
          376,
          1631,
          248858,
          475,
          5908,
          277,
          832,
          1675,
          50835,
          8007,
          151022,
          177,
          5577,
          111,
          4074,
          964,
          33804,
          2661,
          10717,
          165556,
          13835,
          878,
          128,
          7646,
          6018,
          3224,
          128715,
          722,
          1735,
          28278,
          5989,
          1680,
          213,
          7420,
          18182,
          3096,
          15647,
          7565,
          52126,
          6469,
          4074,
          2206,
          1512,
          230,
          276002,
          2607,
          18408,
          5161,
          19090,
          718,
          795,
          224256,
          1725,
          133,
          222,
          2408,
          1507,
          5354,
          1165,
          198,
          1139,
          4005,
          1383,
          324,
          18408,
          73,
          832,
          116001,
          1595797,
          338,
          1930,
          343,
          964,
          206,
          2906700,
          4005,
          733,
          2054,
          19685,
          2471,
          9772,
          190178,
          92043,
          14871,
          67082,
          2303,
          1126,
          241,
          69,
          5548,
          1804,
          1565,
          595,
          1102,
          493,
          286,
          1858,
          71485,
          471,
          186140,
          545147,
          239,
          2054,
          7646,
          1252,
          397,
          205,
          413574,
          48194,
          489,
          116001,
          516,
          771,
          645,
          798,
          3289,
          2457,
          2471,
          744,
          1442,
          35371,
          2504700,
          237282,
          4664,
          695,
          206,
          217,
          19054,
          4154,
          27971,
          166081,
          100,
          642,
          9594,
          71485,
          7268,
          564,
          1274,
          19685,
          51,
          337,
          320,
          467,
          4664,
          267,
          34882,
          6841,
          192805,
          321,
          2158,
          320,
          23,
          298,
          1930,
          13061,
          3862,
          6006,
          863,
          632,
          1766,
          1530,
          63,
          213,
          18182,
          42817,
          237282,
          5211,
          110,
          190,
          76383,
          19408,
          54185,
          76383,
          263,
          107941,
          2916,
          295,
          5507,
          1766,
          19685,
          55581,
          18760,
          753116,
          4056,
          381459,
          1533,
          737,
          2368,
          1302,
          2036,
          2644,
          663,
          1628,
          42384,
          459921,
          463,
          4575,
          192805,
          320,
          237282,
          28425,
          267,
          4367,
          1261,
          504,
          30770,
          1858,
          53,
          5161,
          3996,
          124967,
          19054,
          158701,
          133,
          7646,
          6951,
          254,
          3289,
          581,
          6508,
          126,
          26551,
          1563,
          46,
          6508,
          77,
          307,
          128715,
          76383,
          1324,
          134056,
          5621,
          1126,
          5950,
          348,
          5548,
          741,
          5927,
          24840,
          10076,
          365,
          1897,
          493,
          16163,
          271,
          11256,
          1263321,
          1201,
          11751,
          74,
          761,
          1139,
          3776,
          2786,
          1271,
          337,
          2274,
          922,
          302,
          18760,
          49,
          1132,
          737,
          1654,
          46563,
          1165,
          10076,
          478,
          1312922,
          45303,
          519,
          5621,
          2518,
          7646,
          895,
          55345,
          743,
          1526206,
          733,
          35371,
          27971,
          49,
          965,
          631,
          6018,
          932,
          7646,
          5666,
          450,
          641349,
          5621,
          1302,
          139,
          1132,
          1760,
          2142,
          828,
          12486,
          1261,
          6460,
          1019,
          3066,
          1970,
          10717,
          128,
          267,
          970,
          2457,
          237282,
          3096,
          22305,
          520,
          2856,
          2211,
          3032,
          270712,
          1241364,
          6006,
          126,
          149,
          63,
          1383,
          1186,
          2135,
          348,
          333497,
          28425,
          4573,
          42817,
          1758,
          54185,
          2523,
          1583,
          1680,
          1700,
          1120,
          372,
          3096,
          18128,
          3255,
          1263321,
          218,
          1293,
          22930,
          471,
          5875,
          47772,
          76383,
          14228,
          895,
          21134,
          1139,
          128,
          1523,
          134056,
          911,
          25459,
          42619,
          140,
          1423,
          640470,
          129,
          606,
          18182,
          687276,
          910148,
          736284,
          1420,
          647,
          276,
          112,
          6284,
          28425,
          6629,
          105638,
          823,
          8333,
          207,
          134056,
          1426,
          272,
          795,
          1804,
          4575,
          1689,
          1841,
          139,
          3451,
          1271,
          1382480,
          18128,
          1770,
          24536,
          1847,
          2060,
          795,
          1966,
          673342,
          381459,
          1804,
          76,
          255,
          8874,
          59744,
          60,
          1453,
          695,
          606,
          1643,
          1810,
          163415,
          2872,
          467,
          320,
          1988,
          566,
          4726,
          498,
          116001,
          673342,
          2607,
          2368,
          964,
          888,
          3224,
          7155,
          224256,
          7163,
          5989,
          1228,
          12335,
          1089,
          1426,
          5354,
          1312922,
          653,
          68211,
          1423,
          9496,
          743,
          782,
          964,
          313,
          301,
          753116,
          1089,
          5666,
          1120,
          144160,
          295,
          888,
          9587,
          1420,
          3862,
          1241364,
          1334,
          1684,
          165556,
          910148,
          3224,
          13973,
          1165,
          2395,
          2661,
          2304,
          397,
          134056,
          15426,
          391389,
          526,
          320420,
          242,
          1523,
          31394,
          3263,
          333497,
          1126,
          17047,
          1202,
          3876,
          92294,
          5507,
          55581,
          389246,
          15623,
          1523,
          5512,
          635,
          143,
          606,
          1304,
          3451,
          151785,
          757530,
          111,
          19090,
          4895,
          832,
          6629,
          30770,
          1363,
          1766,
          2258,
          71463,
          1324,
          1166,
          34496,
          190178,
          1645,
          86954,
          1725,
          1126,
          7692,
          87124,
          341,
          673342,
          116001,
          19054,
          601723,
          229,
          18128,
          1923,
          13422,
          965,
          34153,
          630,
          2121,
          1202,
          1426,
          241,
          19054,
          92294,
          471,
          911,
          1523,
          8512,
          725,
          4993,
          725,
          2304,
          137067,
          27971,
          1656,
          1312,
          271,
          95015,
          2870,
          2456,
          5548,
          1760,
          217,
          54767,
          3684,
          34496,
          1810,
          18760,
          1261,
          1970,
          9679,
          7155,
          1847,
          2872,
          302,
          5895,
          811,
          75830,
          277,
          737,
          31515,
          26551,
          151022,
          1725,
          1019,
          733,
          927396,
          9512,
          1383,
          23045,
          4589,
          1725,
          2368,
          1089,
          333497,
          55345,
          1089,
          128,
          1263321,
          166081,
          399,
          230,
          391389,
          2211,
          4845,
          530,
          10076,
          136,
          338,
          54287,
          6460,
          754,
          207,
          391389,
          9587,
          648,
          71463,
          118,
          2328,
          11250,
          732,
          54185,
          1228,
          2607,
          1087,
          5211,
          9587,
          3876,
          1363,
          1360,
          1574,
          1166,
          1080,
          17867,
          1442,
          743,
          213,
          1512,
          1368,
          3684,
          3104,
          1577385,
          4542,
          6434,
          1656,
          18408,
          237282,
          19408,
          1228,
          365,
          1807,
          128715,
          2644,
          258,
          817312,
          271,
          105638,
          118,
          344,
          151022,
          8512,
          7420,
          1745,
          6469,
          4913,
          471,
          26551,
          743,
          641,
          178,
          43102,
          6841,
          34496,
          1196,
          68211,
          18408,
          520,
          333497,
          969,
          3395,
          937,
          302,
          1631,
          413574,
          215,
          92043,
          376,
          272134,
          7646,
          673342,
          1517,
          276002,
          1684,
          7565,
          165,
          241,
          811,
          123,
          1089,
          2148,
          5895,
          3343,
          206,
          1595797,
          5548,
          3688,
          1804,
          186140,
          18128,
          1507,
          1324,
          878,
          7155,
          3263,
          341,
          493,
          1789,
          346,
          653,
          320420,
          129,
          67082,
          233717,
          478,
          5512,
          427,
          190178,
          78968,
          1666,
          459921,
          545147,
          149,
          343,
          888,
          1507,
          95,
          633,
          606,
          75830,
          2376,
          42384,
          680,
          277,
          2395,
          186140,
          1504,
          5161,
          21134,
          341,
          1666,
          760,
          828,
          1760,
          530,
          1725,
          782,
          237282,
          134056,
          206,
          4993,
          276002,
          24840,
          4653,
          970,
          1563,
          922,
          92043,
          92608,
          378909,
          99,
          149,
          71485,
          828,
          11250,
          8874,
          47772,
          3994,
          595,
          349,
          310,
          1139,
          743,
          3766,
          478,
          7155,
          1565,
          1789,
          1847,
          2135,
          3066,
          5895,
          1645,
          4049,
          338,
          1679,
          601723,
          4159,
          19408,
          1263321,
          579,
          74,
          136895,
          1745,
          798,
          198,
          824,
          3228,
          69793,
          255,
          4993,
          509,
          95,
          129,
          6006,
          589,
          277,
          1426,
          910148,
          10256,
          14871,
          1324,
          1140,
          2304,
          1324,
          7155,
          1789,
          4512,
          1363,
          642,
          1132,
          1423,
          1412,
          1770,
          2092,
          137,
          302,
          1195,
          4993,
          248,
          69,
          824,
          1461,
          765,
          79008,
          718,
          419,
          333497,
          3876,
          4533,
          230,
          11256,
          75830,
          647,
          35439,
          6120,
          61,
          2303,
          1679,
          18128,
          9772,
          203571,
          6006,
          1078,
          653,
          38912,
          899,
          86954,
          736284,
          686,
          639,
          69,
          1075,
          1228,
          10295,
          4575,
          237282,
          397,
          551,
          217,
          86954,
          1930,
          1324,
          753116,
          1312922,
          2504700,
          922,
          477,
          4367,
          1970,
          18182,
          516,
          53,
          116001,
          6951,
          1595797,
          136,
          286,
          59744,
          7420,
          1526206,
          19685,
          6841,
          630,
          13061,
          1760,
          129,
          753116,
          34153,
          1565,
          3032,
          94325,
          168,
          153,
          910148,
          1577385,
          50835,
          320420,
          2379,
          313,
          10717,
          346,
          217,
          589,
          18128,
          79008,
          35371,
          5512,
          389246,
          85,
          75830,
          1847,
          1804,
          1019,
          277,
          5989,
          158701,
          910148,
          489,
          545147,
          346,
          4878,
          630,
          2799,
          632,
          2644,
          828,
          270712,
          1725,
          1131,
          21134,
          736284,
          149,
          54185,
          1446,
          1909,
          172817,
          222785,
          134056,
          333497,
          1263321,
          545147,
          725,
          1745,
          3487,
          4090,
          346,
          14871,
          19408,
          178,
          1426,
          836,
          765,
          2526,
          673342,
          1923,
          229,
          22930,
          722,
          5875,
          467,
          910148,
          137,
          21134,
          21125,
          136,
          3119,
          94325,
          1526206,
          158701,
          6841,
          302,
          5512,
          6713,
          4015,
          571,
          1643,
          15426,
          28739,
          1577385,
          7430,
          725,
          153,
          1131,
          964,
          320420,
          1363,
          471,
          2526,
          128715,
          50835,
          176,
          1631,
          648,
          137067,
          143,
          2644,
          9784,
          3224,
          1745,
          1126,
          59744,
          1831,
          76383,
          2607,
          33917,
          218,
          3766,
          5875,
          4015,
          298,
          2518,
          2368,
          3096,
          12349,
          4074,
          2036,
          6469,
          2135,
          271,
          8512,
          2870,
          24536,
          725,
          8874,
          61,
          493806,
          493,
          606,
          26120,
          372,
          757530,
          5512,
          3495,
          100,
          50835,
          2504700,
          23805,
          5438,
          26551,
          4542,
          151815,
          1523,
          166081,
          1288,
          344,
          320420,
          14228,
          18459,
          606,
          1089,
          54767,
          3096,
          124967,
          9993,
          1791,
          307,
          139,
          5908,
          248858,
          276896,
          1831,
          215,
          1804,
          92294,
          2807,
          1506,
          7420,
          206,
          467,
          76,
          687276,
          166081,
          737,
          4726,
          631,
          269,
          932,
          4154,
          1909,
          1606,
          5666,
          606,
          2456,
          888,
          540,
          124967,
          8007,
          397,
          47772,
          6508,
          1190,
          804,
          19408,
          4677,
          1700,
          50489,
          2526,
          3255,
          3688,
          5548,
          633,
          5621,
          3458,
          277,
          190178,
          5196,
          2135,
          1166,
          1213,
          331,
          470,
          601723,
          467,
          93193,
          31394,
          27020,
          18408,
          222,
          37,
          885,
          267,
          22305,
          3096,
          51,
          3730,
          3688,
          5354,
          6006,
          2376,
          1577385,
          1684,
          85,
          247,
          1019,
          3876,
          341,
          899,
          1595797,
          765,
          1791,
          184,
          8333,
          51,
          2304,
          4720,
          754,
          307,
          143,
          124967,
          2916,
          46,
          93193,
          6006,
          111,
          1679,
          648,
          2121,
          1970,
          606,
          372,
          3996,
          85,
          743,
          718,
          376,
          5548,
          54287,
          186140,
          12335,
          140,
          105638,
          9815,
          1312922,
          391389,
          144160,
          85,
          177,
          910148,
          722,
          53,
          1970,
          43,
          19054,
          151022,
          4508,
          1892,
          761,
          6120,
          1312922,
          1146,
          2036,
          680,
          1368,
          5895,
          71463,
          237282,
          19090,
          824,
          76383,
          3805,
          23,
          1892,
          21635,
          12486,
          3279,
          2526,
          937,
          171170,
          92043,
          1446,
          922,
          172817,
          3862,
          48194,
          1493,
          18408,
          10076,
          105638,
          143,
          6508,
          105549,
          1523,
          76,
          134056,
          5875,
          217,
          3255,
          350,
          2443,
          239,
          260,
          124967,
          2054,
          100,
          1700,
          741,
          493806,
          5908,
          2054,
          836,
          95035,
          230,
          3104,
          724,
          13973,
          525713,
          1178,
          54767,
          70,
          248858,
          1186,
          5726,
          4159,
          67858,
          18128,
          1831,
          338,
          238602,
          198,
          1810,
          832,
          34496,
          302,
          5648,
          1689,
          3684,
          99,
          467,
          601723,
          27971,
          59744,
          525713,
          186140,
          238602,
          927396,
          1261,
          54767,
          7155,
          186140,
          427,
          2501,
          5895,
          1166,
          348,
          10256,
          970,
          35371,
          255,
          1228,
          759,
          145,
          1261,
          269,
          18128,
          782,
          19054,
          214703,
          19685,
          1517,
          349,
          118,
          459921,
          12486,
          23,
          372,
          190,
          1461,
          8830,
          9051,
          922,
          110,
          144160,
          516,
          3862,
          260,
          1526206,
          606,
          1312922,
          12486,
          163415,
          2607,
          1841,
          213,
          35439,
          551,
          94325,
          2208,
          2054,
          3395,
          7430,
          1923,
          1909,
          241,
          198,
          2263,
          1186,
          3766,
          7163,
          824,
          1925,
          151785,
          241,
          34882,
          190,
          3876,
          1089,
          3833,
          2206,
          2376,
          27971,
          93193,
          91,
          970,
          2456,
          5895,
          1780,
          7987,
          217,
          1749,
          5451,
          63,
          937,
          2836,
          5662,
          14783,
          2872,
          277,
          568,
          1446,
          741,
          673342,
          4367,
          168,
          18128,
          92608,
          104,
          372,
          2456,
          1700,
          2328,
          46944,
          302,
          970,
          24840,
          94014,
          504,
          922,
          6581,
          99,
          167,
          4589,
          888,
          75830,
          9784,
          272134,
          878,
          1453,
          5895,
          2135,
          21134,
          5621,
          12335,
          19054,
          1228,
          1312,
          198,
          673342,
          36784,
          2223,
          248858,
          4575,
          1745,
          427,
          1909,
          308,
          186140,
          53,
          237282,
          2457,
          1831,
          198,
          27020,
          5196,
          320420,
          1461,
          513,
          3289,
          973849,
          509,
          3833,
          42384,
          85,
          47211,
          1312922,
          640470,
          46944,
          71463,
          2807,
          341,
          736284,
          5732,
          105638,
          1909,
          14871,
          92608,
          149,
          976,
          1293,
          2135,
          88735,
          710,
          631,
          99,
          1526206,
          18128,
          17867,
          43102,
          38912,
          3085,
          3224,
          493806,
          42384,
          737,
          18182,
          427,
          3996,
          302,
          407,
          6284,
          1858,
          158701,
          1446,
          233717,
          1490,
          237282,
          1766,
          1446,
          1645,
          233717,
          4993,
          328,
          1131,
          648,
          31394,
          2078,
          7987,
          1360,
          6006,
          8269,
          471,
          3996,
          571,
          5989,
          348,
          614,
          760,
          105549,
          69793,
          192805,
          2644,
          1523,
          7155,
          1038,
          206,
          86954,
          1423,
          1201,
          320420,
          104,
          910148,
          3876,
          4474,
          68211,
          19090,
          5512,
          229,
          516,
          463,
          2368,
          23045,
          2328,
          151785,
          85,
          1512,
          48194,
          525713,
          271,
          3776,
          12486,
          736284,
          6951,
          3996,
          1656,
          687276,
          192,
          11256,
          1363,
          673342,
          76,
          6581,
          85,
          419,
          922,
          277,
          1766,
          922,
          53,
          46,
          263,
          969,
          3451,
          214703,
          2443,
          3343,
          1100,
          1089,
          1988,
          14742,
          3228,
          50489,
          1038,
          2263,
          3766,
          1892,
          2691,
          222785,
          927396,
          1679,
          1140,
          69793,
          151022,
          1925,
          71485,
          328,
          1690,
          2274,
          2872,
          811,
          10295,
          3688,
          922,
          178,
          19408,
          47211,
          94014,
          11751,
          165,
          470,
          270712,
          166081,
          341,
          450,
          1523,
          1166,
          376,
          2408,
          1789,
          149,
          7646,
          4508,
          467,
          606,
          1263321,
          237282,
          8874,
          4081,
          928,
          760,
          241,
          6951,
          2691,
          1504,
          1139,
          540,
          645,
          263,
          17867,
          3766,
          16183,
          14742,
          4354,
          2523,
          254,
          1241364,
          1493,
          254,
          564,
          165,
          4677,
          533,
          46563,
          1766,
          190,
          276,
          324,
          369,
          6508,
          230,
          46563,
          4895,
          2526,
          349,
          6120,
          68211,
          1766,
          9034,
          732,
          21134,
          1446,
          626,
          163415,
          21134,
          118,
          1791,
          1228,
          50489,
          1126,
          632,
          1645,
          178,
          1892,
          6508,
          2456,
          1423,
          2383912,
          248858,
          2456,
          118,
          218,
          516,
          331,
          3279,
          35439,
          206,
          6469,
          639,
          1645,
          2223,
          116155,
          1087,
          4603,
          389246,
          1228,
          4090,
          20478,
          3255,
          1686,
          7268,
          1841,
          640470,
          828,
          922,
          271,
          355,
          765,
          450,
          30770,
          5621,
          932,
          2036,
          1089,
          533,
          271,
          725,
          765,
          54767,
          166081,
          10076,
          632,
          1263321,
          19054,
          928,
          35371,
          20328,
          1766,
          169,
          9594,
          5438,
          9679,
          4573,
          1139,
          3766,
          1571,
          5662,
          31394,
          267,
          606,
          4878,
          2328,
          2906700,
          6581,
          248858,
          85,
          50489,
          4575,
          725,
          2054,
          343,
          2470,
          21125,
          153,
          673342,
          10295,
          1480,
          1063,
          2054,
          525713,
          1453,
          663,
          8333,
          686,
          341043,
          53,
          477,
          2148,
          5778,
          6006,
          1126,
          475,
          3876,
          71463,
          341,
          99,
          673342,
          545147,
          5901,
          3285,
          725,
          3807,
          579,
          213,
          172247,
          11751,
          18182,
          16183,
          847,
          2456,
          338,
          927396,
          1606,
          9815,
          4542,
          3255,
          344,
          718,
          19054,
          1523,
          1102,
          1804,
          2135,
          34882,
          5778,
          4589,
          67082,
          149,
          1139,
          136,
          27020,
          673342,
          4677,
          1631,
          2054,
          52,
          1979,
          106,
          489,
          140,
          1946,
          878,
          269,
          973849,
          1490,
          59705,
          2872,
          75830,
          48194,
          2036,
          149,
          295,
          153,
          324,
          4653,
          1288,
          4680,
          571,
          27020,
          5848,
          1939,
          2376,
          2328,
          912,
          156391,
          1228,
          35371,
          5657,
          21134,
          4198,
          177,
          46563,
          8019,
          1261,
          2916,
          341,
          165556,
          4512,
          3994,
          3487,
          95,
          73,
          2395,
          3508,
          1577385,
          255,
          23,
          163415,
          397,
          899,
          320420,
          741,
          1383,
          1988,
          92985,
          2786,
          10076,
          15426,
          4154,
          313,
          663,
          471,
          92043,
          673342,
          1493,
          3776,
          1583,
          32891,
          568,
          1680,
          134056,
          2148,
          1178,
          8007,
          69,
          15426,
          828,
          1490,
          8007,
          15623,
          381459,
          21134,
          91,
          73,
          489,
          795,
          2054,
          9034,
          241,
          885,
          1666,
          19685,
          217,
          3684,
          391389,
          2870,
          493,
          9993,
          1988,
          888,
          134056,
          1190,
          3430,
          328,
          320420,
          341,
          673342,
          1195,
          566,
          914,
          381459,
          34882,
          1078,
          1532,
          744,
          1617,
          584,
          9772,
          178,
          1126,
          111,
          18408,
          47249,
          964,
          348,
          1139,
          1075,
          459921,
          35371,
          1382480,
          489,
          177,
          1423,
          1791,
          18128,
          2836,
          601723,
          79008,
          3430,
          16163,
          76,
          2135,
          2408,
          258,
          18182,
          198,
          31515,
          230,
          771,
          1019,
          341,
          118,
          12349,
          13422,
          965,
          207,
          1930,
          1051,
          18128,
          1075,
          192,
          823,
          2142,
          166081,
          15623,
          100,
          223,
          9772,
          30770,
          964,
          1089,
          4573,
          12335,
          4878,
          381459,
          328,
          1089,
          15647,
          2644,
          3096,
          4306,
          4159,
          45100,
          1595797,
          4090,
          4056,
          878,
          355,
          2870,
          10256,
          626,
          177,
          184,
          84861,
          2290,
          112,
          540,
          5161,
          459921,
          1897,
          1382480,
          36784,
          355,
          32891,
          4090,
          217,
          1423,
          2501,
          190178,
          4354,
          2916,
          626,
          28278,
          1078,
          1966,
          1892,
          128354,
          1196,
          899,
          1841,
          1970,
          328,
          1577385,
          3224,
          1190,
          1263321,
          7646,
          3202,
          151815,
          5875,
          128,
          1656,
          718,
          355,
          899,
          3402,
          9594,
          3255,
          134056,
          798,
          43102,
          136,
          67082,
          5161,
          1443,
          1762,
          7268,
          328,
          91,
          3430,
          1420,
          5621,
          1780,
          4172,
          1022298,
          595,
          4575,
          124967,
          75903,
          1766,
          795,
          6508,
          2208,
          1850,
          3495,
          328,
          885,
          2456,
          333497,
          286,
          5895,
          1617,
          2317,
          53,
          76383,
          6284,
          9993,
          471,
          1970,
          263,
          95,
          1261,
          1228,
          1186,
          1766,
          922,
          1506,
          5621,
          31515,
          1196,
          7565,
          3085,
          2856,
          93193,
          47211,
          307,
          568,
          4049,
          11256,
          1563,
          99,
          6629,
          878,
          389246,
          804,
          42817,
          15623,
          1762,
          1680,
          59705,
          9496,
          551,
          233717,
          365,
          1051,
          19054,
          20478,
          328,
          47249,
          478,
          16305,
          137067,
          76383,
          2368,
          601723,
          1075,
          9034,
          2504700,
          4653,
          2307,
          260,
          263,
          1442,
          1532,
          4161,
          16183,
          911,
          13973,
          475,
          970,
          12335,
          1263321,
          2158,
          4729,
          1595797,
          2836,
          184,
          9815,
          6951,
          32891,
          86954,
          9815,
          85,
          828,
          16183,
          7155,
          1261,
          2092,
          11250,
          248858,
          1970,
          836,
          2376,
          1565,
          23,
          1190,
          298,
          277,
          6841,
          19090,
          198,
          4878,
          3451,
          277,
          910148,
          6508,
          224256,
          338,
          35705,
          76383,
          4474,
          413574,
          1930,
          186140,
          1789,
          743,
          1195,
          530,
          233060,
          1261,
          478,
          1443,
          191096,
          1850,
          899,
          1571,
          1923,
          922,
          389246,
          71463,
          158701,
          828,
          215,
          23,
          10076,
          1595797,
          1654,
          736284,
          149,
          4533,
          50835,
          2202,
          4542,
          4512,
          11250,
          158701,
          2456,
          320420,
          276896,
          144160,
          493806,
          1038,
          841711,
          34496,
          5548,
          3224,
          551,
          765,
          823,
          551,
          1789,
          9679,
          19090,
          1675,
          258,
          241,
          823,
          3487,
          3402,
          21134,
          1102,
          743,
          136,
          14742,
          1897,
          1368,
          4138,
          2786,
          23727,
          134056,
          76383,
          19685,
          922,
          1228,
          395,
          602,
          1126,
          95015,
          3776,
          23,
          602,
          695,
          1571,
          817312,
          17047,
          645,
          2317,
          33804,
          3495,
          167,
          5927,
          1195,
          338,
          841711,
          2383912,
          647,
          2870,
          2206,
          5927,
          4290,
          324,
          824,
          6120,
          6006,
          71485,
          718,
          50835,
          3395,
          1420,
          128715,
          470,
          3104,
          1228,
          1063,
          647,
          3263,
          3255,
          518429,
          1360,
          172817,
          222785,
          2644,
          4729,
          205,
          1675,
          1051,
          895,
          378909,
          606,
          7155,
          128715,
          1847,
          4677,
          2121,
          732,
          1075,
          757530,
          1523,
          2317,
          771,
          276896,
          601723,
          4074,
          28278,
          4895,
          34882,
          397,
          92608,
          973849,
          450,
          134056,
          153,
          48194,
          3805,
          519,
          1847,
          4074,
          167,
          1831,
          12335,
          1102,
          1760,
          10295,
          5895,
          1517,
          76,
          19054,
          328,
          5726,
          1261,
          3285,
          648,
          647,
          630,
          344,
          140,
          1690,
          5778,
          1643,
          757530,
          1302,
          836,
          75830,
          1102,
          107941,
          737,
          1583,
          1051,
          1563,
          11751,
          18182,
          6841,
          1766,
          391389,
          4542,
          5341,
          2870,
          526,
          732,
          2807,
          6120,
          923,
          9993,
          551,
          355,
          630,
          1789,
          12335,
          1089,
          525713,
          5196,
          540,
          836,
          614,
          198,
          302,
          166081,
          3458,
          5848,
          4720,
          467,
          1675,
          55581,
          191096,
          5619,
          718,
          2211,
          626,
          2263,
          519,
          4993,
          105549,
          71463,
          277,
          104,
          899,
          736284,
          2092,
          630,
          725,
          5927,
          5196,
          23805,
          60,
          1766,
          18128,
          192805,
          1946,
          12747,
          1412,
          743,
          5901,
          647,
          8269,
          4778,
          24645,
          1526206,
          847,
          20328,
          116001,
          5548,
          19408,
          477,
          71463,
          331,
          76,
          378909,
          5161,
          1923,
          331,
          242,
          477,
          463,
          2807,
          1595797,
          759,
          3688,
          2206,
          5548,
          5895,
          3495,
          192805,
          1758,
          795,
          648,
          1140,
          1312,
          34496,
          5657,
          606,
          349,
          519,
          92043,
          15647,
          2097,
          320420,
          6460,
          224256,
          1675,
          743,
          3096,
          34882,
          6469,
          1352,
          176,
          69793,
          1523,
          111,
          1789,
          99,
          1666,
          973849,
          6469,
          1306,
          5512,
          156391,
          6284,
          4354,
          54287,
          156391,
          28739,
          2304,
          4074,
          5196,
          272134,
          13973,
          95035,
          1263321,
          2121,
          899,
          776,
          206,
          11256,
          1312922,
          94014,
          172817,
          104396,
          1791,
          35439,
          272,
          307,
          9512,
          223,
          190178,
          2661,
          3032,
          286,
          633,
          71463,
          648,
          1970,
          741,
          3805,
          1643,
          922,
          5354,
          1970,
          86954,
          5648,
          5211,
          725,
          1791,
          129,
          1423,
          1306,
          95035,
          224256,
          771,
          5666,
          663,
          911,
          6018,
          2395,
          11256,
          17867,
          743,
          69793,
          632,
          1190,
          28278,
          5161,
          3032,
          3487,
          4542,
          2395,
          337,
          1979,
          1532,
          310,
          1966,
          1423,
          242,
          341043,
          214703,
          14742,
          1261,
          77,
          9815,
          513,
          2158,
          105549,
          647,
          34496,
          606,
          864,
          18408,
          2290,
          1506,
          5216,
          459921,
          836,
          899,
          369,
          341,
          3066,
          4354,
          13602,
          5662,
          754,
          139650,
          2807,
          522,
          528,
          1423,
          6006,
          67082,
          5875,
          23,
          969,
          341,
          3688,
          1195,
          516,
          1766,
          1577385,
          3688,
          149,
          757530,
          10295,
          2274,
          391389,
          308,
          2092,
          10076,
          7430,
          104396,
          20478,
          4913,
          2471,
          112,
          18408,
          28278,
          276896,
          14742,
          73,
          1897,
          10295,
          1453,
          2456,
          6508,
          922,
          71463,
          4575,
          4074,
          128715,
          67082,
          7646,
          31394,
          695,
          172247,
          1700,
          207,
          878,
          3876,
          427,
          4993,
          43102,
          263,
          5875,
          111,
          2054,
          55345,
          77,
          1789,
          198,
          13602,
          910148,
          378909,
          1506,
          1201,
          78968,
          2471,
          18182,
          1288,
          5662,
          632,
          1631,
          16305,
          35299,
          509,
          172817,
          4290,
          2368,
          258,
          533,
          267,
          1078,
          320420,
          4573,
          30770,
          2206,
          75903,
          1930,
          460,
          145,
          757530,
          198,
          1412,
          459921,
          2036,
          2443,
          79008,
          19408,
          118,
          230,
          518429,
          263,
          190178,
          105638,
          1689,
          94325,
          9993,
          149,
          2135,
          1631,
          832,
          2471,
          1791,
          99,
          18760,
          639,
          163415,
          198,
          606,
          413574,
          128715,
          11253,
          6469,
          12335,
          191096,
          2258,
          3224,
          645,
          4729,
          320,
          34153,
          1075,
          2799,
          348,
          2471,
          46,
          8097,
          823,
          15647,
          568,
          1102,
          4677,
          77,
          2836,
          3119,
          71335,
          2526,
          2906700,
          4542,
          1312922,
          1925,
          153,
          75830,
          79008,
          355,
          1909,
          530,
          3096,
          722,
          307,
          36784,
          798,
          18408,
          1684,
          242,
          493,
          1810,
          8830,
          471,
          166081,
          10256,
          12335,
          178,
          21902,
          5161,
          5341,
          43102,
          111,
          12349,
          530,
          2258,
          50489,
          2457,
          1412,
          103927,
          123373,
          36784,
          1617,
          1595797,
          95,
          6120,
          1126,
          2016,
          85,
          2208,
          6469,
          31394,
          321490,
          2258,
          55345,
          832,
          42384,
          1789,
          1909,
          753116,
          255,
          241,
          1166,
          3876,
          1523,
          372,
          3255,
          4593,
          964,
          6841,
          192,
          3451,
          370,
          1675,
          2258,
          10295,
          2304,
          320420,
          276,
          105549,
          663,
          970,
          413574,
          341043,
          632,
          1089,
          5211,
          4049,
          581,
          1288,
          3996,
          3495,
          1925,
          276002,
          2304,
          595,
          54287,
          863,
          824,
          1490,
          144160,
          229,
          92337,
          4664,
          1363,
          2807,
          381459,
          4895,
          1478,
          9594,
          36438,
          1443,
          3430,
          276,
          36784,
          276896,
          5760,
          601723,
          2504700,
          5989,
          6469,
          71463,
          18408,
          19090,
          3876,
          3776,
          136,
          3402,
          722,
          34153,
          1102,
          7646,
          166081,
          67082,
          1643,
          5662,
          1807,
          84106,
          2263,
          1051,
          1089,
          71485,
          16183,
          3343,
          3996,
          28739,
          13717,
          741,
          7155,
          1480,
          397,
          823,
          92043,
          190178,
          33917,
          277,
          69793,
          1089,
          54287,
          31394,
          5548,
          595,
          30770,
          1202,
          54767,
          4542,
          1656,
          123,
          129,
          718,
          1939,
          100,
          88735,
          2303,
          52,
          2206,
          18128,
          276896,
          673342,
          241,
          1490,
          828,
          471,
          5760,
          28739,
          581,
          1679,
          1645,
          20478,
          217,
          247,
          11256,
          1654,
          1368,
          4993,
          1789,
          6841,
          1274,
          718,
          63,
          606,
          4729,
          123373,
          2078,
          970,
          1789,
          54287,
          663,
          21902,
          3805,
          471,
          885,
          85,
          2906700,
          564,
          7155,
          1979,
          732,
          1480,
          1847,
          3224,
          551,
          68211,
          695,
          498,
          914,
          601723,
          4575,
          11256,
          1789,
          1274,
          413574,
          19090,
          626,
          42619,
          10717,
          475,
          1426,
          5548,
          1504,
          53,
          67082,
          105549,
          106,
          349,
          3279,
          338,
          136,
          241,
          5507,
          2290,
          471,
          1850,
          1126,
          74,
          124967,
          198,
          71485,
          532,
          3876,
          2135,
          4573,
          4474,
          104396,
          79613,
          33804,
          513,
          1735,
          528,
          258,
          1139,
          153,
          5457,
          8874,
          320420,
          1288,
          277,
          302,
          21902,
          525713,
          1807,
          67082,
          1089,
          828,
          467,
          277,
          1312922,
          1512,
          1804,
          3684,
          149,
          6713,
          922,
          24840,
          1988,
          32891,
          6629,
          964,
          2470,
          686,
          5895,
          811,
          99,
          1595797,
          1126,
          1631,
          6841,
          7565,
          467,
          2307,
          1274,
          1426,
          1126,
          341,
          4138,
          2607,
          242,
          602,
          85,
          922,
          376,
          95015,
          18128,
          2906700,
          23727,
          7565,
          2368,
          9587,
          633,
          828,
          6469,
          1979,
          75830,
          344,
          10256,
          1022298,
          190178,
          346,
          1810,
          590,
          5211,
          1306,
          4913,
          628,
          153,
          519,
          68211,
          516,
          19054,
          346,
          21134,
          1631,
          1666,
          3805,
          1617,
          19685,
          419,
          2607,
          128715,
          149,
          519,
          207,
          46,
          9815,
          13835,
          5875,
          3104,
          741,
          123,
          230,
          53,
          1166,
          149,
          100,
          910148,
          973849,
          4573,
          2054,
          911,
          391389,
          85,
          732,
          4575,
          1228,
          43102,
          43102,
          18128,
          2906700,
          1725,
          272,
          743,
          3104,
          104396,
          6713,
          6508,
          76383,
          525713,
          26551,
          1271,
          111,
          2211,
          198,
          116001,
          71335,
          4593,
          673342,
          686,
          142,
          28278,
          493,
          1190,
          59744,
          47249,
          2379,
          7430,
          19685,
          1847,
          1526206,
          1645,
          134056,
          302,
          1517,
          5341,
          2036,
          1383,
          1804,
          277,
          7297,
          1078,
          1523,
          168,
          601723,
          139,
          191096,
          17867,
          1126,
          77,
          885,
          135332,
          163415,
          686,
          10076,
          2383912,
          1506,
          144160,
          1725,
          912,
          970,
          9521,
          3343,
          77,
          4726,
          782,
          632,
          313,
          7297,
          1766,
          1178,
          4680,
          4726,
          9565,
          3343,
          673342,
          2856,
          331,
          1352,
          2872,
          346,
          493806,
          145,
          642,
          4367,
          3224,
          478,
          1789,
          888,
          20478,
          272134,
          1745,
          6284,
          1766,
          10076,
          540,
          1847,
          5512,
          695,
          1022298,
          53,
          2304,
          3430,
          479994,
          3688,
          743,
          2368,
          1512,
          478,
          540,
          28739,
          1504,
          5161,
          3833,
          395,
          4664,
          372,
          910148,
          2870,
          71463,
          520,
          864,
          76383,
          1892,
          970,
          6508,
          34153,
          648,
          5548,
          722,
          21134,
          343,
          51427,
          3224,
          589,
          1178,
          291,
          163415,
          1126,
          1360,
          4512,
          6841,
          21134,
          695,
          60,
          4533,
          725,
          2872,
          1656,
          139650,
          54185,
          198,
          1526206,
          2501,
          824,
          79613,
          299480,
          601723,
          2304,
          2526,
          239,
          286,
          1526206,
          34153,
          9034,
          761,
          1089,
          1810,
          86954,
          2906700,
          1078,
          6508,
          92106,
          878,
          166081,
          1190,
          1789,
          302,
          741,
          59744,
          1979,
          895,
          124967,
          409656,
          14783,
          545147,
          10295,
          28739,
          2208,
          17047,
          736284,
          2274,
          5927,
          136895,
          653,
          516,
          885,
          2872,
          571,
          95015,
          5621,
          376,
          156391,
          1078,
          8874,
          18408,
          43102,
          1382480,
          34153,
          5577,
          217,
          1078,
          77,
          836,
          3279,
          2258,
          3119,
          5791,
          177,
          5507,
          133,
          299480,
          18128,
          4512,
          2872,
          4677,
          28739,
          1700,
          2089,
          149,
          725,
          242,
          1930,
          84106,
          2872,
          795,
          27971,
          614,
          378909,
          1288,
          198,
          1661,
          743,
          24536,
          732,
          7565,
          35299,
          77,
          1443,
          337,
          5507,
          1241364,
          376,
          642,
          502,
          69,
          1075,
          1666,
          1241364,
          581,
          198,
          3032,
          1120,
          128,
          276,
          1690,
          1453,
          2258,
          972,
          69,
          4367,
          6951,
          427,
          2401,
          169,
          4575,
          68211,
          11432,
          4306,
          71485,
          124967,
          471,
          378909,
          5895,
          172817,
          153,
          346,
          5760,
          145,
          337,
          6951,
          18408,
          1512,
          134056,
          21134,
          7646,
          269,
          2317,
          2471,
          2661,
          718,
          1228,
          525713,
          92337,
          885,
          2307,
          5657,
          14742,
          743,
          123373,
          1293,
          5791,
          198,
          736284,
          248,
          686,
          77,
          71335,
          5548,
          20328,
          2870,
          5875,
          137067,
          2395,
          6018,
          241,
          15426,
          20478,
          470,
          1847,
          71463,
          6460,
          17867,
          47249,
          24536,
          1461,
          3487,
          1120,
          9051,
          54185,
          566,
          5927,
          198,
          2408,
          136,
          186140,
          54287,
          4533,
          4154,
          686,
          20328,
          733,
          172817,
          571,
          378909,
          24840,
          4913,
          2078,
          8512,
          1789,
          136895,
          94014,
          409656,
          641349,
          5901,
          1382480,
          139650,
          49,
          105549,
          92043,
          313,
          3343,
          5619,
          4720,
          321,
          85,
          4159,
          16163,
          23727,
          67082,
          94325,
          4720,
          1363,
          928,
          151815,
          1368,
          1271,
          5662,
          477,
          5161,
          15269,
          11432,
          1923,
          1684,
          885,
          2202,
          222785,
          372,
          26551,
          1507,
          269,
          8007,
          35371,
          1766,
          1766,
          753116,
          1324,
          5726,
          1453,
          9587,
          18128,
          149,
          1533,
          35371,
          341043,
          237282,
          2526,
          718,
          7420,
          2807,
          601723,
          137067,
          36438,
          33917,
          242,
          78968,
          76383,
          1526206,
          21134,
          1595797,
          76,
          736284,
          910148,
          3085,
          48194,
          18760,
          4653,
          4508,
          129,
          571,
          92337,
          2526,
          320,
          85,
          4878,
          1252,
          145,
          19408,
          11751,
          2644,
          1645,
          338,
          9993,
          4533,
          34882,
          4664,
          21134,
          376,
          504,
          687276,
          3684,
          4049,
          19090,
          137,
          680,
          77,
          1334,
          922,
          139,
          313,
          341,
          757530,
          4074,
          1656,
          2376,
          6006,
          172817,
          760,
          2870,
          11256,
          744,
          324,
          20328,
          47249,
          1446,
          2142,
          19090,
          4159,
          2906700,
          568,
          27020,
          641349,
          21902,
          3451,
          964,
          493806,
          46,
          795,
          241,
          10076,
          1725,
          76,
          427,
          92043,
          14783,
          722,
          63,
          5161,
          673342,
          14075,
          1831,
          30770,
          1789,
          76383,
          242,
          3807,
          7987,
          43102,
          2501,
          237282,
          1382480,
          595,
          348,
          70,
          15426,
          111,
          9815,
          478,
          922,
          207410,
          759,
          395,
          69,
          2097,
          5548,
          9815,
          38912,
          3279,
          2368,
          241,
          1762,
          343,
          757530,
          13061,
          6951,
          1201,
          137067,
          1770,
          46,
          633,
          6581,
          2206,
          1131,
          111,
          242,
          3255,
          5211,
          973849,
          4542,
          276002,
          1689,
          167,
          338,
          151022,
          320,
          71485,
          2092,
          532,
          3699,
          6025,
          313,
          5341,
          83,
          15623,
          2906700,
          13717,
          346,
          1089,
          743,
          741,
          11256,
          584,
          1523,
          1412,
          46563,
          123,
          2872,
          6841,
          5216,
          743,
          3202,
          37,
          32891,
          348,
          1506,
          21437,
          163415,
          272134,
          61,
          498,
          73,
          1847,
          686,
          224256,
          564,
          630,
          1490,
          1201,
          504,
          9034,
          601723,
          116155,
          79613,
          7987,
          1312922,
          718,
          1680,
          192805,
          286,
          95,
          190178,
          1126,
          673342,
          14742,
          71335,
          753116,
          341,
          218,
          1241364,
          663,
          5577,
          94325,
          673342,
          163415,
          5719,
          1684,
          1517,
          1645,
          324,
          2504700,
          302,
          722,
          2290,
          3066,
          165556,
          743,
          2208,
          59744,
          5791,
          743,
          899,
          464,
          9051,
          1689,
          1252,
          3223,
          222,
          47249,
          313,
          1523,
          194500,
          23,
          7297,
          828,
          466,
          1306,
          6018,
          1261,
          172817,
          725,
          1858,
          647,
          328,
          695,
          1831,
          34882,
          566,
          1595797,
          163415,
          4354,
          307,
          642,
          467,
          19090,
          92337,
          88735,
          217,
          258,
          67858,
          4575,
          526,
          42817,
          581,
          76383,
          28425,
          36438,
          1126,
          760,
          134056,
          397,
          26551,
          601723,
          1645,
          1443,
          2644,
          15426,
          21902,
          1261,
          737,
          239,
          51427,
          970,
          30770,
          31394,
          2121,
          116001,
          2304,
          1789,
          372,
          92985,
          4720,
          19685,
          277,
          1523,
          372,
          3032,
          6951,
          6469,
          824,
          156391,
          7430,
          1526206,
          105549,
          3495,
          1186,
          1923,
          149,
          470,
          4090,
          5778,
          14228,
          1645,
          26551,
          4542,
          2368,
          725,
          79008,
          215,
          602,
          46563,
          1201,
          6018,
          2872,
          145,
          310,
          3451,
          910148,
          878,
          9051,
          267,
          3776,
          14742,
          145,
          1446,
          687276,
          128715,
          1675,
          1762,
          3395,
          753116,
          2135,
          13602,
          35371,
          4542,
          17867,
          151815,
          3833,
          1563,
          105549,
          378909,
          673342,
          92608,
          5903,
          761,
          378909,
          237282,
          237282,
          811,
          22191,
          606,
          1532,
          1080,
          1523,
          824,
          105549,
          1841,
          7430,
          333497,
          320420,
          2317,
          6006,
          1831,
          3487,
          376,
          532,
          6460,
          3451,
          1302,
          95035,
          5621,
          795,
          467,
          1312,
          50489,
          1850,
          653,
          134056,
          540,
          718,
          1019,
          21635,
          798,
          76383,
          470,
          95015,
          1312,
          291,
          118,
          1302,
          71463,
          606,
          601723,
          471,
          133,
          238602,
          186140,
          6508,
          641349,
          2872,
          18459,
          151785,
          3833,
          11432,
          46,
          302,
          7163,
          5621,
          20478,
          1725,
          1383,
          5457,
          4172,
          1850,
          832,
          757530,
          823,
          9815,
          45100,
          192805,
          151815,
          139,
          22930,
          7646,
          248,
          1139,
          5778,
          1766,
          270712,
          4533,
          1725,
          214703,
          222,
          13422,
          6629,
          299480,
          4172,
          67082,
          413574,
          1680,
          757530,
          171170,
          2906700,
          151022,
          2328,
          397,
          1383,
          1131,
          2258,
          47772,
          687276,
          13835,
          3279,
          177,
          27971,
          1565,
          4575,
          589,
          54767,
          5196,
          166081,
          2206,
          645,
          1760,
          1526206,
          1131,
          5548,
          6713,
          1645,
          48194,
          419,
          1190,
          1966,
          8333,
          308,
          1453,
          1120,
          134056,
          475,
          269,
          741,
          107941,
          1102,
          3862,
          71463,
          206,
          321,
          910148,
          3688,
          1306,
          343,
          1382480,
          6284,
          163415,
          73,
          71485,
          606,
          8269,
          6841,
          349,
          229,
          4508,
          241,
          3255,
          50835,
          92985,
          1595797,
          725,
          1022298,
          1574,
          1363,
          9496,
          178,
          2307,
          100,
          75830,
          19685,
          46,
          34496,
          1810,
          765,
          71335,
          7646,
          365,
          718,
          4074,
          107941,
          190178,
          190249,
          34153,
          190,
          1523,
          760,
          2258,
          2036,
          1925,
          733,
          49,
          1563,
          83,
          87124,
          337,
          94014,
          16183,
          5621,
          1689,
          471,
          1382480,
          128715,
          370,
          128715,
          2566,
          470,
          3807,
          10076,
          74,
          172817,
          94325,
          242,
          276002,
          4664,
          2304,
          475,
          5875,
          1131,
          863,
          21125,
          205,
          914,
          5548,
          1745,
          2054,
          6951,
          71463,
          14075,
          94014,
          397,
          99,
          324,
          3458,
          828,
          241,
          272,
          1412,
          413574,
          50489,
          516,
          34882,
          1490,
          1490,
          42619,
          151022,
          1617,
          1195,
          1443,
          4575,
          242,
          673342,
          3285,
          71463,
          1213,
          6581,
          248,
          67082,
          123373,
          2274,
          2304,
          9772,
          899,
          341,
          328,
          33804,
          51,
          4471,
          477,
          94014,
          427,
          53,
          74,
          254282,
          86954,
          341043,
          9506,
          2644,
          5548,
          1443,
          14228,
          4993,
          158701,
          5903,
          9587,
          601723,
          1412,
          776,
          63,
          741,
          4198,
          413574,
          291,
          1423,
          798,
          177,
          965,
          1841,
          26551,
          5950,
          223,
          269,
          595,
          35439,
          1504,
          18128,
          1263321,
          722,
          2202,
          9815,
          1745,
          648,
          686,
          732,
          1312922,
          50835,
          213,
          59744,
          2807,
          3862,
          276896,
          2290,
          1443,
          95,
          21437,
          5895,
          92043,
          1019,
          565,
          7155,
          5196,
          1102,
          1749,
          2258,
          2135,
          828,
          579,
          579,
          1228,
          1089,
          9679,
          4161,
          1850,
          328,
          260,
          3202,
          276896,
          2317,
          24645,
          123373,
          3224,
          24840,
          84106,
          635,
          1563,
          149,
          6120,
          50835,
          478,
          463,
          7646,
          1360,
          151815,
          464,
          50489,
          471,
          633,
          647,
          686,
          3085,
          1288,
          111,
          9772,
          9034,
          1595797,
          241,
          134056,
          2274,
          85,
          782,
          20478,
          450,
          3862,
          248858,
          5341,
          2456,
          606,
          260,
          817312,
          450,
          686,
          7646,
          291,
          18128,
          2092,
          922,
          106,
          5760,
          276,
          6951,
          1804,
          1271,
          18408,
          237282,
          1810,
          32891,
          18408,
          782,
          222785,
          1186,
          568,
          1383,
          50835,
          6703,
          60,
          321490,
          1412,
          4573,
          75830,
          277,
          31394,
          18128,
          2807,
          2607,
          27971,
          2526,
          8874,
          6025,
          136895,
          1312,
          1645,
          1770,
          78968,
          217,
          2872,
          5791,
          43,
          248858,
          673342,
          128715,
          6951,
          43,
          8097,
          5161,
          1631,
          214518,
          186140,
          277,
          2395,
          525713,
          47772,
          320420,
          725,
          1312,
          32891,
          4653,
          504,
          242,
          1383,
          4074,
          1241364,
          3430,
          1577385,
          19054,
          192,
          229,
          158701,
          50489,
          1595797,
          276002,
          36438,
          2435,
          10076,
          337,
          165,
          86954,
          1274,
          1126,
          3862,
          124967,
          718,
          190,
          2906700,
          823,
          31394,
          198,
          307,
          276896,
          18128,
          2807,
          95,
          28278,
          1312922,
          1078,
          144160,
          111,
          13602,
          2263,
          1312,
          606,
          3224,
          1804,
          1312922,
          736284,
          2395,
          526,
          3104,
          1480,
          136,
          116001,
          149,
          1970,
          2607,
          4424,
          136,
          207,
          626,
          34882,
          2471,
          140,
          214703,
          1078,
          5895,
          741,
          184,
          647,
          519,
          2872,
          2089,
          198,
          895,
          4653,
          3495,
          43102,
          346,
          276896,
          178,
          76,
          1645,
          3224,
          1930,
          242,
          270712,
          471,
          3119,
          743,
          2303,
          258,
          11751,
          4161,
          192,
          145,
          427,
          33804,
          21902,
          1089,
          229,
          116155,
          1334,
          190,
          123,
          9587,
          31515,
          124967,
          198,
          1102,
          291,
          2054,
          5901,
          158701,
          878,
          21902,
          5341,
          1383,
          36784,
          1679,
          718,
          75830,
          687276,
          1383,
          2054,
          1075,
          5895,
          31515,
          686,
          3104,
          8830,
          823,
          134056,
          276896,
          1643,
          69793,
          12349,
          50489,
          13061,
          3451,
          95015,
          1725,
          4575,
          695,
          10076,
          76,
          4090,
          1140,
          302,
          743,
          4074,
          30770,
          899,
          20478,
          85,
          9594,
          5438,
          498,
          2092,
          275,
          88735,
          965,
          4090,
          71463,
          11432,
          493,
          3833,
          1745,
          795,
          1324,
          307,
          2870,
          5726,
          3402,
          4575,
          910148,
          99,
          99,
          409656,
          92294,
          1533,
          50835,
          11256,
          7155,
          1312922,
          1241364,
          343,
          6841,
          3255,
          27829,
          888,
          21134,
          85,
          1190,
          1078,
          1725,
          1645,
          1472,
          224256,
          1966,
          824,
          34496,
          233717,
          54185,
          75830,
          471,
          123,
          1078,
          2872,
          276,
          186140,
          832,
          110,
          2092,
          6120,
          35371,
          973849,
          67082,
          3451,
          3994,
          710,
          1850,
          3833,
          17867,
          8007,
          7646,
          7155,
          3833,
          5760,
          1766,
          1512,
          5791,
          6951,
          190,
          2607,
          825,
          6951,
          1770,
          4913,
          46,
          61,
          804,
          14742,
          16183,
          5512,
          9165,
          2036,
          1766,
          16305,
          20478,
          2501,
          3862,
          5216,
          1075,
          242,
          215,
          6841,
          516,
          55581,
          4005,
          973849,
          10076,
          741,
          137,
          52,
          2916,
          1228,
          4845,
          1504,
          9512,
          42619,
          145,
          106,
          899,
          397,
          129,
          1661,
          1078,
          337,
          16305,
          450,
          571,
          158701,
          313,
          106,
          498,
          7646,
          313,
          3279,
          190178,
          513,
          142,
          32891,
          899,
          5457,
          1089,
          863,
          10295,
          137,
          1334,
          4290,
          6006,
          798,
          123,
          1443,
          77,
          4172,
          254,
          28425,
          25459,
          595,
          42817,
          5989,
          258,
          466,
          3279,
          4354,
          139,
          2457,
          31515,
          35705,
          178,
          32891,
          2274,
          1617,
          1643,
          6951,
          1493,
          1263321,
          2092,
          4367,
          3699,
          1514,
          413574,
          233717,
          1523,
          71463,
          3807,
          1789,
          606,
          4512,
          31515,
          5507,
          5621,
          564,
          528,
          19685,
          27971,
          19685,
          571,
          105549,
          1302,
          54287,
          4542,
          2263,
          239,
          60,
          3430,
          177,
          71485,
          4542,
          25459,
          1909,
          2661,
          8007,
          128715,
          1656,
          47249,
          2408,
          1312922,
          3223,
          10076,
          337,
          178,
          198,
          771,
          1271,
          2691,
          35299,
          46,
          1022298,
          2906700,
          2036,
          566,
          1302,
          647,
          3430,
          3202,
          1078,
          238602,
          639,
          224256,
          46,
          95015,
          6629,
          579,
          59705,
          1443,
          632,
          337,
          276896,
          341,
          4720,
          1979,
          2518,
          151815,
          1089,
          217,
          5895,
          46944,
          55345,
          5161,
          28739,
          498,
          92106,
          2383912,
          10717,
          642,
          3343,
          198,
          341,
          18408,
          1228,
          518429,
          275,
          3430,
          100,
          1360,
          172817,
          192805,
          1383,
          841711,
          2661,
          595,
          673342,
          214518,
          149,
          3776,
          71463,
          1178,
          10295,
          2258,
          725,
          2121,
          3684,
          2368,
          3104,
          349,
          233060,
          1684,
          7297,
          85,
          214703,
          3684,
          493,
          1745,
          30770,
          3688,
          4845,
          31394,
          186140,
          343,
          139,
          99,
          1126,
          59705,
          910148,
          194500,
          5760,
          192,
          5666,
          589,
          63,
          93193,
          530,
          9772,
          498,
          2906700,
          502,
          4056,
          532,
          1302,
          2870,
          33804,
          1131,
          1312922,
          2807,
          31394,
          2856,
          571,
          1532,
          10256,
          895,
          2457,
          1970,
          365,
          647,
          223,
          46563,
          50835,
          4533,
          4575,
          2644,
          5848,
          3343,
          190249,
          3807,
          176,
          4575,
          241,
          633,
          134056,
          1595797,
          5577,
          5875,
          136,
          467,
          391389,
          4664,
          35439,
          1480,
          571,
          1577385,
          7646,
          3085,
          190178,
          471,
          3684,
          22305,
          32891,
          6120,
          888,
          276002,
          6469,
          722,
          123,
          18128,
          1766,
          3684,
          753116,
          217,
          895,
          2872,
          2872,
          79008,
          341043,
          1645,
          3684,
          248,
          3805,
          519,
          10717,
          92608,
          754,
          5161,
          1563,
          5648,
          1679,
          1526206,
          489,
          1461,
          95,
          6120,
          1446,
          19054,
          9506,
          969,
          630,
          1019,
          276,
          341043,
          608,
          795,
          16183,
          3451,
          177,
          10076,
          922,
          3395,
          3862,
          242,
          4895,
          260,
          177,
          310,
          11253,
          540,
          33917,
          8007,
          92608,
          24645,
          260,
          178,
          2456,
          33917,
          218,
          1606,
          736284,
          43102,
          12335,
          302,
          15647,
          427,
          341043,
          18459,
          479994,
          5619,
          520,
          3495,
          864,
          917,
          2836,
          123,
          454,
          1925,
          1645,
          2456,
          54185,
          4198,
          30770,
          5875,
          166081,
          391389,
          2290,
          520,
          633,
          7268,
          55581,
          6460,
          969,
          316665,
          105549,
          238602,
          3096,
          1577385,
          21134,
          320,
          1089,
          5662,
          2263,
          4575,
          128,
          471,
          302,
          518429,
          564,
          31970,
          18760,
          1745,
          186140,
          136,
          9815,
          168,
          743,
          341,
          1166,
          647,
          717255,
          28739,
          37,
          1478,
          5875,
          4845,
          2368,
          641349,
          136,
          804,
          272,
          67858,
          725,
          1126,
          885,
          74,
          22305,
          46563,
          4090,
          885,
          237282,
          194500,
          302,
          104396,
          68211,
          7692,
          771,
          276002,
          1810,
          5950,
          467,
          67082,
          343,
          55345,
          1166,
          2906700,
          9815,
          5619,
          1423,
          13717,
          111,
          973849,
          95,
          571,
          2523,
          94325,
          1684,
          365,
          6951,
          571,
          178,
          1288,
          139650,
          20328,
          817312,
          135332,
          581,
          3688,
          26551,
          54287,
          163415,
          20328,
          61,
          1089,
          198,
          579,
          532,
          378909,
          673342,
          7163,
          1383,
          1791,
          653,
          1271,
          2379,
          215,
          5161,
          1382480,
          71485,
          43,
          1202,
          4542,
          1617,
          760,
          1789,
          1190,
          2661,
          134056,
          92985,
          4159,
          68211,
          1063,
          1831,
          343,
          4056,
          1453,
          269,
          3343,
          910148,
          20328,
          4090,
          122111,
          6951,
          43,
          217,
          307,
          1504,
          343,
          47772,
          1725,
          10076,
          1190,
          241,
          601723,
          4575,
          149,
          59744,
          34882,
          7163,
          2644,
          5577,
          1228,
          914,
          21902,
          12486,
          320420,
          1789,
          177,
          20328,
          4049,
          16163,
          5666,
          13835,
          18128,
          1766,
          1126,
          15647,
          99,
          1643,
          493806,
          467,
          2148,
          1178,
          6120,
          341,
          1523,
          128,
          1312,
          1988,
          166081,
          489,
          47,
          1831,
          19054,
          718,
          12747,
          467,
          331,
          128,
          513,
          277,
          4367,
          26120,
          1446,
          1617,
          1841,
          91,
          20478,
          145,
          1302,
          241,
          60,
          224256,
          372,
          308,
          1446,
          804,
          6841,
          105549,
          14871,
          695,
          630,
          260,
          165556,
          7268,
          1252,
          1675,
          1507,
          42619,
          6508,
          341,
          1412,
          59744,
          1312922,
          9034,
          172817,
          35371,
          1847,
          478,
          409656,
          741,
          51,
          3430,
          107941,
          5507,
          198,
          2526,
          1909,
          338,
          1075,
          1583,
          34496,
          673342,
          2078,
          1595797,
          136,
          1666,
          198,
          1645,
          1442,
          1312,
          1423,
          489,
          85,
          30770,
          8007,
          54767,
          19054,
          46944,
          302,
          20478,
          71335,
          1139,
          2870,
          67082,
          258,
          4913,
          230,
          18408,
          565,
          5791,
          99,
          1789,
          4049,
          828,
          3279,
          14228,
          7155,
          9784,
          76383,
          4653,
          1725,
          16183,
          519,
          3066,
          239,
          270712,
          166081,
          1617,
          878,
          128715,
          344,
          222785,
          7420,
          1923,
          2054,
          178,
          540,
          3279,
          1075,
          128,
          5196,
          30770,
          3285,
          28739,
          78968,
          5341,
          21902,
          1595797,
          478,
          2368,
          84106,
          1263321,
          124967,
          4015,
          3766,
          1089,
          1019,
          3766,
          73,
          6120,
          8830,
          467,
          737,
          2121,
          54767,
          1565,
          237282,
          34496,
          52126,
          28739,
          277,
          35371,
          2054,
          2870,
          2607,
          172817,
          1512,
          75830,
          241,
          1645,
          1228,
          53,
          1577385,
          4074,
          630,
          7646,
          38912,
          218,
          6581,
          2304,
          391389,
          2872,
          1970,
          718,
          2786,
          3096,
          1089,
          1302,
          27971,
          71485,
          642,
          1563,
          7692,
          9815,
          186140,
          761,
          1847,
          5354,
          932,
          2906700,
          2872,
          1643,
          61,
          673342,
          7646,
          19685,
          2435,
          2368,
          895,
          260,
          4680,
          87124,
          2263,
          5196,
          5726,
          248858,
          2328,
          1506,
          2135,
          5507,
          2456,
          9506,
          136895,
          3699,
          46563,
          9679,
          525713,
          18182,
          7163,
          4575,
          4720,
          1075,
          5778,
          5657,
          1360,
          3224,
          95035,
          1368,
          4913,
          828,
          1102,
          2408,
          493,
          134056,
          341043,
          493,
          910148,
          2971,
          104,
          92608,
          9034,
          6006,
          313,
          477,
          92294,
          277,
          6434,
          5507,
          3032,
          2523,
          5621,
          21134,
          888,
          1523,
          753116,
          12335,
          50835,
          310,
          4589,
          579,
          2456,
          888,
          4575,
          2328,
          321,
          878,
          320420,
          2906700,
          6460,
          1131,
          116155,
          2307,
          2304,
          532,
          1324,
          1461,
          258,
          258,
          459921,
          5875,
          1923,
          21902,
          184,
          1261,
          5950,
          1526206,
          888,
          9594,
          513,
          4138,
          341043,
          3487,
          4729,
          13422,
          1186,
          237282,
          2317,
          516,
          1420,
          136,
          1690,
          4090,
          1241364,
          16183,
          1131,
          725,
          1493,
          1139,
          12486,
          759,
          3224,
          36784,
          1791,
          19090,
          1979,
          1656,
          23805,
          3730,
          149,
          2395,
          899,
          825,
          4878,
          2906700,
          4074,
          1261,
          1988,
          76,
          1966,
          2872,
          2971,
          743,
          899,
          5548,
          28739,
          4729,
          18128,
          722,
          11751,
          467,
          178,
          233717,
          88735,
          30770,
          1725,
          5196,
          11256,
          1446,
          836,
          51,
          9993,
          2457,
          1202,
          14783,
          376,
          1261,
          31394,
          43,
          5548,
          93193,
          687276,
          52126,
          1228,
          471,
          647,
          230,
          4090,
          526,
          110,
          320420,
          564,
          6581,
          1263321,
          3202,
          168,
          1725,
          4845,
          1643,
          2526,
          13717,
          151815,
          2566,
          4664,
          6120,
          24840,
          4726,
          7987,
          3996,
          3289,
          19685,
          49,
          139650,
          2368,
          34882,
          1735,
          8269,
          233717,
          6508,
          3451,
          31394,
          4090,
          7692,
          1261,
          5161,
          1089,
          1789,
          105638,
          4653,
          79613,
          23045,
          144160,
          922,
          7987,
          2368,
          27020,
          6120,
          1252,
          2317,
          6006,
          247,
          4090,
          1446,
          128,
          35439,
          33917,
          222,
          4726,
          140,
          1749,
          836,
          35439,
          343,
          564,
          222785,
          17867,
          1201,
          93193,
          566,
          310,
          2368,
          732,
          207,
          9993,
          15269,
          276002,
          2607,
          4081,
          6508,
          540,
          156391,
          914,
          753116,
          217,
          4589,
          823,
          324,
          151815,
          1426,
          1595797,
          27971,
          77,
          34882,
          828,
          7646,
          1080,
          2870,
          630,
          84106,
          2379,
          61,
          30770,
          307,
          21134,
          824,
          76383,
          1324,
          3224,
          4512,
          23,
          595,
          1645,
          12335,
          965,
          92106,
          1680,
          4354,
          4074,
          13422,
          165556,
          7297,
          92043,
          470,
          525713,
          1022298,
          3032,
          118,
          123,
          463,
          1512,
          3104,
          24536,
          1526206,
          5161,
          1274,
          267,
          166081,
          105638,
          14228,
          1131,
          2148,
          10256,
          151022,
          530,
          5895,
          1661,
          1966,
          9565,
          540,
          35439,
          67082,
          3451,
          639,
          349,
          4056,
          525713,
          27971,
          16163,
          254282,
          158701,
          91,
          4056,
          27971,
          190178,
          1412,
          47,
          341,
          23045,
          55345,
          1132,
          2097,
          3289,
          70,
          19054,
          320,
          48194,
          4729,
          144160,
          1666,
          753116,
          1288,
          722,
          626,
          163415,
          260,
          5548,
          1143,
          565,
          217,
          21134,
          4090,
          1146,
          277,
          54767,
          1288,
          381459,
          4198,
          3451,
          307,
          1228,
          128715,
          976,
          111,
          370,
          4508,
          241,
          14742,
          123373,
          34882,
          743,
          71335,
          15426,
          1241364,
          104396,
          263,
          1595797,
          2872,
          21125,
          48194,
          824,
          1656,
          2135,
          186140,
          1654,
          9815,
          2290,
          2223,
          1271,
          1228,
          230,
          3684,
          760,
          87124,
          3402,
          1923,
          71485,
          489,
          1228,
          4993,
          378909,
          248858,
          459921,
          4542,
          1645,
          640470,
          878,
          5901,
          28739,
          1132,
          530,
          271,
          564,
          2368,
          224256,
          828,
          76383,
          324,
          1126,
          7430,
          248,
          4512,
          1897,
          1063,
          237282,
          23045,
          1312,
          2376,
          928,
          2036,
          2644,
          207,
          269,
          5895,
          2368,
          61,
          76,
          564,
          71463,
          233060,
          5875,
          4074,
          1643,
          718,
          1810,
          823,
          34496,
          5903,
          1442,
          917,
          4172,
          8333,
          5908,
          540,
          1126,
          106,
          477,
          579,
          105549,
          1089,
          14871,
          4895,
          470,
          1700,
          910148,
          477,
          589,
          28425,
          169,
          248858,
          68211,
          3263,
          36438,
          1749,
          828,
          26551,
          571,
          743,
          545147,
          1461,
          885,
          151815,
          970,
          4090,
          53,
          128354,
          30770,
          61,
          1080,
          743,
          6951,
          165556,
          28425,
          1493,
          771,
          34882,
          3487,
          2906700,
          22305,
          3032,
          254282,
          626,
          107941,
          320420,
          4542,
          13835,
          7297,
          129,
          42384,
          5726,
          509,
          4653,
          518429,
          85,
          4354,
          5908,
          4726,
          276,
          5791,
          163415,
          4290,
          8874,
          224256,
          3688,
          254282,
          1190,
          1383,
          165,
          75830,
          1645,
          151022,
          910148,
          1789,
          167,
          237282,
          863,
          493806,
          1178,
          914,
          54287,
          1423,
          20328,
          3223,
          71463,
          1789,
          1312922,
          107941,
          1312922,
          198,
          2470,
          230,
          321,
          59705,
          19090,
          640470,
          564,
          1595797,
          46563,
          241,
          217,
          381459,
          2870,
          973849,
          129,
          2263,
          85,
          653,
          190249,
          71485,
          2526,
          241,
          46944,
          590,
          1139,
          1302,
          493,
          24645,
          186140,
          192,
          663,
          606,
          9587,
          341043,
          1595797,
          47772,
          6018,
          1988,
          1186,
          1196,
          217,
          520,
          6841,
          99,
          828,
          4575,
          504,
          804,
          3430,
          134056,
          26551,
          4726,
          1532,
          151022,
          645,
          54287,
          1760,
          6629,
          1831,
          104396,
          1847,
          2303,
          277,
          1850,
          409656,
          5451,
          276002,
          7646,
          863,
          276002,
          5161,
          760,
          6284,
          4074,
          7155,
          3684,
          271,
          5354,
          917,
          145,
          885,
          1453,
          2317,
          67082,
          1923,
          1241364,
          1274,
          341043,
          1847,
          741,
          92106,
          276,
          1850,
          376,
          1789,
          6951,
          237282,
          2408,
          4354,
          12335,
          123,
          1080,
          145,
          635,
          15269,
          804,
          7987,
          3451,
          111,
          192,
          2906700,
          139,
          123373,
          149,
          124967,
          2807,
          269,
          16183,
          198,
          1202,
          34882,
          761,
          1478,
          836,
          8874,
          1241364,
          215,
          3228,
          19090,
          172817,
          1700,
          349,
          271,
          260,
          7692,
          5548,
          1446,
          9512,
          316665,
          443,
          341,
          5354,
          12335,
          7420,
          1946,
          71463,
          104,
          1847,
          1241364,
          350,
          836,
          9506,
          1523,
          9815,
          242,
          77,
          1443,
          551,
          626,
          805,
          10256,
          589,
          10256,
          1293,
          1523,
          647,
          1075,
          3279,
          595,
          4913,
          255,
          1943,
          811,
          7420,
          1970,
          1770,
          205,
          7987,
          1606,
          911,
          1143,
          1312922,
          6508,
          606,
          516,
          59744,
          4056,
          19054,
          78968,
          34153,
          93193,
          310,
          1293,
          601723,
          1132,
          372,
          7987,
          4512,
          71463,
          1762,
          224256,
          6120,
          46,
          61,
          970,
          134056,
          54185,
          2501,
          128,
          16183,
          601723,
          391389,
          34496,
          21134,
          349,
          1201,
          9772,
          163415,
          205,
          1645,
          1228,
          7297,
          3688,
          2148,
          4993,
          450,
          3085,
          213,
          2870,
          198,
          47249,
          107941,
          1766,
          864,
          3395,
          217,
          965,
          522,
          71485,
          397,
          502,
          54287,
          1063,
          3279,
          6120,
          3508,
          459921,
          470,
          1274,
          15647,
          1146,
          489,
          77,
          5619,
          165556,
          9784,
          1139,
          4090,
          1195,
          782,
          3395,
          165556,
          348,
          190178,
          71485,
          192,
          3279,
          118,
          10295,
          27020,
          922,
          6951,
          50489,
          2089,
          1324,
          165556,
          337,
          753116,
          673342,
          365,
          632,
          509,
          2526,
          237282,
          1791,
          20328,
          22305,
          601723,
          213,
          540,
          1420,
          532,
          4090,
          828,
          267,
          1312922,
          1892,
          427,
          269,
          885,
          144160,
          4056,
          3202,
          3776,
          5989,
          532,
          105549,
          5901,
          595,
          238602,
          321,
          743,
          1443,
          595,
          895,
          798,
          5662,
          528,
          190,
          124967,
          4533,
          641349,
          817312,
          5507,
          1563,
          224256,
          9679,
          46563,
          11250,
          2504700,
          1563,
          10076,
          8830,
          1087,
          470,
          1288,
          95035,
          5657,
          275,
          493806,
          190,
          94014,
          213,
          471,
          1654,
          2786,
          45303,
          11432,
          136,
          163415,
          551,
          5161,
          5548,
          192805,
          163415,
          30770,
          3876,
          276002,
          4677,
          71463,
          1749,
          123,
          2304,
          2872,
          92337,
          313,
          118,
          686,
          2408,
          68211,
          5760,
          3996,
          237282,
          1213,
          4542,
          1923,
          1923,
          754,
          21902,
          2060,
          9051,
          12486,
          498,
          1140,
          3862,
          2376,
          277,
          4729,
          13717,
          376,
          1749,
          885,
          4424,
          22305,
          1679,
          1970,
          823,
          136,
          30770,
          7297,
          2906700,
          1679,
          443,
          1131,
          21125,
          258,
          45303,
          84861,
          85,
          378909,
          84106,
          307,
          3202,
          18128,
          19685,
          206,
          1312922,
          5950,
          1725,
          1196,
          19408,
          47249,
          1288,
          2121,
          1178,
          36438,
          302,
          5989,
          4664,
          1472,
          2661,
          3285,
          864,
          5760,
          4664,
          631,
          270712,
          732,
          471,
          10717,
          4726,
          7987,
          686,
          722,
          1512,
          140,
          111,
          45303,
          13717,
          4005,
          564,
          47249,
          1363,
          276896,
          9496,
          1925,
          136,
          3508,
          27971,
          192,
          1532,
          165,
          107941,
          471,
          46944,
          3032,
          1412,
          4533,
          2395,
          760,
          12335,
          973849,
          8333,
          741,
          27020,
          1075,
          136,
          238602,
          1263321,
          67082,
          34153,
          338,
          139,
          111,
          2836,
          10295,
          7163,
          370,
          571,
          725,
          218,
          653,
          14871,
          863,
          3263,
          1252,
          3032,
          18760,
          530,
          4056,
          42619,
          381459,
          111,
          177,
          513,
          2471,
          61,
          370,
          328,
          718,
          1228,
          5548,
          186140,
          1970,
          248858,
          910148,
          2376,
          1526206,
          4056,
          1213,
          680,
          37,
          168,
          1512,
          341043,
          2906700,
          2457,
          733,
          92985,
          532,
          111,
          1140,
          765,
          365,
          1241364,
          320420,
          757530,
          2223,
          140,
          1526206,
          2401,
          3805,
          46,
          229,
          4895,
          1804,
          1178,
          321490,
          42817,
          2443,
          5577,
          725,
          116155,
          124967,
          137067,
          2872,
          1102,
          2092,
          214703,
          1442,
          2872,
          804,
          53,
          1789,
          1196,
          2148,
          760,
          94325,
          4993,
          76383,
          9496,
          513,
          15426,
          302,
          7297,
          2872,
          6469,
          149,
          5621,
          5903,
          477,
          2395,
          606,
          471,
          2870,
          166081,
          198,
          338,
          92106,
          1132,
          233717,
          3487,
          1909,
          1126,
          409656,
          343,
          1526206,
          4603,
          1523,
          177,
          1563,
          1643,
          139,
          5760,
          2401,
          74,
          899,
          737,
          67082,
          3395,
          190178,
          198,
          15269,
          639,
          2807,
          1166,
          242,
          4290,
          149,
          1196,
          3766,
          215,
          4845,
          48194,
          7155,
          321,
          33804,
          2501,
          736284,
          276002,
          1312,
          467,
          48194,
          663,
          110,
          344,
          129,
          28278,
          46,
          2872,
          571,
          1523,
          27971,
          922,
          1760,
          626,
          198,
          4680,
          324,
          237282,
          798,
          207410,
          1617,
          140,
          1645,
          2307,
          895,
          836,
          2328,
          2395,
          9512,
          4198,
          645,
          23727,
          4056,
          1146,
          1146,
          6508,
          5950,
          238602,
          526,
          630,
          321490,
          1306,
          3766,
          192805,
          94014,
          139,
          47249,
          663,
          4895,
          639,
          277,
          528,
          5648,
          1075,
          27971,
          24536,
          718,
          932,
          1178,
          10076,
          606,
          2435,
          828,
          95,
          191096,
          128715,
          5657,
          1766,
          6006,
          2523,
          863,
          5341,
          19408,
          1186,
          504,
          381459,
          307,
          601723,
          895,
          190,
          471,
          258,
          601723,
          54287,
          467,
          21134,
          824,
          381459,
          28278,
          4049,
          743,
          5875,
          295,
          76383,
          10256,
          214703,
          15426,
          7646,
          1760,
          7268,
          218,
          757530,
          1680,
          972,
          54767,
          2644,
          25459,
          71335,
          878,
          337,
          964,
          269,
          673342,
          34496,
          165556,
          1383,
          1426,
          6713,
          34496,
          7155,
          5908,
          54767,
          128715,
          9815,
          568,
          222785,
          31394,
          143,
          13717,
          1970,
          172817,
          46,
          13983,
          4729,
          3776,
          817312,
          5875,
          1700,
          165,
          11751,
          4573,
          540,
          92043,
          504,
          631,
          3684,
          5760,
          4575,
          3684,
          46,
          520,
          5438,
          258,
          18128,
          498,
          413574,
          1675,
          3688,
          509,
          391389,
          4533,
          4542,
          1412,
          2258,
          103927,
          3688,
          85,
          13422,
          2504700,
          2523,
          2383912,
          3776,
          1414,
          106,
          1140,
          18408,
          2691,
          1577385,
          5848,
          973849,
          1263321,
          47772,
          5719,
          5548,
          71463,
          320420,
          2395,
          85,
          321,
          172817,
          885,
          1383,
          78968,
          42619,
          413574,
          328,
          1831,
          95,
          1700,
          8019,
          1512,
          885,
          302,
          641349,
          218,
          190249,
          4090,
          1383,
          2504700,
          105638,
          37,
          863,
          3104,
          628,
          46944,
          1165,
          1453,
          276002,
          96942,
          24536,
          1512,
          224256,
          23727,
          1178,
          1766,
          92608,
          2328,
          4074,
          532,
          3776,
          1909,
          321,
          79008,
          509,
          3224,
          1645,
          6508,
          241,
          272,
          3876,
          5666,
          54287,
          3255,
          5791,
          811,
          338,
          27020,
          14871,
          172817,
          36784,
          1791,
          454,
          760,
          581,
          87124,
          1423,
          214703,
          1946,
          13602,
          190178,
          1725,
          470,
          1274,
          1988,
          1383,
          1847,
          104,
          166081,
          165,
          1228,
          2304,
          10076,
          4354,
          145,
          765,
          5908,
          836,
          124967,
          2856,
          765,
          409656,
          105549,
          910148,
          6469,
          17867,
          84106,
          1382480,
          49,
          725,
          126,
          1725,
          34882,
          84106,
          105638,
          105549,
          899,
          526,
          4653,
          1202,
          3495,
          5577,
          267,
          71335,
          3279,
          2135,
          4512,
          122111,
          1383,
          2906700,
          126,
          134056,
          1368,
          5211,
          6469,
          13835,
          2135,
          1241364,
          5875,
          2518,
          5354,
          639,
          4993,
          1274,
          2054,
          7987,
          229,
          42619,
          1766,
          749635,
          2856,
          18128,
          344,
          1758,
          4575,
          275,
          1412,
          1201,
          239,
          12335,
          601723,
          475,
          128,
          34153,
          47249,
          4161,
          47772,
          248858,
          2523,
          242,
          54287,
          16183,
          4354,
          4049,
          504,
          54287,
          1831,
          269,
          2916,
          5211,
          450,
          3458,
          2856,
          932,
          1760,
          55581,
          5903,
          1271,
          2471,
          18459,
          346,
          69,
          5548,
          35371,
          36438,
          4474,
          192,
          4074,
          2691,
          922,
          27971,
          4161,
          140,
          8333,
          92294,
          1700,
          47249,
          828,
          85,
          3066,
          2872,
          1493,
          51427,
          722,
          71463,
          878,
          140,
          1631,
          2317,
          54287,
          6469,
          1089,
          15426,
          722,
          1661,
          1228,
          190178,
          86954,
          16163,
          4138,
          276002,
          255,
          1480,
          207410,
          128,
          308,
          267,
          129,
          736284,
          4367,
          271,
          229,
          1446,
          151022,
          888,
          1574,
          71485,
          1363,
          1841,
          9034,
          151785,
          3289,
          1120,
          888,
          2471,
          35299,
          680,
          391389,
          5950,
          1810,
          2607,
          95035,
          895,
          328,
          526,
          73,
          2870,
          1165,
          760,
          140,
          1126,
          1850,
          338,
          2906700,
          94014,
          263,
          632,
          970,
          5657,
          743,
          27020,
          95,
          463,
          2408,
          25459,
          14871,
          5791,
          36438,
          1166,
          530,
          139,
          2906700,
          276002,
          1970,
          9815,
          105638,
          1892,
          9165,
          6469,
          1102,
          1302,
          93193,
          77,
          328,
          20478,
          409656,
          1446,
          20478,
          584,
          151022,
          540,
          2872,
          19090,
          13061,
          626,
          233717,
          1791,
          4354,
          1643,
          7692,
          124967,
          795,
          687276,
          165556,
          344,
          20328,
          2395,
          215,
          137,
          178,
          3263,
          914,
          2368,
          3343,
          75830,
          4172,
          71335,
          450,
          2526,
          1102,
          478,
          1617,
          3684,
          67082,
          31394,
          3862,
          84861,
          124967,
          695,
          136,
          55581,
          18128,
          3202,
          798,
          5512,
          878,
          1426,
          16305,
          10256,
          3487,
          222,
          26551,
          4589,
          1595797,
          532,
          736284,
          1383,
          4593,
          743,
          198,
          6460,
          1766,
          467,
          355,
          632,
          1656,
          47,
          1749,
          275,
          878,
          324,
          443,
          19408,
          21134,
          270712,
          718,
          27020,
          2328,
          76,
          545147,
          355,
          6629,
          1943,
          276896,
          18760,
          606,
          1988,
          118,
          470,
          8512,
          4172,
          153,
          104396,
          237282,
          639,
          922,
          1532,
          687276,
          504,
          144160,
          95035,
          470,
          1363,
          192,
          765,
          606,
          1382480,
          92608,
          759,
          606,
          725,
          134056,
          11256,
          1368,
          112,
          34882,
          695,
          144160,
          5901,
          2523,
          1831,
          4593,
          267,
          516,
          9496,
          525713,
          743,
          128715,
          2368,
          2304,
          28278,
          914,
          320420,
          276002,
          1850,
          92985,
          184,
          1749,
          75830,
          123,
          722,
          9496,
          128354,
          18760,
          2121,
          16183,
          23805,
          123373,
          5848,
          76,
          71485,
          1414,
          68211,
          31394,
          5760,
          47249,
          2872,
          2263,
          5619,
          307,
          92043,
          153,
          6469,
          2786,
          69793,
          2501,
          647,
          1700,
          310,
          736284,
          911,
          42619,
          158701,
          2208,
          46,
          1241364,
          86954,
          149,
          3289,
          760,
          15426,
          5950,
          13602,
          923,
          313,
          344,
          116001,
          765,
          828,
          2135,
          224256,
          3228,
          540,
          2135,
          11751,
          1988,
          73,
          2206,
          134056,
          88735,
          308,
          504,
          2121,
          43102,
          606,
          321490,
          166081,
          718,
          1195,
          2457,
          530,
          184,
          47249,
          1595797,
          1423,
          1791,
          128,
          207,
          18182,
          1628,
          1810,
          15426,
          26551,
          1261,
          1762,
          964,
          2408,
          502,
          3684,
          635,
          123,
          2263,
          348,
          6951,
          50489,
          498,
          1414,
          1675,
          52126,
          1312922,
          320420,
          344,
          1304,
          5927,
          391389,
          6629,
          391389,
          1810,
          111,
          166081,
          2036,
          601723,
          320420,
          43,
          320420,
          498,
          94325,
          413574,
          2870,
          272,
          238602,
          1312,
          198,
          5648,
          551,
          1131,
          1923,
          149,
          27971,
          1423,
          6006,
          1228,
          1523,
          84106,
          1075,
          167,
          733,
          269,
          341043,
          95,
          69793,
          178,
          1423,
          378909,
          1897,
          922,
          397,
          964,
          687276,
          590,
          1302,
          85,
          277,
          1791,
          1595797,
          493,
          206,
          635,
          1139,
          149,
          163415,
          165556,
          5619,
          166081,
          7646,
          1675,
          5341,
          899,
          1847,
          1312922,
          6469,
          3279,
          2016,
          885,
          3402,
          18408,
          3487,
          493806,
          5989,
          35371,
          1831,
          509,
          49,
          27829,
          5621,
          927396,
          22191,
          5895,
          172817,
          518429,
          4367,
          6006,
          20478,
          1512,
          2906700,
          95035,
          310,
          6006,
          1858,
          7692,
          5875,
          95015,
          313,
          86954,
          718,
          1288,
          3688,
          23045,
          2872,
          519,
          626,
          1146,
          13973,
          156391,
          551,
          1762,
          736284,
          54287,
          190178,
          105638,
          19054,
          67082,
          450,
          19685,
          1595797,
          13835,
          1725,
          4664,
          190,
          525713,
          42384,
          177,
          14871,
          3066,
          3766,
          4993,
          14742,
          93193,
          307,
          328,
          255,
          606,
          229,
          4090,
          48194,
          4845,
          11256,
          5341,
          2036,
          35299,
          18408,
          14742,
          372,
          1923,
          331,
          641349,
          331,
          757530,
          1749,
          1382480,
          18128,
          1019,
          1988,
          1523,
          224256,
          5619,
          509,
          370,
          3684,
          640470,
          8874,
          69,
          1178,
          11751,
          7155,
          2208,
          269,
          626,
          21437,
          1514,
          1312,
          863,
          11751,
          19685,
          16305,
          5760,
          46,
          1186,
          413574,
          4198,
          46563,
          1770,
          14871,
          1263321,
          168,
          3255,
          77,
          743,
          307,
          528,
          969,
          42817,
          520,
          75830,
          194500,
          2518,
          100,
          28425,
          5903,
          399,
          139650,
          760,
          9993,
          832,
          20478,
          475,
          8333,
          2036,
          5760,
          1228,
          43102,
          581,
          3430,
          743,
          965,
          4138,
          4729,
          4993,
          680,
          1532,
          1504,
          737,
          190249,
          1228,
          795,
          299480,
          1512,
          725,
          528,
          932,
          26551,
          477,
          11256,
          378909,
          2290,
          94325,
          242,
          5875,
          3776,
          4603,
          32891,
          28425,
          1080,
          601723,
          71485,
          6006,
          23727,
          760,
          18459,
          532,
          743,
          3066,
          9772,
          128,
          136,
          100,
          9594,
          532,
          35299,
          4573,
          1760,
          6469,
          2208,
          241,
          43,
          87124,
          60,
          14871,
          307,
          1690,
          1126,
          99,
          765,
          1166,
          475,
          6018,
          105549,
          754,
          42384,
          4090,
          1595797,
          1810,
          93193,
          3289,
          493,
          6508,
          1504,
          4542,
          77,
          2304,
          3255,
          378909,
          272,
          1858,
          470,
          237282,
          922,
          369,
          459921,
          20328,
          2691,
          54185,
          760,
          14075,
          2870,
          1810,
          190178,
          254282,
          7565,
          355,
          129,
          673342,
          99,
          1631,
          242,
          158701,
          397,
          824,
          478,
          33917,
          459921,
          3776,
          1453,
          1019,
          1252,
          301,
          9784,
          9772,
          255,
          76,
          21902,
          42619,
          5211,
          218,
          107941,
          128,
          6469,
          1532,
          5657,
          1263321,
          254282,
          9679,
          3684,
          32891,
          15623,
          269,
          1523,
          3451,
          349,
          922,
          15269,
          46,
          263,
          579,
          331,
          653,
          551,
          391389,
          1166,
          12335,
          606,
          34496,
          1970,
          427,
          52126,
          140,
          5577,
          76,
          74,
          1075,
          1312922,
          24536,
          145,
          61,
          932,
          349,
          520,
          84106,
          395,
          493806,
          20478,
          1493,
          606,
          1684,
          2408,
          145,
          14871,
          11253,
          1645,
          276002,
          378909,
          2870,
          530,
          2408,
          45100,
          3487,
          653,
          3699,
          1075,
          338,
          36784,
          673342,
          260,
          16163,
          21902,
          310,
          5548,
          248,
          140,
          4474,
          376,
          571,
          5216,
          1126,
          75830,
          606,
          136,
          27971,
          641,
          922,
          111,
          673342,
          5457,
          471,
          36784,
          100,
          969,
          378909,
          8333,
          1656,
          1571,
          105638,
          267,
          6713,
          21125,
          1745,
          1442,
          95035,
          186140,
          4474,
          136,
          365,
          1595797,
          757530,
          71485,
          4172,
          3263,
          7646,
          3343,
          79613,
          4056,
          606,
          5657,
          759,
          663,
          3224,
          3862,
          1595797,
          13602,
          1892,
          6951,
          4575,
          741,
          1420,
          1126,
          20478,
          1533,
          1228,
          1939,
          1684,
          2401,
          192805,
          365,
          95,
          4512,
          4878,
          673342,
          1666,
          5161,
          158701,
          2566,
          471,
          104,
          828,
          1892,
          761,
          286,
          67858,
          687276,
          333497,
          37,
          1923,
          687276,
          4575,
          1195,
          6713,
          350,
          922,
          4138,
          198,
          736284,
          1293,
          9815,
          2368,
          7163,
          5512,
          77,
          4573,
          35299,
          1426,
          2258,
          3402
         ],
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "is_fraud=1<br>city_pop=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "1",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "1",
         "offsetgroup": "1",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          276002,
          5760,
          343,
          178,
          14783,
          47119,
          218,
          107941,
          11253,
          5451,
          34496,
          172817,
          2971,
          100,
          911,
          1490,
          343,
          1536,
          1261,
          1439,
          2906700,
          391389,
          1506,
          1241364,
          397,
          2456,
          917,
          1019,
          12866,
          1656,
          237282,
          409656,
          214518,
          16305,
          3805,
          635,
          121,
          470,
          606,
          163415,
          134056,
          203571,
          20478,
          710,
          1196,
          2906700,
          337,
          8830,
          23045,
          241,
          7987,
          98816,
          513,
          61,
          584,
          270712,
          2623,
          71485,
          144160,
          237282,
          14267,
          3807,
          12626,
          2206,
          151022,
          9165,
          824,
          471,
          111,
          2566,
          1892,
          2368,
          753116,
          800,
          15269,
          19803,
          92985,
          2457,
          1847,
          1274,
          1078,
          2456,
          2379,
          824,
          1686,
          470,
          1628,
          156391,
          6951,
          165,
          3876,
          6629,
          1063,
          759,
          1645,
          28739,
          95,
          190178,
          641349,
          4424,
          9165,
          45303,
          3255,
          7565,
          805,
          21635,
          26551,
          6120,
          1749,
          151815,
          639,
          710,
          744,
          1304,
          1762,
          4603,
          6006,
          641349,
          2456,
          4474,
          344,
          28739,
          248858,
          4424,
          1925,
          7155,
          663,
          28425,
          116155,
          33804,
          895,
          214518,
          1897,
          16305,
          9679,
          2290,
          828,
          1368,
          1368,
          2906700,
          805,
          409656,
          16163,
          1780,
          1075,
          1979,
          238602,
          2092,
          68211,
          28506,
          136,
          754,
          917,
          4005,
          27829,
          1089,
          2202,
          1536,
          307,
          6063,
          344,
          21635,
          964,
          242803,
          98816,
          532,
          1439,
          18128,
          564,
          181438,
          2089,
          2379,
          1617,
          1943,
          2206,
          601723,
          397,
          1925,
          5666,
          409656,
          7565,
          301,
          1780,
          151815,
          52126,
          343,
          156391,
          1760,
          4729,
          4870,
          139,
          1080,
          765,
          151022,
          4870,
          128354,
          67100,
          47,
          910148,
          13602,
          673342,
          4993,
          3255,
          824,
          732,
          9679,
          633,
          217,
          271,
          7268,
          630,
          5548,
          475,
          804,
          31515,
          22305,
          2379,
          34153,
          230,
          166081,
          28425,
          2258,
          7369,
          19880,
          139,
          313,
          5354,
          222,
          34153,
          1420,
          172817,
          381459,
          1506,
          12747,
          686,
          6951,
          33804,
          3224,
          1565,
          381459,
          49,
          55345,
          2916,
          4653,
          348,
          397,
          341043,
          165556,
          8830,
          168,
          99475,
          1480,
          27971,
          222785,
          409656,
          1643,
          2916,
          2971,
          4198,
          1686,
          291,
          459921,
          2395,
          133,
          2526,
          633,
          736284,
          973849,
          2142,
          27829,
          895,
          602,
          632,
          348,
          92985,
          2644,
          2470,
          1512,
          824,
          584,
          100,
          673342,
          9521,
          73,
          121,
          1143,
          1126,
          128354,
          1760,
          10295,
          2691,
          9051,
          27971,
          15269,
          1760,
          1577385,
          369,
          2317,
          631,
          1442,
          271,
          33917,
          237282,
          7322,
          15647,
          2142,
          8019,
          824,
          1179,
          741,
          91,
          136,
          1102,
          759,
          7987,
          1506,
          255,
          459921,
          2906700,
          272,
          717255,
          532,
          11253,
          239,
          79613,
          53,
          178,
          533,
          1383,
          1666,
          116155,
          2208,
          564,
          76,
          6025,
          584,
          2644,
          222785,
          272,
          344,
          276,
          601723,
          12626,
          73,
          969,
          525713,
          45100,
          911,
          18128,
          2906700,
          795,
          369,
          241,
          1196,
          3876,
          761,
          100,
          7155,
          7155,
          1858,
          2148,
          12349,
          2206,
          502,
          8019,
          34882,
          151022,
          471,
          540,
          47211,
          566,
          1120,
          140,
          1666,
          397,
          79613,
          1075,
          1472,
          3223,
          409656,
          27020,
          123373,
          4575,
          2158,
          10295,
          53,
          11751,
          1202,
          6581,
          2328,
          104,
          5451,
          239,
          42619,
          2036,
          18459,
          7155,
          4354,
          53,
          540,
          129,
          1517,
          33804,
          1686,
          911,
          27020,
          1274,
          18799,
          3223,
          804,
          3223,
          110,
          1304,
          19408,
          190249,
          372,
          149,
          254,
          52126,
          172247,
          641349,
          478404,
          3862,
          26120,
          640470,
          104,
          4198,
          922,
          6284,
          194500,
          1684,
          5778,
          910148,
          190178,
          27020,
          270712,
          741,
          4778,
          7297,
          1038,
          467,
          5778,
          1087,
          811,
          635,
          46944
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "legend": {
         "title": {
          "text": "is_fraud"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "city_pop"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.histogram(train_sample, x='city_pop', color='is_fraud', barmode='group') # try changing x to see the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test.sample(frac=0.05, random_state=42) # 5% sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78643, 15), (27786, 15), (26215, 15))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.shape, test_sample.shape, train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numerical_cols = train_sample.select_dtypes(include=(np.number)).columns\n",
    "categorical_cols = train_sample.select_dtypes(include=('object')).columns\n",
    "correlation_matrix = train_sample[numerical_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>amt</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382661</th>\n",
       "      <td>30273037698427</td>\n",
       "      <td>1.92</td>\n",
       "      <td>72165</td>\n",
       "      <td>35.5762</td>\n",
       "      <td>-91.4539</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505568</th>\n",
       "      <td>3513618443244540</td>\n",
       "      <td>73.25</td>\n",
       "      <td>57340</td>\n",
       "      <td>43.7588</td>\n",
       "      <td>-97.8712</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160698</th>\n",
       "      <td>4378993458389620</td>\n",
       "      <td>118.45</td>\n",
       "      <td>3818</td>\n",
       "      <td>43.9742</td>\n",
       "      <td>-71.1503</td>\n",
       "      <td>3807</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252453</th>\n",
       "      <td>5456776410929280</td>\n",
       "      <td>36.48</td>\n",
       "      <td>16048</td>\n",
       "      <td>41.0472</td>\n",
       "      <td>-79.8089</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845278</th>\n",
       "      <td>3585740823295290</td>\n",
       "      <td>85.13</td>\n",
       "      <td>79252</td>\n",
       "      <td>34.2956</td>\n",
       "      <td>-99.7494</td>\n",
       "      <td>3202</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cc_num     amt    zip      lat     long  city_pop  is_fraud  \\\n",
       "382661    30273037698427    1.92  72165  35.5762 -91.4539       111         0   \n",
       "505568  3513618443244540   73.25  57340  43.7588 -97.8712       355         0   \n",
       "160698  4378993458389620  118.45   3818  43.9742 -71.1503      3807         0   \n",
       "252453  5456776410929280   36.48  16048  41.0472 -79.8089       139         0   \n",
       "845278  3585740823295290   85.13  79252  34.2956 -99.7494      3202         0   \n",
       "\n",
       "        age  \n",
       "382661   24  \n",
       "505568   69  \n",
       "160698   25  \n",
       "252453   70  \n",
       "845278   26  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample[numerical_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382661</th>\n",
       "      <td>fraud_Stiedemann Ltd</td>\n",
       "      <td>food_dining</td>\n",
       "      <td>M</td>\n",
       "      <td>06959 Stephen Branch Suite 246</td>\n",
       "      <td>Thida</td>\n",
       "      <td>AR</td>\n",
       "      <td>Careers information officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505568</th>\n",
       "      <td>fraud_Nienow PLC</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>F</td>\n",
       "      <td>954 Reyes Ways</td>\n",
       "      <td>Fulton</td>\n",
       "      <td>SD</td>\n",
       "      <td>Financial adviser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160698</th>\n",
       "      <td>fraud_Koepp-Witting</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>M</td>\n",
       "      <td>1561 Chase Grove</td>\n",
       "      <td>Conway</td>\n",
       "      <td>NH</td>\n",
       "      <td>Surgeon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252453</th>\n",
       "      <td>fraud_Kub-Heaney</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>F</td>\n",
       "      <td>658 Diane Glen Apt. 677</td>\n",
       "      <td>North Washington</td>\n",
       "      <td>PA</td>\n",
       "      <td>Patent attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845278</th>\n",
       "      <td>fraud_Bins-Howell</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>M</td>\n",
       "      <td>082 Hernandez Bypass Apt. 886</td>\n",
       "      <td>Quanah</td>\n",
       "      <td>TX</td>\n",
       "      <td>Librarian, public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    merchant        category gender  \\\n",
       "382661  fraud_Stiedemann Ltd     food_dining      M   \n",
       "505568      fraud_Nienow PLC   entertainment      F   \n",
       "160698   fraud_Koepp-Witting     grocery_pos      M   \n",
       "252453      fraud_Kub-Heaney  health_fitness      F   \n",
       "845278     fraud_Bins-Howell   personal_care      M   \n",
       "\n",
       "                                street              city state  \\\n",
       "382661  06959 Stephen Branch Suite 246             Thida    AR   \n",
       "505568                  954 Reyes Ways            Fulton    SD   \n",
       "160698                1561 Chase Grove            Conway    NH   \n",
       "252453         658 Diane Glen Apt. 677  North Washington    PA   \n",
       "845278   082 Hernandez Bypass Apt. 886            Quanah    TX   \n",
       "\n",
       "                                job  \n",
       "382661  Careers information officer  \n",
       "505568            Financial adviser  \n",
       "160698                      Surgeon  \n",
       "252453              Patent attorney  \n",
       "845278            Librarian, public  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample[categorical_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder().fit(train_sample[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_12648\\228919584.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()\n"
     ]
    }
   ],
   "source": [
    "train_sample[encoded_cols] = encoder.transform(train_sample[categorical_cols]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78643, 3052)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'is_fraud'\n",
    "numerical_cols = numerical_cols.drop('cc_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "train_sample[numerical_cols] = StandardScaler().fit_transform(train_sample[numerical_cols])\n",
    "train_val[numerical_cols] = StandardScaler().fit_transform(train_val[numerical_cols])\n",
    "test[numerical_cols] = StandardScaler().fit_transform(test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382661</th>\n",
       "      <td>-0.480215</td>\n",
       "      <td>0.869213</td>\n",
       "      <td>-0.584466</td>\n",
       "      <td>-0.086520</td>\n",
       "      <td>-0.292978</td>\n",
       "      <td>-1.540940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505568</th>\n",
       "      <td>0.025803</td>\n",
       "      <td>0.318264</td>\n",
       "      <td>1.020359</td>\n",
       "      <td>-0.549910</td>\n",
       "      <td>-0.292153</td>\n",
       "      <td>1.058666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160698</th>\n",
       "      <td>0.346453</td>\n",
       "      <td>-1.670800</td>\n",
       "      <td>1.062605</td>\n",
       "      <td>1.379593</td>\n",
       "      <td>-0.280487</td>\n",
       "      <td>-1.483171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252453</th>\n",
       "      <td>-0.235045</td>\n",
       "      <td>-1.216290</td>\n",
       "      <td>0.488542</td>\n",
       "      <td>0.754360</td>\n",
       "      <td>-0.292883</td>\n",
       "      <td>1.116435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845278</th>\n",
       "      <td>0.110080</td>\n",
       "      <td>1.132590</td>\n",
       "      <td>-0.835625</td>\n",
       "      <td>-0.685534</td>\n",
       "      <td>-0.282531</td>\n",
       "      <td>-1.425402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012404</th>\n",
       "      <td>-0.430415</td>\n",
       "      <td>-0.346999</td>\n",
       "      <td>-1.308996</td>\n",
       "      <td>0.090813</td>\n",
       "      <td>-0.277898</td>\n",
       "      <td>-0.847712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210079</th>\n",
       "      <td>0.009699</td>\n",
       "      <td>-1.755272</td>\n",
       "      <td>0.731269</td>\n",
       "      <td>1.338420</td>\n",
       "      <td>-0.174053</td>\n",
       "      <td>-0.096715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626348</th>\n",
       "      <td>-0.086851</td>\n",
       "      <td>0.148353</td>\n",
       "      <td>0.613789</td>\n",
       "      <td>-0.008295</td>\n",
       "      <td>-0.288534</td>\n",
       "      <td>0.943128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367942</th>\n",
       "      <td>-0.365291</td>\n",
       "      <td>-1.345359</td>\n",
       "      <td>0.569013</td>\n",
       "      <td>1.161838</td>\n",
       "      <td>-0.285722</td>\n",
       "      <td>2.098508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123463</th>\n",
       "      <td>-0.052090</td>\n",
       "      <td>-0.797718</td>\n",
       "      <td>-0.405265</td>\n",
       "      <td>0.778572</td>\n",
       "      <td>-0.281855</td>\n",
       "      <td>2.676198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78643 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              amt       zip       lat      long  city_pop       age\n",
       "382661  -0.480215  0.869213 -0.584466 -0.086520 -0.292978 -1.540940\n",
       "505568   0.025803  0.318264  1.020359 -0.549910 -0.292153  1.058666\n",
       "160698   0.346453 -1.670800  1.062605  1.379593 -0.280487 -1.483171\n",
       "252453  -0.235045 -1.216290  0.488542  0.754360 -0.292883  1.116435\n",
       "845278   0.110080  1.132590 -0.835625 -0.685534 -0.282531 -1.425402\n",
       "...           ...       ...       ...       ...       ...       ...\n",
       "1012404 -0.430415 -0.346999 -1.308996  0.090813 -0.277898 -0.847712\n",
       "210079   0.009699 -1.755272  0.731269  1.338420 -0.174053 -0.096715\n",
       "626348  -0.086851  0.148353  0.613789 -0.008295 -0.288534  0.943128\n",
       "367942  -0.365291 -1.345359  0.569013  1.161838 -0.285722  2.098508\n",
       "123463  -0.052090 -0.797718 -0.405265  0.778572 -0.281855  2.676198\n",
       "\n",
       "[78643 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample[numerical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78643, 3037)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample[encoded_cols].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78643, 6)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample[numerical_cols].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_sample[encoded_cols + list(numerical_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78643, 3043)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1015"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(x_train)\n",
    "n_components = pca.n_components_\n",
    "n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to retain 95.0% variance: 1015\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAByNUlEQVR4nO3dd3RU1d7G8WcSUoEktBR6lRY6gnSF0AXrBRGlqHileFVsoEIEXynqRRQplgtYATsoGEGqAoLSu5QgiglFSggQUma/f3Az1zEJmYGZzGTy/azFkjlnnzO/mT3BebL32cdijDECAAAAAOTJz9MFAAAAAIC3IzgBAAAAQD4ITgAAAACQD4ITAAAAAOSD4AQAAAAA+SA4AQAAAEA+CE4AAAAAkA+CEwAAAADkg+AEAAAAAPkgOAGAkwYNGqSqVate1bFVq1bVoEGDXFqPo66lbnfxxpquRtWqVXXzzTd7ugwAgBsRnAAUSnPnzpXFYsnzz48//ujpEgud48ePq1ixYrrnnnvybHPu3DmFhITo9ttvL8DK8FcpKSkaN26cGjVqpBIlSigkJESxsbF6+umn9ccff3i6vEJv3bp1ev7553XmzBlPlwLAyxTzdAEAcC3Gjx+vatWq5dhes2ZND1STv3379snPzzt/ZxUZGanOnTtr4cKFunDhgkJDQ3O0+fzzz5WWlnbFcOWMt99+W1ar1SXnKgoOHTqkuLg4HTlyRP/4xz/04IMPKjAwUNu3b9d//vMfffHFF/rll188XWahtm7dOo0bN06DBg1SRESEp8sB4EUITgAKte7du6t58+aeLsNhQUFBni7hivr376+EhAQtWrRId911V479H330kcLDw9WzZ89rep7z58+rePHiCggIuKbzFCWZmZm6/fbbdezYMa1atUpt27a12//iiy9q8uTJHqoOAHyfd/7aEwBcJD4+Xn5+flq+fLnd9uzf1G/btk2StGrVKlksFi1YsEDPPPOMoqOjVbx4cfXu3Vu//fZbvs/zyiuvqHXr1ipTpoxCQkLUrFkzffrppzna/f0ap+wph2vXrtXIkSNVrlw5FS9eXLfddptOnDiR4/hvvvlG7dq1U/HixVWyZEn17NlTu3btytHuyy+/VGxsrIKDgxUbG6svvvgi39cgSbfddpuKFy+ujz76KMe+48ePa/ny5brzzjsVFBSk77//Xv/4xz9UuXJlBQUFqVKlSnrsscd08eJFu+MGDRqkEiVK6ODBg+rRo4dKliyp/v372/b9/RonR99Li8WiESNG2F5rUFCQ6tevr4SEhBxtjx49qvvvv1/ly5dXUFCQqlWrpqFDhyo9Pd3W5syZM3r00UdVqVIlBQUFqWbNmpo8ebJTI2JLly5V48aNFRwcrHr16unzzz+37Tt06JAsFoteffXVHMetW7dOFotF8+bNy/Pcn332mbZt26Znn302R2iSpLCwML344ot22z755BM1a9ZMISEhKlu2rO655x4dPXrUrk12/xw5ckQ333yzSpQooQoVKmj69OmSpB07dqhjx44qXry4qlSpkuOzkf0ZXrNmjf75z3+qTJkyCgsL04ABA3T69Okcdc6YMUP169dXUFCQypcvr+HDh+eYFnfjjTcqNjZWu3fv1k033aTQ0FBVqFBBL730Uo7zXbp0SfHx8apZs6btc/jUU0/p0qVLdu0c+bw8//zzevLJJyVJ1apVs039PXz4sCRp2bJlatu2rSIiIlSiRAnVrl1bzzzzTI6aAPgoAwCF0Jw5c4wk891335kTJ07Y/Tl58qStXXp6umnSpImpUqWKSUlJMcYYk5CQYCSZF154wdZu5cqVRpJp0KCBadiwoZkyZYoZNWqUCQ4ONtddd525cOGCre3AgQNNlSpV7OqpWLGiGTZsmHnjjTfMlClTTIsWLYwk8/XXX9u1q1Klihk4cGCO19GkSRPTsWNHM23aNPP4448bf39/06dPH7tj33vvPWOxWEy3bt3MtGnTzOTJk03VqlVNRESESUxMtLX79ttvjZ+fn4mNjTVTpkwxzz77rAkPDzf169fPUXdu7r77bhMYGGj+/PNPu+2vv/66kWRWrFhhjDHm4YcfNj169DATJkwwb775prn//vuNv7+/ufPOO+2OGzhwoAkKCjI1atQwAwcONLNmzTLvvffeNb+XkkyjRo1MTEyMeeGFF8zUqVNN9erVTWhoqN1n4OjRo6Z8+fImNDTUPProo2bWrFlmzJgxpm7duub06dPGGGPOnz9vGjZsaMqUKWOeeeYZM2vWLDNgwABjsVjMI488ku97VqVKFXPdddeZiIgIM2rUKDNlyhTToEED4+fnZ5YuXWpr16ZNG9OsWbMcxw8bNsyULFnSnD9/Ps/nuPvuu40kc+TIkXzrMeZ/n63rr7/evPrqq2bUqFEmJCTEVK1a1fa6jbncB8HBwaZevXrmoYceMtOnTzetW7c2ksycOXNM+fLlzZNPPmmmTZtm6tevb/z9/c2hQ4dyPE+DBg1Mu3btzOuvv26GDx9u/Pz8TPv27Y3VarW1jY+PN5JMXFycmTZtmhkxYoTx9/c3119/vUlPT7e169ChgylfvrypVKmSeeSRR8yMGTNMx44djSSzZMkSW7usrCzTpUsXW9+++eabZsSIEaZYsWLmlltusXs/HPm8bNu2zfTr189IMq+++qp5//33zfvvv29SU1PNzp07TWBgoGnevLl57bXXzKxZs8wTTzxh2rdv71B/ACj8CE4ACqXsL2u5/QkKCrJru2PHDhMYGGgeeOABc/r0aVOhQgXTvHlzk5GRYWuTHZwqVKhgC1jGGPPxxx8bSea1116zbcvty/5fg5UxlwNbbGys6dixo932vIJTXFyc3RfMxx57zPj7+5szZ84YY4w5d+6ciYiIMEOGDLE7X3JysgkPD7fb3rhxYxMTE2M71hhjli5daiQ5FJwWL15sJJk333zTbvsNN9xgKlSoYLKysnJ9zcYYM3HiRGOxWMyvv/5q2zZw4EAjyYwaNSpH+2t5LyWZwMBAc+DAAdu2bdu2GUlm2rRptm0DBgwwfn5+5qeffsrx/Nnv+QsvvGCKFy9ufvnlF7v9o0aNMv7+/vmGlSpVqhhJ5rPPPrNtO3v2rImJiTFNmjSxbXvzzTeNJLNnzx6711e2bFm7z0VumjRpYsLDw6/Y5q/njIyMNLGxsebixYu27V9//bWRZMaOHWvblt0/EyZMsG07ffq0CQkJMRaLxcyfP9+2fe/evUaSiY+Pt23L/gw3a9bMLvy89NJLRpJZuHChMcaY48ePm8DAQNOlSxfbZ8gYY9544w0jycyePdu2rUOHDkaSLWAbY8ylS5dMdHS0ueOOO2zb3n//fePn52e+//57u9c/a9YsI8msXbvWts3Rz8vLL79sJNn9MsIYY1599VUjyZw4ccIAKJqYqgegUJs+fbqWLVtm9+ebb76xaxMbG6tx48bpnXfeUdeuXXXy5Em9++67KlYs52WeAwYMUMmSJW2P77zzTsXExGjJkiVXrCMkJMT299OnT+vs2bNq166dNm/e7NDrePDBB2WxWGyP27Vrp6ysLP3666+SLk8ROnPmjPr166eTJ0/a/vj7+6tly5ZauXKlJCkpKUlbt27VwIEDFR4ebjtf586dVa9ePYdq6dKli8qVK2c3JSsxMVE//vij+vXrZ1vc4q+v+fz58zp58qRat24tY4y2bNmS47xDhw516PmdeS/j4uJUo0YN2+OGDRsqLCxMhw4dkiRZrVZ9+eWX6tWrV67XwmW/55988onatWunUqVK2b2/cXFxysrK0po1a/Ktu3z58rrttttsj7Onq23ZskXJycmSpD59+ig4OFgffvihrd23336rkydP5rvgRkpKit1n80p+/vlnHT9+XMOGDVNwcLBte8+ePVWnTh0tXrw4xzEPPPCA7e8RERGqXbu2ihcvrj59+ti2165dWxEREbb3968efPBBu2vWhg4dqmLFitl+dr777julp6fr0UcftVsgZciQIQoLC8tRU4kSJezek8DAQLVo0cLuuT/55BPVrVtXderUseu3jh07SpLt5yJbfp+XK8leKGLhwoUsaAIUUSwOAaBQa9GihUOLQzz55JOaP3++Nm7cqAkTJuQZImrVqmX32GKxqGbNmrZrHPLy9ddf6//+7/+0detWu2sr/hqGrqRy5cp2j0uVKiVJtmtE9u/fL0m2L4R/FxYWJkm2oPX31yFd/tLrSJArVqyY+vbtqxkzZujo0aOqUKGCLURlX5skSUeOHNHYsWO1aNGiHNeynD17Nsc5K1asmO9zS869l39/36TL7112PSdOnFBKSopiY2Ov+Jz79+/X9u3bVa5cuVz3Hz9+PN+6a9asmaPG6667TpJ0+PBhRUdHKyIiQr169dJHH32kF154QZL04YcfqkKFCnn2bTZHv+BL//sc1K5dO8e+OnXq6IcffrDbFhwcnOO1h4eHq2LFijleU3h4eK7XLv39M1eiRAnFxMTYfnbyqikwMFDVq1e37c+W23OXKlVK27dvtz3ev3+/9uzZ43C/5fd5uZK+ffvqnXfe0QMPPKBRo0apU6dOuv3223XnnXd67UqZAFyL4ASgSDh06JAtfOzYscOl5/7+++/Vu3dvtW/fXjNmzFBMTIwCAgI0Z86cXBdZyI2/v3+u240xkmT7Dff777+v6OjoHO1yGz27Fvfcc4/eeOMNzZs3T0888YTmzZunevXqqXHjxpKkrKwsde7cWadOndLTTz+tOnXqqHjx4jp69KgGDRqU4zfyQUFBDn25dPa9zO99c5TValXnzp311FNP5bo/OwC5woABA/TJJ59o3bp1atCggRYtWqRhw4bl+/7UqVNHW7Zs0W+//aZKlSq5rB4p7/fRVe/v1XDkua1Wqxo0aKApU6bk2vbv79O1vJ6QkBCtWbNGK1eu1OLFi5WQkKAFCxaoY8eOWrp0aZ7nBuA7CE4AfJ7VatWgQYMUFhamRx99VBMmTNCdd96Z601cs8NVNmOMDhw4oIYNG+Z5/s8++0zBwcH69ttv7ZYbnzNnjsteQ/b0osjISMXFxeXZrkqVKpJyvg7p8j2kHNWyZUvVqFFDH330kTp37qxdu3bZrdi2Y8cO/fLLL3r33Xc1YMAA2/Zly5Y5/By5cfV7Wa5cOYWFhWnnzp1XbFejRg2lpqZe8b3Nz4EDB2SMsRslyb6n0l9XDuzWrZvKlSunDz/8UC1bttSFCxd077335nv+Xr16ad68efrggw80evToK7bN/hzs27cvx0jWvn37bPtdaf/+/brppptsj1NTU5WUlKQePXrkqKl69eq2dunp6UpMTLyq975GjRratm2bOnXq5PDobn6udB4/Pz916tRJnTp10pQpUzRhwgQ9++yzWrly5TV9dgAUDowtA/B5U6ZM0bp16/TWW2/phRdeUOvWrTV06FCdPHkyR9v33ntP586dsz3+9NNPlZSUpO7du+d5fn9/f1ksFmVlZdm2HT58WF9++aXLXkPXrl0VFhamCRMmKCMjI8f+7KXLY2Ji1LhxY7377rt20+WWLVum3bt3O/Wc/fv315YtWxQfHy+LxaK7777bti/7t+t//U29MUavvfaaU8/xd65+L/38/HTrrbfqq6++0s8//5xjf3b9ffr00fr16/Xtt9/maHPmzBllZmbm+1x//PGH3bLvKSkpeu+999S4cWO7UcJixYqpX79++vjjjzV37lw1aNDgisE825133qkGDRroxRdf1Pr163PsP3funJ599llJUvPmzRUZGalZs2bZTXf85ptvtGfPnmu+D1du3nrrLbvP5syZM5WZmWn72YmLi1NgYKBef/11u8/Nf/7zH509e/aqaurTp4+OHj2qt99+O8e+ixcv6vz5806fs3jx4pKUY4n0U6dO5WibPQL796XPAfgmRpwAFGrffPON9u7dm2N769atVb16de3Zs0djxozRoEGD1KtXL0mX7zvTuHFjDRs2TB9//LHdcaVLl1bbtm01ePBgHTt2TFOnTlXNmjU1ZMiQPGvo2bOnpkyZom7duunuu+/W8ePHNX36dNWsWdPueoxrERYWppkzZ+ree+9V06ZNddddd6lcuXI6cuSIFi9erDZt2uiNN96QJE2cOFE9e/ZU27Ztdd999+nUqVOaNm2a6tevr9TUVIef85577tH48eO1cOFCtWnTxm7UpE6dOqpRo4aeeOIJHT16VGFhYfrss88culbkStzxXk6YMEFLly5Vhw4d9OCDD6pu3bpKSkrSJ598oh9++EERERF68skntWjRIt18880aNGiQmjVrpvPnz2vHjh369NNPdfjwYZUtW/aKz3Pdddfp/vvv108//aSoqCjNnj1bx44dy3W0bMCAAXr99de1cuVKh29aGxAQoM8//1xxcXFq3769+vTpozZt2iggIEC7du3SRx99pFKlSunFF19UQECAJk+erMGDB6tDhw7q16+fjh07ptdee01Vq1bVY489dlXv5ZWkp6erU6dO6tOnj/bt26cZM2aobdu26t27t6TLo3+jR4/WuHHj1K1bN/Xu3dvW7vrrr893cYzc3Hvvvfr444/10EMPaeXKlWrTpo2ysrK0d+9effzxx/r222+dvkF2s2bNJEnPPvus7rrrLgUEBKhXr14aP3681qxZo549e6pKlSo6fvy4ZsyYoYoVK+Z6Xy0APsgzi/kBwLW50nLk+u/9ZzIzM831119vKlasaLc0tzHGvPbaa0aSWbBggTHmf8uRz5s3z4wePdpERkaakJAQ07NnT7ultY3JfQnt//znP6ZWrVomKCjI1KlTx8yZM8d2z5q/yms58r8vlZ1dz8qVK3Ns79q1qwkPDzfBwcGmRo0aZtCgQebnn3+2a/fZZ5+ZunXrmqCgIFOvXj3z+eef51p3fq6//nojycyYMSPHvt27d5u4uDhTokQJU7ZsWTNkyBDb8s5z5syxtRs4cKApXrx4rue/lvdSkhk+fHiOc/79PTbGmF9//dUMGDDAlCtXzgQFBZnq1aub4cOHm0uXLtnanDt3zowePdrUrFnTBAYGmrJly5rWrVubV155xW6Z7dxUqVLF9OzZ03z77bemYcOGtto/+eSTPI+pX7++8fPzM7///vsVz/13p0+fNmPHjjUNGjQwoaGhJjg42MTGxprRo0ebpKQku7YLFiwwTZo0MUFBQaZ06dKmf//+OZ4vr/7p0KGDqV+/fp6vNVv2Z3j16tXmwQcfNKVKlTIlSpQw/fv3z3EvMGMuLz9ep04dExAQYKKioszQoUPt7it1pefO7fOSnp5uJk+ebOrXr2+CgoJMqVKlTLNmzcy4cePM2bNnbe2c+by88MILpkKFCsbPz8+2NPny5cvNLbfcYsqXL28CAwNN+fLlTb9+/XIsYQ/Ad1mMKYArPAHAy61atUo33XSTPvnkE915552eLgdFQJMmTVS6dGktX77c06Vck7lz52rw4MH66aefnB7dAYDChGucAAAoYD///LO2bt1qt7AGAMC7cY0TAAAFZOfOndq0aZP+/e9/KyYmRn379vV0SQAABzHiBABAAfn00081ePBgZWRkaN68eQoODvZ0SQAAB3GNEwAAAADkgxEnAAAAAMgHwQkAAAAA8lHkFoewWq36448/VLJkSVksFk+XAwAAAMBDjDE6d+6cypcvLz+/K48pFbng9Mcff6hSpUqeLgMAAACAl/jtt99UsWLFK7YpcsGpZMmSki6/OWFhYR6uRsrIyNDSpUvVpUsXBQQEeLocXAP60rfQn76F/vQt9KdvoT99R2Hsy5SUFFWqVMmWEa6kyAWn7Ol5YWFhXhOcQkNDFRYWVmg+YMgdfelb6E/fQn/6FvrTt9CfvqMw96Ujl/CwOAQAAAAA5IPgBAAAAAD5IDgBAAAAQD4ITgAAAACQD4ITAAAAAOSD4AQAAAAA+SA4AQAAAEA+CE4AAAAAkA+CEwAAAADkg+AEAAAAAPkgOAEAAABAPghOAAAAAJAPghMAAAAA5KOYpwsAAMBbZVmN1uw5rsnf7tb+4xeU5emC8Bd+emT9Uk8XAZehP31H/n3pJyksJEDdYqMV36u+QgL9C6a0a+TR4LRmzRq9/PLL2rRpk5KSkvTFF1/o1ltvveIxq1at0siRI7Vr1y5VqlRJzz33nAYNGlQg9QIAfEd2KJqUsEu/nLgo4+mC4CQmzfgW+tN35N+XVklnLmZo/k+/af5Pv6lzvUi9PeB695d2jTwanM6fP69GjRrpvvvu0+23355v+8TERPXs2VMPPfSQPvzwQy1fvlwPPPCAYmJi1LVr1wKoGABQWKRnWvXmmv36z5qDOpNmxG+0AcA7Ldt9XEPe+8nrw5NHg1P37t3VvXt3h9vPmjVL1apV07///W9JUt26dfXDDz/o1VdfJTgBQBGUmpaphz/8SWv3n1J6vq35jTYAeKtlu4/rYnqWV0/bK1TXOK1fv15xcXF227p27apHH300z2MuXbqkS5cu2R6npKRIkjIyMpSRkeGWOp2RXYM31IJrQ1/6FvrTe6SmZeqxBZu19sAZ0RsA4Lv+7+uder5XvQJ9Tmf+P1+oglNycrKioqLstkVFRSklJUUXL15USEhIjmMmTpyocePG5di+dOlShYaGuq1WZy1btszTJcBF6EvfQn8WjEyrtPJ3i1b/YdG5HBcbWf77BwDgy37ed0RL/A8X6HNeuHDB4baFKjhdjdGjR2vkyJG2xykpKapUqZK6dOmisLAwD1Z2WUZGhpYtW6bOnTsrICDA0+XgGtCXvoX+dI/0TKv+s+6QPlx/RMdSMz1dDgDAizSvXVk9ehTsiFP2bDRHFKrgFB0drWPHjtltO3bsmMLCwnIdbZKkoKAgBQUF5dgeEBDgVV+GvK0eXD360rfQn1cnPdOqt78/oPfWHtKxVBbxBgDk77mbYxUQULDXODnz//hCFZxatWqlJUuW2G1btmyZWrVq5aGKAAAX07M0ZuE2fb01SWlkJADAVehcL9KrF4aQPBycUlNTdeDAAdvjxMREbd26VaVLl1blypU1evRoHT16VO+9954k6aGHHtIbb7yhp556Svfdd59WrFihjz/+WIsXL/bUSwCAIuXshQwNeGeddvyRKquniwEA+ATu4+SAn3/+WTfddJPtcfa1SAMHDtTcuXOVlJSkI0eO2PZXq1ZNixcv1mOPPabXXntNFStW1DvvvMNS5ADgYtlT7d5fl6jkc1yLBG9kFUvM+xL603fk35d+ksJCAtQtNlrxvep7/UhTNo8GpxtvvFHG5H2v9rlz5+Z6zJYtW9xYFQAULVlWo1W7jin+6x36/Wz+d0MqavwkhQT6q0W10prWr6lKBBeqWe4+KSMjQ0uWLFGPHt24BtEH0J++w9f7kn/9AaAIybIardlzXJO/3a39xy+oaF2SZPT3Zc39JBUP8lf3BjEa1zu20PzWEwBQ8AhOAODDUtMyNeKDjfrhwGkVxQl3/hYpKixYd19fUTHn9qr3zT188regAAD3IzgBgI8oitclWSQFFbPohupl9MbdzfKcRnd5+sjegi0OAOBTCE4AUEgVlRXuLJIC/S2qWz5M7w5uqfBQRowAAAWP4AQAhUBRuKGsv+XyKktd6xeuVZYAAEUDwQkAvFBqWqYe/vAnrTtwSpfyXny0UCIgAQAKI4ITAHgBX1zEwd8ilQoN0KA21fRg+xoKLMY9WgAAhRfBCQAKmC8u4hDgJ9WMLKknu9ZRh9rl5O9nyf8gAAAKEYITALjZxfQsjV20XQnbk3QuvXDPu7NICgnwV8vq3AwWAFC08H88AHCx9Eyr3lyzX/9Zc1Bn0gpvUGKqHQAA/0NwAoBrlD2i9M22P5Sa4elqro6fLi/Y0C2WBRsAAMgNwQkAnFTYp975SQoJ9FeLaky3AwDAUfzfEgDyUdin3gUXs+iG6mX0xt3NCEkAAFwl/g8KAH+TnmnVrDUH9NZ6Pz2yfqmny3EK90gCAMA9CE4Airwsq9GaPcc1KWGX9p24+Jc93r8YQigr3AEAUCD4vyyAIik1LVMPf/iTvt9/qtDccNYiqUxxVrkDAMATCE4AioTCuKBDkL+fakQW1xNduKksAACeRnAC4JOyrEardh1T/Nc79PvZdE+X4xAWcQAAwHvxf2YAPuNiepbGLNymhVuSlGH1dDX5KxXKIg4AABQWBCcAhVZhWibcIql8RLD6t6yiB9pV5/okAAAKGYITgEIlNS1TIz7YqNUHTsubo5KfpOjwYN1zA0EJAABfQHAC4NXSM616+/sDem/tIR1LzfJ0OXmySKpcOkRjbq6vm+pEspADAAA+huAEwOtkr4D35eY/vPZaJabeAQBQtBCcAHhc9g1oJ3+7W3uPX/B0ObmySIph6h0AAEUWwQmAR2RPwXt79UGdSfPOYaWIAKse6HCdHryxFkEJAIAijuAEoMB4+xS8kkH+6t4gRuN6x6qYxaolS5aoR4fqCiA0AQBQ5BGcALhValqmHv7wJ63af8rrVsHzs0gNK4br3cEtFR4aYLcvwxuTHQAA8BiCEwCXyw5LK/ef8nQpOVRgQQcAAHAVCE4Arpk3L+5QPNBPvRpVUHyv+goJ9Pd0OQAAoJAiOAG4Kt66uIOfRaoTXVJPdKmjDrXLcT8lAADgEgQnAA7LDkvTVxzQhQzvuWKpPMuEAwAANyM4AbgibwxL/hapXa2yeuPuZioRzD9jAADA/fjGASAHbwxLJYP89c8ONfRg+xqMKgEAgAJHcAIgyTvDUpXSIRpzc33dVCeSa5UAAIBHEZyAIszbwpKfpA61y2lav6ZMwQMAAF6FbyZAEeNtYal4oL96NSrPcuEAAMCrEZyAIiD7PksjP92q0xczPV0OU/AAAEChQ3ACfFhqWqb6zvpBu5LPe7oUNa4UrncHt1R4aICnSwEAAHAawQnwMalpmRrxwUatOnDa06UQlgAAgM8gOAE+4GJ6lsYs3KbPNiXJk1ctsbgDAADwVXyzAQqpi+lZGrtouz7f9IeyPJiWilmkO5tXYnEHAADg0whOQCGSvcjDwws2KzXd6rE6CEsAAKCoITgBhUBqWqbuenOtdialeqyGoGIW3dakImEJAAAUSQQnwEtl32/p1WX7lemhwaXgYhaN6FhLD7avocBifp4pAgAAwAsQnAAvk5qWqe5TV+m3M5c88vyEJQAAgJwIToAXSM+06s01+/XqsgOyemChB8ISAADAlRGcAA86eyFDcf9eqRPnMwr8uQP8pEfiriMsAQAAOIDgBBSw7GXEP/35jwK/55JF0j+aV9S43rEs8AAAAOAEghNQQFLTMtXhpeX680JmgT/3jdeV1Rt3N+OmtAAAAFeJb1GAG2VZjVbtOqaH5m1SRgGvjBcbU0Lz/9mGsAQAAOACfKMC3OBiepbue3eD1h88XaDPW7p4gF65s7E61C4nfz9LgT43AACALyM4AS6UlindMHFFgU7HK2aRRnaprQfaVWeRBwAAADchOAEukJqWqRsmfKfUdH9JBROabqpdTtP6NWUqHgAAQAHgGxdwlXK/fsm90+PKlQjQdyNvUnhogFufBwAAAPYIToCT0jOtevLTrVq4NalAns9f0mNduN8SAACAJxGcAAelZ1rV/531+unwmQJ5voqlgpTwyI1MxQMAAPACfCMD8pFlNRr2/iZ9u+eY25+LhR4AAAC8E8EJyENBTsmLjSmp+f9szegSAACAl+JbGvA3BTXCFGCRZt7bXDfVieSeSwAAAF6O4AT8V5bVaMq3+zR99UG3Pk+ZUH+tfiqO0SUAAIBChG9ugKQvNh/VYx9vdetz1I4qri+Ht1NIoL9bnwcAAACuR3BCkZaalqnm/7dMaZnW/BtfBT9JT3RlsQcAAIDCjuCEIik906p2Ly3XsZR0t5w/2N+iDc925ka1AAAAPoLghCInfuFOvbv+V7ecu7hfln4Y3VmlSoa45fwAAADwDIITiozUtEw1Gvetsozrz10+LFAJj7TTyu++ZdEHAAAAH8Q3PPg8d07L++uCDxkZGS4/PwAAALwDwQk+K8tqNPyDTUrY7fr7MdUoG6xvHr2JBR8AAACKCIITfNLCrUf1yPytLj8vS4oDAAAUTQQn+BR3TctjhAkAAKBoIzjBZ4z/apdmrz3s0nOWCvbXumc6M8IEAABQxBGcUOilZ1p1/YvLdPZipsvOGeQvbRrTlRXyAAAAIInghELOHfdkmnpnQ93avJJLzwkAAIDCjeCEQik906rY5xOUnum6mzJ1rV9OM/pfL38/i8vOCQAAAN9AcEKhM27RLs1Zd9hl54ssUUw/jOrMwg8AAADIE8EJhUZ6plWNx3+rC+lWl5zPT9L257mOCQAAAPnjGyMKBVePMt3bqqJeuKWRy84HAAAA30ZwglfLsho1Gb9UKWmuWTEvLNhPPz/XlWl5AAAAcArBCV5r4dajemT+Vpedj9XyAAAAcLUITvBKN7/+vXb+keKSc1UpFaQVT3ZitTwAAABcNYITvEp6plX1479RRpZrzvd6n0bq3bSia04GAACAIovgBK8x/qtdmr32sEvOxT2ZAAAA4EoEJ3iFdpNX6LfTF6/5PMH+0vZx3Vn8AQAAAC5FcIJHZVmN6o1ZoksumJp303WlNee+Vtd+IgAAAOBvCE7wGFeumvfGXY11c+MKLjkXAAAA8HcEJ3iEq1bNa1yxpD4b1o5rmQAAAOBWBCcUqCyrUf2x3ygt01zzuRhlAgAAQEEhOKHAfLXtDz08b8s1n6dscX9teLYro0wAAAAoMAQnFIj75m7Uir0nrvk8g9tUVnyvBi6oCAAAAHAcwQlu13bycv1+Ou2azhFgkXa9wDLjAAAA8AyPfwudPn26qlatquDgYLVs2VIbN268YvupU6eqdu3aCgkJUaVKlfTYY48pLe3avpTDfZqM+/aaQ1O96FDtn9iT0AQAAACP8eiI04IFCzRy5EjNmjVLLVu21NSpU9W1a1ft27dPkZGROdp/9NFHGjVqlGbPnq3WrVvrl19+0aBBg2SxWDRlyhQPvAJcSd1nl+hi1rUtAvF6n0bq3bSiiyoCAAAAro5Hf4U/ZcoUDRkyRIMHD1a9evU0a9YshYaGavbs2bm2X7dundq0aaO7775bVatWVZcuXdSvX798R6lQsLKsRtVGLb6m0OQv6eCEHoQmAAAAeAWPjTilp6dr06ZNGj16tG2bn5+f4uLitH79+lyPad26tT744ANt3LhRLVq00KFDh7RkyRLde++9eT7PpUuXdOnSJdvjlJTL9w7KyMhQRkaGi17N1cuuwRtqcYXFO5L16Mfbr+kcdSJD9NXD7WTNypQ1y0WFFQBf68uijv70LfSnb6E/fQv96TsKY186U6vFGHPtN9S5Cn/88YcqVKigdevWqVWrVrbtTz31lFavXq0NGzbketzrr7+uJ554QsYYZWZm6qGHHtLMmTPzfJ7nn39e48aNy7H9o48+Umho6LW/ENi8tceiXWf8JF3tMuFGHSKtur2GRz6SAAAAKGIuXLigu+++W2fPnlVYWNgV2xaqVfVWrVqlCRMmaMaMGWrZsqUOHDigRx55RC+88ILGjBmT6zGjR4/WyJEjbY9TUlJUqVIldenSJd83pyBkZGRo2bJl6ty5swICAjxdzlW7dfo67TqTek3neL1PI3VvEO2iigqer/QlLqM/fQv96VvoT99Cf/qOwtiX2bPRHOGx4FS2bFn5+/vr2LFjdtuPHTum6OjcvzyPGTNG9957rx544AFJUoMGDXT+/Hk9+OCDevbZZ+Xnl/OSraCgIAUFBeXYHhAQ4FUd6m31OKPNxO909Oyl/BvmoUyovzY+5zs3tC3MfYmc6E/fQn/6FvrTt9CfvqMw9aUzdXpscYjAwEA1a9ZMy5cvt22zWq1avny53dS9v7pw4UKOcOTv7y9J8tCMwyKv3thvrik01Y8urk1ju/lMaAIAAIBvuqrg9P7776tNmzYqX768fv31V0mX76+0cOFCp84zcuRIvf3223r33Xe1Z88eDR06VOfPn9fgwYMlSQMGDLBbPKJXr16aOXOm5s+fr8TERC1btkxjxoxRr169bAEKBafuc0t0Id161cd3qlNWix+90XUFAQAAAG7i9FS9mTNnauzYsXr00Uf14osvKivr8rJnERERmjp1qm655RaHz9W3b1+dOHFCY8eOVXJysho3bqyEhARFRUVJko4cOWI3wvTcc8/JYrHoueee09GjR1WuXDn16tVLL774orMvA9eozrOLlXYNK969cVdj3dy4gusKAgAAANzI6eA0bdo0vf3227r11ls1adIk2/bmzZvriSeecLqAESNGaMSIEbnuW7Vqld3jYsWKKT4+XvHx8U4/D1yn1ujFyriGmZEHJ/Rgah4AAAAKFaen6iUmJqpJkyY5tgcFBen8+fMuKQreq+aoqw9NQf7S4Uk9CU0AAAAodJwOTtWqVdPWrVtzbE9ISFDdunVdURO8VM1Ri5V5lcdGBPtp34s9XVoPAAAAUFCcnqo3cuRIDR8+XGlpaTLGaOPGjZo3b54mTpyod955xx01wgtcS2iqGB6oH0Z3dmk9AAAAQEFyOjg98MADCgkJ0XPPPWe702758uX12muv6a677nJHjfCwawlNN11XRnPuu8Gl9QAAAAAF7apugNu/f3/1799fFy5cUGpqqiIjI11dF7zEtYSmwW2qKL5XrEvrAQAAADzB6eCUmJiozMxM1apVS6GhoQoNDZUk7d+/XwEBAapataqra4SHXEtoGtKuqp7tWd+l9QAAAACe4vTiEIMGDdK6detybN+wYYMGDRrkiprgBWqOvvrQ9MZdTQhNAAAA8ClOB6ctW7aoTZs2ObbfcMMNua62h8KnznOLlXmVS47PuLuJbm5c3rUFAQAAAB7m9FQ9i8Wic+fO5dh+9uxZZWVluaQoeE6j579R2lUONc26p6m6xca4tiAAAADACzg94tS+fXtNnDjRLiRlZWVp4sSJatu2rUuLQ8FqMi5BZ9OsV3XsL//XndAEAAAAn+X0iNPkyZPVvn171a5dW+3atZMkff/990pJSdGKFStcXiAKRpuJy3T64tWNGM66p6kCizmdwQEAAIBCw+lvu/Xq1dP27dvVp08fHT9+XOfOndOAAQO0d+9excay9HRh1GPqKh09m35VxzI9DwAAAEXBVd3HqXz58powYYKra4EH3Pzaau1OPu/0cRZJByb0kL+fxfVFAQAAAF7mqoLTmTNntHHjRh0/flxWq/01MQMGDHBJYXC/++du0M6k1Ks6ltAEAACAosTp4PTVV1+pf//+Sk1NVVhYmCyW/315tlgsBKdC4uutR7V878mrOnbG3U0JTQAAAChSnL7G6fHHH9d9992n1NRUnTlzRqdPn7b9OXXqlDtqhItlWY1GzN96VccOaVdNPRpyTRMAAACKFqeD09GjR/Wvf/1LoaGh7qgHBeC6Z5dc1XGD21TVsz3rubgaAAAAwPs5HZy6du2qn3/+2R21oAA0fv4bZRnnj+tYu5zie9V3fUEAAABAIeD0NU49e/bUk08+qd27d6tBgwYKCAiw29+7d2+XFQfX6vHqSp25ihvcxpYvqdmDW7ihIgAAAKBwcDo4DRkyRJI0fvz4HPssFouysq7uJqpwr/vnbtDuYxecPq5eTAl9/a/2bqgIAAAAKDycDk5/X34c3u9qV9CrEBGkJY90cENFAAAAQOHi9DVOKFyudgW9UiHFtHZUnOsLAgAAAAqhq7oB7vnz57V69WodOXJE6enpdvv+9a9/uaQwuEbD+G+cPibQT9oS39UN1QAAAACFk9PBacuWLerRo4cuXLig8+fPq3Tp0jp58qRCQ0MVGRlJcPIibSct0/kM55fQ2/N/PdxQDQAAAFB4OT1V77HHHlOvXr10+vRphYSE6Mcff9Svv/6qZs2a6ZVXXnFHjbgK477aod/PpOff8G+m9Wsifz+LGyoCAAAACi+ng9PWrVv1+OOPy8/PT/7+/rp06ZIqVaqkl156Sc8884w7aoST0jOtmrP2iNPHdaoTqV6NyruhIgAAAKBwczo4BQQEyM/v8mGRkZE6cuTyF/Tw8HD99ttvrq0OV6X+WOeva6ofU1L/GXS9G6oBAAAACj+nr3Fq0qSJfvrpJ9WqVUsdOnTQ2LFjdfLkSb3//vuKjY11R41wQpuJS5Xh5IrxJQL9tPgR7tUEAAAA5MXpEacJEyYoJiZGkvTiiy+qVKlSGjp0qE6cOKG33nrL5QXCceO+2qGjZzOcPm7b893cUA0AAADgO5wecWrevLnt75GRkUpISHBpQbg6V3td04y7m7IYBAAAAJAPboDrIxo+73yAva9NVfVoGOOGagAAAADf4tCIU9OmTbV8+XKVKlVKTZo0kcWS9wjF5s2bXVYcHNN24jKlZTp3v6b6MSU1tld9N1UEAAAA+BaHgtMtt9yioKAgSdKtt97qznrgpPvm/Kjfzzp3v6bgYhYWgwAAAACc4FBwio+PlyRlZWXppptuUsOGDRUREeHOuuCAr7ce1Yp9fzp93K7x3d1QDQAAAOC7nLrGyd/fX126dNHp06fdVQ8clGU1enj+VqePe+2uxiwGAQAAADjJ6cUhYmNjdejQIXfUAidMXbpPzl3VJFUrE6pbGldwSz0AAACAL3M6OP3f//2fnnjiCX399ddKSkpSSkqK3R+4X5bVaNqqg04f993jN7q+GAAAAKAIcPo+Tj169JAk9e7d2251PWOMLBaLsrKyXFcdctXyxaVOH8P9mgAAAICr53RwWrlypTvqgIPGfbVDJ89nOnXM/W2rcb8mAAAA4Bo4HZw6dOjgjjrggPRMq+asPeLUMY0rhmnMzfXcVBEAAABQNDgdnLJduHBBR44cUXq6/T2EGjZseM1FIXf3vvOj08d8NqytGyoBAAAAihang9OJEyc0ePBgffPNN7nu5xon90jPtGrDYeeWgWfpcQAAAMA1nF5V79FHH9WZM2e0YcMGhYSEKCEhQe+++65q1aqlRYsWuaNGyPnRJpYeBwAAAFzH6RGnFStWaOHChWrevLn8/PxUpUoVde7cWWFhYZo4caJ69uzpjjqLtKsZbWLpcQAAAMB1nB5xOn/+vCIjIyVJpUqV0okTJyRJDRo00ObNm11bHSQ5P9r0r5tqMkUPAAAAcCGng1Pt2rW1b98+SVKjRo305ptv6ujRo5o1a5ZiYljy2tWcHW3y95Me6XydGysCAAAAih6np+o98sgjSkpKkiTFx8erW7du+vDDDxUYGKi5c+e6ur4ib+7aRKfaT+3bhNEmAAAAwMUcDk533nmnHnjgAfXv318Wy+Uv5s2aNdOvv/6qvXv3qnLlyipbtqzbCi2q/vOD48GpVmRx9WpU3o3VAAAAAEWTw1P1Tp8+rZ49e6py5coaO3asDh06JEkKDQ1V06ZNCU1ukJ5p1bFzlxxuv/hf7d1YDQAAAFB0ORycli9frkOHDun+++/XBx98oFq1aqljx4766KOPdOmS41/u4bh31x12uG2NcqEKLOb0JWsAAAAAHODUN+0qVaro+eef16FDh7Rs2TKVL19eQ4YMUUxMjIYPH65Nmza5q84i6YMfDzvc9vmbY91XCAAAAFDEXfUQRceOHfXBBx8oOTlZEydO1Pz589WyZUtX1lakpWda9eupiw619bNIrWsxVRIAAABwF6dX1furxMREzZ07V3PnztXZs2cVFxfnqrqKPGem6cXVjWQlPQAAAMCNnB5xSktL0wcffKCOHTuqVq1aeu+993T//fcrMTFRCQkJ7qixSPpq+1GH2w5sVc2NlQAAAABweMRp48aNmj17thYsWKC0tDTddtttSkhIUKdOnWzLk8M1sqxGu46mONS2mJ9FN9Qo4+aKAAAAgKLN4eB0ww03qFGjRnrhhRfUv39/lSpVyp11FWk/HvpTWcaxth3rlGOaHgAAAOBmDgenn3/+WU2bNnVnLfivdQdPOtyWaXoAAACA+zl8jROhqeAcPe3YanqB/kzTAwAAAAoCd0z1Qr+fvuBQu0YVw5mmBwAAABQAgpOXybIabT1yxqG25SNC3FsMAAAAAEkEJ6/z46E/lengwhAVShGcAAAAgIJAcPIyziwM0aZGOTdWAgAAACCbQ6vqNWnSxOF7NW3evPmaCirqNiaecqgdC0MAAAAABceh4HTrrbfa/p6WlqYZM2aoXr16atWqlSTpxx9/1K5duzRs2DC3FFlUZFmNtvx62qG2LAwBAAAAFByHglN8fLzt7w888ID+9a9/6YUXXsjR5rfffnNtdUWMM9c3XV+ttHuLAQAAAGDj9DVOn3zyiQYMGJBj+z333KPPPvvMJUUVVVzfBAAAAHgnp4NTSEiI1q5dm2P72rVrFRwc7JKiiiqubwIAAAC8k0NT9f7q0Ucf1dChQ7V582a1aNFCkrRhwwbNnj1bY8aMcXmBRQXXNwEAAADey+ngNGrUKFWvXl2vvfaaPvjgA0lS3bp1NWfOHPXp08flBRYVGxJPcX0TAAAA4KWcDk6S1KdPH0KSi60/5Ng0PYnrmwAAAICCdlU3wD1z5ozeeecdPfPMMzp16vIX/s2bN+vo0aMuLa4oSTp70aF2XN8EAAAAFDynR5y2b9+uuLg4hYeH6/Dhw3rggQdUunRpff755zpy5Ijee+89d9Tp86LCghxqd1OdSK5vAgAAAAqY0yNOI0eO1KBBg7R//367VfR69OihNWvWuLS4ouT42UsOtWtauZSbKwEAAADwd04Hp59++kn//Oc/c2yvUKGCkpOTXVJUUWM10tI9xx1qe/ZihpurAQAAAPB3TgenoKAgpaSk5Nj+yy+/qFw5Fi24GgdTLLqQYXWoLbP0AAAAgILndHDq3bu3xo8fr4yMyyMfFotFR44c0dNPP6077rjD5QUWBWfTHW/bqnpZ9xUCAAAAIFdOB6d///vfSk1NVWRkpC5evKgOHTqoZs2aKlmypF588UV31OjzzjkYnEIC/FhRDwAAAPAAp1fVCw8P17Jly/TDDz9o+/btSk1NVdOmTRUXF+eO+oqE85mOzb9rf105VtQDAAAAPOCqboArSW3btlXbtm1dWUuRdcyxWzipZmQJ9xYCAAAAIFdXFZyWL1+u5cuX6/jx47Ja7Rc1mD17tksKKyqyrEb7zjg2ihQREuDmagAAAADkxungNG7cOI0fP17NmzdXTEyMLBamjl2Ln389rUvGsfewbAnHbpILAAAAwLWcDk6zZs3S3Llzde+997qjniInOSXN4bbR4SFurAQAAABAXpxeVS89PV2tW7d2Ry1F0qnzji2pFxZcTC2qlXZzNQAAAABy43RweuCBB/TRRx+5o5YiKSLUseuWbmtSgRX1AAAAAA9xeqpeWlqa3nrrLX333Xdq2LChAgLsv/hPmTLFZcUVBWcuZDjUrnLpUDdXAgAAACAvTgen7du3q3HjxpKknTt32u1joQjnOTriFBEa6OZKAAAAAOTF6eC0cuVKd9RRZDk64nTmgmPXQgEAAABwPaevcYJr/X7asbvfli7OiBMAAADgKQ6NON1+++2aO3euwsLCdPvtt1+x7eeff+5UAdOnT9fLL7+s5ORkNWrUSNOmTVOLFi3ybH/mzBk9++yz+vzzz3Xq1ClVqVJFU6dOVY8ePZx6Xm+QZTX6anuyQ21ZihwAAADwHIeCU3h4uO36pfDwcJc9+YIFCzRy5EjNmjVLLVu21NSpU9W1a1ft27dPkZGROdqnp6erc+fOioyM1KeffqoKFSro119/VUREhMtqKkgbE0/ptANT9coUD2QpcgAAAMCDHApOc+bMyfXv12rKlCkaMmSIBg8eLOnyzXUXL16s2bNna9SoUTnaz549W6dOndK6detsq/lVrVrVZfUUNEdvftu7cXmWIgcAAAA8yOnFIVwlPT1dmzZt0ujRo23b/Pz8FBcXp/Xr1+d6zKJFi9SqVSsNHz5cCxcuVLly5XT33Xfr6aeflr+/f67HXLp0SZcuXbI9TklJkSRlZGQoI8OxhRnc5UTKBYfaxYQFerxW5C+7j+gr30B/+hb607fQn76F/vQdhbEvnan1qoLTp59+qo8//lhHjhxRerr9am+bN2926BwnT55UVlaWoqKi7LZHRUVp7969uR5z6NAhrVixQv3799eSJUt04MABDRs2TBkZGYqPj8/1mIkTJ2rcuHE5ti9dulShoZ69N9KRExZJuQc+u3b792jJmd3uLwgusWzZMk+XABeiP30L/elb6E/fQn/6jsLUlxcuODaQIV1FcHr99df17LPPatCgQVq4cKEGDx6sgwcP6qefftLw4cOdPZ1TrFarIiMj9dZbb8nf31/NmjXT0aNH9fLLL+cZnEaPHq2RI0faHqekpKhSpUrq0qWLwsLC3FpvfiIO/qkPDmzKt13nti3UukaZAqgI1yIjI0PLli1T586dc9wYGoUP/elb6E/fQn/6FvrTdxTGvsyejeYIp4PTjBkz9NZbb6lfv36aO3eunnrqKVWvXl1jx47VqVOnHD5P2bJl5e/vr2PHjtltP3bsmKKjo3M9JiYmRgEBAXbT8urWravk5GSlp6crMDDnkt1BQUEKCgrKsT0gIMDjHVrM37G3v5h/MY/XCsd5w2cLrkN/+hb607fQn76F/vQdhakvnanT6fs4HTlyRK1bt5YkhYSE6Ny5c5Kke++9V/PmzXP4PIGBgWrWrJmWL19u22a1WrV8+XK1atUq12PatGmjAwcOyGq12rb98ssviomJyTU0ebuT5y/l38iJdgAAAADcw+ngFB0dbRtZqly5sn788UdJUmJioowxTp1r5MiRevvtt/Xuu+9qz549Gjp0qM6fP29bZW/AgAF2i0cMHTpUp06d0iOPPKJffvlFixcv1oQJE9w+RdBdypbIORJ2Le0AAAAAuIfTU/U6duyoRYsWqUmTJho8eLAee+wxffrpp/r555/zvTnu3/Xt21cnTpzQ2LFjlZycrMaNGyshIcG2YMSRI0fk5/e/bFepUiV9++23euyxx9SwYUNVqFBBjzzyiJ5++mlnX4Z3cDRnOpdHAQAAALiY08Hprbfesk2VGz58uMqUKaN169apd+/e+uc//+l0ASNGjNCIESNy3bdq1aoc21q1amUb5Srsjqc6NgXP0XYAAAAA3MPp4OTn52c3CnTXXXfprrvucmlRRcUpBwORo+0AAAAAuIdDwWn79u0On7Bhw4ZXXUxR8/tpx9aNL1288C18AQAAAPgSh4JT48aNZbFY8l38wWKxKCsryyWF+bosq9HCbX841DY6PMTN1QAAAAC4EoeCU2JiorvrKHI2Jp7SqfMZ+bYrUzxQLaqVLoCKAAAAAOTFoeBUpUoVd9dR5Bw/l+ZQu1sal5e/n8XN1QAAAAC4EqcXh5Ckffv2adq0adqzZ48kqW7dunr44YdVu3Ztlxbnyxy9N1OnulFurgQAAABAfpy+Ae5nn32m2NhYbdq0SY0aNVKjRo20efNmxcbG6rPPPnNHjb6JezgBAAAAhYbTI05PPfWURo8erfHjx9ttj4+P11NPPaU77rjDZcX5spPnHVti3NF2AAAAANzH6RGnpKQkDRgwIMf2e+65R0lJSS4pqiiILBns0nYAAAAA3Mfp4HTjjTfq+++/z7H9hx9+ULt27VxSVFHQrEop5bfmg5/lcjsAAAAAnuX0VL3evXvr6aef1qZNm3TDDTdIkn788Ud98sknGjdunBYtWmTXFrnb9OtpWfO5fslqLrdrVaNMwRQFAAAAIFdOB6dhw4ZJkmbMmKEZM2bkuk/iZrj5cXQ5ckfbAQAAAHAfp4OT1Wp1Rx1FjqPLkTvaDgAAAID7OH2N05VcuHDBlafzbSxHDgAAABQaTgenTp066ejRozm2b9iwQY0bN3ZFTUUCy5EDAAAAhYfTwSk4OFgNGzbUggULJF2euvf888+rXbt26tGjh8sL9FWHT553qB3LkQMAAACe5/Q1TosXL9b06dN13333aeHChTp8+LB+/fVXff311+rSpYs7avQ5WVajeRuP5NsuJjxYLaqVLoCKAAAAAFyJ08FJkoYPH67ff/9dkydPVrFixbRq1Sq1bt3a1bX5rI2Jp5Sckv8UvLuuryz//G72BAAAAMDtnJ6qd/r0ad1xxx2aOXOm3nzzTfXp00ddunTJsTQ58uboEuNVy4a6uRIAAAAAjnB6xCk2NlbVqlXTli1bVK1aNQ0ZMkQLFizQsGHDtHjxYi1evNgddfoUR69b4vomAAAAwDs4PeL00EMPac2aNapWrZptW9++fbVt2zalp6e7tDhf1axKKeU3A8/PcrkdAAAAAM9zOjiNGTNGfn45D6tYsaKWLVvmkqJ83aZfT8uaz/2ZrOZyOwAAAACe53Bweumll3Tx4kXb47Vr1+rSpf8tcHDu3DkNGzbMtdX5KEevcXK0HQAAAAD3cjg4jR49WufOnbM97t69u92NcC9cuKA333zTtdX5KK5xAgAAAAoXh4OTMeaKj+E4rnECAAAAChenr3HCteMaJwAAAKBwITh5ANc4AQAAAIWLU/dxeuedd1SiRAlJUmZmpubOnauyZctKkt31T7gyrnECAAAACheHg1PlypX19ttv2x5HR0fr/fffz9EG+WtRrbQiQgN05kJGnm1KhQaoRbXSBVgVAAAAgLw4HJwOHz7sxjLwdyy9AQAAAHgPrnHygI2Jp6442iRJZy5kaGPiqQKqCAAAAMCVEJw8gMUhAAAAgMKF4OQBLA4BAAAAFC4EJw9oUa20YsKDldc9cC2SYsKDWRwCAAAA8BIEJw/w97Movle9XPdlh6n4XvXk75dXtAIAAABQkK4qOB08eFDPPfec+vXrp+PHj0uSvvnmG+3atculxfmybrExmnlPU4UF2y9sGB0erJn3NFW32BgPVQYAAADg75wOTqtXr1aDBg20YcMGff7550pNTZUkbdu2TfHx8S4v0Jd1i43RiJuqS5IaVwrXvCE36IenOxKaAAAAAC/jdHAaNWqU/u///k/Lli1TYGCgbXvHjh31448/urS4ouHydLxKpULUqkYZpucBAAAAXsjp4LRjxw7ddtttObZHRkbq5MmTLimqKDHm8q1u/SwEJgAAAMBbOR2cIiIilJSUlGP7li1bVKFCBZcUVZRk2YKThwsBAAAAkCeng9Ndd92lp59+WsnJybJYLLJarVq7dq2eeOIJDRgwwB01+jSr9fJ//UhOAAAAgNdyOjhNmDBBderUUaVKlZSamqp69eqpffv2at26tZ577jl31OjTmKoHAAAAeL9i+TexFxgYqLfffltjxozRzp07lZqaqiZNmqhWrVruqM/nWS/nJqbqAQAAAF7M6eD0ww8/qG3btqpcubIqV67sjpqKFOt/R5wsjDgBAAAAXsvpqXodO3ZUtWrV9Mwzz2j37t3uqKlIMYw4AQAAAF7P6eD0xx9/6PHHH9fq1asVGxurxo0b6+WXX9bvv//ujvp8XhbXOAEAAABez+ngVLZsWY0YMUJr167VwYMH9Y9//EPvvvuuqlatqo4dO7qjRp+VZTX67fQFSdKxlEvKyr7gCQAAAIBXcTo4/VW1atU0atQoTZo0SQ0aNNDq1atdVZfPS9iZpLaTV2jRtmRJ0rI9x9V28gol7Mx5jywAAAAAnnXVwWnt2rUaNmyYYmJidPfddys2NlaLFy92ZW0+K2FnkoZ+sFlJZ9PstiefTdPQDzYTngAAAAAv4/SqeqNHj9b8+fP1xx9/qHPnznrttdd0yy23KDQ01B31+Zwsq9G4r3Yrt0l5RpJF0rivdqtzvWj5s2IEAAAA4BWcDk5r1qzRk08+qT59+qhs2bLuqMmnbUw8lWOk6a+MpKSzadqYeEqtapQpuMIAAAAA5Mnp4LR27Vp31FFkHD+Xd2i6mnYAAAAA3M+h4LRo0SJ1795dAQEBWrRo0RXb9u7d2yWF+arIksEubQcAAADA/RwKTrfeequSk5MVGRmpW2+9Nc92FotFWVlZrqrNJ7WoVlox4cFKPpuW63VOFknR4cFqUa10QZcGAAAAIA8OrapntVoVGRlp+3tefwhN+fP3syi+Vz1Jl0PSX2U/ju9Vj4UhAAAAAC/i9HLk7733ni5dupRje3p6ut577z2XFOXrusXGaOY9TRUdbj8dLzo8WDPvaapusTEeqgwAAABAbpwOToMHD9bZs2dzbD937pwGDx7skqKKgm6xMfrh6Y666brLKxPe0bS8fni6I6EJAAAA8EJOBydjjCyWnNPIfv/9d4WHh7ukqKLC38+iciWDJElVSocyPQ8AAADwUg4vR96kSRNZLBZZLBZ16tRJxYr979CsrCwlJiaqW7dubinSl2WZy0tE+OUSRgEAAAB4B4eDU/Zqelu3blXXrl1VokQJ277AwEBVrVpVd9xxh8sL9HXW/y6t5+f02B8AAACAguJwcIqPj5ckVa1aVX379lVwMPcZcgVjZcQJAAAA8HYOB6dsAwcOdEcdRZZtxIngBAAAAHgtp4NTVlaWXn31VX388cc6cuSI0tPT7fafOnXKZcUVBdb/XuNEbgIAAAC8l9NX1owbN05TpkxR3759dfbsWY0cOVK33367/Pz89Pzzz7uhRN9mGHECAAAAvJ7TwenDDz/U22+/rccff1zFihVTv3799M4772js2LH68ccf3VGjT/vfqnoeLgQAAABAnpwOTsnJyWrQoIEkqUSJErab4d58881avHixa6srAqwsRw4AAAB4PaeDU8WKFZWUlCRJqlGjhpYuXSpJ+umnnxQUFOTa6ooApuoBAAAA3s/p4HTbbbdp+fLlkqSHH35YY8aMUa1atTRgwADdd999Li/Q11mZqgcAAAB4PadX1Zs0aZLt73379lXlypW1fv161apVS7169XJpcUXB/1bVIzkBAAAA3srp4PR3rVq1UqtWrVxRS5H0v/s4ebYOAAAAAHlzKDgtWrTI4RP27t37qospiqxWFocAAAAAvJ1DwenWW2916GQWi0VZWVnXUk+RYxtxYsgJAAAA8FoOBSer1eruOoosw+IQAAAAgNdzelU9uBb3cQIAAAC8n9OLQ4wfP/6K+8eOHXvVxRRFLA4BAAAAeD+ng9MXX3xh9zgjI0OJiYkqVqyYatSoQXByEsuRAwAAAN7P6eC0ZcuWHNtSUlI0aNAg3XbbbS4pqihhxAkAAADwfi65xiksLEzjxo3TmDFjXHG6IoVrnAAAAADv57LFIc6ePauzZ8+66nRFhi04MeQEAAAAeC2np+q9/vrrdo+NMUpKStL777+v7t27u6ywosIwVQ8AAADwek4Hp1dffdXusZ+fn8qVK6eBAwdq9OjRLiusKMiyGp1Ly5Ak/XIsVR3rGvmToAAAAACv43RwSkxMdEcdRU7CziSN+2q3ks6mSZJeXrpfH2z4TfG96qlbbIyHqwMAAADwV9wA1wMSdiZp6AebbaEpW/LZNA39YLMSdiZ5qDIAAAAAuXF6xCktLU3Tpk3TypUrdfz4cVmtVrv9mzdvdllxvijLajTuq90yuewzkiySxn21W53rRTNtDwAAAPASTgen+++/X0uXLtWdd96pFi1acONWJ21MPJVjpOmvjKSks2namHhKrWqUKbjCAAAAAOTJ6eD09ddfa8mSJWrTpo076vF5x8/lHZquph0AAAAA93P6GqcKFSqoZMmS7qilSIgsGezSdgAAAADcz+ng9O9//1tPP/20fv31V3fU4/NaVCutmPBg5TXB0SIpJjxYLaqVLsiyAAAAAFyB08GpefPmSktLU/Xq1VWyZEmVLl3a7g+uzN/Povhe9SQpR3jKfhzfqx4LQwAAAABexOlrnPr166ejR49qwoQJioqKcsniENOnT9fLL7+s5ORkNWrUSNOmTVOLFi3yPW7+/Pnq16+fbrnlFn355ZfXXEdB6RYbo5n3NLW7j5MkRYcHcx8nAAAAwAs5HZzWrVun9evXq1GjRi4pYMGCBRo5cqRmzZqlli1baurUqeratav27dunyMjIPI87fPiwnnjiCbVr184ldRS0brEx6lwvWi1fXKaT5zP0/M11dG/r6ow0AQAAAF7I6al6derU0cWLF11WwJQpUzRkyBANHjxY9erV06xZsxQaGqrZs2fneUxWVpb69++vcePGqXr16i6rpaD5+1kUFOAvSWpQIZzQBAAAAHgpp0ecJk2apMcff1wvvviiGjRooICAALv9YWFhDp8rPT1dmzZt0ujRo23b/Pz8FBcXp/Xr1+d53Pjx4xUZGan7779f33///RWf49KlS7p06ZLtcUpKiiQpIyNDGRkZDtfqLlnWy7fCzcrK9Ip6cPWy+49+9A30p2+hP30L/elb6E/fURj70planQ5O3bp1kyR16tTJbrsxRhaLRVlZWQ6f6+TJk8rKylJUVJTd9qioKO3duzfXY3744Qf95z//0datWx16jokTJ2rcuHE5ti9dulShoaEO1+ouaWn+kizauGGDknZ5uhq4wrJlyzxdAlyI/vQt9KdvoT99C/3pOwpTX164cMHhtk4Hp5UrVzp7iMucO3dO9957r95++22VLVvWoWNGjx6tkSNH2h6npKSoUqVK6tKli1OjY+7y4s5VUnq6brjhBjWqzKqEhVlGRoaWLVumzp075xiJReFDf/oW+tO30J++hf70HYWxL7NnoznC6eDUoUMHZw/JU9myZeXv769jx47ZbT927Jiio6NztD948KAOHz6sXr162bZZrVZJUrFixbRv3z7VqFHD7pigoCAFBQXlOFdAQICXdOjl65oCAop5ST24Vt7z2YIr0J++hf70LfSnb6E/fUdh6ktn6nQ6OK1Zs+aK+9u3b+/wuQIDA9WsWTMtX75ct956q6TLQWj58uUaMWJEjvZ16tTRjh077LY999xzOnfunF577TVVqlTJ4ef2FsZcvsbJzwXLugMAAABwD6eD04033phj21/v5eTMNU6SNHLkSA0cOFDNmzdXixYtNHXqVJ0/f16DBw+WJA0YMEAVKlTQxIkTFRwcrNjYWLvjIyIiJCnH9sLiv2tD5LgZLgAAAADv4XRwOn36tN3jjIwMbdmyRWPGjNGLL77odAF9+/bViRMnNHbsWCUnJ6tx48ZKSEiwLRhx5MgR+fk5vWp6oWF0OTkx4AQAAAB4L6eDU3h4eI5tnTt3VmBgoEaOHKlNmzY5XcSIESNynZonSatWrbrisXPnznX6+byJyR5xIjkBAAAAXstlQzlRUVHat2+fq05XZBim6gEAAABez+kRp+3bt9s9NsYoKSlJkyZNUuPGjV1VV5GRPVWPxSEAAAAA7+V0cGrcuLEsFottNbhsN9xwg2bPnu2ywooK2+IQ5CYAAADAazkdnBITE+0e+/n5qVy5cgoODnZZUUWJITgBAAAAXs/p4FSlShV31FFk/W9VPZITAAAA4K0cXhxixYoVqlevnlJSUnLsO3v2rOrXr6/vv//epcUVBSwOAQAAAHg/h4PT1KlTNWTIEIWFheXYFx4ern/+85+aMmWKS4srCrKvFWPACQAAAPBeDgenbdu2qVu3bnnu79Kly1Xdw6moy14cglX1AAAAAO/lcHA6duyYAgIC8txfrFgxnThxwiVFFSXZaxMSmwAAAADv5XBwqlChgnbu3Jnn/u3btysmJsYlRRUl/5uqR3QCAAAAvJXDwalHjx4aM2aM0tLScuy7ePGi4uPjdfPNN7u0uKKA5cgBAAAA7+fwcuTPPfecPv/8c1133XUaMWKEateuLUnau3evpk+frqysLD377LNuK9RXMVUPAAAA8H4OB6eoqCitW7dOQ4cO1ejRo+2mmHXt2lXTp09XVFSU2wr1Vdb/vo8sDgEAAAB4L6dugFulShUtWbJEp0+f1oEDB2SMUa1atVSqVCl31efzmKoHAAAAeD+nglO2UqVK6frrr3d1LUVO9qidxOIQAAAAgDdzeHEIuN5fchPXOAEAAABejODkQX/JTUzVAwAAALwYwcmDrH8ZcmJxCAAAAMB7EZw8iKl6AAAAQOFAcPKgTKvV9vdNR04ry2qu0BoAAACApxCcPCRhZ5I6vrLK9vjBD7aq7eQVStiZ5LmiAAAAAOSK4OQBCTuTNPSDzUpOuWS3PflsmoZ+sJnwBAAAAHgZglMBy7Iajftqt3KblJe9bdxXu5m2BwAAAHgRglMB25h4Skln0/LcbyQlnU3TxsRTBVcUAAAAgCsiOBWw4+fyDk1X0w4AAACA+xGcClhkyWCXtgMAAADgfgSnAtaiWmnFhAfned8mi6SY8GC1qFa6IMsCAAAAcAUEpwLm72dRfK96knLe9Db7cXyvevL345a4AAAAgLcgOHlAt9gYzbynqcqVDLLbHh0erJn3NFW32BgPVQYAAAAgN8U8XUBR1S02Rk0rl1KLCcslSe8PbqbWtaIYaQIAAAC8ECNOHmSx/C8k3VC9DKEJAAAA8FIEJw8y/73lrSXX2+ECAAAA8BYEJ08iLwEAAACFAsHJg6z/DU4WZugBAAAAXo3g5EH/m6oHAAAAwJsRnDzINuLk2TIAAAAA5IPg5EHGMOIEAAAAFAYEJw8y2YtDkJwAAAAAr0Zw8iDDVD0AAACgUCA4eRCLQwAAAACFA8HJg6xM1QMAAAAKBYKTB2UvDkEnAAAAAN6N7+weZPJvAgAAAMALEJw8yLYcOVP1AAAAAK9GcPIgVtUDAAAACgeCkwcxVQ8AAAAoHAhOHmRlqh4AAABQKBCcPIipegAAAEDhQHDyINuIk4frAAAAAHBlBCcPYsQJAAAAKBwITt6A5AQAAAB4NYKTBzFVDwAAACgcCE4exFQ9AAAAoHAgOHkQy5EDAAAAhQPByYOyb4BLbgIAAAC8G8HJg7Kn6gEAAADwbgQnDzJM1QMAAAAKBYKTBzFVDwAAACgcCE4eZLWyHDkAAABQGBCcPMg24kRyAgAAALwawcmDsrIuR6eLmdKGxFPKsrJaBAAAAOCNCE4ekrAzSQ/P3yJJSsmw6J7ZP6vt5BVK2Jnk4coAAAAA/B3ByQMSdiZp6Aebdep8ut325LNpGvrBZsITAAAA4GUITgUsy2o07qvdym1SXva2cV/tZtoeAAAA4EUITgVsY+IpJZ1Ny3O/kZR0Nk0bE08VXFEAAAAArojgVMCOn8s7NF1NOwAAAADuR3AqYJElg13aDgAAAID7EZwKWItqpRUTHpznTW8tkmLCg9WiWumCLAsAAADAFRCcCpi/n0Xxverlui87TMX3qid/P+6KCwAAAHgLgpMHdIuN0cx7mqpUaIDd9ujwYM28p6m6xcZ4qDIAAAAAuSnm6QKKqm6xMbLIon9+sEllg4ym9r9erWpGMtIEAAAAeCFGnDzpvxmpRIDUslppQhMAAADgpQhOHmT+e49bC3kJAAAA8GoEJ48yni4AAAAAgAMITh5k/W9uohMAAAAA78Z3dg8yDDgBAAAAhQLByYOs/01OXOMEAAAAeDeCkwdlDzhZuNYJAAAA8GoEJw8yzNUDAAAACgWCkwexHDkAAABQOBCcPMj8d4oeuQkAAADwbgQnD7JaL/+X4AQAAAB4N4KTB9kWhyA5AQAAAF6N4ORBLA4BAAAAFA4EJw+yLQ7h2TIAAAAA5IPg5EG2xSFITgAAAIBXIzh5kJURJwAAAKBQIDh5EJc4AQAAAIUDwcmDuI8TAAAAUDh4RXCaPn26qlatquDgYLVs2VIbN27Ms+3bb7+tdu3aqVSpUipVqpTi4uKu2N6b2abqkZwAAAAAr+bx4LRgwQKNHDlS8fHx2rx5sxo1aqSuXbvq+PHjubZftWqV+vXrp5UrV2r9+vWqVKmSunTpoqNHjxZw5S5gGHECAAAACgOPB6cpU6ZoyJAhGjx4sOrVq6dZs2YpNDRUs2fPzrX9hx9+qGHDhqlx48aqU6eO3nnnHVmtVi1fvryAK792thvgerQKAAAAAPkp5sknT09P16ZNmzR69GjbNj8/P8XFxWn9+vUOnePChQvKyMhQ6dKlc91/6dIlXbp0yfY4JSVFkpSRkaGMjIxrqP7aZWRmXf6LRR6vBdcuuw/pS99Af/oW+tO30J++hf70HYWxL52p1aPB6eTJk8rKylJUVJTd9qioKO3du9ehczz99NMqX7684uLict0/ceJEjRs3Lsf2pUuXKjQ01PmiXWhXkkWSvyySli1b5tFa4Dr0pW+hP30L/elb6E/fQn/6jsLUlxcuXHC4rUeD07WaNGmS5s+fr1WrVik4ODjXNqNHj9bIkSNtj1NSUmzXRYWFhRVUqbk6tu5X6fA+WSR17txZAQEBHq0H1yYjI0PLli2jL30E/elb6E/fQn/6FvrTdxTGvsyejeYIjwansmXLyt/fX8eOHbPbfuzYMUVHR1/x2FdeeUWTJk3Sd999p4YNG+bZLigoSEFBQTm2BwQEeLxD/fwuX2JmsXhHPXAN+tK30J++hf70LfSnb6E/fUdh6ktn6vTo4hCBgYFq1qyZ3cIO2Qs9tGrVKs/jXnrpJb3wwgtKSEhQ8+bNC6JUAAAAAEWYx6fqjRw5UgMHDlTz5s3VokULTZ06VefPn9fgwYMlSQMGDFCFChU0ceJESdLkyZM1duxYffTRR6pataqSk5MlSSVKlFCJEiU89jquhpXlyAEAAIBCwePBqW/fvjpx4oTGjh2r5ORkNW7cWAkJCbYFI44cOWKb0iZJM2fOVHp6uu68806788THx+v5558vyNKvmeEGuAAAAECh4PHgJEkjRozQiBEjct23atUqu8eHDx92f0EFxJodnDxbBgAAAIB8ePwGuEWZsd0CFwAAAIA3Izh5kGHECQAAACgUCE4eZLIXhyA5AQAAAF6N4ORBjDgBAAAAhQPByYNYHAIAAAAoHAhOHmRbHILkBAAAAHg1gpMHMVUPAAAAKBwITh5kWxzCw3UAAAAAuDKCkwdl38WJVfUAAAAA70Zw8qCs/64OceKitCHxlO0xAAAAAO9CcPKQhJ1Jenf9YUnS3rN+umf2z2o7eYUSdiZ5tjAAAAAAORCcPCBhZ5KGfrBZ5y9l2W1PPpumoR9sJjwBAAAAXobgVMCyrEbjvtqt3CblZW8b99Vupu0BAAAAXoTgVMA2Jp5S0tm0PPcbSUln07Qx8VTBFQUAAADgighOBez4ubxD09W0AwAAAOB+BKcCFlky2KXtAAAAALgfwamAtahWWjHhwXne9NYiKSY8WC2qlS7IsgAAAABcAcGpgPn7WRTfq54k5QhP2Y/je9WTvx93xQUAAAC8BcHJA7rFxmjmPU0VHW4/HS86PFgz72mqbrExHqoMAAAAQG6KebqAoqpbbIw614vW+gPHtfT7DerSrqVa1YxkpAkAAADwQgQnD/L3s6hltdL6c49Ry2qlCU0AAACAl2KqHgAAAADkg+AEAAAAAPkgOAEAAABAPghOAAAAAJAPghMAAAAA5IPgBAAAAAD5IDgBAAAAQD4ITgAAAACQD4ITAAAAAOSD4AQAAAAA+SA4AQAAAEA+CE4AAAAAkA+CEwAAAADko5inCyhoxhhJUkpKiocruSwjI0MXLlxQSkqKAgICPF0OrgF96VvoT99Cf/oW+tO30J++ozD2ZXYmyM4IV1LkgtO5c+ckSZUqVfJwJQAAAAC8wblz5xQeHn7FNhbjSLzyIVarVX/88YdKliwpi8Xi6XKUkpKiSpUq6bffflNYWJiny8E1oC99C/3pW+hP30J/+hb603cUxr40xujcuXMqX768/PyufBVTkRtx8vPzU8WKFT1dRg5hYWGF5gOGK6MvfQv96VvoT99Cf/oW+tN3FLa+zG+kKRuLQwAAAABAPghOAAAAAJAPgpOHBQUFKT4+XkFBQZ4uBdeIvvQt9KdvoT99C/3pW+hP3+HrfVnkFocAAAAAAGcx4gQAAAAA+SA4AQAAAEA+CE4AAAAAkA+CEwAAAADkg+DkQdOnT1fVqlUVHBysli1bauPGjZ4uCX/z/PPPy2Kx2P2pU6eObX9aWpqGDx+uMmXKqESJErrjjjt07Ngxu3McOXJEPXv2VGhoqCIjI/Xkk08qMzOzoF9KkbRmzRr16tVL5cuXl8Vi0Zdffmm33xijsWPHKiYmRiEhIYqLi9P+/fvt2pw6dUr9+/dXWFiYIiIidP/99ys1NdWuzfbt29WuXTsFBwerUqVKeumll9z90oqk/Ppz0KBBOX5eu3XrZteG/vQOEydO1PXXX6+SJUsqMjJSt956q/bt22fXxlX/vq5atUpNmzZVUFCQatasqblz57r75RU5jvTnjTfemOPn86GHHrJrQ396h5kzZ6phw4a2m9i2atVK33zzjW1/kf7ZNPCI+fPnm8DAQDN79myza9cuM2TIEBMREWGOHTvm6dLwF/Hx8aZ+/fomKSnJ9ufEiRO2/Q899JCpVKmSWb58ufn555/NDTfcYFq3bm3bn5mZaWJjY01cXJzZsmWLWbJkiSlbtqwZPXq0J15OkbNkyRLz7LPPms8//9xIMl988YXd/kmTJpnw8HDz5Zdfmm3btpnevXubatWqmYsXL9radOvWzTRq1Mj8+OOP5vvvvzc1a9Y0/fr1s+0/e/asiYqKMv379zc7d+408+bNMyEhIebNN98sqJdZZOTXnwMHDjTdunWz+3k9deqUXRv60zt07drVzJkzx+zcudNs3brV9OjRw1SuXNmkpqba2rji39dDhw6Z0NBQM3LkSLN7924zbdo04+/vbxISEgr09fo6R/qzQ4cOZsiQIXY/n2fPnrXtpz+9x6JFi8zixYvNL7/8Yvbt22eeeeYZExAQYHbu3GmMKdo/mwQnD2nRooUZPny47XFWVpYpX768mThxogerwt/Fx8ebRo0a5brvzJkzJiAgwHzyySe2bXv27DGSzPr1640xl7/o+fn5meTkZFubmTNnmrCwMHPp0iW31g57f/+ibbVaTXR0tHn55Zdt286cOWOCgoLMvHnzjDHG7N6920gyP/30k63NN998YywWizl69KgxxpgZM2aYUqVK2fXn008/bWrXru3mV1S05RWcbrnlljyPoT+91/Hjx40ks3r1amOM6/59feqpp0z9+vXtnqtv376ma9eu7n5JRdrf+9OYy8HpkUceyfMY+tO7lSpVyrzzzjtF/meTqXoekJ6erk2bNikuLs62zc/PT3FxcVq/fr0HK0Nu9u/fr/Lly6t69erq37+/jhw5IknatGmTMjIy7PqxTp06qly5sq0f169frwYNGigqKsrWpmvXrkpJSdGuXbsK9oXATmJiopKTk+36Lzw8XC1btrTrv4iICDVv3tzWJi4uTn5+ftqwYYOtTfv27RUYGGhr07VrV+3bt0+nT58uoFeDbKtWrVJkZKRq166toUOH6s8//7Ttoz+919mzZyVJpUuXluS6f1/Xr19vd47sNvy/1r3+3p/ZPvzwQ5UtW1axsbEaPXq0Lly4YNtHf3qnrKwszZ8/X+fPn1erVq2K/M9mMU8XUBSdPHlSWVlZdh8oSYqKitLevXs9VBVy07JlS82dO1e1a9dWUlKSxo0bp3bt2mnnzp1KTk5WYGCgIiIi7I6JiopScnKyJCk5OTnXfs7eB8/Jfv9z65+/9l9kZKTd/mLFiql06dJ2bapVq5bjHNn7SpUq5Zb6kVO3bt10++23q1q1ajp48KCeeeYZde/eXevXr5e/vz/96aWsVqseffRRtWnTRrGxsZLksn9f82qTkpKiixcvKiQkxB0vqUjLrT8l6e6771aVKlVUvnx5bd++XU8//bT27dunzz//XBL96W127NihVq1aKS0tTSVKlNAXX3yhevXqaevWrUX6Z5PgBFxB9+7dbX9v2LChWrZsqSpVqujjjz/22h9qoKi66667bH9v0KCBGjZsqBo1amjVqlXq1KmTByvDlQwfPlw7d+7UDz/84OlS4AJ59eeDDz5o+3uDBg0UExOjTp066eDBg6pRo0ZBl4l81K5dW1u3btXZs2f16aefauDAgVq9erWny/I4pup5QNmyZeXv759jBZJjx44pOjraQ1XBEREREbruuut04MABRUdHKz09XWfOnLFr89d+jI6OzrWfs/fBc7Lf/yv9HEZHR+v48eN2+zMzM3Xq1Cn6uBCoXr26ypYtqwMHDkiiP73RiBEj9PXXX2vlypWqWLGibbur/n3Nq01YWBi//HKDvPozNy1btpQku59P+tN7BAYGqmbNmmrWrJkmTpyoRo0a6bXXXivyP5sEJw8IDAxUs2bNtHz5cts2q9Wq5cuXq1WrVh6sDPlJTU3VwYMHFRMTo2bNmikgIMCuH/ft26cjR47Y+rFVq1basWOH3Ze1ZcuWKSwsTPXq1Svw+vE/1apVU3R0tF3/paSkaMOGDXb9d+bMGW3atMnWZsWKFbJarbb/6bdq1Upr1qxRRkaGrc2yZctUu3ZtpnV52O+//64///xTMTExkuhPb2KM0YgRI/TFF19oxYoVOaZHuurf11atWtmdI7sN/691rfz6Mzdbt26VJLufT/rTe1mtVl26dImfTU+vTlFUzZ8/3wQFBZm5c+ea3bt3mwcffNBERETYrUACz3v88cfNqlWrTGJiolm7dq2Ji4szZcuWNcePHzfGXF6Ss3LlymbFihXm559/Nq1atTKtWrWyHZ+9JGeXLl3M1q1bTUJCgilXrhzLkReQc+fOmS1btpgtW7YYSWbKlClmy5Yt5tdffzXGXF6OPCIiwixcuNBs377d3HLLLbkuR96kSROzYcMG88MPP5hatWrZLV995swZExUVZe69916zc+dOM3/+fBMaGsry1W5wpf48d+6ceeKJJ8z69etNYmKi+e6770zTpk1NrVq1TFpamu0c9Kd3GDp0qAkPDzerVq2yW576woULtjau+Pc1e8njJ5980uzZs8dMnz69UCx5XNjk158HDhww48ePNz///LNJTEw0CxcuNNWrVzft27e3nYP+9B6jRo0yq1evNomJiWb79u1m1KhRxmKxmKVLlxpjivbPJsHJg6ZNm2YqV65sAgMDTYsWLcyPP/7o6ZLwN3379jUxMTEmMDDQVKhQwfTt29ccOHDAtv/ixYtm2LBhplSpUiY0NNTcdtttJikpye4chw8fNt27dzchISGmbNmy5vHHHzcZGRkF/VKKpJUrVxpJOf4MHDjQGHN5SfIxY8aYqKgoExQUZDp16mT27dtnd44///zT9OvXz5QoUcKEhYWZwYMHm3Pnztm12bZtm2nbtq0JCgoyFSpUMJMmTSqol1ikXKk/L1y4YLp06WLKlStnAgICTJUqVcyQIUNy/DKK/vQOufWjJDNnzhxbG1f9+7py5UrTuHFjExgYaKpXr273HHCN/PrzyJEjpn379qZ06dImKCjI1KxZ0zz55JN293Eyhv70Fvfdd5+pUqWKCQwMNOXKlTOdOnWyhSZjivbPpsUYYwpufAsAAAAACh+ucQIAAACAfBCcAAAAACAfBCcAAAAAyAfBCQAAAADyQXACAAAAgHwQnAAAAAAgHwQnAAAAAMgHwQkAAAAA8kFwAgA47fDhw7JYLNq6daunS7HZu3evbrjhBgUHB6tx48aeLgcA4GMITgBQCA0aNEgWi0WTJk2y2/7ll1/KYrF4qCrPio+PV/HixbVv3z4tX748z3bJycl6+OGHVb16dQUFBalSpUrq1avXFY8pigYNGqRbb73V02UAgNcgOAFAIRUcHKzJkyfr9OnTni7FZdLT06/62IMHD6pt27aqUqWKypQpk2ubw4cPq1mzZlqxYoVefvll7dixQwkJCbrppps0fPjwq35uAIDvIzgBQCEVFxen6OhoTZw4Mc82zz//fI5pa1OnTlXVqlVtj7NHFiZMmKCoqChFRERo/PjxyszM1JNPPqnSpUurYsWKmjNnTo7z7927V61bt1ZwcLBiY2O1evVqu/07d+5U9+7dVaJECUVFRenee+/VyZMnbftvvPFGjRgxQo8++qjKli2rrl275vo6rFarxo8fr4oVKyooKEiNGzdWQkKCbb/FYtGmTZs0fvx4WSwWPf/887meZ9iwYbJYLNq4caPuuOMOXXfddapfv75GjhypH3/80dbuyJEjuuWWW1SiRAmFhYWpT58+OnbsWI73dfbs2apcubJKlCihYcOGKSsrSy+99JKio6MVGRmpF1980e75LRaLZs6cqe7duyskJETVq1fXp59+atdmx44d6tixo0JCQlSmTBk9+OCDSk1NzdFfr7zyimJiYlSmTBkNHz5cGRkZtjaXLl3SE088oQoVKqh48eJq2bKlVq1aZds/d+5cRURE6Ntvv1XdunVVokQJdevWTUlJSbbX9+6772rhwoWyWCyyWCxatWqV0tPTNWLECMXExCg4OFhVqlS54ucPAHwJwQkACil/f39NmDBB06ZN0++//35N51qxYoX++OMPrVmzRlOmTFF8fLxuvvlmlSpVShs2bNBDDz2kf/7znzme58knn9Tjjz+uLVu2qFWrVurVq5f+/PNPSdKZM2fUsWNHNWnSRD///LMSEhJ07Ngx9enTx+4c7777rgIDA7V27VrNmjUr1/pee+01/fvf/9Yrr7yi7du3q2vXrurdu7f2798vSUpKSlL9+vX1+OOPKykpSU888USOc5w6dUoJCQkaPny4ihcvnmN/RESEpMsh7ZZbbtGpU6e0evVqLVu2TIcOHVLfvn3t2h88eFDffPONEhISNG/ePP3nP/9Rz5499fvvv2v16tWaPHmynnvuOW3YsMHuuDFjxuiOO+7Qtm3b1L9/f911113as2ePJOn8+fPq2rWrSpUqpZ9++kmffPKJvvvuO40YMcLuHCtXrtTBgwe1cuVKvfvuu5o7d67mzp1r2z9ixAitX79e8+fP1/bt2/WPf/xD3bp1s71fknThwgW98sorev/997VmzRodOXLE9r498cQT6tOnjy1MJSUlqXXr1nr99de1aNEiffzxx9q3b58+/PBDuxAOAD7NAAAKnYEDB5pbbrnFGGPMDTfcYO677z5jjDFffPGF+es/7fHx8aZRo0Z2x7766qumSpUqdueqUqWKycrKsm2rXbu2adeune1xZmamKV68uJk3b54xxpjExEQjyUyaNMnWJiMjw1SsWNFMnjzZGGPMCy+8YLp06WL33L/99puRZPbt22eMMaZDhw6mSZMm+b7e8uXLmxdffNFu2/XXX2+GDRtme9yoUSMTHx+f5zk2bNhgJJnPP//8is+1dOlS4+/vb44cOWLbtmvXLiPJbNy40Rhz+X0NDQ01KSkptjZdu3Y1VatWzfE+Tpw40fZYknnooYfsnq9ly5Zm6NChxhhj3nrrLVOqVCmTmppq27948WLj5+dnkpOTjTH/66/MzExbm3/84x+mb9++xhhjfv31V+Pv72+OHj1q9zydOnUyo0ePNsYYM2fOHCPJHDhwwLZ/+vTpJioqyvb4r5+xbA8//LDp2LGjsVqteb5/AOCrGHECgEJu8uTJevfdd22jFlejfv368vP73/8SoqKi1KBBA9tjf39/lSlTRsePH7c7rlWrVra/FytWTM2bN7fVsW3bNq1cuVIlSpSw/alTp46ky6M12Zo1a3bF2lJSUvTHH3+oTZs2dtvbtGnj1Gs2xjjUbs+ePapUqZIqVapk21avXj1FRETYPV/VqlVVsmRJ2+OoqCjVq1cvx/t4pfcs+3H2effs2aNGjRrZjYi1adNGVqtV+/bts22rX7++/P39bY9jYmJsz7Njxw5lZWXpuuuus3vvV69ebfe+h4aGqkaNGrmeIy+DBg3S1q1bVbt2bf3rX//S0qVLr9geAHxJMU8XAAC4Nu3bt1fXrl01evRoDRo0yG6fn59fjsDw12thsgUEBNg9tlgsuW6zWq0O15WamqpevXpp8uTJOfbFxMTY/p7btDl3qFWrliwWi/bu3euS87njPbuW585+ntTUVPn7+2vTpk124UqSSpQoccVz5BcumzZtqsTERH3zzTf67rvv1KdPH8XFxeW4TgsAfBEjTgDgAyZNmqSvvvpK69evt9terlw5JScn230hduW9l/66oEJmZqY2bdqkunXrSrr8JXvXrl2qWrWqatasaffHmbAUFham8uXLa+3atXbb165dq3r16jl8ntKlS6tr166aPn26zp8/n2P/mTNnJEl169bVb7/9pt9++822b/fu3Tpz5oxTz5eXv75n2Y+z37O6detq27ZtdvWtXbtWfn5+ql27tkPnb9KkibKysnT8+PEc73t0dLTDdQYGBiorKyvH9rCwMPXt21dvv/22FixYoM8++0ynTp1y+LwAUFgRnADABzRo0ED9+/fX66+/brf9xhtv1IkTJ/TSSy/p4MGDmj59ur755huXPe/06dP1xRdfaO/evRo+fLhOnz6t++67T5I0fPhwnTp1Sv369dNPP/2kgwcP6ttvv9XgwYNz/UJ+JU8++aQmT56sBQsWaN++fRo1apS2bt2qRx55xOl6s7Ky1KJFC3322Wfav3+/9uzZo9dff902hS4uLs72fm7evFkbN27UgAED1KFDBzVv3typ58vNJ598otmzZ+uXX35RfHy8Nm7caFv8oX///goODtbAgQO1c+dOrVy5Ug8//LDuvfdeRUVFOXT+6667Tv3799eAAQP0+eefKzExURs3btTEiRO1ePFih+usWrWqtm/frn379unkyZPKyMjQlClTNG/ePO3du1e//PKLPvnkE0VHR9sW1gAAX0ZwAgAfMX78+BzTwurWrasZM2Zo+vTpatSokTZu3JjrinNXa9KkSZo0aZIaNWqkH374QYsWLVLZsmUlyTZKlJWVpS5duqhBgwZ69NFHFRERYXcdkCP+9a9/aeTIkXr88cfVoEEDJSQkaNGiRapVq5ZT56levbo2b96sm266SY8//rhiY2PVuXNnLV++XDNnzpR0ecrawoULVapUKbVv315xcXGqXr26FixY4NRz5WXcuHGaP3++GjZsqPfee0/z5s2zjWSFhobq22+/1alTp3T99dfrzjvvVKdOnfTGG2849Rxz5szRgAED9Pjjj6t27dq69dZb9dNPP6ly5coOn2PIkCGqXbu2mjdvrnLlymnt2rUqWbKkXnrpJTVv3lzXX3+9Dh8+rCVLljjdnwBQGFmMo1fLAgCAa2KxWPTFF1/o1ltv9XQpAAAn8SsiAAAAAMgHwQkAAAAA8sFy5AAAFBBmxwNA4cWIEwAAAADkg+AEAAAAAPkgOAEAAABAPghOAAAAAJAPghMAAAAA5IPgBAAAAAD5IDgBAAAAQD4ITgAAAACQj/8HZs4VmS8+PEMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pca = PCA().fit(x_train)  # Fit PCA without specifying n_components\n",
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cumulative_variance_ratio, marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by Components')\n",
    "plt.grid(True)\n",
    "\n",
    "# Find the number of components for a desired explained variance, e.g., 0.95\n",
    "desired_variance = 0.95\n",
    "components_for_desired_variance = np.where(cumulative_variance_ratio >= desired_variance)[0][0] + 1\n",
    "print(f\"Number of components to retain {desired_variance*100}% variance: {components_for_desired_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "reduced_cols = IncrementalPCA(n_components = n_components, batch_size = n_components).fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78643, 1015)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "predictor = IsolationForest(n_estimators=200, random_state=42, contamination=0.01).fit_predict(reduced_cols)\n",
    "predictor = np.where(predictor == -1, 2, predictor)  # Temporarily replace -1 with 2 to avoid conflict\n",
    "predictor = np.where(predictor == 1, 0, predictor)  # Replace 1 with 0\n",
    "predictor = np.where(predictor == 2, 1, predictor)  # Finally, replace 2 (originally -1) with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([77856,   787], dtype=int64))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictor,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     78197\n",
      "           1       0.01      0.02      0.02       446\n",
      "\n",
      "    accuracy                           0.98     78643\n",
      "   macro avg       0.50      0.51      0.51     78643\n",
      "weighted avg       0.99      0.98      0.99     78643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(train_sample[target_col], predictor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77421,   776],\n",
       "       [  435,    11]], dtype=int64)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(train_sample[target_col], predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.5073700113849515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc_roc_score = roc_auc_score(train_sample[target_col], predictor)\n",
    "print(\"AUC-ROC Score:\", auc_roc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
